{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1mISXVRx2Td0mxPxl27QqNP_ypRaiEZCA","authorship_tag":"ABX9TyM5FegVhEaSdKqKK7VxiZpB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Installation"],"metadata":{"id":"pKTBSZFCd8g9"}},{"cell_type":"code","source":["%%bash\n","pip install  --upgrade\\\n","    'vllm>=0.8.2' \\\n","    'transformers>=4.50.3' \\\n","    pyzmq \\\n","    unsloth \\\n","    accelerate \\\n","    bitsandbytes \\\n","    openai \\\n","    langchain-text-splitters \\\n","    peft \\\n","    FlagEmbedding \\\n","    datasets \\\n","    faiss-cpu \\\n","    \"flashinfer-python>=0.2.4\"  --extra-index-url https://flashinfer.ai/whl/cu124/torch2.6/\n","git clone https://github.com/ggml-org/llama.cpp.git\n","cd llama.cpp/gguf-py/ && pip install --editable .\n","pip install jupyter-kernel-gateway ipykernel\n","pip install --upgrade --no-deps numpy==1.26.4 pandas==2.2.2"],"metadata":{"id":"cxg_aTF0B-DJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743843348690,"user_tz":-540,"elapsed":195826,"user":{"displayName":"정권환","userId":"03859214150473665717"}},"outputId":"edcb9b7c-580a-4d9a-9855-3953eebbf636"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://flashinfer.ai/whl/cu124/torch2.6/\n","Collecting vllm>=0.8.2\n","  Downloading vllm-0.8.2-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n","Requirement already satisfied: transformers>=4.50.3 in /usr/local/lib/python3.11/dist-packages (4.50.3)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (24.0.1)\n","Collecting pyzmq\n","  Downloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n","Collecting unsloth\n","  Downloading unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.2/46.2 kB 4.8 MB/s eta 0:00:00\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n","Collecting accelerate\n","  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n","Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/dist-packages (0.3.7)\n","Collecting langchain-text-splitters\n","  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n","Collecting peft\n","  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n","Collecting FlagEmbedding\n","  Downloading FlagEmbedding-1.3.4.tar.gz (163 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 16.8 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting datasets\n","  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n","Collecting flashinfer-python>=0.2.4\n","  Downloading https://github.com/flashinfer-ai/flashinfer/releases/download/v0.2.5/flashinfer_python-0.2.5%2Bcu124torch2.6-cp38-abi3-linux_x86_64.whl (544.2 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 544.2/544.2 MB 3.3 MB/s eta 0:00:00\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (5.5.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (0.2.0)\n","Collecting numpy<2.0.0 (from vllm>=0.8.2)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 6.2 MB/s eta 0:00:00\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (4.67.1)\n","Collecting blake3 (from vllm>=0.8.2)\n","  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (9.0.0)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (0.21.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (5.29.4)\n","Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (3.11.15)\n","Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (2.11.1)\n","Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (0.21.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (11.1.0)\n","Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm>=0.8.2)\n","  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n","Collecting tiktoken>=0.6.0 (from vllm>=0.8.2)\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm>=0.8.2)\n","  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n","Collecting llguidance<0.8.0,>=0.7.9 (from vllm>=0.8.2)\n","  Downloading llguidance-0.7.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n","Collecting outlines==0.1.11 (from vllm>=0.8.2)\n","  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n","Collecting lark==1.2.2 (from vllm>=0.8.2)\n","  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n","Collecting xgrammar==0.1.16 (from vllm>=0.8.2)\n","  Downloading xgrammar-0.1.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n","Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (4.13.0)\n","Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (3.18.0)\n","Collecting partial-json-parser (from vllm>=0.8.2)\n","  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n","Collecting msgspec (from vllm>=0.8.2)\n","  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Collecting gguf==0.10.0 (from vllm>=0.8.2)\n","  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (8.6.1)\n","Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm>=0.8.2)\n","  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (6.0.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (0.8.1)\n","Collecting compressed-tensors==0.9.2 (from vllm>=0.8.2)\n","  Downloading compressed_tensors-0.9.2-py3-none-any.whl.metadata (7.0 kB)\n","Collecting depyf==0.18.0 (from vllm>=0.8.2)\n","  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (3.1.1)\n","Collecting watchfiles (from vllm>=0.8.2)\n","  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting python-json-logger (from vllm>=0.8.2)\n","  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (1.14.1)\n","Collecting ninja (from vllm>=0.8.2)\n","  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: numba==0.60.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (0.60.0)\n","Collecting ray>=2.43.0 (from ray[cgraph]>=2.43.0->vllm>=0.8.2)\n","  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (2.6.0+cu124)\n","Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (2.6.0+cu124)\n","Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.8.2) (0.21.0+cu124)\n","Collecting xformers==0.0.29.post2 (from vllm>=0.8.2)\n","  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Collecting astor (from depyf==0.18.0->vllm>=0.8.2)\n","  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n","Collecting dill (from depyf==0.18.0->vllm>=0.8.2)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.60.0->vllm>=0.8.2) (0.43.0)\n","Collecting interegular (from outlines==0.1.11->vllm>=0.8.2)\n","  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm>=0.8.2) (3.1.6)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm>=0.8.2) (1.6.0)\n","Collecting diskcache (from outlines==0.1.11->vllm>=0.8.2)\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm>=0.8.2) (0.36.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm>=0.8.2) (4.23.0)\n","Collecting pycountry (from outlines==0.1.11->vllm>=0.8.2)\n","  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n","Collecting airportsdata (from outlines==0.1.11->vllm>=0.8.2)\n","  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n","Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm>=0.8.2)\n","  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm>=0.8.2) (3.4.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm>=0.8.2) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm>=0.8.2) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm>=0.8.2) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm>=0.8.2) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm>=0.8.2) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm>=0.8.2) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->vllm>=0.8.2) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.3) (0.30.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.3) (24.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.3) (2024.11.6)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.3) (0.5.3)\n","Collecting unsloth_zoo>=2025.3.17 (from unsloth)\n","  Downloading unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\n","Collecting tyro (from unsloth)\n","  Downloading tyro-0.9.18-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n","Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n","  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n","Collecting protobuf (from vllm>=0.8.2)\n","  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n","Collecting hf_transfer (from unsloth)\n","  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.32.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Collecting langchain-core<1.0.0,>=0.3.51 (from langchain-text-splitters)\n","  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (from FlagEmbedding) (3.4.1)\n","Collecting ir-datasets (from FlagEmbedding)\n","  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill (from depyf==0.18.0->vllm>=0.8.2)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec (from torch==2.6.0->vllm>=0.8.2)\n","  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n","Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n","Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n","Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm>=0.8.2) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm>=0.8.2) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm>=0.8.2) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm>=0.8.2) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm>=0.8.2) (6.3.1)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm>=0.8.2) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm>=0.8.2) (1.18.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.3.22)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (9.1.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.33)\n","Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.5.4->vllm>=0.8.2) (4.11.0.86)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm>=0.8.2) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm>=0.8.2) (2.33.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm>=0.8.2) (0.4.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.43.0->ray[cgraph]>=2.43.0->vllm>=0.8.2) (8.1.8)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.43.0->ray[cgraph]>=2.43.0->vllm>=0.8.2) (1.1.0)\n","Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]>=2.43.0->vllm>=0.8.2) (13.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm>=0.8.2) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm>=0.8.2) (2.3.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (13.9.4)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2025.3.17->unsloth)\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm>=0.8.2) (3.21.0)\n","Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->FlagEmbedding) (4.13.3)\n","Collecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding)\n","  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->FlagEmbedding) (5.3.1)\n","Collecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding)\n","  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n","Collecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding)\n","  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding)\n","  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n","Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding)\n","  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding)\n","  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n","Collecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding)\n","  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Collecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding)\n","  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->FlagEmbedding) (1.6.1)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\n","Collecting shtab>=1.5.6 (from tyro->unsloth)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding) (2.6)\n","Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2) (0.15.2)\n","Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading rich_toolkit-0.14.1-py3-none-any.whl.metadata (999 bytes)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm>=0.8.2) (3.0.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (3.0.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm>=0.8.2) (2024.10.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm>=0.8.2) (0.24.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (3.10.16)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.23.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.18.0)\n","Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding)\n","  Downloading cbor-1.0.0.tar.gz (20 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2)\n","  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2) (15.0.1)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.43.0->vllm>=0.8.2) (0.8.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (3.6.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.8.2) (1.5.4)\n","Downloading vllm-0.8.2-cp38-abi3-manylinux1_x86_64.whl (293.6 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 293.6/293.6 MB 4.3 MB/s eta 0:00:00\n","Downloading compressed_tensors-0.9.2-py3-none-any.whl (97 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 10.8 MB/s eta 0:00:00\n","Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n","Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.6/71.6 kB 8.4 MB/s eta 0:00:00\n","Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 111.0/111.0 kB 13.2 MB/s eta 0:00:00\n","Downloading outlines-0.1.11-py3-none-any.whl (87 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.6/87.6 kB 9.8 MB/s eta 0:00:00\n","Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl (44.3 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.3/44.3 MB 51.4 MB/s eta 0:00:00\n","Downloading xgrammar-0.1.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 101.8 MB/s eta 0:00:00\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 2.8 MB/s eta 0:00:00\n","Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 123.4 MB/s eta 0:00:00\n","Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 91.7 MB/s eta 0:00:00\n","Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 60.3 MB/s eta 0:00:00\n","Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 2.0 MB/s eta 0:00:00\n","Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 4.6 MB/s eta 0:00:00\n","Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 42.1 MB/s eta 0:00:00\n","Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 19.1 MB/s eta 0:00:00\n","Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 5.9 MB/s eta 0:00:00\n","Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 100.2 MB/s eta 0:00:00\n","Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 343.3/343.3 kB 34.3 MB/s eta 0:00:00\n","Downloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (862 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 862.4/862.4 kB 58.2 MB/s eta 0:00:00\n","Downloading unsloth-2025.3.19-py3-none-any.whl (192 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 192.7/192.7 kB 21.9 MB/s eta 0:00:00\n","Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 354.7/354.7 kB 36.8 MB/s eta 0:00:00\n","Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.0/76.0 MB 29.0 MB/s eta 0:00:00\n","Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n","Downloading peft-0.15.1-py3-none-any.whl (411 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 411.0/411.0 kB 41.1 MB/s eta 0:00:00\n","Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 491.2/491.2 kB 44.2 MB/s eta 0:00:00\n","Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 30.7/30.7 MB 74.2 MB/s eta 0:00:00\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 14.0 MB/s eta 0:00:00\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 kB 11.5 MB/s eta 0:00:00\n","Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 183.9/183.9 kB 17.4 MB/s eta 0:00:00\n","Downloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 423.3/423.3 kB 41.1 MB/s eta 0:00:00\n","Downloading llguidance-0.7.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 118.8 MB/s eta 0:00:00\n","Downloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.2/44.2 kB 5.1 MB/s eta 0:00:00\n","Downloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 119.0 MB/s eta 0:00:00\n","Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.5/143.5 kB 16.2 MB/s eta 0:00:00\n","Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 110.5 MB/s eta 0:00:00\n","Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n","Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.1/162.1 kB 19.0 MB/s eta 0:00:00\n","Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.1/68.1 MB 8.4 MB/s eta 0:00:00\n","Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 67.1 MB/s eta 0:00:00\n","Downloading trl-0.15.2-py3-none-any.whl (318 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 318.9/318.9 kB 32.9 MB/s eta 0:00:00\n","Downloading unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.8/127.8 kB 14.7 MB/s eta 0:00:00\n","Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 376.2/376.2 kB 36.3 MB/s eta 0:00:00\n","Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 109.3 MB/s eta 0:00:00\n","Downloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 859.0/859.0 kB 56.7 MB/s eta 0:00:00\n","Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.7/210.7 kB 23.5 MB/s eta 0:00:00\n","Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 422.8/422.8 kB 37.2 MB/s eta 0:00:00\n","Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n","Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n","Downloading tyro-0.9.18-py3-none-any.whl (123 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.6/123.6 kB 15.4 MB/s eta 0:00:00\n","Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 452.6/452.6 kB 34.7 MB/s eta 0:00:00\n","Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.8/194.8 kB 21.0 MB/s eta 0:00:00\n","Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n","Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n","Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.2/119.2 kB 14.2 MB/s eta 0:00:00\n","Downloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.1/45.1 kB 4.9 MB/s eta 0:00:00\n","Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n","Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 71.5 MB/s eta 0:00:00\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.0/72.0 kB 9.0 MB/s eta 0:00:00\n","Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n","Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n","Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.3/62.3 kB 7.6 MB/s eta 0:00:00\n","Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n","Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n","Downloading airportsdata-20250224-py3-none-any.whl (913 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 913.7/913.7 kB 58.7 MB/s eta 0:00:00\n","Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.5/45.5 kB 5.4 MB/s eta 0:00:00\n","Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 124.4 MB/s eta 0:00:00\n","Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 313.6/313.6 kB 32.0 MB/s eta 0:00:00\n","Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 459.8/459.8 kB 43.5 MB/s eta 0:00:00\n","Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Downloading rich_toolkit-0.14.1-py3-none-any.whl (24 kB)\n","Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.0/4.0 MB 117.0 MB/s eta 0:00:00\n","Building wheels for collected packages: FlagEmbedding, warc3-wet-clueweb09, cbor\n","  Building wheel for FlagEmbedding (setup.py): started\n","  Building wheel for FlagEmbedding (setup.py): finished with status 'done'\n","  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.3.4-py3-none-any.whl size=232500 sha256=70bb4c2563233245cc170a526e53c8769f846b218ccd04efd7f57c5159fab815\n","  Stored in directory: /root/.cache/pip/wheels/57/69/8b/bb209413e16cb21065716300c291e75ca5949c878283836c4d\n","  Building wheel for warc3-wet-clueweb09 (setup.py): started\n","  Building wheel for warc3-wet-clueweb09 (setup.py): finished with status 'done'\n","  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=8d8c40bcd7c3e27dc5183856e4f48cdac29cbbbc926dd5d291604651405b2dbd\n","  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\n","  Building wheel for cbor (setup.py): started\n","  Building wheel for cbor (setup.py): finished with status 'done'\n","  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53930 sha256=4e3078b689417a3c056b731879bb955b24f75c86661ce3388d7d47a1c4d0f4f9\n","  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\n","Successfully built FlagEmbedding warc3-wet-clueweb09 cbor\n","Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, blake3, zlib-state, xxhash, uvloop, uvicorn, unlzw3, shtab, pyzmq, python-multipart, python-json-logger, python-dotenv, pycountry, protobuf, partial-json-parser, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, msgspec, lz4, llguidance, lark, interegular, httptools, hf_transfer, fsspec, dnspython, diskcache, dill, astor, airportsdata, watchfiles, trec-car-tools, tiktoken, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, inscriptis, gguf, faiss-cpu, email-validator, depyf, tyro, rich-toolkit, prometheus-fastapi-instrumentator, nvidia-cusolver-cu12, lm-format-enforcer, ir-datasets, fastapi, ray, outlines_core, mistral_common, langchain-core, fastapi-cli, datasets, xgrammar, xformers, outlines, langchain-text-splitters, flashinfer-python, cut_cross_entropy, compressed-tensors, bitsandbytes, accelerate, trl, peft, vllm, unsloth_zoo, FlagEmbedding, unsloth\n","  Attempting uninstall: pyzmq\n","    Found existing installation: pyzmq 24.0.1\n","    Uninstalling pyzmq-24.0.1:\n","      Successfully uninstalled pyzmq-24.0.1\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.4\n","    Uninstalling protobuf-5.29.4:\n","      Successfully uninstalled protobuf-5.29.4\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.49\n","    Uninstalling langchain-core-0.3.49:\n","      Successfully uninstalled langchain-core-0.3.49\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.3.7\n","    Uninstalling langchain-text-splitters-0.3.7:\n","      Successfully uninstalled langchain-text-splitters-0.3.7\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.5.2\n","    Uninstalling accelerate-1.5.2:\n","      Successfully uninstalled accelerate-1.5.2\n","  Attempting uninstall: peft\n","    Found existing installation: peft 0.14.0\n","    Uninstalling peft-0.14.0:\n","      Successfully uninstalled peft-0.14.0\n","Successfully installed FlagEmbedding-1.3.4 accelerate-1.6.0 airportsdata-20250224 astor-0.8.1 bitsandbytes-0.45.4 blake3-1.0.4 cbor-1.0.0 compressed-tensors-0.9.2 cut_cross_entropy-25.1.1 datasets-3.5.0 depyf-0.18.0 dill-0.3.8 diskcache-5.6.3 dnspython-2.7.0 email-validator-2.2.0 faiss-cpu-1.10.0 fastapi-0.115.12 fastapi-cli-0.0.7 flashinfer-python-0.2.5+cu124torch2.6 fsspec-2024.12.0 gguf-0.10.0 hf_transfer-0.1.9 httptools-0.6.4 ijson-3.3.0 inscriptis-2.6.0 interegular-0.3.3 ir-datasets-0.5.10 langchain-core-0.3.51 langchain-text-splitters-0.3.8 lark-1.2.2 llguidance-0.7.13 lm-format-enforcer-0.10.11 lz4-4.4.4 mistral_common-1.5.4 msgspec-0.19.0 multiprocess-0.70.16 ninja-1.11.1.4 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 peft-0.15.1 prometheus-fastapi-instrumentator-7.1.0 protobuf-3.20.3 pycountry-24.6.1 python-dotenv-1.1.0 python-json-logger-3.3.0 python-multipart-0.0.20 pyzmq-26.4.0 ray-2.44.1 rich-toolkit-0.14.1 shtab-1.7.1 starlette-0.46.1 tiktoken-0.9.0 trec-car-tools-2.6 trl-0.15.2 tyro-0.9.18 unlzw3-0.2.3 unsloth-2025.3.19 unsloth_zoo-2025.3.17 uvicorn-0.34.0 uvloop-0.21.0 vllm-0.8.2 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 watchfiles-1.0.4 xformers-0.0.29.post2 xgrammar-0.1.16 xxhash-3.5.0 zlib-state-0.1.9\n","Obtaining file:///content/llama.cpp/gguf-py\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Checking if build backend supports build_editable: started\n","  Checking if build backend supports build_editable: finished with status 'done'\n","  Getting requirements to build editable: started\n","  Getting requirements to build editable: finished with status 'done'\n","  Preparing editable metadata (pyproject.toml): started\n","  Preparing editable metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from gguf==0.16.0) (1.26.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from gguf==0.16.0) (6.0.2)\n","Requirement already satisfied: sentencepiece<=0.2.0,>=0.1.98 in /usr/local/lib/python3.11/dist-packages (from gguf==0.16.0) (0.2.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from gguf==0.16.0) (4.67.1)\n","Building wheels for collected packages: gguf\n","  Building editable for gguf (pyproject.toml): started\n","  Building editable for gguf (pyproject.toml): finished with status 'done'\n","  Created wheel for gguf: filename=gguf-0.16.0-py3-none-any.whl size=3460 sha256=229fa87e0fcf06fd475f2202b6660b9177b6c0a0c1f3259ed622aedb06294ec4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-n_o3l7ee/wheels/a1/6c/c6/6dbfb804e7a1607174676026fc9bf5d1006ceff85ba5c680b6\n","Successfully built gguf\n","Installing collected packages: gguf\n","  Attempting uninstall: gguf\n","    Found existing installation: gguf 0.10.0\n","    Uninstalling gguf-0.10.0:\n","      Successfully uninstalled gguf-0.10.0\n","Successfully installed gguf-0.16.0\n","Collecting jupyter-kernel-gateway\n","  Downloading jupyter_kernel_gateway-3.0.1-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (6.17.1)\n","Collecting jupyter-client>=8.6 (from jupyter-kernel-gateway)\n","  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: jupyter-core>=5.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-kernel-gateway) (5.7.2)\n","Collecting jupyter-server>=2.12 (from jupyter-kernel-gateway)\n","  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyter-kernel-gateway) (2.32.3)\n","Requirement already satisfied: tornado>=6.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-kernel-gateway) (6.4.2)\n","Collecting traitlets>=5.14.1 (from jupyter-kernel-gateway)\n","  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (1.8.0)\n","Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (7.34.0)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel) (1.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel) (5.9.5)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (26.4.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (75.2.0)\n","Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.50)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=8.6->jupyter-kernel-gateway) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=5.7->jupyter-kernel-gateway) (4.3.7)\n","Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (4.9.0)\n","Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (23.1.0)\n","Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (3.1.6)\n","Collecting jupyter-events>=0.11.0 (from jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n","Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (7.16.6)\n","Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (5.10.4)\n","Collecting overrides>=5.0 (from jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (0.21.1)\n","Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (0.18.1)\n","Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=2.12->jupyter-kernel-gateway) (1.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyter-kernel-gateway) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyter-kernel-gateway) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyter-kernel-gateway) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyter-kernel-gateway) (2025.1.31)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server>=2.12->jupyter-kernel-gateway) (1.3.1)\n","Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server>=2.12->jupyter-kernel-gateway) (4.13.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server>=2.12->jupyter-kernel-gateway) (21.2.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyter-server>=2.12->jupyter-kernel-gateway) (3.0.2)\n","Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (4.23.0)\n","Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (3.3.0)\n","Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (6.0.2)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (0.36.2)\n","Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (4.13.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (3.1.3)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (0.10.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (1.5.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server>=2.12->jupyter-kernel-gateway) (2.21.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=8.6->jupyter-kernel-gateway) (1.17.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (1.4.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (2024.10.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (0.24.0)\n","Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (3.0.0)\n","Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway) (24.11.1)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=2.12->jupyter-kernel-gateway) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=2.12->jupyter-kernel-gateway) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=2.12->jupyter-kernel-gateway) (2.22)\n","Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n","Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=2.12->jupyter-kernel-gateway)\n","  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n","Downloading jupyter_kernel_gateway-3.0.1-py3-none-any.whl (53 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 6.3 MB/s eta 0:00:00\n","Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.1/106.1 kB 12.7 MB/s eta 0:00:00\n","Downloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.8/385.8 kB 37.8 MB/s eta 0:00:00\n","Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 10.5 MB/s eta 0:00:00\n","Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 81.2 MB/s eta 0:00:00\n","Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n","Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n","Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n","Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n","Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n","Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n","Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n","Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 7.5 MB/s eta 0:00:00\n","Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n","Installing collected packages: uri-template, types-python-dateutil, traitlets, rfc3986-validator, rfc3339-validator, overrides, jedi, fqdn, jupyter-server-terminals, arrow, jupyter-client, isoduration, jupyter-events, jupyter-server, jupyter-kernel-gateway\n","  Attempting uninstall: traitlets\n","    Found existing installation: traitlets 5.7.1\n","    Uninstalling traitlets-5.7.1:\n","      Successfully uninstalled traitlets-5.7.1\n","  Attempting uninstall: jupyter-client\n","    Found existing installation: jupyter-client 6.1.12\n","    Uninstalling jupyter-client-6.1.12:\n","      Successfully uninstalled jupyter-client-6.1.12\n","  Attempting uninstall: jupyter-server\n","    Found existing installation: jupyter-server 1.16.0\n","    Uninstalling jupyter-server-1.16.0:\n","      Successfully uninstalled jupyter-server-1.16.0\n","Successfully installed arrow-1.3.0 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-kernel-gateway-3.0.1 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 overrides-7.7.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 traitlets-5.14.3 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n","Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /whl/cu124/torch2.6/warc3-wet-clueweb09/\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n","tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n","Cloning into 'llama.cpp'...\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","vllm 0.8.2 requires gguf==0.10.0, but you have gguf 0.16.0 which is incompatible.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n"]}]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","os.environ[\"HF_TOKEN\"] = userdata.get('HF_WRITE_TOKEN')\n","!huggingface-cli login --add-to-git-credential --token $HF_TOKEN\n","os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"],"metadata":{"id":"KEz4lxmqeEih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_9QlQdVmA2TQ"},"source":["```bash\n","VLLM_BACKEND=FLASHINFER VLLM_USE_V1=1 VLLM_ALLOW_LONG_MAX_MODEL_LEN=1 TOKENIZERS_PARALLELISM=true MAX_JOBS=2 vllm serve ISTA-DASLab/gemma-3-27b-it-GPTQ-4b-128g --port 8877 --max-model-len 4096 --api-key token-abc123 --quantization compressed-tensors --max-num-seqs=1\n","```"]},{"cell_type":"markdown","source":["# Web Search"],"metadata":{"id":"D3vY4k59SJPU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"088a415c-d647-4929-a8e1-53b459e8d9b5"},"outputs":[],"source":["from tavily import TavilyClient\n","import asyncio, os, requests, time, json\n","from IPython.display import display, Markdown, Latex\n","\n","tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d41e290-4bc3-4eab-aa2a-5b7aba37f183"},"outputs":[],"source":["from openai import OpenAI\n","import math\n","import time\n","import json\n","\n","client = OpenAI(\n","    base_url=\"localhost:8877/v1\",\n","    api_key=\"token-abc123\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bf367e2-79bc-4af2-9914-c71bcea0a7e9"},"outputs":[],"source":["def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):\n","     # Collect all results\n","    sources_list = []\n","    for response in search_response:\n","        sources_list.extend(response['results'])\n","\n","    # Deduplicate by URL\n","    unique_sources = {source['url']: source for source in sources_list}\n","\n","    # Format output\n","    formatted_text = \"Content from sources:\\n\"\n","    for i, source in enumerate(unique_sources.values(), 1):\n","        formatted_text += f\"{'='*80}\\n\"  # Clear section separator\n","        formatted_text += f\"Source: {source['title']}\\n\"\n","        formatted_text += f\"{'-'*80}\\n\"  # Subsection separator\n","        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n","        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n","        if include_raw_content:\n","            # Using rough estimate of 4 characters per token\n","            char_limit = max_tokens_per_source * 4\n","            # Handle None raw_content\n","            raw_content = source.get('raw_content', '')\n","            if raw_content is None:\n","                raw_content = ''\n","                print(f\"Warning: No raw_content found for source {source['url']}\")\n","            if len(raw_content) > char_limit:\n","                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n","            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n","        formatted_text += f\"{'='*80}\\n\\n\" # End section separator\n","\n","    return formatted_text.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2440775f-4d4f-481e-9a58-a83f1984bb9e"},"outputs":[],"source":["def generate_response(message_list):\n","    completion = client.chat.completions.create(\n","        model = \"Llama-3.1-8B-Instruct\",\n","        messages = message_list,\n","        max_tokens=2048,\n","        frequency_penalty=0.3,\n","        temperature=0.6,\n","        stream=True,\n","    )\n","\n","    final_answer = []\n","    assistant_response = \"\"\n","\n","    start = time.time()\n","\n","    # 스트림 모드에서는 completion.choices 를 반복문으로 순회\n","    for chunk in completion:\n","        chunk_content = chunk.choices[0].delta.content\n","\n","        if isinstance(chunk_content, str):\n","            final_answer.append(chunk_content)\n","            # 토큰 단위로 실시간 답변 출력\n","            print(chunk_content, end=\"\")\n","            assistant_response += chunk_content\n","\n","    end = time.time()\n","    print(f\"\\n\\ninference time: {end - start:.5f} sec \\n\\n\")\n","    return assistant_response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bc6e7991-8b1f-4e08-9a8e-39402ad5966f"},"outputs":[],"source":["import threading\n","\n","def worker(query, search_result, req_num_result, include_raw, req_topic):\n","    print(f\"Thread: {query}\")\n","    search_result.append(\n","        tavily_client.search(\n","            query,\n","            max_results= req_num_result,\n","            include_raw_content= include_raw,\n","            topic= req_topic\n","        )\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37f4b17b-86e5-45ab-9885-89404c578304"},"outputs":[],"source":["def ask_tavily(search_queries, search_tasks, req_num_result, include_raw, req_topic):\n","    start_time = time.time()\n","    threads = []\n","\n","    for query in search_queries:\n","        t = threading.Thread(target=worker, args=(query, search_tasks, req_num_result, include_raw, req_topic))\n","        threads.append(t)\n","        t.start()\n","\n","    for thread in threads:\n","        thread.join()\n","\n","    end_time = time.time()\n","    execution_time = end_time - start_time\n","\n","    print(f\"\\nask_tavily task running time: {execution_time:.2f}초 \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bc19754-1bb4-44fa-bd34-40781b75e958"},"outputs":[],"source":["def ask_plan_query_writer(topic, content):\n","    llm_prompt = \"\"\"You are an expert technical writer crafting a section that synthesizes information\n","<section topic>\n","\"\"\" + topic + \"\"\"\n","</section topic>\n","\n","<section organization>\n","\"\"\" + content + \"\"\"\n","</section organization>\n","\n","<Task>\n","Your goal is to generate 3 web search queries that will help gather information for planning the sections.\n","\n","The queries should:\n","\n","1. Be related to the section topic\n","2. Help satisfy the requirements specified in the section organization\n","\n","Make the queries specific enough to find high-quality, relevant sources while covering the breadth needed for the section structure.\n","\n","Note1. that today's date is \"\"\"+time.strftime(\"%Y-%m-%d\")+\"\"\".\n","Note2. Output your response in JSON format, with the following structure: { \"queries\": [ \"query1\", \"query2\", \"query3\" ] }\n","</Task>\"\"\"\n","\n","    return llm_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fea43e2f-f69f-4481-86be-031acbfda0d8"},"outputs":[],"source":["def ask_final_writer_instructions(topic, content, search_tasks):\n","    final_section_writer=\"\"\"You are an expert technical writer.\n","\n","<Section name>\n","\"\"\" + content + \"\"\"\n","</Section name>\n","\n","<Section topic>\n","\"\"\" + topic + \"\"\"\n","</Section topic>\n","\n","<Available Website Search Content>\n","\"\"\" + deduplicate_and_format_sources(search_tasks, max_tokens_per_source=4000, include_raw_content=True) + \"\"\"\n","</Available Website Search Content>\n","\n","<Task>\n","1. Section-Specific Approach:\n","\n","For Introduction:\n","- Use # for Website Search title (Markdown format)\n","- Write in simple and clear language\n","- Focus on the core motivation for the Section in 1-2 paragraphs\n","- Use a clear narrative arc to introduce the Section\n","- Include NO structural elements (no lists or tables)\n","- No sources section needed\n","\n","For Conclusion/Summary:\n","- Use ## for Conclusion/Summary title (Markdown format)\n","- For comparative Conclusion/Summary:\n","    * Must include a focused comparison table using Markdown table syntax\n","    * Table should distill insights from the Section\n","    * Keep table entries clear and concise\n","- For non-comparative Conclusion/Summary:\n","    * Only use ONE structural element IF it helps distill the points made in the Section:\n","    * Either a focused table comparing items present in the Section (using Markdown table syntax)\n","    * Or a short list using proper Markdown list syntax:\n","      - Use `*` or `-` for unordered lists\n","      - Use `1.` for ordered lists\n","      - Ensure proper indentation and spacing\n","- Sources and url section needed. (especially when expressing a URL, please provide the entire URL exactly as given in the content without abbreviating it.)\n","- End with specific next steps or implications\n","\n","2. Writing Approach:\n","- Use concrete details over general statements\n","- Make every word count\n","- Focus on your single most important point\n","</Task>\n","\n","<Quality Checks>\n","- Verify that EVERY claim is grounded in the provided Source material\n","- Confirm each URL appears ONLY ONCE in the Source list\n","- For introduction: # for Website Search title, no structural elements, no sources section\n","- For conclusion: ## for Conclusion/Summary title, only ONE structural element at most, add sources and url section\n","- Markdown format\n","- Do not include word count or any preamble in your response\n","</Quality Checks>\n","\n","Please note that respond in Korean always.\"\"\"\n","\n","    return final_section_writer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31b7c569-67dd-450b-8657-b8f7197bd980","outputId":"fc0b3bce-c58b-488a-f848-a2cdac1c901e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{ \n","  \"queries\": [\n","    \"MCP vs A2A 프로토콜: 주요 차이점\",\n","    \"2025년 현재 MCP 및 A2A 프로토콜의 최신 기술 동향\",\n","    \"MCP 및 A2A 프로토콜의 비교: 모델 컨텍스트 프로토콜과 에이전트 투 에이전트\"\n","  ]\n","}\n","\n","inference time: 2.72356 sec \n","\n","\n"]}],"source":["system_prompt = \"You are a helpful assistant. And Answers must be in Korean.\"\n","\n","topic = \"기술동향\"\n","content = \"MCP(model context protocol) 과 A2A(Agent to Agent) 는 어떤 차이가 있는것인지 알려줘.\"\n","\n","messages = [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": ask_plan_query_writer(topic, content)},\n","    ]\n","\n","response_query = generate_response(messages)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dbc2f92-e585-4fcc-b959-a2265785db2c","outputId":"ec69636e-2c19-4ffc-b9a9-cc2be66b3aea"},"outputs":[{"name":"stdout","output_type":"stream","text":["사용자 발화 기반으로 추출한 web query 문장 3건:\n","['MCP vs A2A 프로토콜: 주요 차이점', '2025년 현재 MCP 및 A2A 프로토콜의 최신 기술 동향', 'MCP 및 A2A 프로토콜의 비교: 모델 컨텍스트 프로토콜과 에이전트 투 에이전트']\n","Thread: MCP vs A2A 프로토콜: 주요 차이점\n","Thread: 2025년 현재 MCP 및 A2A 프로토콜의 최신 기술 동향\n","Thread: MCP 및 A2A 프로토콜의 비교: 모델 컨텍스트 프로토콜과 에이전트 투 에이전트\n","\n","ask_tavily task running time: 2.25초 \n","\n","[{'query': 'MCP vs A2A 프로토콜: 주요 차이점', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'A2A vs MCP: 새로운 에이전트 생태계를 위한 두 개의 보완적 프로토콜 · Logto 블로그', 'url': 'https://blog.logto.io/ko/a2a-mcp', 'content': '이 기사에서는 AI 에이전트 시스템의 미래를 형성하는 두 가지 프로토콜, A2A와 MCP를 소개합니다. 이들이 어떻게 작동하고, 어떻게 다른지, 그리고 이 아키텍처를 이해하는 것이 개발자, 디자이너 및 AI 제품 제작자에게 왜 중요한지를 설명합니다.', 'score': 0.7325349, 'raw_content': None}, {'title': '구글의 A2a, Ai 에이전트 시대의 새로운 표준이 될까? - Mcp와의 비교부터 실제 사용 예시까지 한눈에 정리', 'url': 'https://digitalbourgeois.tistory.com/1039', 'content': '구글의 A2A, AI 에이전트 시대의 새로운 표준이 될까? 구글의 A2A, AI 에이전트 시대의 새로운 표준이 될까? 🛠 실제 사용 예시 – A2A 에이전트 체험기 주 용도에이전트 간 협업LLM 기능 확장 및 도구 연결아키텍처클라이언트-서버호스트-LLM-리소스인터페이스JSON, Agent CardJSON-RPC 2.0, 리소스/툴 구성통신 방식HTTP, JSON-RPCstdio 기반 JSON-RPC, SSE특징다중 에이전트 관리, 태스크 중심, 멀티모달 지원모듈성, 툴 재사용, 캐싱생태계구글 중심, 초기 단계이미 대규모 도입 진행 중 멀티 에이전트 기반 AI 시스템이 점점 확산되는 지금, A2A는 이를 구축하는 데 있어 실용적인 대안이 될 수 있습니다. https://hackernoon.com/google-a2a-a-first-look-at-another-agent-agent-protocol Google A2A - a First Look at Another Agent-agent Protocol | HackerNoon Google A2A - a first look at another agent-agent protocol and compared to Anthropic’s MCP. “에이전트가 개발을 대신해준다?” Google Cloud Next ‘25, 개발의 미래를 엿보다\\xa0\\xa0(0)2025.04.11“AI의 판을 다시 짠다” – 구글 클라우드 Next 25에서 공개된 차세대 AI 기술 총정리\\xa0\\xa0(0)2025.04.11딥시크-R1을 넘어선 새로운 강자?', 'score': 0.6342494, 'raw_content': None}, {'title': 'MCP, API, AI Agent의 차이점 완벽 정리', 'url': 'https://nextitnow.tistory.com/entry/MCP-API-AI-Agent의-차이점-완전-정리', 'content': 'MCP, API, AI Agent의 차이점 완전 정리헷갈리기 쉬운 기술 용어들, MCP, API, 그리고 AI Agent. 도대체 뭐가 다른 걸까요? 한 번에 쏙 이해되는 핵심 정리!안녕하세요, 기술 용어에 머리가 지끈지끈 아팠던 개발자 지망생, 그리고 현업 분들까지 모두 반가워요! 요즘 AI랑 자동화 관련해서 자주 듣게 되는 단어가', 'score': 0.38595363, 'raw_content': None}], 'response_time': 1.54}, {'query': 'MCP 및 A2A 프로토콜의 비교: 모델 컨텍스트 프로토콜과 에이전트 투 에이전트', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'A2A vs MCP: 새로운 에이전트 생태계를 위한 두 개의 보완적 프로토콜 · Logto 블로그', 'url': 'https://blog.logto.io/ko/a2a-mcp', 'content': 'MCP 호스트는 AI 앱 자체로 생각할 수 있습니다 — Claude Desktop이나 코딩 도우미와 같은. 적절한 MCP 서버 세트를 통해, 사용자는 모든 MCP 클라이언트를 \"모든 것을 할 수 있는 앱\"으로 변환할 수 있습니다. 개발자 역할 | 엔드포인트를 통해 작업 및 아티팩트를 노출하는 에이전트 구축 | 모델이 사용할 수 있는 구조화된 도구와 컨텍스트 정의 함께 사용될 때, 이는 구성 가능한 다중 에이전트 시스템을 지원하여, 확장 가능하고 상호 운용할 수 있습니다. MCP + A2A 기반 인프라가 에이전트 제품 마켓플레이스의 미래를 어떻게 형성할 수 있는가# 우리는 점점 더 많은 MCP 서버가 등장하는 것을 확인할 수 있습니다. 에이전트(예: MCP 클라이언트로)가 이러한 서버 여러 개를 한 번에 연결할 수 있다면 — 이전에는 맞춤형 통합이나 밀접\\x00하게 연결된 앱이 필요했던 워크플로를 잠금 해제할 수 있습니다.', 'score': 0.751375, 'raw_content': None}, {'title': '모델 컨텍스트 프로토콜(Mcp) 분석하기', 'url': 'https://botpress.com/ko/blog/model-context-protocol', 'content': 'AI 시스템이 사용자 지정 API 통합, 수동으로 구조화된 요청, 서비스별 인증에 의존할 필요 없이 MCP는 AI 에이전트가 표준화된 방식으로 구조화된 데이터를 검색, 처리 및 조치할 수 있도록 통합된 프레임워크를 제공합니다. MCP는 공통 프로토콜을 정의함으로써 개발자가 상호 작용하는 모든 시스템에 대해 맞춤형 API 브리지를 구축할 필요 없이 AI 모델이 데이터를 더 잘 인식할 수 있도록 합니다. MCP는 AI 에이전트가 API와 개별적으로 상호 작용하도록 강제하는 대신 인증, 요청 실행 및 데이터 형식의 복잡성을 추상화하는 통합 프로토콜을 설정하여 AI 시스템이 낮은 수준의 통합 로직이 아닌 추론에 집중할 수 있도록 합니다. 수동 구문 분석이 필요한 원시 API 응답과 달리 MCP는 검색된 모든 데이터가 예측 가능하고 구조화된 형식을 따르기 때문에 AI 모델이 더 쉽게 이해하고 활용할 수 있습니다. MCP는 AI 상호 작용을 간소화하지만 인증 및 구조화된 API 액세스는 여전히 주요 과제로 남아 있습니다.', 'score': 0.6617704, 'raw_content': None}, {'title': 'Model Context Protocol(MCP) 완벽 가이드: AI 애플리케이션 개발 표준화하기', 'url': 'https://dma-ai.kr/77', 'content': 'MCP 호스트사용자가 상호작용하는 프론트엔드 애플리케이션 (Claude Desktop, IDE, AI 도구 등)MCP 클라이언트MCP 서버와 1:1 연결을 유지하며 통신을 중개하는 역할MCP 서버특정 기능을 노출하는 경량 프로그램으로, 애플리케이션과 LLM 간 연결 담당로컬 데이터 소스사용자의 컴퓨터에 있는 파일, 데이터베이스, 서비스원격 서비스인터넷을 통해 접근 가능한 외부 시스템 (API 등) Claude.app 및 claude.ai MCP 통합과 관련된 문제는 웹사이트에 제공된 연락처 정보를 통해 지원받을 수 있습니다. 블렌더-mcp 사용 가이드: Claude AI와 블렌더 연동으로 3D 제작 혁신하기\\xa0\\xa0(0)2025.03.21Claude 데스크톱 앱을 위한 MCP-인스톨러 완벽 가이드: 설치부터 문제해결까지\\xa0\\xa0(0)2025.03.21【완벽 가이드】Claude for Desktop에서 파일 시스템 접근 기능 설정하기\\xa0\\xa0(1)2025.03.20Unreal Engine 5와 AI 통합 가이드: MCP 서버 활용법\\xa0\\xa0(2)2025.03.20', 'score': 0.34534863, 'raw_content': None}], 'response_time': 1.64}, {'query': '2025년 현재 MCP 및 A2A 프로토콜의 최신 기술 동향', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': '2025년 2-3월 Ai 핵심 기술 동향: 모델 컨텍스트 프로토콜(Mcp)과 딥 리서치의 진화 : 네이버 블로그', 'url': 'https://blog.naver.com/PostView.naver?blogId=leanstarter&logNo=223789809167', 'content': '2025년 2-3월 AI 핵심 기술 동향: 모델 컨텍스트 프로토콜(MCP)과 딥 리서치의 진화 ... 이 프로토콜의 도입으로 기업들은 평균 73%의 통합 비용을 절감했으며, 특히 금융 서비스 분야에서 실시간 데이터 처리 속도가 300% 향상된 사례가 보고되었습니다. ... MCP의 경량화', 'score': 0.78493005, 'raw_content': None}, {'title': 'Mcp 시장 지도 완벽 분석: 2025년 모델 컨텍스트 프로토콜 생태계 총정리', 'url': 'https://dma-ai.kr/81', 'content': 'MCP(Model Context Protocol)는 AI 모델과 에이전트가 다양한 도구 및 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다. 1. Top MCP Clients (주요 MCP 클라이언트) 2. Top MCP Servers (주요 MCP 서버) 특징: MCP 애플리케이션의 자원 관리 및 최적화를 위한 도구입니다. 특징: MCP 생태계 내의 통합 및 커뮤니케이션을 관리하는 도구입니다. 주요 MCP 생태계 참여자 클라이언트 | Cursor | https://www.cursor.com | AI 기반 코드 에디터 | Anthropic | https://www.anthropic.com | AI 안전 및 연구 회사 | OpenTools | https://opentools.com | AI 도구 디렉토리 MCP 시장 동향 및 전망 주요 MCP 클라이언트 주요 MCP 서버 주요 MCP 클라이언트, 서버, 마켓플레이스 및 도구들의 총정리와 미래 전망 제시. 순차적 사고(Sequential Thinking) MCP 서버 설치 및 활용 가이드(0) | 2025.03.25', 'score': 0.638588, 'raw_content': None}, {'title': '2025년 인공지능 뉴스: Gemini 3, 오픈AI, MCP 최신 동향', 'url': 'https://sugar-family.tistory.com/548', 'content': '2025년 AI 시장에서는 오픈소스 기술이 점점 더 주목받고 있어요. 최근 공개된 Sesame 오픈소스 AI는 폐쇄형 AI 모델과의 경쟁에서 강력한 도전자로 떠오르고 있어요. Sesame은 완전한 오픈소스 AI 모델로, 누구나 자유롭게 수정하고 활용할 수 있어요. 특히, AI 기반 투자 모델은 인간이 감지하기 어려운 데이터 패턴을 분석하고, 초고속 매매를 실행할 수 있다는 점에서 강력한 경쟁력을 가지고 있어요. 예를 들어, AI 영상 편집 기술을 활용하면 원본 영상을 자동으로 분석하고, 최적의 컷을 찾아 편집할 수 있어요. Gemini 3는 멀티모달 AI 기능이 강화되어 이미지, 텍스트, 오디오를 동시에 분석할 수 있어요. AI 기반 투자는 빠른 분석과 자동 매매가 가능하지만, 경제 위기나 예측 불가능한 사건에는 취약할 수 있어요. ai 뉴스, AI 투자, AI 트렌드, gemini 3, MCP, 오픈AI, 오픈소스 ai, 인공지능, 자동화 기술, 콘텐츠 ai', 'score': 0.5843666, 'raw_content': None}], 'response_time': 2.0}]\n"]}],"source":["json_data = json.loads(response_query)\n","queries = json_data['queries']\n","\n","print(\"사용자 발화 기반으로 추출한 web query 문장 3건:\")\n","print(queries)\n","\n","search_tasks = []\n","req_topic = 'general' # news   gerneral 과 news 중 선택\n","req_num_result = 3    # 각 web query 에 대해 리턴할 site 개수\n","include_raw = False    # site 의 원본 컨텐츠 리턴 유무\n","\n","ask_tavily(queries, search_tasks, req_num_result, include_raw, req_topic)\n","print(search_tasks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6543581-a4e6-4d00-af86-71ae7a0f92ba","outputId":"a1b19753-a88b-49fe-d97c-0333d3c88298"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","=================================================================\n","\n","Warning: No raw_content found for source https://blog.logto.io/ko/a2a-mcp\n","Warning: No raw_content found for source https://digitalbourgeois.tistory.com/1039\n","Warning: No raw_content found for source https://nextitnow.tistory.com/entry/MCP-API-AI-Agent의-차이점-완전-정리\n","Warning: No raw_content found for source https://botpress.com/ko/blog/model-context-protocol\n","Warning: No raw_content found for source https://dma-ai.kr/77\n","Warning: No raw_content found for source https://blog.naver.com/PostView.naver?blogId=leanstarter&logNo=223789809167\n","Warning: No raw_content found for source https://dma-ai.kr/81\n","Warning: No raw_content found for source https://sugar-family.tistory.com/548\n","<section topic>\n","기술동향\n","</section topic>\n","\n","<section organization>\n","MCP(model context protocol) 과 A2A(Agent to Agent) 는 어떤 차이가 있는것인지 알려줘.\n","</section organization>\n","\n","<Task>\n","1. Section-Specific Approach:\n","\n","# MCP와 A2A의 차이점\n","\n","MCP(model context protocol)과 A2A(Agent to Agent)는 AI 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다. 하지만 두 프로토콜은 서로 다른 특징과 목적을 가지고 있습니다. 이 섹션에서는 MCP와 A2A의 차이점을 비교하고 분석할 것입니다.\n","\n","MCP는 AI 모델과 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다. MCP는 AI 애플리케이션의 자원 관리 및 최적화를 위한 도구입니다. 반면에 A2A는 에이전트 간 협업을 위한 표준화된 프로토콜입니다. A2A는 에이전트 간의 통신과 협력을 쉽게 할 수 있도록 하는 도구입니다.\n","\n","두 프로토콜 모두 AI 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다. 하지만 MCP는 AI 애플리케이션의 자원 관리 및 최적화를 위한 도구로 사용되며, A2A는 에이전트 간 협업을 위한 표준화된 프로토콜로 사용됩니다.\n","\n","## 결론\n","\n","| 특징 | MCP | A2A |\n","| --- | --- | --- |\n","| 목적 | AI 애플리케이션의 자원 관리 및 최적화 | 에이전트 간 협업 |\n","| 기능 | 자원 관리 및 최적화 | 통신 및 협력 |\n","\n","Sources:\n","- https://blog.logto.io/ko/a2a-mcp\n","- https://digitalbourgeois.tistory.com/1039\n","- https://nextitnow.tistory.com/entry/MCP-API-AI-Agent의-차이점-완전-정리\n","- https://botpress.com/ko/blog/model-context-protocol\n","- https://dma-ai.kr/77\n","- https://dma-ai.kr/81\n","- https://sugar-family.tistory.com/548\n","\n","다음으로는 MCP와 A2A를 사용하는 경우에 대한 고려 사항을 살펴볼 것입니다.\n","\n","## 다음 단계\n","\n","MCP와 A2A를 사용하는 경우에 대한 고려 사항은 다음과 같습니다.\n","\n","*   MCP를 사용하는 경우, AI 애플리케이션의 자원 관리 및 최적화를 위해 사용해야 합니다.\n","*   A2A를 사용하는 경우, 에이전트 간 협업을 위해 사용해야 합니다.\n","*   두 프로토콜 모두 AI 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다.\n","\n","Sources:\n","- https://blog.logto.io/ko/a2a-mcp\n","- https://digitalbourgeois.tistory.com/1039\n","- https://nextitnow.tistory.com/entry/MCP-API-AI-Agent의-차이점-완전-정리\n","- https://botpress.com/ko/blog/model-context-protocol\n","- https://dma-ai.kr/77\n","- https://dma-ai.kr/81\n","- https://sugar-family.tistory.com/548\n","\n","</Task>\n","\n","<Quality Checks>\n","EVERY claim is grounded in the provided Source material.\n","각 URL은 Source list에서 ONLY 한 번만 나타납니다.\n","introduction: # for Website Search title, no structural elements, no sources section.\n","conclusion: ## for Conclusion/Summary title, only ONE structural element at most, add sources and url section.\n","Markdown format.\n","word count 또는 preamble 포함되지 않습니다.\n","</Quality Checks>\n","\n","<Task>\n","2. Writing Approach:\n","\n","Writing Approach를 위해 다음 내용을 추가합니다.\n","\n","*   Concrete details over general statements: \n","    +   \"MCP는 AI 모델과 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다.\" 대신 \"MCP는 AI 모델과 에이전트가 다양한 도구와 서비스를 연결하는 데 사용되는 표준화된 프로토콜입니다.\"\n","*   Make every word count:\n","    +   \"두 프로토콜은 서로 다른 특징과 목적을 가지고 있습니다.\" 대신 \"MCP와 A2A는 서로 다른 기능과 목적을 가지고 있습니다.\"\n","*   Focus on your single most important point:\n","    +   \"두 프로토콜 모두 AI 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다.\" 대신 \"MCP는 AI 모델과 에이전트가 다양한 도구와 서비스를 연결하는 데 사용되는 표준화된 프로토콜이며, A2A는 에이전트 간 협업을 위한 표준화된 프로토콜입니다.\"\n","\n","</Task>\n","\n","<Quality Checks>\n","EVERY claim is grounded in the provided Source material.\n","각 URL은 Source list에서 ONLY 한 번만 나타납니다.\n","introduction: # for Website Search title, no structural elements, no sources section.\n","conclusion: ## for Conclusion/Summary title, only ONE structural element at most, add sources and url section.\n","Markdown format.\n","word count 또는 preamble 포함되지 않습니다.\n","</Quality Checks>\n","\n","<Task>\n","3. Web Search Queries:\n","\n","다음 Web Search Queries를 추가합니다.\n","\n","1.  \"MCP vs A2A\"\n","2.  \"AI 에이전트간 협업\"\n","3.  \"AI 모델과 에이전트간 연결\"\n","\n","</Task>\n","\n","<Quality Checks>\n","EVERY claim is grounded in the provided Source material.\n","각 URL은 Source list에서 ONLY 한 번만 나타납니다.\n","introduction: # for Website Search title, no structural elements, no sources section.\n","conclusion: ## for Conclusion/Summary title, only ONE structural element at most, add sources and url section.\n","Markdown format.\n","word count 또는 preamble 포함되지 않습니다.\n","</Quality Checks>\n","\n","inference time: 47.30096 sec \n","\n","\n","\n","\n","=========================  Search Report  ========================================\n","\n"]},{"data":{"text/markdown":["<section topic>\n","기술동향\n","</section topic>\n","\n","<section organization>\n","MCP(model context protocol) 과 A2A(Agent to Agent) 는 어떤 차이가 있는것인지 알려줘.\n","</section organization>\n","\n","<Task>\n","1. Section-Specific Approach:\n","\n","# MCP와 A2A의 차이점\n","\n","MCP(model context protocol)과 A2A(Agent to Agent)는 AI 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다. 하지만 두 프로토콜은 서로 다른 특징과 목적을 가지고 있습니다. 이 섹션에서는 MCP와 A2A의 차이점을 비교하고 분석할 것입니다.\n","\n","MCP는 AI 모델과 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다. MCP는 AI 애플리케이션의 자원 관리 및 최적화를 위한 도구입니다. 반면에 A2A는 에이전트 간 협업을 위한 표준화된 프로토콜입니다. A2A는 에이전트 간의 통신과 협력을 쉽게 할 수 있도록 하는 도구입니다.\n","\n","두 프로토콜 모두 AI 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다. 하지만 MCP는 AI 애플리케이션의 자원 관리 및 최적화를 위한 도구로 사용되며, A2A는 에이전트 간 협업을 위한 표준화된 프로토콜로 사용됩니다.\n","\n","## 결론\n","\n","| 특징 | MCP | A2A |\n","| --- | --- | --- |\n","| 목적 | AI 애플리케이션의 자원 관리 및 최적화 | 에이전트 간 협업 |\n","| 기능 | 자원 관리 및 최적화 | 통신 및 협력 |\n","\n","Sources:\n","- https://blog.logto.io/ko/a2a-mcp\n","- https://digitalbourgeois.tistory.com/1039\n","- https://nextitnow.tistory.com/entry/MCP-API-AI-Agent의-차이점-완전-정리\n","- https://botpress.com/ko/blog/model-context-protocol\n","- https://dma-ai.kr/77\n","- https://dma-ai.kr/81\n","- https://sugar-family.tistory.com/548\n","\n","다음으로는 MCP와 A2A를 사용하는 경우에 대한 고려 사항을 살펴볼 것입니다.\n","\n","## 다음 단계\n","\n","MCP와 A2A를 사용하는 경우에 대한 고려 사항은 다음과 같습니다.\n","\n","*   MCP를 사용하는 경우, AI 애플리케이션의 자원 관리 및 최적화를 위해 사용해야 합니다.\n","*   A2A를 사용하는 경우, 에이전트 간 협업을 위해 사용해야 합니다.\n","*   두 프로토콜 모두 AI 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다.\n","\n","Sources:\n","- https://blog.logto.io/ko/a2a-mcp\n","- https://digitalbourgeois.tistory.com/1039\n","- https://nextitnow.tistory.com/entry/MCP-API-AI-Agent의-차이점-완전-정리\n","- https://botpress.com/ko/blog/model-context-protocol\n","- https://dma-ai.kr/77\n","- https://dma-ai.kr/81\n","- https://sugar-family.tistory.com/548\n","\n","</Task>\n","\n","<Quality Checks>\n","EVERY claim is grounded in the provided Source material.\n","각 URL은 Source list에서 ONLY 한 번만 나타납니다.\n","introduction: # for Website Search title, no structural elements, no sources section.\n","conclusion: ## for Conclusion/Summary title, only ONE structural element at most, add sources and url section.\n","Markdown format.\n","word count 또는 preamble 포함되지 않습니다.\n","</Quality Checks>\n","\n","<Task>\n","2. Writing Approach:\n","\n","Writing Approach를 위해 다음 내용을 추가합니다.\n","\n","*   Concrete details over general statements: \n","    +   \"MCP는 AI 모델과 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다.\" 대신 \"MCP는 AI 모델과 에이전트가 다양한 도구와 서비스를 연결하는 데 사용되는 표준화된 프로토콜입니다.\"\n","*   Make every word count:\n","    +   \"두 프로토콜은 서로 다른 특징과 목적을 가지고 있습니다.\" 대신 \"MCP와 A2A는 서로 다른 기능과 목적을 가지고 있습니다.\"\n","*   Focus on your single most important point:\n","    +   \"두 프로토콜 모두 AI 에이전트가 다양한 도구와 서비스와 원활하게 상호작용할 수 있도록 하는 표준화된 프로토콜입니다.\" 대신 \"MCP는 AI 모델과 에이전트가 다양한 도구와 서비스를 연결하는 데 사용되는 표준화된 프로토콜이며, A2A는 에이전트 간 협업을 위한 표준화된 프로토콜입니다.\"\n","\n","</Task>\n","\n","<Quality Checks>\n","EVERY claim is grounded in the provided Source material.\n","각 URL은 Source list에서 ONLY 한 번만 나타납니다.\n","introduction: # for Website Search title, no structural elements, no sources section.\n","conclusion: ## for Conclusion/Summary title, only ONE structural element at most, add sources and url section.\n","Markdown format.\n","word count 또는 preamble 포함되지 않습니다.\n","</Quality Checks>\n","\n","<Task>\n","3. Web Search Queries:\n","\n","다음 Web Search Queries를 추가합니다.\n","\n","1.  \"MCP vs A2A\"\n","2.  \"AI 에이전트간 협업\"\n","3.  \"AI 모델과 에이전트간 연결\"\n","\n","</Task>\n","\n","<Quality Checks>\n","EVERY claim is grounded in the provided Source material.\n","각 URL은 Source list에서 ONLY 한 번만 나타납니다.\n","introduction: # for Website Search title, no structural elements, no sources section.\n","conclusion: ## for Conclusion/Summary title, only ONE structural element at most, add sources and url section.\n","Markdown format.\n","word count 또는 preamble 포함되지 않습니다.\n","</Quality Checks>"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["print(\"\\n\\n=================================================================\\n\")\n","messages.append({\"role\": \"user\", \"content\": ask_final_writer_instructions(topic, content, search_tasks)})\n","response_query = generate_response(messages)\n","\n","print(\"\\n\\n=========================  Search Report  ========================================\\n\")\n","display(Markdown(response_query))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"820360c5-94fc-4270-98de-730cd1d384dc"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Web RAG"],"metadata":{"id":"Xjvk0QMXSMlI"}},{"cell_type":"code","source":[],"metadata":{"id":"xkyBva41SOU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96d12b3f-1667-425d-916f-f47d7f7f5a28"},"outputs":[],"source":["from openai import OpenAI\n","import math\n","import time\n","import json\n","\n","client = OpenAI(\n","    base_url=\"localhost:8877/v1\",\n","    api_key=\"token-abc123\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6cacd48f-181d-4056-b80a-14f76565b114"},"outputs":[],"source":["def generate_response(message_list):\n","    completion = client.chat.completions.create(\n","        model = \"Llama-3.1-8B-Instruct\",\n","        messages = message_list,\n","        max_tokens=1024,\n","        frequency_penalty=0.3,\n","        temperature=0.6,\n","        stream=True,\n","    )\n","\n","    final_answer = []\n","    assistant_response = \"\"\n","\n","    start = time.time()\n","\n","    # 스트림 모드에서는 completion.choices 를 반복문으로 순회\n","    for chunk in completion:\n","        chunk_content = chunk.choices[0].delta.content\n","\n","        if isinstance(chunk_content, str):\n","            final_answer.append(chunk_content)\n","            # 토큰 단위로 실시간 답변 출력\n","            print(chunk_content, end=\"\")\n","            assistant_response += chunk_content\n","\n","    end = time.time()\n","    print(f\"\\n\\ninference time: {end - start:.5f} sec \\n\\n\")\n","    return assistant_response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1bcc01f-f613-41d4-9809-773d8d1740b2","outputId":"c9094d0a-3fb1-41b0-a5eb-fefa78af05ba"},"outputs":[{"name":"stdin","output_type":"stream","text":["USER >  안녕 너는 지금 정상이니?\n"]},{"name":"stdout","output_type":"stream","text":["안녕하세요! 저는 정상입니다. 제가 보유한 지식과 정보를 기반으로 유저의 질문에 답변해드릴 준비가 되어 있습니다. 어떤 질문이 궁금한가요?\n","\n","inference time: 1.43665 sec \n","\n","\n"]},{"name":"stdin","output_type":"stream","text":["USER >  quit\n"]}],"source":["message_list = [{\"role\": \"system\", \"content\": \"당신은 유저의 질문에 최대한 정확하고 풍부한 정보를 전달하는 assistant 이다. 답변은 항상 한국어로 공손하게 답변해줘.\"}]\n","\n","while True:\n","    user_prompt = input(\"USER > \")\n","    if user_prompt.lower() == \"quit\":\n","        break\n","    message_list.append({\"role\": \"user\", \"content\": user_prompt})\n","\n","    assistant = generate_response(message_list)\n","    message_list.append({\"role\": \"assistant\", \"content\": assistant})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"849c0000-551b-41ad-9054-d5b70317bba5"},"outputs":[],"source":["system_prompt = \"You are a helpful assistant. And Answers must be in Korean.\"\n","user_prompt = \"\"\"프로 테니스 대회에서 테니스 공은 한번에 6개를 사용합니다. 이 6개의 공을 처음에는 게임 수의 합이 7게임, 다음부터는 9게임마다 새 공으로 교체를 합니다.\n","만일 3세트 경기가 6:5 3:6 6:4 로 진행됐다고 하면 총 몇 개의 공을 사용했을까요?\n","답:\n","각 세트마다 게임 수를 더하면 11+9+10 = 30 으로 총 30게임이 진행됐습니다.\n","테니스 공은 7번째 교체 후 9번째 게임마다 교체되니 7,16,25 게임에 총 3회에 교체 됩니다.\n","최종적으로 경기시작 시 사용한 공 6개 + 교체 시 마다 6개의 새 공으로 교체 했으니 6 + (6 * 3) = 24, 사용된 공은 총 24개 입니다.\n","\n","질문:\n","아마추어 테니스 대회에서는 테니스공을 한번에 2개 사용합니다. 그리고 이 2개의 공을 처음에는 게임 수의 합이 7게임, 다음부터는 9게임마다 새공으로 교체를 합니다.\n","만일 3세트 경기가 6:5 5:7 6:7 로 진행됐다고 하면 총 몇 개의 공을 사용했을까요?\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"712e56a8-7d68-46cb-bb52-8c8955fb8629","outputId":"9dee2556-2f74-4230-ad5c-7ca0dd11cd1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["이 문제를 해결하려면, 각 세트의 게임 수를 더하고, 테니스 공의 교체 횟수를 계산하여야 합니다.\n","\n","각 세트의 게임 수를 더하면 다음과 같습니다.\n","6 + 5 = 11\n","5 + 7 = 12\n","7 + 7 = 14\n","총 게임 수는 11 + 12 + 14 = 37\n","\n","테니스 공은 처음에는 7 번째 게임에서 교체되고, 다음부터는 9 번째 게임마다 교체됩니다. 따라서, 총 교체 횟수는 다음과 같습니다.\n","7 번째 게임 (1 회)\n","16 번째 게임 (2 회)\n","25 번째 게임 (3 회)\n","32 번째 게임 (4 회)\n","35 번째 게임 (5 회)\n","38 번째 게임 (6 회)\n","총 교체 횟수는 6회입니다.\n","\n","각 세트의 시작 시 사용한 공 2개 + 교체 시 마다 2개의 새 공으로 교체 한 횟수 * 2 = 총 사용된 공의 개수입니다.\n","각 세트의 시작 시 사용한 공은 총 3세트 * 각 세트당 사용한 공의 개수 * 시작 시 사용한 공의 개수 = 총 시작 시 사용한 공의 개수입니다.\n","3 * (11+12+14)/9 * 2 = 시작 시 사용한 공은 총 20개입니다.\n","\n","교체 된 후에 사용된 총 공의 수는 다음과 같습니다.\n","교체 된 후에 사용된 총 공의 수는 각 세트당 시작 시 사용한 공의 개수 * 교체 된 후에 사용된 총 공의 수입니다.\n","20 + (6 * 2) = 총 사용된 공은 32개입니다.\n","\n","그러므로, 아마추어 테니스 대회에서는 이 경기에서 총 32개의 테니스공이 사용되었습니다.\n","\n","inference time: 13.37074 sec \n","\n","\n"]},{"data":{"text/plain":["'이 문제를 해결하려면, 각 세트의 게임 수를 더하고, 테니스 공의 교체 횟수를 계산하여야 합니다.\\n\\n각 세트의 게임 수를 더하면 다음과 같습니다.\\n6 + 5 = 11\\n5 + 7 = 12\\n7 + 7 = 14\\n총 게임 수는 11 + 12 + 14 = 37\\n\\n테니스 공은 처음에는 7 번째 게임에서 교체되고, 다음부터는 9 번째 게임마다 교체됩니다. 따라서, 총 교체 횟수는 다음과 같습니다.\\n7 번째 게임 (1 회)\\n16 번째 게임 (2 회)\\n25 번째 게임 (3 회)\\n32 번째 게임 (4 회)\\n35 번째 게임 (5 회)\\n38 번째 게임 (6 회)\\n총 교체 횟수는 6회입니다.\\n\\n각 세트의 시작 시 사용한 공 2개 + 교체 시 마다 2개의 새 공으로 교체 한 횟수 * 2 = 총 사용된 공의 개수입니다.\\n각 세트의 시작 시 사용한 공은 총 3세트 * 각 세트당 사용한 공의 개수 * 시작 시 사용한 공의 개수 = 총 시작 시 사용한 공의 개수입니다.\\n3 * (11+12+14)/9 * 2 = 시작 시 사용한 공은 총 20개입니다.\\n\\n교체 된 후에 사용된 총 공의 수는 다음과 같습니다.\\n교체 된 후에 사용된 총 공의 수는 각 세트당 시작 시 사용한 공의 개수 * 교체 된 후에 사용된 총 공의 수입니다.\\n20 + (6 * 2) = 총 사용된 공은 32개입니다.\\n\\n그러므로, 아마추어 테니스 대회에서는 이 경기에서 총 32개의 테니스공이 사용되었습니다.'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["messages = [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": user_prompt},\n","    ]\n","generate_response(messages)"]},{"cell_type":"markdown","source":["# Deep Search"],"metadata":{"id":"t99gIVQzSXpf"}},{"cell_type":"code","source":[],"metadata":{"id":"l9OJxJM8SY8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"af317be9-b6f6-4986-9b05-ee8a25de06e6"},"outputs":[],"source":["from tavily import TavilyClient\n","import asyncio, os, requests, time, json\n","import threading, queue\n","from IPython.display import display, Markdown, Latex\n","\n","tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09e7b2d7-3d6f-4012-8d9e-99e8e8a66d34"},"outputs":[],"source":["from openai import OpenAI\n","import math\n","import time\n","import json\n","\n","client = OpenAI(\n","    base_url=\"localhost:8877/v1\",\n","    api_key=\"token-abc123\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"802ea473-ad78-43fe-b096-84fcccecd767"},"outputs":[],"source":["from pydantic import BaseModel, Field\n","import operator\n","\n","class Section(BaseModel):\n","    name: str = Field(\n","        description=\"Name for this section of the report.\",\n","    )\n","    description: str = Field(\n","        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n","    )\n","    research: bool = Field(\n","        description=\"Whether to perform web research for this section of the report.\"\n","    )\n","    content: str = Field(\n","        description=\"The content of the section.\"\n","    )\n","    search_query: str = Field(None, description=\"Query for web search.\")\n","    query_content: str = Field(None, description=\"Content of web search.\")\n","    section_content: str = Field(None, description=\"Content of section.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7187e4d1-633c-4d42-a63a-07185476fa36"},"outputs":[],"source":["def generate_response(message_list):\n","    completion = client.chat.completions.create(\n","        model = \"Llama-3.1-8B-Instruct\",\n","        messages = message_list,\n","        max_tokens=2048,\n","        frequency_penalty=0.3,\n","        temperature=0.6,\n","        stream=True,\n","    )\n","\n","    final_answer = []\n","    assistant_response = \"\"\n","\n","    start = time.time()\n","\n","    # 스트림 모드에서는 completion.choices 를 반복문으로 순회\n","    for chunk in completion:\n","        chunk_content = chunk.choices[0].delta.content\n","\n","        if isinstance(chunk_content, str):\n","            final_answer.append(chunk_content)\n","            # 토큰 단위로 실시간 답변 출력\n","            print(chunk_content, end=\"\")\n","            assistant_response += chunk_content\n","\n","    end = time.time()\n","    print(f\"\\n\\ninference time: {end - start:.5f} sec \\n\\n\")\n","    return assistant_response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8e3ec1bb-cf1c-421c-bb6e-3ac5d2559fad"},"outputs":[],"source":["def report_planner_instructions(topic, report_organization, context, feedback):\n","    planner_writer=\"\"\"You are performing research for a report.\n","<Report topic>\n","\"\"\" + topic + \"\"\"\n","</Report topic>\n","\n","<Report organization>\n","\"\"\" + report_organization + \"\"\"\n","</Report organization>\n","\n","<Context>\n","Here is context to use to plan the sections of the report:\n","\"\"\" + context + \"\"\"\n","</Context>\n","\n","<Task>\n","Generate a list of sections for the report. Your plan should be tight and focused with NO overlapping sections or unnecessary filler.\n","\n","For example, a good report structure might look like:\n","1/ intro\n","2/ overview of topic A\n","3/ overview of topic B\n","4/ comparison between A and B\n","5/ conclusion\n","\n","Each section should have the fields:\n","\n","- Name - Name for this section of the report.\n","- Description - Brief overview of the main topics covered in this section.\n","- Research - Whether to perform web research for this section of the report.\n","- Content - The content of the section, which you will leave blank for now.\n","\n","Integration guidelines:\n","- Include examples and implementation details within main topic sections, not as separate sections\n","- Ensure each section has a distinct purpose with no content overlap\n","- Combine related concepts rather than separating them\n","\n","Before submitting, review your structure to ensure it has no redundant sections and follows a logical flow.\n","</Task>\n","\n","<Feedback>\n","Here is feedback on the report structure from review (if any):\n","\"\"\" + feedback + \"\"\"\n","</Feedback>\n","\n","Note1. that today's date is \"\"\"+time.strftime(\"%Y-%m-%d\")+\"\"\".\n","Note2. Output your response in JSON format, with the following structure: { \"sections\": [ \"section1\", \"section2\", \"section3\" ] }\n","Only output in JSON format when generating responses. Never include additional phrases such as \"here is content in JSON format\".\n","\"\"\"\n","\n","    return planner_writer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5dd2eaf-4a7c-479c-9f86-955e1bfbc2c3"},"outputs":[],"source":["def report_query_writer(topic, report_organization, num_queries):\n","    llm_prompt = \"\"\"You are performing research for a report.\n","\n","<Report topic>\n","\"\"\" + topic + \"\"\"\n","</Report topic>\n","\n","<Report organization>\n","\"\"\" + report_organization + \"\"\"\n","</Report organization>\n","\n","<Task>\n","Your goal is to generate \"\"\" + num_queries + \"\"\" web search queries that will help gather information for planning the report sections.\n","\n","The queries should:\n","\n","1. Be related to the Report topic\n","2. Help satisfy the requirements specified in the report organization\n","\n","Make the queries specific enough to find high-quality, relevant sources while covering the breadth needed for the report structure.\n","\n","Note1. that today's date is \"\"\"+time.strftime(\"%Y-%m-%d\")+\"\"\".\n","Note2. Output your response in JSON format, with the following structure: { \"queries\": [ \"query1\", \"query2\", \"query3\" ] }\n","Only output in JSON format when generating responses. Never include additional phrases such as \"here is content in JSON format\".\n","</Task>\n","\"\"\"\n","\n","    return llm_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"15a539f5-c50a-4337-b78a-71bfdab4bdab"},"outputs":[],"source":["def section_writer_inputs(topic, section_name, section_topic, context):\n","    section_writer_prompt=\"\"\"\n","<Report topic>\n","\"\"\" + topic + \"\"\"\n","</Report topic>\n","\n","<Section name>\n","\"\"\" + section_name + \"\"\"\n","</Section name>\n","\n","<Section topic>\n","\"\"\" + section_topic + \"\"\"\n","</Section topic>\n","\n","<Source material>\n","\"\"\" + context + \"\"\"\n","</Source material>\n","\"\"\"\n","    return section_writer_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb095563-f701-4681-99cd-fa10ea5a4613"},"outputs":[],"source":["def final_section_writer_instructions(topic, section_name, section_topic, context):\n","    final_writer_prompt=\"\"\"You are an expert technical writer crafting a section that synthesizes information from the rest of the report.\n","\n","<Report topic>\n","\"\"\" + topic + \"\"\"\n","</Report topic>\n","\n","<Section name>\n","\"\"\" + section_name + \"\"\"\n","</Section name>\n","\n","<Section topic>\n","\"\"\" + section_topic + \"\"\"\n","</Section topic>\n","\n","<Available report content>\n","\"\"\" + context + \"\"\"\n","</Available report content>\n","\n","<Task>\n","1. Section-Specific Approach:\n","\n","For Introduction:\n","- Use # for report title (Markdown format)\n","- 50-100 word limit\n","- Write in simple and clear language\n","- Focus on the core motivation for the report in 1-2 paragraphs\n","- Use a clear narrative arc to introduce the report\n","- Include NO structural elements (no lists or tables)\n","- No sources section needed\n","\n","For Conclusion:\n","- Use ## for section title (Markdown format)\n","- 200-300 word limit\n","- For comparative reports:\n","    * Must include a focused comparison table using Markdown table syntax\n","    * Table should distill insights from the report\n","    * Keep table entries clear and concise\n","- For non-comparative reports:\n","    * Only use ONE structural element IF it helps distill the points made in the report:\n","    * Either a focused table comparing items present in the report (using Markdown table syntax)\n","    * Or a short list using proper Markdown list syntax:\n","      - Use `*` or `-` for unordered lists\n","      - Use `1.` for ordered lists\n","      - Ensure proper indentation and spacing\n","- End with specific next steps or implications\n","- No sources section needed\n","\n","2. Writing Approach:\n","- Use concrete details over general statements\n","- Make every word count\n","- Focus on your single most important point\n","</Task>\n","\n","<Quality Checks>\n","- For introduction: 50-100 word limit, # for report title, no structural elements, no sources section\n","- For conclusion: 200-300 word limit, ## for section title, only ONE structural element at most, no sources section\n","- Markdown format\n","- Do not include word count or any preamble in your response\n","</Quality Checks>\n","\n","Please note that respond in Korean always.\"\"\"\n","\n","    return final_writer_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5a562baf-69b4-4a79-a840-699b407551bd"},"outputs":[],"source":["report_organization = \"\"\"Use this structure to create a report on the user-provided topic:\n","\n","1. Introduction (no research needed)\n","   - Brief overview of the topic area\n","\n","2. Main Body Sections:\n","   - Each section should focus on a sub-topic of the user-provided topic\n","\n","3. Conclusion\n","   - Aim for 1 structural element (either a list of table) that distills the main body sections\n","   - Provide a concise summary of the report\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31db4c38-0935-4715-9274-7b40d975f14b"},"outputs":[],"source":["section_writer_instructions = \"\"\"Write one section of a research report.\n","\n","<Task>\n","1. Review the report topic, section name, and section topic carefully.\n","2. If present, review any existing section content.\n","3. Then, look at the provided Source material.\n","4. Decide the sources that you will use it to write a report section.\n","5. Write the report section and list your sources.\n","</Task>\n","\n","<Writing Guidelines>\n","- If existing section content is not populated, write from scratch\n","- If existing section content is populated, synthesize it with the source material\n","- Strict 150-200 word limit\n","- Use simple, clear language\n","- Use short paragraphs (2-3 sentences max)\n","- Use ## for section title (Markdown format)\n","</Writing Guidelines>\n","\n","<Citation Rules>\n","- Assign each unique URL a single citation number in your text\n","- End with ### Sources that lists each source with corresponding numbers\n","- IMPORTANT: Number sources sequentially without gaps (1,2,3,4...) in the final list regardless of which sources you choose\n","- Example format:\n","  [1] Source Title: URL\n","  [2] Source Title: URL\n","</Citation Rules>\n","\n","<Final Check>\n","1. Verify that EVERY claim is grounded in the provided Source material\n","2. Confirm each URL appears ONLY ONCE in the Source list\n","3. Verify that sources are numbered sequentially (1,2,3...) without any gaps\n","</Final Check>\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f915b96a-a771-49e2-8056-91d4d435cd4b"},"outputs":[],"source":["def worker(query, search_result, req_num_result, include_raw, req_topic):\n","    print(f\"Thread: {query}\")\n","    search_result.append(\n","        tavily_client.search(\n","            query,\n","            max_results= req_num_result,\n","            include_raw_content= include_raw,\n","            topic= req_topic\n","        )\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f27acce1-9f64-46af-8fb6-752fdb5f69b8"},"outputs":[],"source":["def ask_tavily(search_queries, search_tasks, req_num_result, include_raw, req_topic, opt_print=True):\n","    if opt_print:\n","        print(\"\\nRun ask_tavily task: \\n\")\n","\n","    threads = []\n","    start_time = time.time()\n","\n","    for query in search_queries:\n","        t = threading.Thread(target=worker, args=(query, search_tasks, req_num_result, include_raw, req_topic))\n","        threads.append(t)\n","        t.start()\n","\n","    for thread in threads:\n","        thread.join()\n","\n","    end_time = time.time()\n","    execution_time = end_time - start_time\n","\n","    if opt_print:\n","        print(f\"\\nask_tavily task running time: {execution_time:.2f}초 \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb72fc1e-d5eb-44ae-966e-7aeb00c21bb4"},"outputs":[],"source":["def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):\n","     # Collect all results\n","    sources_list = []\n","    for response in search_response:\n","        sources_list.extend(response['results'])\n","\n","    # Deduplicate by URL\n","    unique_sources = {source['url']: source for source in sources_list}\n","\n","    # Format output\n","    formatted_text = \"Content from sources:\\n\"\n","    for i, source in enumerate(unique_sources.values(), 1):\n","        formatted_text += f\"{'='*80}\\n\"  # Clear section separator\n","        formatted_text += f\"Source: {source['title']}\\n\"\n","        formatted_text += f\"{'-'*80}\\n\"  # Subsection separator\n","        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n","        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n","        if include_raw_content:\n","            # Using rough estimate of 4 characters per token\n","            char_limit = max_tokens_per_source * 2\n","            # Handle None raw_content\n","            raw_content = source.get('raw_content', '')\n","            if raw_content is None:\n","                raw_content = ''\n","                print(f\"Warning: No raw_content found for source {source['url']}\")\n","            if len(raw_content) > char_limit:\n","                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n","            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n","        formatted_text += f\"{'='*80}\\n\\n\" # End section separator\n","\n","    return formatted_text.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f96e90b0-74fd-4ea5-be28-2544492488a5"},"outputs":[],"source":["def web_search_worker(section: Section, opt_print=False):\n","    print(f\"Thread: {section}\")\n","\n","    if section.research:\n","        section_query_prompt = report_query_writer(section.name, section.description, \"3\")\n","\n","        messages = [\n","            {\"role\": \"system\", \"content\": section_query_prompt},\n","            {\"role\": \"user\", \"content\": \"Generate search queries on the provided topic.\"},\n","        ]\n","\n","        response_section_queries = generate_response(messages)\n","\n","        json_data = json.loads(response_section_queries)\n","        queries = json_data['queries']\n","\n","        section.search_query = queries\n","\n","        search_tasks = []\n","        req_topic = 'general' # news   gerneral 과 news 중 선택\n","        req_num_result = 2    # 각 web query 에 대해 리턴할 site 개수\n","        include_raw = True    # site 의 원본 컨텐츠 리턴 유무\n","\n","        ask_tavily(queries, search_tasks, req_num_result, include_raw, req_topic, opt_print)\n","        source_str = deduplicate_and_format_sources(search_tasks, max_tokens_per_source=2000, include_raw_content=True)\n","        section.query_content = source_str\n","\n","        messages = [\n","            {\"role\": \"system\", \"content\": section_writer_instructions},\n","            {\"role\": \"user\", \"content\": section_writer_inputs(topic, section.name, section.description, source_str)},\n","        ]\n","        section.section_content = generate_response(messages)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82f26101-f94f-49af-b222-a070d04aa20d"},"outputs":[],"source":["def final_section_writer_worker(section: Section, opt_print=True):\n","    user_prompt = \"Generate a report section based on the provided sources.\"\n","    final_section_writer_instructions(topic, section.name, section.description, source_str)\n","\n","    messages = [\n","        {\"role\": \"system\", \"content\": final_section_writer_instructions},\n","        {\"role\": \"user\", \"content\": user_prompt}\n","    ]\n","\n","    section.section_content = generate_response(messages)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"afa5a365-3ad0-4745-8735-b2fc15dbc765"},"outputs":[],"source":["topic = \"MCP(model context protocol) 과 A2A(Agent to Agent) 는 어떤 차이가 있는것인지 알려줘.\"\n","num_queries = \"3\"\n","model_id = 102\n","report_planner_query_prompt = report_query_writer(topic, report_organization, num_queries)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ea948e2-f58a-4175-b808-88fe0a9412fb","outputId":"ac303208-f1e7-47ea-9f04-d592792534a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"queries\": [\n","    \"MCP vs A2A protocol differences in communication systems\",\n","    \"Comparison of MCP and A2A protocols in agent-to-agent communication\",\n","    \"Key features and applications of MCP and A2A protocols in model context\"\n","  ]\n","}\n","\n","inference time: 1.92460 sec \n","\n","\n","사용자 발화 기반으로 추출한 web query 문장 3건:\n","['MCP vs A2A protocol differences in communication systems', 'Comparison of MCP and A2A protocols in agent-to-agent communication', 'Key features and applications of MCP and A2A protocols in model context']\n"]}],"source":["user_prompt = \"Generate search queries that will help with planning the sections of the report.\"\n","messages = [\n","    {\"role\": \"system\", \"content\": report_planner_query_prompt},\n","    {\"role\": \"user\", \"content\": user_prompt}\n","]\n","\n","response_query = generate_response(messages)\n","\n","json_data = json.loads(response_query)\n","queries = json_data['queries']\n","\n","print(\"사용자 발화 기반으로 추출한 web query 문장 3건:\")\n","print(queries)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"affbae24-f9c8-4957-a3a5-89e9ba61b4f5","outputId":"db5cb9bc-8860-45ab-aa6c-dc470f9fa4a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Run ask_tavily task: \n","\n","Thread: MCP vs A2A protocol differences in communication systems\n","Thread: Comparison of MCP and A2A protocols in agent-to-agent communication\n","Thread: Key features and applications of MCP and A2A protocols in model context\n","\n","ask_tavily task running time: 2.76초 \n","\n"]}],"source":["search_tasks = []\n","req_topic = 'general' # news   gerneral 과 news 중 선택\n","req_num_result = 2    # 각 web query 에 대해 리턴할 site 개수\n","include_raw = False    # site 의 원본 컨텐츠 리턴 유무\n","\n","ask_tavily(queries, search_tasks, req_num_result, include_raw, req_topic)\n","source_str = deduplicate_and_format_sources(search_tasks, max_tokens_per_source=2000, include_raw_content=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7f263d81-0014-4360-a51d-13c50fea7007","outputId":"72391584-18f2-45d0-e74c-30d9530a7eb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are performing research for a report. \n","<Report topic>\n","MCP(model context protocol) 과 A2A(Agent to Agent) 는 어떤 차이가 있는것인지 알려줘.\n","</Report topic>\n","\n","<Report organization>\n","Use this structure to create a report on the user-provided topic:\n","\n","1. Introduction (no research needed)\n","   - Brief overview of the topic area\n","\n","2. Main Body Sections:\n","   - Each section should focus on a sub-topic of the user-provided topic\n","   \n","3. Conclusion\n","   - Aim for 1 structural element (either a list of table) that distills the main body sections \n","   - Provide a concise summary of the report\n","</Report organization>\n","    \n","<Context>\n","Here is context to use to plan the sections of the report: \n","Content from sources:\n","================================================================================\n","Source: A2A vs MCP: key difference - by fulliron\n","--------------------------------------------------------------------------------\n","URL: https://fulliron.substack.com/p/a2a-vs-mcp-key-difference\n","===\n","Most relevant content from source: Full Iron Substack A2A vs MCP: key difference Full Iron Substack A2A vs MCP: key difference The key differences between **A2A (Agent-to-Agent Protocol)** and **MCP (Model Context Protocol)** lie in their focus and functionality: In summary, A2A focuses on agent collaboration, while MCP standardizes how models interact with external resources. [4] Make Your Agentic Applications More Powerful With MCP (Model Context Protocol) https://www.linkedin.com/pulse/make-your-agentic-applications-more-powerful-mcp-model-belagatti-ll7cc [5] AI Spotlight: MCP (Model Context Protocol) and Agentic AI systems https://www.gravitee.io/blog/mcp-model-context-protocol-agentic-ai https://ai.stackexchange.com/questions/26289/what-are-the-differences-between-an-agent-and-a-model [7] The Dawn of Agentic DevOps: Understanding Model Context Protocol (MCP) https://www.linkedin.com/pulse/dawn-agentic-devops-understanding-model-context-protocol-gourav-shah-wjqjc [8] PydanticAI Agents vs Model Context Protocol (MCP) Subscribe to Full Iron Substack Full Iron Substack A2A vs MCP: key difference Click the link we sent to , or click here to sign in.\n","===\n","================================================================================\n","\n","================================================================================\n","Source: Agent-to-Agent (A2A) vs Model Context Protocol (MCP)\n","--------------------------------------------------------------------------------\n","URL: https://shieldbase.ai/blog/agent-to-agent-(a2a)-vs-model-context-protocol-(mcp)\n","===\n","Most relevant content from source: Two approaches have gained prominence in this new frontier: Agent-to-Agent (A2A) communication and Model Context Protocol (MCP). While both aim to orchestrate multiple AI models or agents to solve enterprise-grade problems, they do so in fundamentally different ways.\n","===\n","================================================================================\n","\n","================================================================================\n","Source: Agents Today #15 - AI Agent Interoperability: Head-to-Head with MCP and A2A\n","--------------------------------------------------------------------------------\n","URL: https://agentstoday.substack.com/p/agents-today-15-ai-agent-interoperability\n","===\n","Most relevant content from source: Taking a look at how can AI agents could effectively work with tools, data sources, and other agents using Anthropic MCP and the newly announced Google A2A protocols While MCP focuses on connecting AI models to external tools and data, A2A aims to enable seamless communication between agents themselves. MCP provides the foundation—connecting agents to the data and tools they need—while A2A builds on this by enabling agents to collaborate with each other. While MCP addresses how agents connect to tools and data, Google's A2A protocol focuses on a different challenge: how agents communicate with each other. These complementary protocols address different aspects of the interoperability challenge: MCP connects agents to tools and data, while A2A enables agents to communicate with each other.\n","===\n","================================================================================\n","\n","================================================================================\n","Source: Model Context Protocol (MCP): The Key To Agentic AI\n","--------------------------------------------------------------------------------\n","URL: https://medium.com/@jalajagr/model-context-protocol-mcp-the-key-to-agentic-ai-a26eaf19050e\n","===\n","Most relevant content from source: Stories Member-only story Model Context Protocol (MCP): The Key To Agentic AI Jalaj Agrawal MCP, or Model Context Protocol, is a framework that allows AI models to retrieve and process external context — from databases to files and APIs. The name itself reveals its core purpose: If you ask an AI to verify the sum of orders in an SQLite database and match it with a PowerPoint presentation, the model alone can’t do it — it needs access to those files and databases. MCP solves this problem by acting as a middleware layer, allowing AI models to: This means richer responses, deeper integrations, and more intelligent AI-powered applications. An AI enthusiast exploring intersection of ML, LLM, personalized experiences, human-centric design. No responses yet\n","===\n","================================================================================\n","\n","================================================================================\n","Source: Model Context Protocol (MCP): Integrating Azure OpenAI for Enhanced ...\n","--------------------------------------------------------------------------------\n","URL: https://techcommunity.microsoft.com/blog/azure-ai-services-blog/model-context-protocol-mcp-integrating-azure-openai-for-enhanced-tool-integratio/4393788\n","===\n","Most relevant content from source: Ultimately, MCP aims to transform AI Agents from isolated chatbots into context-aware, interoperable systems deeply integrated into digital environments. Key elements from the Model Context Protocol: Standardization: MCP provides a standardized way for language models to interact with tools, promoting interoperability.\n","===\n","================================================================================\n","</Context>\n","\n","<Task>\n","Generate a list of sections for the report. Your plan should be tight and focused with NO overlapping sections or unnecessary filler. \n","\n","For example, a good report structure might look like:\n","1/ intro\n","2/ overview of topic A\n","3/ overview of topic B\n","4/ comparison between A and B\n","5/ conclusion\n","\n","Each section should have the fields:\n","\n","- Name - Name for this section of the report.\n","- Description - Brief overview of the main topics covered in this section.\n","- Research - Whether to perform web research for this section of the report.\n","- Content - The content of the section, which you will leave blank for now.\n","\n","Integration guidelines:\n","- Include examples and implementation details within main topic sections, not as separate sections\n","- Ensure each section has a distinct purpose with no content overlap\n","- Combine related concepts rather than separating them\n","\n","Before submitting, review your structure to ensure it has no redundant sections and follows a logical flow.\n","</Task>\n","\n","<Feedback>\n","Here is feedback on the report structure from review (if any):\n","\n","</Feedback>\n","\n","Note1. that today's date is 2025-04-12.\n","Note2. Output your response in JSON format, with the following structure: { \"sections\": [ \"section1\", \"section2\", \"section3\" ] }\n","Only output in JSON format when generating responses. Never include additional phrases such as \"here is content in JSON format\".\n","\n"]}],"source":["feedback = \"\"\n","planner_writer_prompt = report_planner_instructions(topic, report_organization, source_str, feedback)\n","print(planner_writer_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67c70fe7-d9b1-456c-90d3-13dddefa94f9","outputId":"9d2b6170-2e4f-4d97-fd5f-74a26e7ab6e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"sections\": [\n","    {\n","      \"name\": \"Introduction\",\n","      \"description\": \"Brief overview of the topic area\",\n","      \"research\": false,\n","      \"content\": \"\"\n","    },\n","    {\n","      \"name\": \"Overview of A2A (Agent-to-Agent Protocol)\",\n","      \"description\": \"Focus on agent collaboration and functionality\",\n","      \"research\": true,\n","      \"content\": \"\"\n","    },\n","    {\n","      \"name\": \"Overview of MCP (Model Context Protocol)\",\n","      \"description\": \"Standardization of how models interact with external resources\",\n","      \"research\": true,\n","      \"content\": \"\"\n","    },\n","    {\n","      \"name\": \"Comparison between A2A and MCP\",\n","      \"description\": \"Key differences and complementary protocols\",\n","      \"research\": true,\n","      \"content\": \"\"\n","    },\n","    {\n","      \"name\": \"Conclusion\",\n","      \"description\": \"\",\n","      \"research\": false,\n","      \"content\": \"\"\n","    }\n","  ]\n","}\n","\n","inference time: 7.00290 sec \n","\n","\n"]}],"source":["plan_user_prompt = \"\"\"Generate the sections of the report. Your response must include a 'sections' field containing a list of sections.\n","                      Each section must have: name, description, research and content fields.\n","                      You must not add anything other than these fields under any circumstances.\"\"\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": planner_writer_prompt},\n","    {\"role\": \"user\", \"content\": plan_user_prompt}\n","]\n","\n","response_planner = generate_response(messages)\n","\n","json_planner_data = json.loads(response_planner)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7fad2b6a-0b32-4b75-8f52-26a0bb20be55","outputId":"9fd7bd1f-534d-4c3a-885c-e4edd18408a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[\n","    {\n","        \"name\": \"Introduction\",\n","        \"description\": \"Brief overview of the topic area\",\n","        \"research\": false,\n","        \"content\": \"\"\n","    },\n","    {\n","        \"name\": \"Overview of A2A (Agent-to-Agent Protocol)\",\n","        \"description\": \"Focus on agent collaboration and functionality\",\n","        \"research\": true,\n","        \"content\": \"\"\n","    },\n","    {\n","        \"name\": \"Overview of MCP (Model Context Protocol)\",\n","        \"description\": \"Standardization of how models interact with external resources\",\n","        \"research\": true,\n","        \"content\": \"\"\n","    },\n","    {\n","        \"name\": \"Comparison between A2A and MCP\",\n","        \"description\": \"Key differences and complementary protocols\",\n","        \"research\": true,\n","        \"content\": \"\"\n","    },\n","    {\n","        \"name\": \"Conclusion\",\n","        \"description\": \"\",\n","        \"research\": false,\n","        \"content\": \"\"\n","    }\n","]\n"]}],"source":["plan_from_llm = json_planner_data['sections']\n","print(json.dumps(plan_from_llm, indent=4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fd78a78e-265c-49a8-973a-03d934e31082"},"outputs":[],"source":["report_sections = []\n","\n","for part in plan_from_llm:\n","    section = Section(\n","        name=part['name'],\n","        description=part['description'],\n","        content=part['content'],\n","        research=part['research']\n","    )\n","    report_sections.append(section)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cef6d502-0bc6-4484-b238-525c3c221e17","outputId":"2ead816d-62ae-4e71-d84f-df240de34cb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["name='Introduction' description='Brief overview of the topic area' research=False content='' search_query=None query_content=None section_content=None \n","\n","name='Overview of A2A (Agent-to-Agent Protocol)' description='Focus on agent collaboration and functionality' research=True content='' search_query=None query_content=None section_content=None \n","\n","name='Overview of MCP (Model Context Protocol)' description='Standardization of how models interact with external resources' research=True content='' search_query=None query_content=None section_content=None \n","\n","name='Comparison between A2A and MCP' description='Key differences and complementary protocols' research=True content='' search_query=None query_content=None section_content=None \n","\n","name='Conclusion' description='' research=False content='' search_query=None query_content=None section_content=None \n","\n"]}],"source":["for section in report_sections:\n","    print(f'{section} \\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00feeb50-0ffd-4a3a-9d53-ea2e192cf094","outputId":"896bee48-39d1-4405-edca-17dbd77dfa67"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thread: name='Introduction' description='Brief overview of the topic area' research=False content='' search_query=None query_content=None section_content=None\n","Thread: name='Overview of A2A (Agent-to-Agent Protocol)' description='Focus on agent collaboration and functionality' research=True content='' search_query=None query_content=None section_content=None\n","Thread: name='Overview of MCP (Model Context Protocol)' description='Standardization of how models interact with external resources' research=True content='' search_query=None query_content=None section_content=None\n","Thread: name='Comparison between A2A and MCP' description='Key differences and complementary protocols' research=True content='' search_query=None query_content=None section_content=None\n","Thread: name='Conclusion' description='' research=False content='' search_query=None query_content=None section_content=None\n","{\n","{\n"," {\n","   \" \"queries \"queriesqueries\":\":\": [\n"," [\n"," [\n","       \"    \" \"AAM2A2CPA protocol model context agent vs MCP protocol collaboration standard communication techniques protocolsization for framework: enhanced architecture key functionality differences\",\n","\",\n","    in    implementation \" \" andModelAgent Context application-to Protocol\",\n","-Agent    interaction protocol \" with architectureComparison external and of design resources best A principles2 practices for\",\n","A effective and    collaboration MCP \"\",\n"," protocolsM   :CP \" protocol protocolCompar stacks implementationative analysis guidelines and for architectural of model differences A deployment\",\n","2 and   A \" integration protocol\"\n"," featuresA2  and ]\n"," capabilitiesA and} in\n","\n","inference time: 1.83319 sec \n","\n","\n","\n","Run ask_tavily task: \n","\n","Thread: MCP model context protocol standardization framework architecture\n"," MCPThread: Model Context Protocol interaction with external resources best practices\n"," multiThread: MCP protocol implementation guidelines for model deployment and integration\n"," communication-agent protocols systems:\"\n"," complementary  use ]\n"," cases} and\n","\n","inference time: 2.08370 sec \n","\n","\n","\n","Run ask_tavily task: \n","\n","Thread: A2A protocol agent collaboration techniques for enhanced functionality\n","Thread: Agent-to-Agent protocol architecture and design principles for effective collaboration\n","Thread: Comparative analysis of A2A protocol features and capabilities in multi-agent systems\n"," scenarios in modern systems\"\n","  ]\n","}\n","\n","inference time: 2.38542 sec \n","\n","\n","\n","Run ask_tavily task: \n","\n","Thread: A2A vs MCP communication protocols: key differences in implementation and application\n","Thread: Comparison of A2A and MCP protocols: protocol stacks and architectural differences\n","Thread: A2A and MCP communication protocols: complementary use cases and scenarios in modern systems\n","\n","ask_tavily task running time: 2.03초 \n","\n","\n","ask_tavily task running time: 2.70초 \n","\n","Warning: No raw_content found for source https://modelcontextprotocol.info/specification/\n","##"]},{"name":"stderr","output_type":"stream","text":["Exception in thread Thread-11:\n","Traceback (most recent call last):\n","  File \"/home/freenak/miniconda3/envs/plug_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n","    self.run()\n","  File \"/home/freenak/miniconda3/envs/plug_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n","    _threading_Thread_run(self)\n","  File \"/home/freenak/miniconda3/envs/plug_env/lib/python3.9/threading.py\", line 917, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/tmp/ipykernel_49922/3898379593.py\", line 32, in web_search_worker\n","  File \"/tmp/ipykernel_49922/1369138122.py\", line 2, in generate_response\n","  File \"/home/freenak/miniconda3/envs/plug_env/lib/python3.9/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/home/freenak/miniconda3/envs/plug_env/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\", line 914, in create\n","    return self._post(\n","  File \"/home/freenak/miniconda3/envs/plug_env/lib/python3.9/site-packages/openai/_base_client.py\", line 1242, in post\n","    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n","  File \"/home/freenak/miniconda3/envs/plug_env/lib/python3.9/site-packages/openai/_base_client.py\", line 919, in request\n","    return self._request(\n","  File \"/home/freenak/miniconda3/envs/plug_env/lib/python3.9/site-packages/openai/_base_client.py\", line 1023, in _request\n","    raise self._make_status_error_from_response(err.response) from None\n","openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 8192 tokens. However, you requested 9490 tokens (7442 in the messages, 2048 in the completion). Please reduce the length of the messages or completion.\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n"]},{"name":"stdout","output_type":"stream","text":["\n","ask_tavily task running time: 3.15초 \n","\n","Warning: No raw_content found for source https://www.theriseunion.com/blog/MCP-vs-A2A.html\n"," Overview of## A2 Overview ofA MCP ( (AgentModel-to Context-Agent Protocol Protocol)\n","\n",")\n","TheThe Model Agent Context-to Protocol-Agent ( (MACP2)A is) a protocol standardized is protocol an designed open to standard enhance developed the by interaction Google between to Large enable Language communication Models and ( collaborationLL betweenMs autonomous) agents and, applications regardless by of their providing structured underlying context frameworks management or. vendors MCP. takes This some protocol inspiration aims from to the simplify Language enterprise Server agent Protocol integration, and which address standard theizes current how lack to of add agent support interoper forability programming.\n","\n"," languages### across Key a Features whole\n","\n"," ecosystem* of   development Dynamic tools,.\n","\n"," multimModalCP communication standard betweenizes different how agents to without integrate sharing additional memory context, and resources tools, into and the tools ecosystem\n"," of* AI   applications Open. standard It driven enables by powerful community capabilities\n"," through* arbitrary   data Supports access key and enterprise code requirements execution, paths including. capability Host discoverys, must user obtain experience explicit negotiation user, consent task before and exposing state user management data, to and servers secure, collaboration and\n"," hosts* must   not Emp transmitowers resource developers data to elsewhere build without agents user capable consent of.\n","\n"," connectingThe with protocol any uses other JSON agent-R builtPC using  the2 protocol.\n","0* messages   to Offers establish users communication the between flexibility hosts to, combine clients agents, from and various servers providers.\n","\n"," Host###s Comparison are with L MCPLM ( applicationsModel that Context initiate Protocol connections)\n","\n",",While clients MCP are provides connectors helpful within tools the and host context application to, agents and, A servers are2 servicesA that focuses provide on context agent and-agent capabilities collaboration.\n","\n"," and[ communication1.] MCP https connects:// agentsmodel tocontext toolsprotocol,.io APIs/docs,/con andcepts resources/arch withitecture structured\n"," inputs[/2outputs], https whereas:// Atech2communityA.microsoft enables.com dynamic/blog communication/ betweeneduc independentator AIdeveloper agentsblog.\n","\n","/un###le Adoptionashing and-the Community-power Support-of\n","\n","-modelThe-context A-2protocolA-m protocolcp has-a gained-game significant-ch tractionanger,-in with- overai -int50egr technologyat partners/ contributing439 to756 its4 development\n",".[ The3 open]-source https project:// ismodel runcontext byprotocol Google.info LLC/docs and/con iscepts open/resources to/\n"," contributions[ from4 the] entire https community://.\n","\n","model###context Realprotocol-.infoWorld/spec Applicationsification\n","\n","/\n","The[ A52]A https protocol:// hasspec the.model potentialcontext toprotocol revolution.ioize/spec multiification-agent/ AI202 systems4 by- providing11 a- standardized05 way/ for AI\n","\n","inference time: 12.32576 sec \n","\n","\n"," agents to communicate. This can lead to increased autonomy, productivity gains, and reduced long-term costs.\n","\n","### Conclusion\n","\n","In conclusion, the A2A protocol is a significant step towards enabling seamless collaboration between autonomous agents. Its open standard nature, community-driven development, and wide adoption make it an exciting development in the field of AI.\n","\n","### Sources:\n","[1] Agent2Agent Protocol: https://google.github.io/A2A/\n","[2] Announcing the Agent2Agent Protocol (A2A) - Google Developers Blog: https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/\n","[3] GitHub - google/A2A: An open protocol enabling communication and interoperability between opaque agentic applications.: https://github.com/google/A2A\n","[4] Meet Google A2A: The Protocol That will Revolutionize Multi-Agent AI Systems | by Manoj Desai | Apr, 2025 | Medium: https://medium.com/@the_manoj_desai/meet-google-a2a-the-protocol-that-will-revolutionize-multi-agent-ai-systems-80d55a4583ed\n","\n","inference time: 20.92519 sec \n","\n","\n","실행 시간: 25.13초\n"]}],"source":["start_time = time.time()\n","threads = []\n","\n","for section in report_sections:\n","    t = threading.Thread(target=web_search_worker, args=(section, True,))\n","    threads.append(t)\n","    t.start()\n","\n","for thread in threads:\n","    thread.join()\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","\n","print(f\"실행 시간: {execution_time:.2f}초\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2c4cc1aa-e849-4cdd-9b7a-96fcc7ac5918","outputId":"4dab5e78-0350-45c4-deab-3f8703cfaf73"},"outputs":[{"name":"stdout","output_type":"stream","text":["section.name: Introduction\n","section.description: Brief overview of the topic area\n","section.search_query: \n","None\n","section.section_content: \n","None\n","====================================\n","section.name: Overview of A2A (Agent-to-Agent Protocol)\n","section.description: Focus on agent collaboration and functionality\n","section.search_query: \n","['A2A protocol agent collaboration techniques for enhanced functionality', 'Agent-to-Agent protocol architecture and design principles for effective collaboration', 'Comparative analysis of A2A protocol features and capabilities in multi-agent systems']\n","section.section_content: \n","## Overview of A2A (Agent-to-Agent Protocol)\n","The Agent-to-Agent (A2A) protocol is an open standard developed by Google to enable communication and collaboration between autonomous agents, regardless of their underlying frameworks or vendors. This protocol aims to simplify enterprise agent integration and address the current lack of agent interoperability.\n","\n","### Key Features\n","\n","*   Dynamic, multimodal communication between different agents without sharing memory, resources, and tools\n","*   Open standard driven by community\n","*   Supports key enterprise requirements, including capability discovery, user experience negotiation, task and state management, and secure collaboration\n","*   Empowers developers to build agents capable of connecting with any other agent built using the protocol\n","*   Offers users the flexibility to combine agents from various providers\n","\n","### Comparison with MCP (Model Context Protocol)\n","\n","While MCP provides helpful tools and context to agents, A2A focuses on agent-agent collaboration and communication. MCP connects agents to tools, APIs, and resources with structured inputs/outputs, whereas A2A enables dynamic communication between independent AI agents.\n","\n","### Adoption and Community Support\n","\n","The A2A protocol has gained significant traction, with over 50 technology partners contributing to its development. The open-source project is run by Google LLC and is open to contributions from the entire community.\n","\n","### Real-World Applications\n","\n","The A2A protocol has the potential to revolutionize multi-agent AI systems by providing a standardized way for AI agents to communicate. This can lead to increased autonomy, productivity gains, and reduced long-term costs.\n","\n","### Conclusion\n","\n","In conclusion, the A2A protocol is a significant step towards enabling seamless collaboration between autonomous agents. Its open standard nature, community-driven development, and wide adoption make it an exciting development in the field of AI.\n","\n","### Sources:\n","[1] Agent2Agent Protocol: https://google.github.io/A2A/\n","[2] Announcing the Agent2Agent Protocol (A2A) - Google Developers Blog: https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/\n","[3] GitHub - google/A2A: An open protocol enabling communication and interoperability between opaque agentic applications.: https://github.com/google/A2A\n","[4] Meet Google A2A: The Protocol That will Revolutionize Multi-Agent AI Systems | by Manoj Desai | Apr, 2025 | Medium: https://medium.com/@the_manoj_desai/meet-google-a2a-the-protocol-that-will-revolutionize-multi-agent-ai-systems-80d55a4583ed\n","====================================\n","section.name: Overview of MCP (Model Context Protocol)\n","section.description: Standardization of how models interact with external resources\n","section.search_query: \n","['MCP model context protocol standardization framework architecture', 'Model Context Protocol interaction with external resources best practices', 'MCP protocol implementation guidelines for model deployment and integration']\n","section.section_content: \n","## Overview of MCP (Model Context Protocol)\n","\n","The Model Context Protocol (MCP) is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and applications by providing structured context management. MCP takes some inspiration from the Language Server Protocol, which standardizes how to add support for programming languages across a whole ecosystem of development tools.\n","\n","MCP standardizes how to integrate additional context and tools into the ecosystem of AI applications. It enables powerful capabilities through arbitrary data access and code execution paths. Hosts must obtain explicit user consent before exposing user data to servers, and hosts must not transmit resource data elsewhere without user consent.\n","\n","The protocol uses JSON-RPC 2.0 messages to establish communication between hosts, clients, and servers. Hosts are LLM applications that initiate connections, clients are connectors within the host application, and servers are services that provide context and capabilities.\n","\n","[1] https://modelcontextprotocol.io/docs/concepts/architecture\n","[2] https://techcommunity.microsoft.com/blog/educatordeveloperblog/unleashing-the-power-of-model-context-protocol-mcp-a-game-changer-in-ai-integrat/4397564\n","[3] https://modelcontextprotocol.info/docs/concepts/resources/\n","[4] https://modelcontextprotocol.info/specification/\n","[5] https://spec.modelcontextprotocol.io/specification/2024-11-05/\n","====================================\n","section.name: Comparison between A2A and MCP\n","section.description: Key differences and complementary protocols\n","section.search_query: \n","['A2A vs MCP communication protocols: key differences in implementation and application', 'Comparison of A2A and MCP protocols: protocol stacks and architectural differences', 'A2A and MCP communication protocols: complementary use cases and scenarios in modern systems']\n","section.section_content: \n","None\n","====================================\n","section.name: Conclusion\n","section.description: \n","section.search_query: \n","None\n","section.section_content: \n","None\n","====================================\n"]}],"source":["for section in report_sections:\n","    print(\"section.name: \" + section.name)\n","    print(\"section.description: \" + section.description)\n","    print(\"section.search_query: \")\n","    print(section.search_query)\n","    print(\"section.section_content: \")\n","    print(section.section_content)\n","    print(\"====================================\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5e3bd5d-e11d-4d66-ad4a-e865e5cc66a4","outputId":"f4c90e72-0ec5-4067-c179-4aad28cffb7e"},"outputs":[{"data":{"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["## Overview of A2A (Agent-to-Agent Protocol)\n","The Agent-to-Agent (A2A) protocol is an open standard developed by Google to enable communication and collaboration between autonomous agents, regardless of their underlying frameworks or vendors. This protocol aims to simplify enterprise agent integration and address the current lack of agent interoperability.\n","\n","### Key Features\n","\n","*   Dynamic, multimodal communication between different agents without sharing memory, resources, and tools\n","*   Open standard driven by community\n","*   Supports key enterprise requirements, including capability discovery, user experience negotiation, task and state management, and secure collaboration\n","*   Empowers developers to build agents capable of connecting with any other agent built using the protocol\n","*   Offers users the flexibility to combine agents from various providers\n","\n","### Comparison with MCP (Model Context Protocol)\n","\n","While MCP provides helpful tools and context to agents, A2A focuses on agent-agent collaboration and communication. MCP connects agents to tools, APIs, and resources with structured inputs/outputs, whereas A2A enables dynamic communication between independent AI agents.\n","\n","### Adoption and Community Support\n","\n","The A2A protocol has gained significant traction, with over 50 technology partners contributing to its development. The open-source project is run by Google LLC and is open to contributions from the entire community.\n","\n","### Real-World Applications\n","\n","The A2A protocol has the potential to revolutionize multi-agent AI systems by providing a standardized way for AI agents to communicate. This can lead to increased autonomy, productivity gains, and reduced long-term costs.\n","\n","### Conclusion\n","\n","In conclusion, the A2A protocol is a significant step towards enabling seamless collaboration between autonomous agents. Its open standard nature, community-driven development, and wide adoption make it an exciting development in the field of AI.\n","\n","### Sources:\n","[1] Agent2Agent Protocol: https://google.github.io/A2A/\n","[2] Announcing the Agent2Agent Protocol (A2A) - Google Developers Blog: https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/\n","[3] GitHub - google/A2A: An open protocol enabling communication and interoperability between opaque agentic applications.: https://github.com/google/A2A\n","[4] Meet Google A2A: The Protocol That will Revolutionize Multi-Agent AI Systems | by Manoj Desai | Apr, 2025 | Medium: https://medium.com/@the_manoj_desai/meet-google-a2a-the-protocol-that-will-revolutionize-multi-agent-ai-systems-80d55a4583ed"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["## Overview of MCP (Model Context Protocol)\n","\n","The Model Context Protocol (MCP) is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and applications by providing structured context management. MCP takes some inspiration from the Language Server Protocol, which standardizes how to add support for programming languages across a whole ecosystem of development tools.\n","\n","MCP standardizes how to integrate additional context and tools into the ecosystem of AI applications. It enables powerful capabilities through arbitrary data access and code execution paths. Hosts must obtain explicit user consent before exposing user data to servers, and hosts must not transmit resource data elsewhere without user consent.\n","\n","The protocol uses JSON-RPC 2.0 messages to establish communication between hosts, clients, and servers. Hosts are LLM applications that initiate connections, clients are connectors within the host application, and servers are services that provide context and capabilities.\n","\n","[1] https://modelcontextprotocol.io/docs/concepts/architecture\n","[2] https://techcommunity.microsoft.com/blog/educatordeveloperblog/unleashing-the-power-of-model-context-protocol-mcp-a-game-changer-in-ai-integrat/4397564\n","[3] https://modelcontextprotocol.info/docs/concepts/resources/\n","[4] https://modelcontextprotocol.info/specification/\n","[5] https://spec.modelcontextprotocol.io/specification/2024-11-05/"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["for section in report_sections:\n","    display(Markdown(section.section_content))"]}]}