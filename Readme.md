# 자연어 처리 노트북
---
<b>Directories</b>
* gpt generations
  - gpt-3 text generation
* Text Analysis
  - 기본적인 텍스트 분석 기법
* Transformers
  - pytorch Transformer 구조 모델 연구
* rlhl
  - gpt 강화학습 연구
* LLM parallelism
  - 병렬처리를 통한 LLM 서비스 연구
---

> Reading Pappers \
[Evolutionary Optimization of Model Merging Recipes](https://arxiv.org/pdf/2403.13187) \
[AVATAR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval](https://arxiv.org/pdf/2406.11200v2)



> Read Pappers \
[CoMPM: Context Modeling with Speaker’s Pre-trained Memory Tracking for Emotion Recognition in Conversation](https://arxiv.org/pdf/2108.11626.pdf) \
[Persona-Knowledge Dialogue Multi-Context Retrieval and Enhanced Decoding Methods](https://arxiv.org/pdf/2207.13919.pdf)\
[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf)\
[Few-Shot Parameter-Efficient Fine-Tuning is Betterand Cheaper than In-Context Learning](https://arxiv.org/pdf/2205.05638.pdf)\
[Few-shot Natural Language Generation for Task-Oriented Dialog](https://aclanthology.org/2020.findings-emnlp.17.pdf)\
[Towards a Human-like Open-Domain Chatbot](https://arxiv.org/pdf/2001.09977.pdf)\
[Implicit Unlikelihood Training: Improving Neural Text Generation withReinforcement Learning](https://arxiv.org/pdf/2101.04229.pdf)\
[Few-Shot Text Generation with Pattern-Exploiting Training](https://aclanthology.org/2021.emnlp-main.32.pdf)\
[Making Pre-trained Language Models Better Few-shot Learners](https://aclanthology.org/2021.acl-long.295.pdf)\
[Persona-Knowledge Dialogue Multi-Context Retrieval and Enhanced Decoding Methods](https://arxiv.org/pdf/2207.13919.pdf)\
[Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/pdf/1908.10084.pdf)\
[Generative Language Models for Paragraph-Level Question Generation](https://arxiv.org/pdf/2210.03992v3.pdf)\
[Fine-Tuning Language Models from Human Preferences](https://arxiv.org/pdf/1909.08593v2.pdf) \
[GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL](https://arxiv.org/pdf/2210.02414v1.pdf) \
[Ankh : Optimized Protein Language Model Unlocks General-Purpose Modelling](https://arxiv.org/ftp/arxiv/papers/2301/2301.06568.pdf)\
[HuaTuo (华驼): Tuning LLaMA Model with Chinese Medical Knowledge](https://arxiv.org/pdf/2304.06975v1.pdf)
