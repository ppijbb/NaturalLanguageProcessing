{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4254,"status":"ok","timestamp":1746000385467,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"iCRpjtCdPPRx","outputId":"da3acd6c-0e90-4b16-f230-0a9bb4acde79"},"outputs":[{"name":"stdout","output_type":"stream","text":["Token is valid (permission: write).\n","The token `WriteToken` has been saved to /root/.cache/huggingface/stored_tokens\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful.\n","The current active token is: `WriteToken`\n"]}],"source":["#@title Huggingface Login\n","#@markdown huggingface weight 를 이용하고 싶다면 로그인 필수\n","from google.colab import userdata\n","import os\n","\n","os.environ[\"HF_WRITE_TOKEN\"] = userdata.get(\"HF_WRITE_TOKEN\")\n","os.environ[\"HUGGINGFACE_API_KEY\"] = os.getenv(\"HF_WRITE_TOKEN\")\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GEMINI_KEY\")\n","os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_KEY\")\n","os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_KEY')\n","os.environ[\"SERP_API_KEY\"] = userdata.get('SERP_API_KEY')\n","os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n","!huggingface-cli login --add-to-git-credential --token $HF_WRITE_TOKEN\n"]},{"cell_type":"markdown","metadata":{"id":"weO225X2EjZ2"},"source":["# Installation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128500,"status":"ok","timestamp":1745919420929,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"pPlW06ckPRG_","outputId":"222c9638-6434-4a56-9609-ae7c758aa4e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'oneCCL'...\n","remote: Enumerating objects: 12941, done.\u001b[K\n","remote: Counting objects: 100% (1667/1667), done.\u001b[K\n","remote: Compressing objects: 100% (667/667), done.\u001b[K\n","remote: Total 12941 (delta 1128), reused 1121 (delta 953), pack-reused 11274 (from 5)\u001b[K\n","Receiving objects: 100% (12941/12941), 229.46 MiB | 28.24 MiB/s, done.\n","Resolving deltas: 100% (8669/8669), done.\n","-- The C compiler identification is GNU 11.4.0\n","-- The CXX compiler identification is GNU 11.4.0\n","-- Detecting C compiler ABI info\n","-- Detecting C compiler ABI info - done\n","-- Check for working C compiler: /usr/bin/cc - skipped\n","-- Detecting C compile features\n","-- Detecting C compile features - done\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Check for working CXX compiler: /usr/bin/c++ - skipped\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Installation directory: /content/oneCCL/build/_install\n","-- Build type: release\n","-- C compiler : /usr/bin/cc\n","-- CXX compiler : /usr/bin/c++\n","-- Build examples: ON\n","-- Build functional tests: ON\n","-- Build cmake configs: ON\n","-- Enable MPI support: ON\n","-- Enable MPI tests support: ON\n","-- Enable SYCL interop event support: ON\n","-- Enable OFI HMEM support: ON\n","-- Enable OFI out-of-tree providers support: OFF\n","-- Enable ITT profiling support: ON\n","-- Enable PMIX support: ON\n","-- Enable UMF support: ON\n","-- Enable DRM support: TRUE\n","-- Enable stub backend: ON\n","-- Enable linker rpath flags: OFF\n","-- Enable openMP extension for intra-node collectives: ON\n","-- MPI_INCLUDE_DIR: /content/oneCCL/deps/mpi/include/\n","-- MPI_LIB_DIR: /content/oneCCL/deps/mpi/lib/\n","-- LIBFABRIC_LIB_DIR: /content/oneCCL/deps/ofi/lib/\n","-- LIBFABRIC_INCLUDE_DIR: /content/oneCCL/deps/ofi/include\n","-- HWLOC_INCLUDE_DIR: /content/oneCCL/deps/hwloc/include/\n","-- HWLOC_LIB_DIR: /content/oneCCL/deps/hwloc/lib/\n","-- ITT_INCLUDE_DIR: /content/oneCCL/deps/itt/include\n","-- ITT_LIB_DIR: /content/oneCCL/deps/itt/lib64\n","-- LEVEL_ZERO_INCLUDE_DIR: /content/oneCCL/deps/level_zero/include/\n","-- DRM_INCLUDE_DIR: /usr/include/drm\n","-- PMIX_INCLUDE_DIR: /content/oneCCL/deps/pmix/include/\n","-- UMF_INCLUDE_DIR: /content/oneCCL/deps/umf/include/\n","-- COMPUTE_BACKEND is not defined\n","-- Enable ITT profiling support\n","-- Enable PMIX support\n","-- Enable UMF support\n","-- Enable DRM support\n","-- Enable stub backend\n","-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n","-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n","-- Found OpenMP: TRUE (found version \"4.5\")\n","-- Enable openMP extension\n","-- BF16 AVX512F compiler: ON\n","-- binutils version: 2.38\n","-- BF16 AVX512BF compiler: ON\n","-- BF16 target attributes: ON\n","-- BF16 GPU truncate: OFF\n","-- FP16 compiler: ON\n","-- FP16 AVX512FP16 compiler: OFF\n","-- FP16 target attributes: ON\n","-- FP16 GPU truncate: OFF\n","-- AVX compiler: ON\n","-- AVX target attributes: ON\n","\u001b[0m-- Git branch: master, commit: 0b49b8f\u001b[0m\n","-- SRC C_FLAGS:   -Wall -Wextra -Wno-unused-parameter -Werror  -D_GNU_SOURCE -fvisibility=internal -Wno-implicit-fallthrough  -Wformat -Wformat-security -D_FORTIFY_SOURCE=2 -fstack-protector -fstack-protector-strong -DCCL_ENABLE_MPI -pthread\n","-- SRC CXX_FLAGS:   -Wall -Wextra -Wno-unused-parameter -Werror  -D_GNU_SOURCE -fvisibility=internal -Wno-implicit-fallthrough -DCCL_ENABLE_ITT=1 -DCCL_ENABLE_PMIX=1 -DCCL_ENABLE_UMF=1 -DCCL_ENABLE_DRM=1 -DCCL_ENABLE_STUB_BACKEND=1 -DCCL_ENABLE_OMP=1 -faligned-new -DCCL_ENABLE_SYCL_INTEROP_EVENT=1  -Wformat -Wformat-security -D_FORTIFY_SOURCE=2 -fstack-protector -fstack-protector-strong -DCCL_ENABLE_MPI -pthread\n","-- SRC SHARED_LINKER_FLAGS:   -fPIE -fPIC -z noexecstack -z relro -z now -Wl,--version-script=/content/oneCCL/ccl.map\n","-- SRC INCLUDE_DIRS: /content/oneCCL/include;/content/oneCCL/src;/content/oneCCL/src/atl;/content/oneCCL/deps/level_zero/include/;/content/oneCCL/deps/ofi/include;/content/oneCCL/deps/hwloc/include/;/content/oneCCL/deps/itt/include;/content/oneCCL/deps/pmix/include/;/content/oneCCL/deps/umf/include/;/content/oneCCL/deps/mpi/include/\n","-- SRC LINK_DIRS: \n","-- SRC LINK_LIBS: dl;pthread;/content/oneCCL/deps/hwloc/lib//libhwloc.a;/content/oneCCL/deps/itt/lib64/libittnotify.a\n","-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n","-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n","-- Found NUMA: /usr/lib/x86_64-linux-gnu/libnuma.so\n","-- NUMA was found, include_dir: /usr/include, libraries: /usr/lib/x86_64-linux-gnu/libnuma.so\n","-- FT CMAKE_PROJECT_NAME: oneCCL\n","-- FT PROJECT_NAME: oneCCL functional tests\n","-- PROC_MAPS: 2:1,2\n","-- Found Python3: /usr/local/bin/python (found version \"3.11.12\") found components: Interpreter\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n","-- Found Threads: TRUE\n","-- FT build type: Release\n","-- FT CCL_ROOT: \n","-- FT INC_DIRS: /content/oneCCL/tests/functional/../googletest-release-1.8.1//include;/content/oneCCL/tests/functional/../googletest-release-1.8.1//src;/content/oneCCL/tests/functional/../../examples/include\n","-- FT COMPUTE_BACKEND: \n","-- Configuring done (1.7s)\n","-- Generating done (0.1s)\n","-- Build files have been written to: /content/oneCCL/build\n","[  1%] \u001b[32mBuilding CXX object tests/functional/gtest_build/googletest/CMakeFiles/gtest.dir/src/gtest-all.cc.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comm/stub_comm.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/stub_kvs_impl.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/atl_base_comm.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/atl_base_transport.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/atl_def.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/mpi/atl_mpi.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/mpi/atl_mpi_comm.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/ofi/atl_ofi.cpp.o\u001b[0m\n","[  5%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/mpi/atl_mpi_ctx.cpp.o\u001b[0m\n","[  6%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/ofi/atl_ofi_comm.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_resizable_rt/pmi_resizable_simple.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_resizable_rt/pmi_resizable_simple_internal.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/ofi/atl_ofi_helper.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_resizable_rt/pmi_resizable/kvs_keeper.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_rt/pmi_simple.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_resizable_rt/pmi_resizable/kvs/internal_kvs_server.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_resizable_rt/pmi_resizable/kvs/users_kvs.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding C object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_rt/pmi/simple_pmiutil.c.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_resizable_rt/pmi_resizable/kvs/internal_kvs.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_common_op_attrs.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_allgather_op_attr.cpp.o\u001b[0m\n","[ 11%] \u001b[32mBuilding C object src/CMakeFiles/ccl-objects.dir/atl/util/pm/pmi_rt/pmi/simple_pmi.c.o\u001b[0m\n","[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_allgatherv_op_attr.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_allreduce_op_attr.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_alltoall_op_attr.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_alltoallv_op_attr.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_barrier_op_attr.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_bcast_op_attr.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_pt2pt_op_attr.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_reduce_op_attr.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/attr/ccl_reduce_scatter_op_attr.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/allreduce/allreduce_rma.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/coll_param.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/alltoall/alltoall.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/barrier/barrier.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/allgatherv/allgatherv.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/allgather.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/algorithm_utils.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/coll_util.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/broadcast/bcast.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/allreduce/allreduce.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/alltoallv.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/broadcast/broadcast.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/double_tree_ops.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/reduce.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/recv.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/reduce_scatter/reduce_scatter.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/algorithms/send.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/coll.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/coll_check.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/group/group.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selection.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_allgather.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_allgatherv.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_allreduce.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_alltoall.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_alltoallv.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_barrier.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_bcast.cpp.o\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_recv.cpp.o\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_reduce.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_reduce_scatter.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/coll/selection/selector_send.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comm/atl_tag.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comm/mt_comm.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comm/comm_selector.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comm/comm.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/context/context.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/datatype/datatype.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/device/device.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/env/env.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/env/env_parser.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/event/ccl_event.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/event/impls/host_event.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/event/impls/native_event.cpp.o\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/framework/framework.cpp.o\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/global/global.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/log/log.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/request/request.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/stream/stream.cpp.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/utils/exchange_utils.cpp.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/utils/fd_info.cpp.o\u001b[0m\n","[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/utils/memcpy.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/utils/spinlock.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/utils/profile.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/utils/utils.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/utils/version.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/utils/yield.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/api_wrapper/api_wrapper.cpp.o\u001b[0m\n","[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/api_wrapper/mpi_api_wrapper.cpp.o\u001b[0m\n","[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/api_wrapper/ofi_api_wrapper.cpp.o\u001b[0m\n","[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/api_wrapper/pmix_api_wrapper.cpp.o\u001b[0m\n","[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/api_wrapper/umf_api_wrapper.cpp.o\u001b[0m\n","[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/common/api_wrapper/openmp_wrapper.cpp.o\u001b[0m\n","[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comp/bf16/bf16.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comp/bf16/bf16_intrisics.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comp/comp.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comp/fp16/fp16.cpp.o\u001b[0m\n","[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/exec/thread/base_thread.cpp.o\u001b[0m\n","[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/comp/fp16/fp16_intrisics.cpp.o\u001b[0m\n","[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/exec/exec.cpp.o\u001b[0m\n","[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/exec/thread/listener.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/exec/thread/service_worker.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/exec/thread/worker.cpp.o\u001b[0m\n","[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/hwloc/hwloc_wrapper.cpp.o\u001b[0m\n","[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/fusion/fusion.cpp.o\u001b[0m\n","[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/native_device_api/sycl/export.cpp.o\u001b[0m\n","[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/parallelizer/parallelizer.cpp.o\u001b[0m\n","[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/buffer/buffer_cache.cpp.o\u001b[0m\n","[ 50%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/buffer/buffer_manager.cpp.o\u001b[0m\n","[ 50%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/cache/cache.cpp.o\u001b[0m\n","[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/cache/key.cpp.o\u001b[0m\n","[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/cache/recycle_storage.cpp.o\u001b[0m\n","[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/entry/coll/coll_entry.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/entry/copy/copy_entry.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/entry/copy/copy_helper.cpp.o\u001b[0m\n","[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/entry/deps_entry.cpp.o\u001b[0m\n","[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/entry/entry.cpp.o\u001b[0m\n","[ 54%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/entry/factory/chunked_entry_factory.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/entry/reduce_local_entry.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/entry/recv_copy_entry.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/queue/flow_control.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/queue/queue.cpp.o\u001b[0m\n","[ 56%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/queue/strict_queue.cpp.o\u001b[0m\n","[ 56%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/sched.cpp.o\u001b[0m\n","[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/sched_base.cpp.o\u001b[0m\n","[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/sched_group.cpp.o\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/sched_restart_manager.cpp.o\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/sched/sched_timer.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/topology/mt_topo_manager.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/topology/topo_manager.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_api_functions.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/unordered_coll/unordered_coll.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_app_api_comm_split_attr.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_app_api_coll_attr.cpp.o\u001b[0m\n","[ 61%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_app_api_comm_attr.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_app_api_datatype_attr.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_app_api_event.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_app_api_init_attr.cpp.o\u001b[0m\n","[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_app_api_kvs_attr.cpp.o\u001b[0m\n","[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_cpp_communicator.cpp.o\u001b[0m\n","[ 64%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_cpp_context.cpp.o\u001b[0m\n","[ 64%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_cpp_device.cpp.o\u001b[0m\n","[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_cpp_environment.cpp.o\u001b[0m\n","[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_cpp_kvs.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_cpp_stream.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_empty_attr.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_cpp_utils.cpp.o\u001b[0m\n","[ 67%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_empty_coll_attr.cpp.o\u001b[0m\n","[ 67%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_empty_comm_attr.cpp.o\u001b[0m\n","[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_empty_comm_split_attr.cpp.o\u001b[0m\n","[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_empty_init_attr.cpp.o\u001b[0m\n","[ 69%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_empty_kvs_attr.cpp.o\u001b[0m\n","[ 69%] \u001b[32mBuilding CXX object src/CMakeFiles/ccl-objects.dir/ccl_empty_stream.cpp.o\u001b[0m\n","[ 69%] \u001b[32m\u001b[1mLinking CXX static library libgtest.a\u001b[0m\n","[ 69%] Built target gtest\n","[ 70%] \u001b[32mBuilding CXX object tests/functional/gtest_build/googletest/CMakeFiles/gtest_main.dir/src/gtest_main.cc.o\u001b[0m\n","[ 70%] \u001b[32m\u001b[1mLinking CXX static library libgtest_main.a\u001b[0m\n","[ 70%] Built target gtest_main\n","[ 70%] Built target ccl-objects\n","[ 71%] \u001b[32m\u001b[1mLinking CXX static library libccl.a\u001b[0m\n","[ 71%] \u001b[32m\u001b[1mLinking CXX shared library libccl.so\u001b[0m\n","[ 71%] Built target ccl-static\n","[ 71%] Built target ccl\n","[ 72%] \u001b[32mBuilding CXX object src/ext/openmp/CMakeFiles/ccl_openmp.dir/openmp_ext.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object examples/benchmark/CMakeFiles/benchmark.dir/src/benchmark.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object examples/common/CMakeFiles/version.dir/version.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object examples/cpu/CMakeFiles/cpu_allgather_test.dir/cpu_allgather_test.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object examples/cpu/CMakeFiles/cpu_allreduce_bf16_test.dir/cpu_allreduce_bf16_test.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object examples/cpu/CMakeFiles/cpu_allgatherv_test.dir/cpu_allgatherv_test.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object examples/cpu/CMakeFiles/cpu_allreduce_test.dir/cpu_allreduce_test.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object examples/cpu/CMakeFiles/cpu_broadcast_test.dir/cpu_broadcast_test.cpp.o\u001b[0m\n","[ 73%] \u001b[32mBuilding CXX object examples/pt2pt/CMakeFiles/ccl_bw.dir/src/ccl_bw.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object examples/pt2pt/CMakeFiles/ccl_latency.dir/src/ccl_latency.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object examples/external_launcher/CMakeFiles/external_launcher.dir/external_launcher.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allgather_test.dir/conf.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allgather_test.dir/allgather_test.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allgatherv_test.dir/allgatherv_test.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allgatherv_test.dir/conf.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allgatherv_test.dir/lp.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allgatherv_test.dir/transport.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allreduce_test.dir/allreduce_test.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allgather_test.dir/transport.cpp.o\u001b[0m\n","[ 76%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allgather_test.dir/lp.cpp.o\u001b[0m\n","[ 76%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allreduce_test.dir/lp.cpp.o\u001b[0m\n","[ 77%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allreduce_test.dir/conf.cpp.o\u001b[0m\n","[ 78%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/alltoallv_test.dir/alltoallv_test.cpp.o\u001b[0m\n","[ 79%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/alltoall_test.dir/alltoall_test.cpp.o\u001b[0m\n","[ 79%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/alltoallv_test.dir/conf.cpp.o\u001b[0m\n","[ 80%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/alltoallv_test.dir/lp.cpp.o\u001b[0m\n","[ 80%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/alltoall_test.dir/conf.cpp.o\u001b[0m\n","[ 81%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/allreduce_test.dir/transport.cpp.o\u001b[0m\n","[ 82%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/reduce_scatter_test.dir/reduce_scatter_test.cpp.o\u001b[0m\n","[ 82%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/bcast_test.dir/bcast_test.cpp.o\u001b[0m\n","[ 82%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/broadcast_test.dir/broadcast_test.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/reduce_test.dir/reduce_test.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/bcast_test.dir/conf.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/reduce_scatter_test.dir/conf.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/broadcast_test.dir/conf.cpp.o\u001b[0m\n","[ 84%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/bcast_test.dir/lp.cpp.o\u001b[0m\n","[ 84%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/reduce_test.dir/conf.cpp.o\u001b[0m\n","[ 85%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/broadcast_test.dir/lp.cpp.o\u001b[0m\n","[ 86%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/reduce_scatter_test.dir/lp.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/reduce_test.dir/lp.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/reduce_scatter_test.dir/transport.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/alltoall_test.dir/lp.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/reduce_test.dir/transport.cpp.o\u001b[0m\n","[ 88%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/alltoall_test.dir/transport.cpp.o\u001b[0m\n","[ 88%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/broadcast_test.dir/transport.cpp.o\u001b[0m\n","[ 88%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/alltoallv_test.dir/transport.cpp.o\u001b[0m\n","[ 88%] \u001b[32mBuilding CXX object tests/functional/CMakeFiles/bcast_test.dir/transport.cpp.o\u001b[0m\n","[ 89%] \u001b[32m\u001b[1mLinking CXX executable cpu_allreduce_test\u001b[0m\n","[ 90%] \u001b[32m\u001b[1mLinking CXX executable version\u001b[0m\n","[ 90%] Built target cpu_allreduce_test\n","[ 90%] Built target version\n","[ 91%] \u001b[32m\u001b[1mLinking CXX executable cpu_allgatherv_test\u001b[0m\n","[ 91%] Built target cpu_allgatherv_test\n","[ 91%] \u001b[32m\u001b[1mLinking CXX executable cpu_allgather_test\u001b[0m\n","[ 92%] \u001b[32m\u001b[1mLinking CXX executable cpu_allreduce_bf16_test\u001b[0m\n","[ 93%] \u001b[32m\u001b[1mLinking CXX executable cpu_broadcast_test\u001b[0m\n","[ 93%] Built target cpu_allgather_test\n","[ 93%] Built target cpu_broadcast_test\n","[ 93%] Built target cpu_allreduce_bf16_test\n","[ 93%] \u001b[32m\u001b[1mLinking CXX executable external_launcher\u001b[0m\n","[ 93%] Built target external_launcher\n","[ 93%] \u001b[32m\u001b[1mLinking CXX executable ccl_latency\u001b[0m\n","[ 93%] Built target ccl_latency\n","[ 93%] \u001b[32m\u001b[1mLinking CXX executable ccl_bw\u001b[0m\n","[ 93%] Built target ccl_bw\n","[ 93%] \u001b[32m\u001b[1mLinking CXX shared library libccl_openmp.so\u001b[0m\n","[ 93%] Built target ccl_openmp\n","[ 94%] \u001b[32m\u001b[1mLinking CXX executable alltoallv_test\u001b[0m\n","[ 94%] Built target alltoallv_test\n","[ 95%] \u001b[32m\u001b[1mLinking CXX executable broadcast_test\u001b[0m\n","[ 95%] Built target broadcast_test\n","[ 96%] \u001b[32m\u001b[1mLinking CXX executable reduce_test\u001b[0m\n","[ 96%] Built target reduce_test\n","[ 96%] \u001b[32m\u001b[1mLinking CXX executable alltoall_test\u001b[0m\n","[ 96%] Built target alltoall_test\n","[ 96%] \u001b[32m\u001b[1mLinking CXX executable allreduce_test\u001b[0m\n","[ 96%] Built target allreduce_test\n","[ 96%] \u001b[32m\u001b[1mLinking CXX executable reduce_scatter_test\u001b[0m\n","[ 96%] Built target reduce_scatter_test\n","[ 97%] \u001b[32m\u001b[1mLinking CXX executable bcast_test\u001b[0m\n","[ 97%] Built target bcast_test\n","[ 98%] \u001b[32m\u001b[1mLinking CXX executable allgather_test\u001b[0m\n","[ 98%] Built target allgather_test\n","[ 99%] \u001b[32m\u001b[1mLinking CXX executable allgatherv_test\u001b[0m\n","[ 99%] Built target allgatherv_test\n","[100%] \u001b[32m\u001b[1mLinking CXX executable benchmark\u001b[0m\n","[100%] Built target benchmark\n","\u001b[36mInstall the project...\u001b[0m\n","-- Install configuration: \"Release\"\n","-- Installing: /content/oneCCL/build/_install/env/vars.sh\n","-- Installing: /content/oneCCL/build/_install/env/setvars.sh\n","-- Installing: /content/oneCCL/build/_install/modulefiles/ccl\n","-- Installing: /content/oneCCL/build/_install/share/doc/ccl/licensing/third-party-programs.txt\n","-- Installing: /content/oneCCL/build/_install/share/doc/ccl/licensing/LICENSE\n","-- Installing: /content/oneCCL/build/_install/lib/cmake/oneCCL/oneCCLConfig.cmake\n","-- Installing: /content/oneCCL/build/_install/lib/cmake/oneCCL/oneCCLConfigVersion.cmake\n","-- Installing: /content/oneCCL/build/_install/lib/libccl.so.1.0\n","-- Installing: /content/oneCCL/build/_install/lib/libccl.so.1\n","-- Installing: /content/oneCCL/build/_install/lib/libccl.so\n","-- Installing: /content/oneCCL/build/_install/lib/FindIntelSYCL.cmake\n","-- Installing: /content/oneCCL/build/_install/lib/FindIntelSYCL_level_zero.cmake\n","-- Installing: /content/oneCCL/build/_install/lib/FindNUMA.cmake\n","-- Installing: /content/oneCCL/build/_install/lib/FindSYCL.cmake\n","-- Installing: /content/oneCCL/build/_install/lib/libccl.a\n","-- Installing: /content/oneCCL/build/_install/include\n","-- Installing: /content/oneCCL/build/_install/include/oneapi\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/comm_split_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/device_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/event.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/lp_types.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/type_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/comm_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/datatype_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/comm_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/sycl\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/sycl/export.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/export_api.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/empty\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/empty/event.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/empty/platform.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/empty/primitives.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/empty/context.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/empty/device.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/empty/queue.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/native_device_api/empty/export.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/context_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/communicator.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/init_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/kvs.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/kvs_attr.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/stream_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/context.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/coll_attr.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/stream.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/stream_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/api_functions.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/coll_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/datatype_attr.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/device_types.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/datatype_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/device_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/device.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/comm_attr.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/kvs_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/coll_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/context_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/exception.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/comm_split_attr.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/aliases.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/init_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/kvs_attr_ids.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/device_type_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/types.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/environment.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/types_policy.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/comm_split_attr_ids_traits.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/string.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/config.h\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl/init_attr.hpp\n","-- Installing: /content/oneCCL/build/_install/include/oneapi/ccl.hpp\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/prov\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/prov/libshm-fi.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/prov/libpsm3-fi.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/prov/libverbs-1.12-fi.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/prov/librxm-fi.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/prov/libpsmx2-fi.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/prov/libverbs-1.1-fi.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/prov/libtcp-fi.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/libfabric.so.1\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/libfabric/lib/libfabric.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/hydra_bstrap_proxy\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/hydra_nameserver\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/hydra_pmi_proxy\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpicc\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpicxx\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpiexec\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpiexec.hydra\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpigcc\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpigxx\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpiicc\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpiicpc\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpiicpx\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpiicx\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/bin/mpirun\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/include\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/include/mpio.h\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/include/mpicxx.h\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/include/mpi.h\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpi.so.12.0.0\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpi.so.12.0\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpifort.so.12.0.0\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpicxx.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpifort.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpi.so.12\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpi.so\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpicxx.so.12.0\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpifort.so.12.0\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpifort.so.12\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpicxx.so.12\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/lib/libmpicxx.so.12.0.0\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc/\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_shm-ofi_psm3.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_clx-ap_ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm_efa.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_spr_shm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm-ofi_mlx_100.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_shm-ofi_tcp-ofi-rxm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_emr_shm-ofi_psm3_100.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_spr_shm-ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm_tcp.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_ofi_tcp-ofi-rxm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_generic_shm-ofi_mlx_hcoll.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_gnr_shm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm-ofi_psm3_200.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_shm-ofi_tcp.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_emr_shm-ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm-ofi_efa_100_x2.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_generic_shm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_clx-ap_shm-ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_spr_shm-ofi_tcp.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_shm-ofi_efa.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_generic_ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_ofi_efa.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm-ofi_mlx.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm-ofi_psm3.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_ofi_mlx.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_emr_shm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_clx-ap_shm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_generic_shm-ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm-ofi_efa.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_ofi_psm3.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_shm-ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_emr_shm-ofi_psm3_200.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_skx_shm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_srf_shm-ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm_efa_100_x2.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_generic_ofi_mlx_hcoll.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_spr_shm_tcp.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_spr_shm-ofi_cxi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm-ofi_tcp.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_gnr_shm-ofi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_spr_shm_cxi.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_icx_shm.dat\n","-- Installing: /content/oneCCL/build/_install/opt/mpi/etc//tuning_srf_shm.dat\n","-- Installing: /content/oneCCL/build/_install/share/doc/ccl/licensing/mpi/\n","-- Installing: /content/oneCCL/build/_install/share/doc/ccl/licensing/mpi//license.txt\n","-- Installing: /content/oneCCL/build/_install/share/doc/ccl/licensing/mpi//third-party-programs.txt\n","-- Installing: /content/oneCCL/build/_install/lib/libccl_openmp.so.0\n","-- Installing: /content/oneCCL/build/_install/lib/libccl_openmp.so.0.1\n","-- Installing: /content/oneCCL/build/_install/lib/libccl_openmp.so\n","-- Installing: /content/oneCCL/build/_install/examples/benchmark/benchmark\n","-- Installing: /content/oneCCL/build/_install/examples/common/version\n","-- Installing: /content/oneCCL/build/_install/examples/cpu/cpu_allgather_test\n","-- Installing: /content/oneCCL/build/_install/examples/cpu/cpu_allgatherv_test\n","-- Installing: /content/oneCCL/build/_install/examples/cpu/cpu_allreduce_bf16_test\n","-- Installing: /content/oneCCL/build/_install/examples/cpu/cpu_allreduce_test\n","-- Installing: /content/oneCCL/build/_install/examples/cpu/cpu_broadcast_test\n","-- Installing: /content/oneCCL/build/_install/examples/pt2pt/ccl_bw\n","-- Installing: /content/oneCCL/build/_install/examples/pt2pt/ccl_latency\n","-- Installing: /content/oneCCL/build/_install/examples/external_launcher/external_launcher\n","-- Installing: /content/oneCCL/build/_install/examples/external_launcher/run.sh\n","-- Installing: /content/oneCCL/build/_install/examples/external_launcher/run_binary.sh\n","-- Installing: /content/oneCCL/build/allgather_test\n","-- Installing: /content/oneCCL/build/allgatherv_test\n","-- Installing: /content/oneCCL/build/allreduce_test\n","-- Installing: /content/oneCCL/build/alltoall_test\n","-- Installing: /content/oneCCL/build/alltoallv_test\n","-- Installing: /content/oneCCL/build/bcast_test\n","-- Installing: /content/oneCCL/build/broadcast_test\n","-- Installing: /content/oneCCL/build/reduce_scatter_test\n","-- Installing: /content/oneCCL/build/reduce_test\n"]},{"data":{"text/plain":[]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["%%shell\n","git clone https://github.com/oneapi-src/oneCCL.git\n","cd oneCCL\n","mkdir build\n","cd build\n","cmake ..\n","make -j install\n","mkdir -p /opt/intel/oneccl\n","mv ./_install/env /opt/intel/oneccl"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1737086731589,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"aAphU6E1lcvy","outputId":"cac68744-3eaf-46e6-d3c4-7fc06466ef01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing requirements.txt\n"]}],"source":["#@title Requirements\n","%%writefile requirements.txt\n","onnx\n","onnxruntime\n","onnx2pytorch\n","tensorrt\n","vllm\n","lmdeploy\n","openvino\n","ipex_llm[all]\n","optimum-intel[extras]\n","ray\n","nncf\n","konlpy\n","mpi4py\n","deepspeed"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"cATRLnmdnFU3"},"outputs":[],"source":["#@title Install Packages\n","%%capture\n","!pip install intel_extension_for_pytorch==2.1.0 --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\n","!pip install https://intel-extension-for-pytorch.s3.amazonaws.com/torch_ccl/cpu/oneccl_bind_pt-2.1.0%2Bcpu-cp39-cp39-linux_x86_64.whl\n","!VLLM_TARGET_DEVICE=cpu pip install -r -U requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":426,"status":"ok","timestamp":1737089800449,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"810xGT1_CF-0","outputId":"d1db0627-c3de-4999-81c8-f750715ea46a"},"outputs":[{"name":"stdout","output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 0\n","cpu cores\t: 6\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 1\n","cpu cores\t: 6\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 2\n","cpu cores\t: 6\n","apicid\t\t: 4\n","initial apicid\t: 4\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 3\n","cpu cores\t: 6\n","apicid\t\t: 6\n","initial apicid\t: 6\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 4\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 4\n","cpu cores\t: 6\n","apicid\t\t: 8\n","initial apicid\t: 8\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 5\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 5\n","cpu cores\t: 6\n","apicid\t\t: 10\n","initial apicid\t: 10\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 6\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 0\n","cpu cores\t: 6\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 7\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 1\n","cpu cores\t: 6\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 8\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 2\n","cpu cores\t: 6\n","apicid\t\t: 5\n","initial apicid\t: 5\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 9\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 3\n","cpu cores\t: 6\n","apicid\t\t: 7\n","initial apicid\t: 7\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 10\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 4\n","cpu cores\t: 6\n","apicid\t\t: 9\n","initial apicid\t: 9\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 11\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 7\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2200.168\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 12\n","core id\t\t: 5\n","cpu cores\t: 6\n","apicid\t\t: 11\n","initial apicid\t: 11\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities\n","bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs taa mmio_stale_data retbleed eibrs_pbrsb bhi\n","bogomips\t: 4400.33\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"]}],"source":["!cat /proc/cpuinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1705,"status":"ok","timestamp":1737089862573,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"R3-EU5iXPMhF","outputId":"28715462-08e6-4f98-cc7b-a93652419f92"},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","The token `WriteToken` has been saved to /root/.cache/huggingface/stored_tokens\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful.\n","The current active token is: `WriteToken`\n"]}],"source":["from google.colab import userdata\n","import os\n","os.environ[\"HF_WRITE_TOKEN\"] = userdata.get(\"HF_WRITE_TOKEN\")\n","os.environ[\"HUGGINGFACE_API_KEY\"] = os.getenv(\"HF_WRITE_TOKEN\")\n","!huggingface-cli login --token $HF_WRITE_TOKEN"]},{"cell_type":"markdown","metadata":{"id":"uuZ4dVPUFWP5"},"source":["# Select Model"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["3093e44ce71f4b1184c6ad41f9366828","f88f6a06723c4c26a51520d4c1f38e09","048fdf8bd4144256b590cf891482ca66","4c93244f86144a629de856530d8cf57c","105d7c0d88d245dfb3b783132b17cabd","6ff0da55f425452b99dcaf0d65aa4343","1acf18ef4e2b44f0a3f776e502d866ae","2fd06061b42b4883907eb9b1b933a0ed","271905d3f72849faafb23bb54cade703","e57158efc35540f3931b1eb03ec222a0","316b0929b0ca4aa3a9d3f042bd82bdad","ef2bf0bf1adf4ff3952d03ee9725274f","3dfa51e077ff44dd9b165c241e2d89db","279ed0a4d9b04c1ebfe7da72e293c150","3e1d32656e34480d9ba035a927e2559b","fa423d05dc834f96b3374498045ab662","0a8c1864808f4b4aaac32025025b9254","790f68676eb24742bbc954a6584e8aa9","4d3372d6a39242198855a3c155219ebe","137da20dc49e4f48bbbc863ddc51da93","b316cf5d7bf14a7da993cbdc4e1517c8","4981e5daedc74e8a9f76def793e3b776","f0fb074f7ae34a00961f14fe2247c968","8311db8fcda749a388e1d9df7cec44f7","b31f036b859f4613a3f3203b5f1f6a6a","39475f620182432facc0874b70a069e2","2d2d0873e38e49d689aa9aba5f2b1e34","37344bea3ea9444181ce13fd6d693db0","8ea7a0dadb064d8b9e71dffa0eb99c37","80244154e07e4c4d820ce4f733363000","55cec9f47a1b4631a923707f5e69f7e7","a9da06749e8a46d9b81d54946ae003a6","2ecc8d45fb0f43f4bc05fd2c95b1ee7f","3d31ca43a7494a8890104e4c1bc57090","51a356cd86f84f2ab685ba274e855e23","a08d331060304951b93a6ce4750d2e3e","05c53b75268743f299b19991d241f72e","b0b983e2e0b0422b9359dc072b15cb71","4022aa5e0d1149f9bf91cdecdec2b794","fc121834f82b4444ad34b180a93e0831","e1682931e96f41ee821f8abf35430413","5ed9954fd9714a40bbaec897c9466537","a22fa254fdd749489e61720c23dfee47","3f0207f55d6645efbdb5185859d59eb8","c9fad8a53d284e3d9eaa8adb157b379b","64fc8f0ff4094710b3493b1eff90251e","3dec33cd6b1e4b598113299c3aca9032","be64018d3a2c4a19a26d38b710116f09","f94b0344782f4829ba14cc99775d52ca","d84c158175294ee992d69cef0e73d95e","3aa3e8b7bda64f0884e5fb2772c102f7","50e72b6991b24edab0dcfc95582ef1dc","587fa5004af64cb8ae38cf21098d4a9d","6a8de695f35a4202b8124b775a3c11d7","7ad7fef57fec4fd2bc69f8dbf7d19a85","c1510b0bebf04555ba0b21969962e9a0","818cef3bf98d492fbe7a204f316b81de","67ac877348894aa3b200afd273475110","ae7a0531b72f46909fa9286a981632d3","fd20878d760146608cad0efa6c6a79e0","c5f1d96d4dc64c508a0a28c0309f128d","96df4692ff47452e8f88a1ee77dd4e81","c3b294ebf3294db8bb97729007611353","307cd30565234a96b384b9eebac2d226","b7f3cb1a847645d69ad71db604a77922","0079e32b0cb64ba088dc7667b27163ad"]},"executionInfo":{"elapsed":174669,"status":"ok","timestamp":1721366230425,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"9W9RxgzzFX41","outputId":"3cc741cc-8431-4d58-9944-e6de3dd4e8b0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3093e44ce71f4b1184c6ad41f9366828","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef2bf0bf1adf4ff3952d03ee9725274f","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/6.09G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0fb074f7ae34a00961f14fe2247c968","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d31ca43a7494a8890104e4c1bc57090","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9fad8a53d284e3d9eaa8adb157b379b","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.69M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1510b0bebf04555ba0b21969962e9a0","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["#@title Select Language Model\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","import gc\n","\n","if \"origin_model\" in globals() or \"origin_model\" in locals():\n","    del origin_model\n","\n","gc.collect()\n","\n","base_model_id = \"beomi/KoAlpaca-KoRWKV-1.5B\" # @param [\"Gunulhona/tb_pretrained_sts\", \"Gunulhona/tb_pretrained\", \"google/flan-t5-xxl\", \"meta-llama/Meta-Llama-3-8B\", \"meta-llama/Meta-Llama-3-70B-Instruct\", \"mistralai/Mistral-7B-Instruct-v0.3\", \"Qwen/Qwen2-7B-Instruct\", \"google/gemma-7b\", \"MLP-KTLim/llama-3-Korean-Bllossom-8B\", \"EleutherAI/polyglot-ko-12.8b\", \"vilm/vulture-40b\", \"arcee-ai/Arcee-Spark\", \"Qwen/Qwen2-1.5B-Instruct\", \"OuteAI/Lite-Mistral-150M-v2-Instruct\", \"google/gemma-2b-it\", \"beomi/KoAlpaca-KoRWKV-1.5B\"] {allow-input: true}\n","\n","origin_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,\n","    trust_remote_code=True,\n","    # quantization_config=bnb_config\n","    )\n","\n","processor = AutoTokenizer.from_pretrained(\n","    base_model_id,\n","    add_special_tokens=True,\n","    trust_remote_code=True)\n","processor.model_input_names=['input_ids', 'attention_mask']\n","if processor.pad_token is None:\n","    processor.pad_token = processor.eos_token\n","\n","processor.padding_side = \"right\"\n","processor.truncation_side = \"right\"\n","\n","@torch.inference_mode()\n","def inference(input_, model):\n","    template = {\n","        \"role\": \"user\",\n","        \"content\": input_\n","    }\n","    inputs = processor.apply_to_template(\n","        template,\n","        return_tensors='pt'\n","    )\n","    # inputs = processor(input_,\n","    #                    return_tensors=\"pt\",\n","    #                    padding=\"max_length\",\n","    #                    truncation=True,\n","    #                    max_length=128)\n","    outputs = model.generate(inputs,\n","                             max_new_tokens=50)\n","    return processor.batch_decode(outputs, skip_special_tokens=True)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"ifokOEXAGJev"},"outputs":[],"source":["#@title Select Vision Model\n","\n","from transformers import AutoProcessor, Owlv2ForObjectDetection, Owlv2VisionConfig\n","import torch\n","\n","base_model_id = \"google/owlv2-base-patch16-ensemble\" # @param [\"google/owlv2-base-patch16-ensemble\", \"\"] {allow-input: true}\n","\n","processor = AutoProcessor.from_pretrained(base_model_id)\n","origin_model = Owlv2ForObjectDetection.from_pretrained(base_model_id)\n","\n","@torch.inference_mode()\n","def inference(input_, model):\n","    model.eval()\n","    inputs = processor(input_, return_tensors=\"pt\")\n","    outputs = model(**inputs)\n","    return outputs"]},{"cell_type":"markdown","metadata":{"id":"3h222ZK1EV0M"},"source":["# Quantize Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"executionInfo":{"elapsed":4530,"status":"error","timestamp":1721366234954,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"6k0sn_rfOD1w","outputId":"f112cb23-43c1-4b6c-c512-ae54e1fec751"},"outputs":[{"ename":"AttributeError","evalue":"'PreTrainedTokenizerFast' object has no attribute 'apply_to_template'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b95b35b9d72c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mipex_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m outputs = inference(input_=\"test 입력 처리 요구\",\n\u001b[0m\u001b[1;32m      7\u001b[0m                     model=ipex_model)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-cfb4bf8e8825>\u001b[0m in \u001b[0;36minference\u001b[0;34m(input_, model)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     }\n\u001b[0;32m---> 36\u001b[0;31m     inputs = processor.apply_to_template(\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PreTrainedTokenizerFast' object has no attribute 'apply_to_template'"]}],"source":["from ipex_llm.transformers import AutoModelForCausalLM\n","from transformers import AutoTokenizer\n","\n","ipex_model = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True)\n","\n","outputs = inference(input_=\"test 입력 처리 요구\",\n","                    model=ipex_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3442637,"status":"error","timestamp":1721369703335,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"zyU0RmgXpreF","outputId":"52099de6-0a40-4453-f827-76fbbeef9df3"},"outputs":[{"name":"stderr","output_type":"stream","text":["`attention_mask` was passed, but it is unused in this model.\n","WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.0/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.0/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.1/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.1/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.2/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.2/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.3/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.3/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.4/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.4/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.5/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.5/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.6/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.6/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.7/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.7/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.8/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.8/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.9/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.9/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.10/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.10/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.11/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.11/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.12/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.12/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.13/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.13/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.14/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.14/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.15/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.15/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.16/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.16/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.17/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.17/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.18/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.18/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.19/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.19/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.20/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.20/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.21/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.21/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.22/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.22/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.23/attention/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n","WARNING:root:Inference failed or unsupported type to quantize for tensor '/rwkv/blocks.23/feed_forward/time_shift/Slice_output_0', type is tensor_type {\n","  elem_type: 7\n","  shape {\n","    dim {\n","      dim_value: 3\n","    }\n","    dim {\n","      dim_value: 2\n","    }\n","  }\n","}\n",".\n"]},{"ename":"AttributeError","evalue":"'PreTrainedTokenizerFast' object has no attribute 'apply_to_template'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-e51621459a61>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandomtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     outputs = inference(input_=t,\n\u001b[0m\u001b[1;32m     59\u001b[0m                         model=origin_model)\n\u001b[1;32m     60\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-cfb4bf8e8825>\u001b[0m in \u001b[0;36minference\u001b[0;34m(input_, model)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     }\n\u001b[0;32m---> 36\u001b[0;31m     inputs = processor.apply_to_template(\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PreTrainedTokenizerFast' object has no attribute 'apply_to_template'"]}],"source":["# prompt: 기존 모델 실행 시간과 onnx qunatization 실행 및 quantized 모델의 실행 시간 비교 하는 코드\n","\n","import time\n","import numpy as np\n","import torch\n","import onnx\n","import onnxruntime as ort\n","import random\n","import ray\n","from copy import deepcopy\n","import string\n","from pathlib import Path\n","from onnxruntime.quantization import quantize_dynamic, QuantType\n","from optimum.onnxruntime import ORTModelForCausalLM, ORTConfig\n","from transformers.onnx import FeaturesManager\n","import transformers\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","@ray.remote\n","def make_texts():\n","    return \"\".join(random.sample('가나다라마바사아자차카타파하그느드르므브스으즈츠크트프흐구누두루무부수우주추쿠투푸후', 30))\n","\n","randomtexts = ray.get([ make_texts.remote() for i in range(10) ])\n","\n","\n","# Load your original model\n","original_model = origin_model\n","test_in = torch.randint(1000, (1, 128))\n","with torch.no_grad():\n","    torch.onnx.export(\n","        original_model,\n","        args=tuple(processor(randomtexts[0], return_tensors=\"pt\").values()),\n","        input_names=[\"input_ids\", \"attention_mask\"],\n","        output_names=[\"logits\"],\n","        dynamic_axes={'input_ids': {0: 'batch_size', 1: 'sequence'},\n","                      'attention_mask': {0: 'batch_size', 1: 'sequence'},\n","                      'logits': {0: 'batch_size', 1: 'sequence'}},\n","        f=\"original_model.pt\")\n","\n","\n","# Quantize the model using ONNX\n","quantized_model = quantize_dynamic(\n","    model_input=\"original_model.pt\",\n","    model_output=\"quantized_model.onnx\",\n","    weight_type=onnx.TensorProto.INT8\n",")\n","\n","# Save the quantized model\n","# onnx.save(quantized_model, \"quantized_model.onnx\")\n","\n","# Measure execution time for the original model\n","start_time = time.time()\n","# Run inference with the original model\n","result = []\n","for t in randomtexts:\n","    outputs = inference(input_=t,\n","                        model=origin_model)\n","    result.append(outputs)\n","end_time = time.time()\n","original_execution_time = end_time - start_time\n","print(\"Original model execution time:\", original_execution_time)\n","print(result[0])\n","\n","# Measure execution time for the quantized model\n","start_time = time.time()\n","# Run inference with the quantized model\n","q_session = ort.InferenceSession(\"quantized_model.onnx\", providers=[\"CPUExecutionProvider\"])\n","\n","result = []\n","for t in randomtexts:\n","    preprocessed = processor(t, return_tensors=\"np\", padding=\"max_length\", truncation=True, max_length=128)\n","    onnx_input= {\n","         \"input_ids\": preprocessed[\"input_ids\"].astype(np.int64),\n","         \"attention_mask\": preprocessed[\"attention_mask\"].astype(np.int64)\n","     }\n","    result.append(q_session.run(None, input_feed=onnx_input)[0])\n","end_time = time.time()\n","quantized_execution_time = end_time - start_time\n","print(\"Quantized model execution time:\", quantized_execution_time)\n","print(result[0].shape)\n","config = deepcopy(original_model.config)\n","\n","\n","\n","feature = \"causal-lm\"\n","model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(\n","    original_model, feature=feature)\n","onnx_config = model_onnx_config(original_model.config)\n","\n","# export\n","onnx_inputs, onnx_outputs = transformers.onnx.export(\n","        preprocessor=processor,\n","        model=original_model,\n","        config=onnx_config,\n","        opset=16,\n","        output=Path(\"trfs-model.onnx\"))\n","\n","q_model = ORTModelForCausalLM(q_session, original_model.config,\n","                              use_io_binding=False, use_cache=False)\n","\n","# @ray.remote\n","def ray_onnx(text):\n","    return inference(input_=text,\n","                     model=q_model)\n","\n","start_time = time.time()\n","result = [ray_onnx(t) for t in randomtexts]\n","end_time = time.time()\n","ray_quantized_execution_time = end_time - start_time\n","print(\"Ray + Quantized model execution time:\", ray_quantized_execution_time)\n","\n","# Compare execution times\n","speedup = original_execution_time / quantized_execution_time\n","print(\"Speedup:\", speedup)\n","speedup = original_execution_time / ray_quantized_execution_time\n","print(\"Ray Speedup:\", speedup)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"piv_sBHMOqYS"},"outputs":[],"source":["import deepspeed\n","from ipex_llm import optimize_model\n","import os\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","original_model = origin_model\n","\n","# Measure execution time for the original model\n","start_time = time.time()\n","# Run inference with the original model\n","result = []\n","for t in randomtexts:\n","    outputs = inference(input_=t,\n","                        model=origin_model)\n","    result.append(outputs)\n","end_time = time.time()\n","original_execution_time = end_time - start_time\n","print(\"Original model execution time:\", original_execution_time)\n","print(result[0])\n","\n","\n","world_size = int(os.getenv(\"WORLD_SIZE\", \"2\"))\n","local_rank = int(os.getenv(\"RANK\", \"-1\")) # RANK is automatically set by CCL distributed backend\n","\n","ds_model = deepspeed.init_inference(\n","    original_model, # an AutoModel of Transformers\n","    mp_size = world_size, # instance (process) count\n","    dtype=torch.int8,\n","    replace_method=\"auto\")\n","\n","ds_model = optimize_model(ds_model.module.to(f'cpu'), low_bit='sym_int4')\n","ds_model = ds_model.to(f'cpu:{local_rank}') # move partial model to local rank\n","result = []\n","with torch.inference_mode():\n","    start_time = time.time()\n","    result += [inference(t, ds_model) for t in randomtexts]\n","    end_time = time.time()\n","\n","quantized_execution_time = end_time - start_time\n","print(\"Deepspeed model execution time:\", quantized_execution_time)\n","print(result[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwhYub_Hp6sT","outputId":"8eb2ba60-e58f-4ed9-b4e2-a120c02cb8f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original model execution time: 179.06584286689758\n"]}],"source":["# prompt: 기존 모델 실행 시간과 tensorrt qunatization 실행 및 quantized 모델의 실행 시간 비교 하는 코드\n","\n","import time\n","import torch\n","import onnx\n","import ray\n","import tensorrt as trt\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Load your original model\n","original_model = origin_model\n","test_time = 5\n","\n","# Measure execution time for the original model\n","start_time = time.time()\n","# Run inference with the original model\n","for _ in range(test_time):\n","    outputs = inference(input_=\"test 입력 처리 요구\",\n","                        model=origin_model)\n","end_time = time.time()\n","original_execution_time = end_time - start_time\n","print(\"Original model execution time:\", original_execution_time)\n","\n","# TensorRT quantization and execution\n","logger = trt.Logger(trt.Logger.INFO)\n","builder = trt.Builder(logger)\n","network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n","parser = trt.OnnxParser(network, logger)\n","\n","with open(\"quantized_model.onnx\", \"rb\") as model:\n","    if not parser.parse(model.read()):\n","        for error in range(parser.num_errors):\n","            print(parser.get_error(error))\n","\n","# Build TensorRT engine\n","engine = builder.build_cuda_engine(network)\n","\n","# Measure execution time for the TensorRT quantized model\n","start_time = time.time()\n","# Run inference with the TensorRT engine\n","for _ in range(test_time):\n","    preprocessed = processor(\"test 입력 처리 요구\",\n","                             return_tensors=\"np\",\n","                             padding=\"max_length\",\n","                             truncation=True,\n","                             max_length=128)\n","    inputs[0].host = preprocessed[\"input_ids\"].astype(np.float32)  # Assuming input_ids is the input tensor name\n","    trt_outputs = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n","end_time = time.time()\n","trt_quantized_execution_time = end_time - start_time\n","print(\"TensorRT quantized model execution time:\", trt_quantized_execution_time)\n","\n","@ray.remote\n","def ray_inference(text):\n","    preprocessed = processor(text,\n","                            return_tensors=\"np\",\n","                            padding=\"max_length\",\n","                            truncation=True,\n","                            max_length=128)\n","    inputs[0].host = preprocessed[\"input_ids\"].astype(np.float32)  # Assuming input_ids is the input tensor name\n","    return do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n","\n","\n","start_time = time.time()\n","for _ in range(test_time):\n","    text_id = ray.put(\"test 입력 처리 요구\")\n","    ray.get([ray_inference.remote(text_id)])\n","\n","end_time = time.time()\n","ray_trt_quantized_execution_time = end_time - start_time\n","print(\"Ray + TensorRT quantized model execution time:\", ray_trt_quantized_execution_time)\n","\n","\n","# Compare execution times\n","speedup_trt = original_execution_time / trt_quantized_execution_time\n","speedup_ray = original_execution_time / ray_trt_quantized_execution_time\n","print(\"Speedup with TensorRT quantization:\", speedup_trt)\n","print(\"Speedup with Ray + TensorRT :\", speedup_ray)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"elapsed":224353,"status":"error","timestamp":1721228741162,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"QPrvNnf_qGTZ","outputId":"85f85fc1-9d60-49ae-d1dd-cfac2637ede8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original model execution time: 222.8475422859192\n","INFO 07-17 15:05:38 llm_engine.py:174] Initializing an LLM engine (v0.5.2) with config: model='Qwen/Qwen2-1.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2-1.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=Qwen/Qwen2-1.5B-Instruct, use_v2_block_manager=False, enable_prefix_caching=False)\n","WARNING 07-17 15:05:39 cpu_executor.py:134] CUDA graph is not supported on CPU, fallback to the eager mode.\n","WARNING 07-17 15:05:39 cpu_executor.py:161] Environment variable VLLM_CPU_KVCACHE_SPACE (GB) for CPU backend is not set, using 4 by default.\n"]},{"ename":"RuntimeError","evalue":"Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e51d3b0cb176>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# vllm quantization and execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Initialize vLLM with the quantized model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m llm = LLM(model=base_model_id,\n\u001b[0m\u001b[1;32m     27\u001b[0m           \u001b[0mtensor_parallel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           device='cpu')\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, enforce_eager, max_context_len_to_capture, max_seq_len_to_capture, disable_custom_all_reduce, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         )\n\u001b[0;32m--> 150\u001b[0;31m         self.llm_engine = LLMEngine.from_engine_args(\n\u001b[0m\u001b[1;32m    151\u001b[0m             engine_args, usage_context=UsageContext.LLM_CLASS)\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_engine_args\u001b[0;34m(cls, engine_args, usage_context)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mexecutor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# Create the LLM engine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         engine = cls(\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mengine_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mexecutor_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, multimodal_config, speculative_config, decoding_config, observability_config, prompt_adapter_config, executor_class, log_stats, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    247\u001b[0m             self.model_config)\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         self.model_executor = executor_class(\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mcache_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/executor_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, multimodal_config, speculative_config, prompt_adapter_config)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_adapter_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_adapter_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/cpu_executor.py\u001b[0m in \u001b[0;36m_init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Instantiate the worker and load the model to CPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/cpu_executor.py\u001b[0m in \u001b[0;36m_init_worker\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m         distributed_init_method = get_distributed_init_method(\n\u001b[1;32m     38\u001b[0m             get_ip(), get_open_port())\n\u001b[0;32m---> 39\u001b[0;31m         self.driver_worker = CPUWorker(\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mparallel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/cpu_worker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_config, parallel_config, scheduler_config, device_config, cache_config, load_config, local_rank, rank, distributed_init_method, lora_config, multimodal_config, kv_cache_dtype, prompt_adapter_config, is_driver_worker)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_cached_hf_modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0minit_cached_hf_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         self.model_runner: CPUModelRunner = CPUModelRunner(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mparallel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/cpu_model_runner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_config, parallel_config, scheduler_config, device_config, cache_config, load_config, lora_config, multimodal_config, kv_cache_dtype, prompt_adapter_config, is_driver_worker, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msliding_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sliding_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         self.attn_backend = get_attn_backend(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_attention_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/attention/selector.py\u001b[0m in \u001b[0;36mget_attn_backend\u001b[0;34m(num_heads, head_size, num_kv_heads, sliding_window, dtype, kv_cache_dtype, block_size, is_blocksparse)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBlocksparseFlashAttentionBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     backend = which_attn_to_use(num_heads, head_size, num_kv_heads,\n\u001b[0m\u001b[1;32m     46\u001b[0m                                 \u001b[0msliding_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                                 block_size)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/attention/selector.py\u001b[0m in \u001b[0;36mwhich_attn_to_use\u001b[0;34m(num_heads, head_size, num_kv_heads, sliding_window, dtype, kv_cache_dtype, block_size)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m# FlashAttn in NVIDIA GPUs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mselected_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_Backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLASH_ATTN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_capability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0;31m# Volta and Turing NVIDIA GPUs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             logger.info(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmajor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mminor\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0mcapability\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \"\"\"\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \"\"\"\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}],"source":["# prompt: 기존 모델 실행 시간과 vllm qunatization 실행 및 quantized 모델의 실행 시간 비교 하는 코드\n","import os\n","import time\n","import torch\n","import onnx\n","import tensorrt as trt\n","from vllm import LLM, SamplingParams\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","os.environ[\"VLLM_TARGET_DEVICE\"] = \"cpu\"\n","\n","# Load your original model\n","original_model = origin_model\n","test_time = 5\n","\n","# Measure execution time for the original model\n","start_time = time.time()\n","# Run inference with the original model\n","for _ in range(test_time):\n","    outputs = inference(input_=\"test 입력 처리 요구\",\n","                        model=origin_model)\n","end_time = time.time()\n","original_execution_time = end_time - start_time\n","print(\"Original model execution time:\", original_execution_time)\n","\n","# vllm quantization and execution\n","# Initialize vLLM with the quantized model\n","llm = LLM(model=base_model_id,\n","          tensor_parallel_size=1,\n","          device='cpu')\n","\n","# Generate text using vLLM\n","prompts = [\"This is a prompt.\"]\n","sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n","start_time = time.time()\n","for _ in range(test_time):\n","    result = llm.generate(prompts, sampling_params)\n","end_time = time.time()\n","vllm_quantized_execution_time = end_time - start_time\n","print(\"vLLM quantized model execution time:\", vllm_quantized_execution_time)\n","\n","# Compare execution times\n","speedup_vllm = original_execution_time / vllm_quantized_execution_time\n","print(\"Speedup with vLLM quantization:\", speedup_vllm)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":630},"executionInfo":{"elapsed":30999,"status":"error","timestamp":1721278381525,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"VtG4Vcx7qMND","outputId":"b319acf2-aa54-47eb-8506-94a3be7bce09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original model execution time: 29.716737508773804\n"]},{"ename":"OSError","evalue":"Incorrect path_or_model_id: 'Gunulhona/tb_pretrained_sts/triton_models/tokenizer'. Please provide either the path to a local folder or the repo_id of a model on the Hub.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'Gunulhona/tb_pretrained_sts/triton_models/tokenizer'. Use `repo_type` argument if needed.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-c07f1a6ffed2>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# hf_model.save_pretrained(\"onnx_hf_model\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTurboMind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m tm.quantize(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lmdeploy/turbomind/turbomind.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, engine_config, model_source, model_name, model_format, group_size, tp, chat_template_config, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m             tokenizer_model_path = osp.join(model_path, 'triton_models',\n\u001b[1;32m    190\u001b[0m                                             'tokenizer')\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             self.model_comm = self._from_workspace(model_path=model_path,\n\u001b[1;32m    193\u001b[0m                                                    engine_config=engine_config)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lmdeploy/tokenizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_file)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentencePieceTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lmdeploy/tokenizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_dir)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;34m'Can not find tokenizer.json. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 'It may take long time to initialize the tokenizer.')\n\u001b[0;32m--> 150\u001b[0;31m         self.model = AutoTokenizer.from_pretrained(model_dir,\n\u001b[0m\u001b[1;32m    151\u001b[0m                                                    trust_remote_code=True)\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix_space_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHFValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;34mf\"Incorrect path_or_model_id: '{path_or_repo_id}'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         ) from e\n","\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: 'Gunulhona/tb_pretrained_sts/triton_models/tokenizer'. Please provide either the path to a local folder or the repo_id of a model on the Hub."]}],"source":["\n","# prompt: 기존 모델 실행 시간과 lmdeploy qunatization 실행 및 quantized 모델의 실행 시간 비교 하는 코드\n","# 단 lmdeploy는 cli가 아닌 lmdeploy 패키지 import 를 통해 실행하여야 함\n","\n","import time\n","import torch\n","import onnx\n","import lmdeploy\n","from onnx2pytorch import ConvertModel\n","from transformers import AutoConfig, AutoModelForCausalLM\n","from lmdeploy import turbomind as tm\n","from lmdeploy import pipeline, TurbomindEngineConfig, ChatTemplateConfig\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","# Load your original model\n","original_model = origin_model\n","test_time = 5\n","\n","# Measure execution time for the original model\n","start_time = time.time()\n","# Run inference with the original model\n","for _ in range(test_time):\n","    outputs = inference(input_=\"test 입력 처리 요구\",\n","                        model=origin_model)\n","end_time = time.time()\n","original_execution_time = end_time - start_time\n","print(\"Original model execution time:\", original_execution_time)\n","\n","# lmdeploy quantization\n","onnx_model = onnx.load(\"quantized_model.onnx\" ,load_external_data=True)\n","\n","torch.save(original_model.model, \"hf_model.pth\")\n","\n","# pytorch_model = ConvertModel(onnx_model)\n","# config = AutoConfig.from_pretrained(\"bart\")  # 적절한 모델 구성으로 변경하세요\n","# config.architectures = [\"BartModel\"]  # 모델 아키텍처에 맞게 조정하세요\n","\n","# hf_model = AutoModelForCausalLM.from_config(config)\n","# hf_model.load_state_dict(pytorch_model.state_dict())\n","# hf_model.save_pretrained(\"onnx_hf_model\")\n","\n","tm_model = tm.TurboMind(model_path=base_model_id)\n","\n","tm.quantize(\n","    base_model_id,\n","    \"lmdeploy_quantized.tm\",\n","    w_bits=4, w_group_size=128)\n","quantized_tm_model = tm.TurboMind(model_path=quantized_model_path)\n","chat = quantized_tm_model.create_chat_session()\n","\n","# lmdeploy_pipe = pipeline(\n","#     base_model_id,\n","#     backend_config=TurbomindEngineConfig(model_format='hf', tp=4),\n","#     chat_template_config=ChatTemplateConfig(model_name='llama2'))\n","\n","# Measure execution time for the lmdeploy quantized model\n","# Run inference with the quantized model\n","start_time = time.time()\n","# Run inference with the original model\n","for _ in range(test_time):\n","    response, _ = quantized_chat.chat(\"This is a prompt.\")\n","end_time = time.time()\n","lmdeploy_quantized_execution_time = end_time - start_time\n","print(\"lmdeploy quantized model execution time:\", lmdeploy_quantized_execution_time)\n","\n","# Compare execution times\n","speedup_lmdeploy = original_execution_time / lmdeploy_quantized_execution_time\n","print(\"Speedup with lmdeploy quantization:\", speedup_lmdeploy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":464450,"status":"ok","timestamp":1721285623327,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"Y7SVCYOfqeDn","outputId":"b297c337-f072-439c-bf5e-c666e8006bb2"},"outputs":[{"name":"stderr","output_type":"stream","text":["No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Original model execution time: 409.310045003891\n"]},{"name":"stderr","output_type":"stream","text":["Compiling the model to CPU ...\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["OpenVINO quantized model execution time: 45.05198836326599\n","Speedup with OpenVINO quantization: 9.08528257850723\n"]}],"source":["# prompt: 기존 모델 실행 시간과 openvino qunatization 실행 및 quantized 모델의 실행 시간 비교 하는 코드\n","#@markdown Colab 환경에서는 AMD CPU 사용 중\n","\n","\n","import numpy as np\n","import openvino as ov\n","from optimum.intel import OVModelForCausalLM\n","from optimum.intel.openvino import OVQuantizationConfig\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Load your original model\n","original_model = origin_model\n","test_time = 5\n","\n","# Measure execution time for the original model\n","start_time = time.time()\n","# Run inference with the original model\n","for _ in range(test_time):\n","    outputs = inference(input_=\"test 입력 처리 요구\",\n","                        model=origin_model)\n","end_time = time.time()\n","original_execution_time = end_time - start_time\n","print(\"Original model execution time:\", original_execution_time)\n","\n","# Load the ONNX model\n","core = ov.Core()\n","ov_model = core.read_model(\"quantized_model.onnx\")\n","ov_model.reshape({model_input.any_name: ov.PartialShape([1, '?']) for model_input in ov_model.inputs})\n","\n","# Quantize the model\n","tput = {'PERFORMANCE_HINT': 'THROUGHPUT'}\n","compiled_model = core.compile_model(ov_model, 'CPU', tput)\n","\n","# ireqs = ov.AsyncInferQueue(compiled_model)\n","\n","# ov_model = OVModelForCausalLM.from_pretrained(base_model_id, export=True)\n","ov_model = OVModelForCausalLM(model=ov_model,\n","                              config=original_model.config,\n","                              use_cache=False,\n","                              use_io_binding=False,)\n","\n","\n","# Save the quantized model\n","# ov.serialize(quantized_model, \"quantized_model.xml\")\n","\n","# Load the quantized model\n","\n","# Measure execution time for the OpenVINO quantized model\n","start_time = time.time()\n","# Run inference with the OpenVINO quantized model\n","for _ in range(test_time):\n","    preprocessed = processor(\"test 입력 처리 요구\",\n","                             return_tensors=\"np\",\n","                             padding=\"max_length\",\n","                             truncation=True,\n","                             max_length=128)\n","    onnx_input= {\n","        \"input_ids\": preprocessed[\"input_ids\"].astype(np.int64),\n","        \"attention_mask\": preprocessed[\"attention_mask\"].astype(np.int64),\n","     }\n","\n","    # ireqs.start_async(onnx_input)\n","    result = inference(input_=\"test 입력 처리 요구\",\n","                       model=ov_model)\n","end_time = time.time()\n","# ireqs.wait_all()\n","openvino_quantized_execution_time = end_time - start_time\n","print(\"OpenVINO quantized model execution time:\", openvino_quantized_execution_time)\n","\n","# Compare execution times\n","speedup_openvino = original_execution_time / openvino_quantized_execution_time\n","print(\"Speedup with OpenVINO quantization:\", speedup_openvino)\n"]},{"cell_type":"markdown","metadata":{"id":"6v8KdM8BNomI"},"source":["# AWQ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265947,"status":"ok","timestamp":1745920979157,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"Lw7fduiLORql","outputId":"78997cae-32a8-4579-bb96-4c04af88852d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting autoawq\n","  Downloading autoawq-0.2.8.tar.gz (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from autoawq) (2.6.0+cu124)\n","Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (from autoawq) (3.2.0)\n","Collecting transformers<=4.47.1,>=4.45.0 (from autoawq)\n","  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from autoawq) (0.21.1)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from autoawq) (4.13.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from autoawq) (1.6.0)\n","Collecting datasets>=2.20 (from autoawq)\n","  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from autoawq) (0.23.0)\n","Requirement already satisfied: huggingface_hub>=0.26.5 in /usr/local/lib/python3.11/dist-packages (from autoawq) (0.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.20->autoawq)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (4.67.1)\n","Collecting xxhash (from datasets>=2.20->autoawq)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=2.20->autoawq)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20->autoawq)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (3.11.15)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (6.0.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->autoawq) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->autoawq) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->autoawq) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->autoawq) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->autoawq) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.6.0->autoawq)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->autoawq) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->autoawq) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<=4.47.1,>=4.45.0->autoawq) (2024.11.6)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<=4.47.1,>=4.45.0->autoawq) (0.5.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->autoawq) (5.9.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (1.20.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.20->autoawq) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.20->autoawq) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.20->autoawq) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.20->autoawq) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->autoawq) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.20->autoawq) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.20->autoawq) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.20->autoawq) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.20->autoawq) (1.17.0)\n","Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m128.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: autoawq\n","  Building wheel for autoawq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autoawq: filename=autoawq-0.2.8-py3-none-any.whl size=108745 sha256=93eda20cfd9fb2bb3840944ef54691b16df34efc0d347e72fc4a373baebfef0f\n","  Stored in directory: /root/.cache/pip/wheels/fd/03/fe/99c1c678bfe8aca712186466969ed866f52feda95ae1dcd1b1\n","Successfully built autoawq\n","Installing collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, autoawq\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.51.3\n","    Uninstalling transformers-4.51.3:\n","      Successfully uninstalled transformers-4.51.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed autoawq-0.2.8 datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.47.1 xxhash-3.5.0\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.47.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.6.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n","Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n","Collecting transformers\n","  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m138.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.47.1\n","    Uninstalling transformers-4.47.1:\n","      Successfully uninstalled transformers-4.47.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","autoawq 0.2.8 requires transformers<=4.47.1,>=4.45.0, but you have transformers 4.51.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed transformers-4.51.3\n","Collecting av\n","  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n","Collecting decord\n","  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from decord) (2.0.2)\n","Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: decord, av\n","Successfully installed av-14.3.0 decord-0.6.0\n"]}],"source":["!pip install --upgrade git+https://github.com/casper-hansen/AutoAWQ.git --force-reinstall\n","!pip install peft\n","!pip install transformers --upgrade\n","!pip install av decord\n","# !git clone https://github.com/kongds/MoRA.git && pip install -e MoRA/peft-mora"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399,"referenced_widgets":["01db25ebaa584f1ea13e1dfefb20ba43","c9d46dace4404393acb7bf5821989788","cbb7fce6e2014917aea72068d32e5cde","75e32d5750c94b54b7500211f7e25e25","a1e985c6a5cf44ca9e309dbb5fda5181","3c8af2e43c6842158ecef9632b401538","f8fb343668c345b4ad0a085167aa6b0e","c585fbbff57a4db78053b107bd685332","fa9d34458f6a43e69115e295fae6d615","937745596ad245c3be8b49370ee1e258","d87dcb12d77946b7ae259e266b5a05a4","e4859f8439c24bd0a25cf95ec4e3f84d","144b0d3a77114619b4e5efba35c4538a","4da767faa1e94df0b917d36069803c7b","a9a0e595d6f249d68ecad4609610c723","74c12595ebd34481bcfc6e6dfb3d840b","134f790e9c9043f49eb310a104ce6712","af700317f5b549eaa40d0363733eb473","258432df09754afeb91106a60993447f","4c4e565fb1df439884bf1a7073b8f705","a78f69b7088c4106a466f0c14ec5376a","17a29d963aa549fda98b68477129f55d","ce547895eb154e00a5d0a92ab35612c9","408e1572664b48b89b78e922df7eee67","4173d0b4083c45b0a78b592284691708","3faacff9ab974932884102d616a54675","84904a7d4fa44ef289946b8e2a535bc8","a6435dd10e624cbc90bb60cd3166dd0e","5562a7fd47d2480eab596fe54d2028fb","4b9271792b5646dca3d6c956f193c84b","a2fb856c576f46868f74e27a84a630fc","0b18666e18114853aadb6acf77275b51","6dc46a819e42488f9378ca1a9b645463","0db312959225425ebb1618936ef69c3c","b7cd87c1198347218b2154b8ed62ec45","07e5ff27b6b24f5cbbe93562c574b945","51d29331f7aa495fa9f15f5c4bf26df2","d7d5f90c980d446b9f9765d87715d777","03a31c58cede44788f68333a4a9ed97f","0f751611020f47328a1e20c398c05fc2","b32a8d6c5a254138a2bf8d1d37c4faab","0e01d43b2f5448078ef009d35b6143ef","b88c16b0ac3e40849e6a5ea3cf0f4b4f","81225223f16441e8af0e0b7bf1a77e07","122cdf484a444af093661e031c737f1d","cd22bef0a5a94a1b9db7dda3ff1466aa","e37021ca26a641fc8a183b7473e00a93","97d3be8b2e5f459ca241e75bf66b398f","7ee95536bb874f32b8f50b0f0d568071","327243bb8e7348cfa846c1d52174c588","dec11545ff04478eabd1be53d2c386d9","a8cc249168a54afc9e363c78a7e85d3a","9100593b71af4354ad098f1f765951ad","0e4b3678c3b64607828517e2c12bf913","97e07dec60c349afbed88fbe7edc5f26"]},"executionInfo":{"elapsed":3683937,"status":"ok","timestamp":1745925162677,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"7Ox6932pOTlQ","outputId":"3f7dd26e-206d-4cb9-c2c0-5f8cb515cdf1"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01db25ebaa584f1ea13e1dfefb20ba43","version_major":2,"version_minor":0},"text/plain":["Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4859f8439c24bd0a25cf95ec4e3f84d","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce547895eb154e00a5d0a92ab35612c9","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/167 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n","Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0db312959225425ebb1618936ef69c3c","version_major":2,"version_minor":0},"text/plain":["val.jsonl.zst:   0%|          | 0.00/471M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"122cdf484a444af093661e031c737f1d","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/214670 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["AWQ: 100%|██████████| 64/64 [59:29<00:00, 55.77s/it]\n"]},{"data":{"text/plain":["('quantized-awq/tokenizer_config.json',\n"," 'quantized-awq/special_tokens_map.json',\n"," 'quantized-awq/vocab.json',\n"," 'quantized-awq/merges.txt',\n"," 'quantized-awq/added_tokens.json',\n"," 'quantized-awq/tokenizer.json')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Calibration 데이터셋을 사용하여 모델을 양자화합니다.\n","# Calibration 데이터셋이 없으면 AutoAWQ가 자동으로 생성합니다.\n","\n","# Qwen2VLAwqQuantizer의 경우, Qwen2VLAwqQuantizer를 사용해야합니다.\n","# from autoawq.quantizers.qwen2_vl_awq_quantizer import Qwen2VLAwqQuantizer\n","\n","#quantized_model = AutoAWQForCausalLM.from_pretrained(\n","#    model_id,\n","#    quantization_config=quant_config,\n","#    trust_remote_code=True,\n","#    quantizer_cls=Qwen2VLAwqQuantizer\n","#)\n","# quantized_model = AutoAWQForCausalLM.from_pretrained(\n","#     model_id,\n","#     quantization_config=quant_config,\n","#     trust_remote_code=True,\n","    # calibration data를 지정할 경우, 아래와 같이 지정합니다.\n","    # calib_data=inputs\n","# )\n","\n","# 모델을 저장합니다.\n","# quantized_model.save_pretrained(\"quantized_model\")\n","\n","from awq import AutoAWQForCausalLM\n","from transformers import AutoTokenizer\n","\n","quant_path = 'quantized-awq'\n","quant_config = {\n","    \"zero_point\": True,\n","    \"q_group_size\": 128,\n","    \"w_bit\": 4,\n","    \"version\": \"GEMM\"\n","}\n","\n","# Load model\n","model = AutoAWQForCausalLM.from_pretrained(model_id, **{\"low_cpu_mem_usage\": True})\n","tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n","\n","# Quantize\n","model.quantize(tokenizer, quant_config=quant_config)\n","\n","# Save quantized model\n","model.save_quantized(quant_path)\n","tokenizer.save_pretrained(quant_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_50Hg6PoUwMK"},"outputs":[],"source":["import torch\n","import gc\n","\n","if \"quantized_model\" in locals():\n","    del quantized_model\n","    print(\"`quantized_model` deleted\")\n","if \"model\" in locals():\n","    del model\n","    print(\"`model` deleted\")\n","\n","# Clear CUDA memory\n","if torch.cuda.is_available():\n","  torch.cuda.empty_cache()\n","\n","# Run garbage collection\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":791,"referenced_widgets":["18dd080dc14848b2872c9fbd76af7015","39f5b21c32134e43bb52b96a2ba1c4b0","6a96952edbb14ca08572a4ba44572571","4f4c25a7e0be402ea3466f38d5d72b4c","8d58d2e9ff6d407c8c52acae933bafdb","2cbbe5058acc4ecf9725e77ffabd7ac5","ab06dfed2c1d481eb843b63daa50e86a","ad9d08d505484306a00876a1a163bbd5","cad0e6699f8342e78f5984650a76b5d6","42f0212b80024f049a1290d74dc00bfd","ee90862a2ea6460d9c89597c2a2b8773"]},"executionInfo":{"elapsed":7325,"status":"error","timestamp":1745927127699,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"XTo7tJ4ROUGX","outputId":"413b3a4d-33a9-4c40-9fe1-a1004b062d3d"},"outputs":[{"name":"stderr","output_type":"stream","text":["We suggest you to set `torch_dtype=torch.float16` for better efficiency with AWQ.\n"]},{"name":"stdout","output_type":"stream","text":["`quantized_model` deleted\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18dd080dc14848b2872c9fbd76af7015","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"CompilationError","evalue":"at 108:22:\n        masks_s = masks_sk[:, None] & masks_sn[None, :]\n        scales_ptrs = scales_ptr + offsets_s\n        scales = tl.load(scales_ptrs, mask=masks_s)\n        scales = tl.broadcast_to(scales, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n\n        b = (b >> shifts) & 0xF\n        zeros = (zeros >> shifts) & 0xF\n        b = (b - zeros) * scales\n        b = b.to(c_ptr.type.element_ty)\n\n        # Accumulate results.\n        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n                      ^","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/language/core.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                              \"(`_builder` argument must be provided outside of JIT functions.)\")\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/language/core.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(input, other, acc, input_precision, allow_tf32, max_num_imprecise_acc, out_dtype, _builder)\u001b[0m\n\u001b[1;32m   1547\u001b[0m     \u001b[0mmax_num_imprecise_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constexpr_to_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_num_imprecise_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msemantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_imprecise_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_builder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/language/semantic.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(lhs, rhs, acc, input_precision, max_num_imprecise_acc, out_dtype, builder)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                              tl.float32), f\"Unsupported rhs dtype {rhs.dtype}\"\n\u001b[0;32m-> 1470\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Both operands must be same dtype. Got {lhs.dtype} and {rhs.dtype}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Both operands must be same dtype. Got fp16 and bf16","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mCompilationError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-b0bce73d631d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# 추론을 실행합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m outputs = quantized_model.generate(\n\u001b[0m\u001b[1;32m     39\u001b[0m     input_ids=tokenizer(\n\u001b[1;32m     40\u001b[0m         \u001b[0;34m\"한국어로 된 질문에 답변해 주세요. 어떤 삶을 살아왔나요?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3431\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3432\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    851\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 )\n\u001b[1;32m    575\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    577\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         hidden_states, self_attn_weights = self.self_attn(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mhidden_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/awq/modules/linear/gemm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 out = WQLinearMMFunction.apply(\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/awq/modules/linear/gemm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, x, qweight, qzeros, scales, w_bit, group_size, bias, out_features)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 out = awq_gemm_triton(\n\u001b[0m\u001b[1;32m     68\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_k_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/awq/modules/triton/gemm.py\u001b[0m in \u001b[0;36mawq_gemm_triton\u001b[0;34m(input, qweight, scales, qzeros, split_k_iters, block_size_m, block_size_n, block_size_k)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;31m# A = M x K, B = K x N, C = M x N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_same_device_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         awq_gemm_kernel[grid](\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mqweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mmemorizes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \"\"\"\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;31m# return cast(T, functools.partial(cast(Callable, self.run), grid=grid))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, grid, warmup, *args, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;31m# compile the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASTSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             kernel = self.compile(\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/compiler/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(src, target, options)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mmodule_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_module_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodegen_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mfilter_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/compiler/compiler.py\u001b[0m in \u001b[0;36mmake_ir\u001b[0;34m(self, options, codegen_fns, module_map, context)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodegen_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\n\u001b[0m\u001b[1;32m    101\u001b[0m                            module_map=module_map)\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCompilationError\u001b[0m: at 108:22:\n        masks_s = masks_sk[:, None] & masks_sn[None, :]\n        scales_ptrs = scales_ptr + offsets_s\n        scales = tl.load(scales_ptrs, mask=masks_s)\n        scales = tl.broadcast_to(scales, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n\n        b = (b >> shifts) & 0xF\n        zeros = (zeros >> shifts) & 0xF\n        b = (b - zeros) * scales\n        b = b.to(c_ptr.type.element_ty)\n\n        # Accumulate results.\n        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n                      ^"]}],"source":["import torch\n","import gc\n","\n","if \"quantized_model\" in locals():\n","    del quantized_model\n","    print(\"`quantized_model` deleted\")\n","if \"model\" in locals():\n","    del model\n","    print(\"`model` deleted\")\n","\n","# Clear CUDA memory\n","if torch.cuda.is_available():\n","  torch.cuda.empty_cache()\n","\n","# Run garbage collection\n","gc.collect()\n","\n","# 몇 가지 예제 텍스트를 사용하여 calibration 데이터셋을 생성합니다.\n","calibration_data = [\n","    \"안녕하세요. 오늘 날씨가 어떻습니까?\",\n","    \"한국어로 된 질문에 답변해 주세요.\",\n","    \"이 모델은 AutoAWQ를 사용하여 양자화되었습니다.\"\n","]\n","inputs = tokenizer(calibration_data, return_tensors=\"pt\", padding=True)\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    inputs = inputs.to(device)\n","else:\n","    device = torch.device(\"cpu\")\n","\n","# 양자화된 모델을 로드합니다.\n","quantized_model = AutoAWQForCausalLM.from_pretrained(\n","    \"/content/quantized-awq\",\n","    trust_remote_code=True).to(device)\n","\n","# 추론을 실행합니다.\n","outputs = quantized_model.generate(\n","    input_ids=tokenizer(\n","        \"한국어로 된 질문에 답변해 주세요. 어떤 삶을 살아왔나요?\",\n","        return_tensors=\"pt\")[\"input_ids\"].to(device))\n","print(tokenizer.decode(outputs[0], skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":463,"referenced_widgets":["1250be42b2924dc5a129c120aa9a6e37","9bd160da391a40079f5ee5236e070ded","b83e722445c044df98921eb523c10326","d5a540f0ae554ca5a0a224e77a723c3c","ebeb22c4c6ce4ad89042c0498ce75a5b","09db184c8c6e4b678bfe24a2f4c6bad6","f69dd1622f514179a00151c93f0030f3","085f90eefced42028b1e042db09d4e61","7f15667c49c04c0f8d989428cefc6c42","850121a0da4140c2a7a59f420768f2cb","08f70c9ba5f54f5c8db0c444aad4e0ce","3343fd1ff7fd41278e191f9ab1c573b3","364418d7afdb4b229f60fbbbc2e91617","7ef09edcad7041269f5f20ec31ef01c2","5f730705c1e545f79f19d5e660b02edd","866355f0e97c4eddb30dcc508e30595e","05cacd64f0874b5784875a80f2c31898","a1d14d3fafb94609905fc79fa2bedcd1","7977dc9ff0124a85b424b9fbf9550fb2","be68f823edfe4f6daad44f7b3323b239","433445fa58744b5bb21fde29eb1c18cc","44d7486d7f814413a4c2a8367a40e175","e13667aee47b4254b2df273f71e3f71e","2e8e8ad8b1134717990e2d0bb4bd04d2","4df6230c4c824fc4861b7ca090c82d77","86c9f7831e6340719d69ca4087fac3d2","d4ec32eb8126489497513347cd22714f","99bf4012b65b4de8878761d2e89f832f","197f1e48e12a43cc9d4b676adb468720","24a06af73b024eab8b64723b8cf2df6b","dfe175edf8a44de786cdf1159b1d922b","dc2fbf91b935448fa48425e52a0d9520","c07bfda1069f440ca62e2c244c9d53cd","f8e5d4cac90c44679c0d718415d5a496","e158a4d56adc4aea8f193b283e85f8c1","6625ee772bdb432f99316ccc700ed523","1e39994307d141bc8736f392f5859f91","d593a76d9e684257ba57aff818e5985f","46ba727e2ffa4926947664589444e3da","9a52464692004c63b82b10771a0e2625","f60797d5e4d74b6482ea56087841fb50","1037170738084fddb4dcd0244048be7f","1b22e3a7bfe6412696542c7bb076dcaf","8be488fd81c14bbdac16058c5d10a5d3","b65216a5f3d4458b8639839cd343c084","d92f72f4c3b74b1fa9bfe5b6c48d6e29","ecc9661d8f844b42ab2102d7e3e78e1b","46ce82f30eb54b638ec7b9c2b296d175","3733f79962024c969156c22aee99bebc","12f54a34ccaf43218825ad0c9ae2a5b0","cb2b66d89c574385ba52b1b45263c5f6","c27620e0710e4a8e859d2ed70fc3bfa3","66e131eaad794ad7aa43f00d9a705990","21c8536c6843493fa1fa4ccf936442b9","315004cb004c47629a6a41b02ddf18f1","5669cb09e6464babab4a7a1414f11754","22a4b14727b8457390fe133f375af0a6","8a1fb056147e442a853084cd1050d5f9","2c9307631ded4c4da02735ca025e8142","b405140afd5348a2a568cc3f59ebac51","25423c2f912d4c1a90695b7dc8c72219","24b253c76aab4cd8a79c465c864639dd","b7af7d5489d14342b7e4bd7153a07659","a14d574e35a847df93a5e5b63b0bee75","e081a53574124d26914298bb26c3a84d","1f874a426fa049118dd57ffe189e5106","f7cef7cae860442888c1323837bc007a","4147acf49ab74e7b8ee5c09552d8ea3f","e6fbf261839042f882cbc540ffb81d65","0aa301aeef5a4b4a9e3319d52fb90d09","9891fb318acf4318bb1c1a13e1e02d50","e55a9640e8984295a191cd930934bcf8","acb6e270a66248b9a5bb24a1ec3478c6","ffbae49e989e49b8b16f63264f304952","31d2939315d54017b7cdc413b8c0d085","7a2100b514b645a4be517295a71ce0da","e7950701ebb349fb93e7a3258b8484f2"]},"executionInfo":{"elapsed":363528,"status":"ok","timestamp":1745925578701,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"7KFC0MIoOc53","outputId":"2b327364-36b3-4443-a80f-1a3e9314bb28"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1250be42b2924dc5a129c120aa9a6e37","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/4.41G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3343fd1ff7fd41278e191f9ab1c573b3","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e13667aee47b4254b2df273f71e3f71e","version_major":2,"version_minor":0},"text/plain":["Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8e5d4cac90c44679c0d718415d5a496","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b65216a5f3d4458b8639839cd343c084","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5669cb09e6464babab4a7a1414f11754","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7cef7cae860442888c1323837bc007a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["CommitInfo(commit_url='https://huggingface.co/Gunulhona/Qwen3-32B-awq-4bit/commit/5d0625e127551d998858a4dcf02652015acc60cd', commit_message='Upload tokenizer', commit_description='', oid='5d0625e127551d998858a4dcf02652015acc60cd', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Gunulhona/Qwen3-32B-awq-4bit', endpoint='https://huggingface.co', repo_type='model', repo_id='Gunulhona/Qwen3-32B-awq-4bit'), pr_revision=None, pr_num=None)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# repo_name = \"Gunulhona/Gemma-System-9B-MoRA-SimPO-AWQ\"\n","repo_name = \"Gunulhona/Qwen3-32B-awq-4bit\"\n","quantized_model.push_to_hub(repo_name)\n","tokenizer.push_to_hub(repo_name)"]},{"cell_type":"markdown","metadata":{"id":"mCL4MMALu1iW"},"source":["# GTPQ Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ufwZHtTyvBMV","outputId":"21891e41-ad79-47f7-e682-5e1bfbb9ed99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'GPTQModel'...\n","remote: Enumerating objects: 17950, done.\u001b[K\n","remote: Counting objects: 100% (1303/1303), done.\u001b[K\n","remote: Compressing objects: 100% (660/660), done.\u001b[K\n","remote: Total 17950 (delta 1088), reused 665 (delta 643), pack-reused 16647 (from 2)\u001b[K\n","Receiving objects: 100% (17950/17950), 12.30 MiB | 17.89 MiB/s, done.\n","Resolving deltas: 100% (13219/13219), done.\n","Using pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n","Processing /content/GPTQModel\n","  Running command python setup.py egg_info\n","  /usr/local/lib/python3.11/dist-packages/setuptools/dist.py:333: InformationOnly: Normalizing '3.1.0-dev' to '3.1.0.dev0'\n","    self.metadata.version = self._normalize_version(self.metadata.version)\n","  conda_cuda_include_dir /usr/lib/python3.11/site-packages/nvidia/cuda_runtime/include\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-6fl2e_dd/gptqmodel.egg-info\n","  writing /tmp/pip-pip-egg-info-6fl2e_dd/gptqmodel.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-6fl2e_dd/gptqmodel.egg-info/dependency_links.txt\n","  writing requirements to /tmp/pip-pip-egg-info-6fl2e_dd/gptqmodel.egg-info/requires.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-6fl2e_dd/gptqmodel.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-6fl2e_dd/gptqmodel.egg-info/SOURCES.txt'\n","  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:529: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","    warnings.warn(msg.format('we could not find ninja.'))\n","  reading manifest file '/tmp/pip-pip-egg-info-6fl2e_dd/gptqmodel.egg-info/SOURCES.txt'\n","  reading manifest template 'MANIFEST.in'\n","  no previously-included directories found matching 'format'\n","  adding license file 'LICENSE'\n","  writing manifest file '/tmp/pip-pip-egg-info-6fl2e_dd/gptqmodel.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: accelerate>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (1.6.0)\n","Collecting datasets>=3.5.0 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for datasets>=3.5.0 from https://files.pythonhosted.org/packages/e3/f5/668b3444a2f487b0052b908af631fe39eeb2bdb2359d9bbc2c3b80b71119/datasets-3.5.1-py3-none-any.whl.metadata\n","  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (2.0.2)\n","Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (2.6.0+cu124)\n","Requirement already satisfied: safetensors>=0.5.3 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (0.5.3)\n","Requirement already satisfied: transformers>=4.51.2 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (4.51.3)\n","Requirement already satisfied: threadpoolctl>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (3.6.0)\n","Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (24.2)\n","Collecting device-smi==0.4.1 (from gptqmodel==3.1.0.dev0)\n","  Downloading device_smi-0.4.1.tar.gz (17 kB)\n","  Running command python setup.py egg_info\n","  /usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py:261: UserWarning: Unknown distribution option: 'platform'\n","    warnings.warn(msg)\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-aafi5icm/device_smi.egg-info\n","  writing /tmp/pip-pip-egg-info-aafi5icm/device_smi.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-aafi5icm/device_smi.egg-info/dependency_links.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-aafi5icm/device_smi.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-aafi5icm/device_smi.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-aafi5icm/device_smi.egg-info/SOURCES.txt'\n","  adding license file 'LICENSE'\n","  writing manifest file '/tmp/pip-pip-egg-info-aafi5icm/device_smi.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: protobuf>=5.29.3 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (5.29.4)\n","Requirement already satisfied: pillow>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (11.2.1)\n","Collecting hf_transfer>=0.1.9 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for hf_transfer>=0.1.9 from https://files.pythonhosted.org/packages/d6/d8/f87ea6f42456254b48915970ed98e993110521e9263472840174d32c880d/hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: huggingface_hub>=0.30.1 in /usr/local/lib/python3.11/dist-packages (from gptqmodel==3.1.0.dev0) (0.30.2)\n","Collecting random_word==1.0.13 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for random_word==1.0.13 from https://files.pythonhosted.org/packages/df/46/3ce7166b6f99e61fab286d807bf8834cb8e23adbc1becff047b37c9cd666/random_word-1.0.13-py3-none-any.whl.metadata\n","  Downloading random_word-1.0.13-py3-none-any.whl.metadata (4.3 kB)\n","Collecting tokenicer==0.0.4 (from gptqmodel==3.1.0.dev0)\n","  Downloading tokenicer-0.0.4.tar.gz (10 kB)\n","  Running command python setup.py egg_info\n","  /usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py:261: UserWarning: Unknown distribution option: 'platform'\n","    warnings.warn(msg)\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-1cospj1p/tokenicer.egg-info\n","  writing /tmp/pip-pip-egg-info-1cospj1p/tokenicer.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-1cospj1p/tokenicer.egg-info/dependency_links.txt\n","  writing requirements to /tmp/pip-pip-egg-info-1cospj1p/tokenicer.egg-info/requires.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-1cospj1p/tokenicer.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-1cospj1p/tokenicer.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-1cospj1p/tokenicer.egg-info/SOURCES.txt'\n","  reading manifest template 'MANIFEST.in'\n","  no previously-included directories found matching 'tests'\n","  adding license file 'LICENSE'\n","  writing manifest file '/tmp/pip-pip-egg-info-1cospj1p/tokenicer.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting logbar==0.0.4 (from gptqmodel==3.1.0.dev0)\n","  Downloading logbar-0.0.4.tar.gz (12 kB)\n","  Running command python setup.py egg_info\n","  /usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py:261: UserWarning: Unknown distribution option: 'platform'\n","    warnings.warn(msg)\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-y4c2qe8s/logbar.egg-info\n","  writing /tmp/pip-pip-egg-info-y4c2qe8s/logbar.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-y4c2qe8s/logbar.egg-info/dependency_links.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-y4c2qe8s/logbar.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-y4c2qe8s/logbar.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-y4c2qe8s/logbar.egg-info/SOURCES.txt'\n","  reading manifest template 'MANIFEST.in'\n","  no previously-included directories found matching 'tests'\n","  adding license file 'LICENSE'\n","  writing manifest file '/tmp/pip-pip-egg-info-y4c2qe8s/logbar.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting autopep8<3.0.0,>=2.3.1 (from random_word==1.0.13->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for autopep8<3.0.0,>=2.3.1 from https://files.pythonhosted.org/packages/9e/43/53afb8ba17218f19b77c7834128566c5bbb100a0ad9ba2e8e89d089d7079/autopep8-2.3.2-py2.py3-none-any.whl.metadata\n","  Downloading autopep8-2.3.2-py2.py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: pytest<9.0.0,>=8.3.3 in /usr/local/lib/python3.11/dist-packages (from random_word==1.0.13->gptqmodel==3.1.0.dev0) (8.3.5)\n","Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from random_word==1.0.13->gptqmodel==3.1.0.dev0) (6.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from random_word==1.0.13->gptqmodel==3.1.0.dev0) (2.32.3)\n","Collecting vllm>=0.7.3 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for vllm>=0.7.3 from https://files.pythonhosted.org/packages/26/7e/08d7a75c47792fd07d02b2be6fe6adbb29dfcbd31e94784844d7f730d0bc/vllm-0.8.5-cp38-abi3-manylinux1_x86_64.whl.metadata\n","  Downloading vllm-0.8.5-cp38-abi3-manylinux1_x86_64.whl.metadata (14 kB)\n","Collecting flashinfer-python>=0.2.1 (from gptqmodel==3.1.0.dev0)\n","  Downloading flashinfer_python-0.2.5.tar.gz (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Running command Preparing metadata (pyproject.toml)\n","  running dist_info\n","  creating /tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python.egg-info\n","  writing /tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python.egg-info/dependency_links.txt\n","  writing requirements to /tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python.egg-info/requires.txt\n","  writing top-level names to /tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python.egg-info/SOURCES.txt'\n","  adding license file 'LICENSE'\n","  writing manifest file '/tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python.egg-info/SOURCES.txt'\n","  creating '/tmp/pip-modern-metadata-jgwgi5m8/flashinfer_python-0.2.5.dist-info'\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting bitblas==0.0.1-dev13 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for bitblas==0.0.1-dev13 from https://files.pythonhosted.org/packages/c3/74/2ba2c9400321271f43a3a2ce8c6b4d8a27ccacc3a840613ba13642354002/bitblas-0.0.1.dev13-py3-none-manylinux1_x86_64.whl.metadata\n","  Downloading bitblas-0.0.1.dev13-py3-none-manylinux1_x86_64.whl.metadata (11 kB)\n","Collecting intel_extension_for_pytorch>=2.6.0 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for intel_extension_for_pytorch>=2.6.0 from https://files.pythonhosted.org/packages/5e/ba/04cf1c89cef2ac88dfdf4609badccf49de6a69abebdb92ec88e227eaa61d/intel_extension_for_pytorch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n","  Downloading intel_extension_for_pytorch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n","Collecting auto_round>=0.3 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for auto_round>=0.3 from https://files.pythonhosted.org/packages/dd/8f/3fe5260d49f303c0c6a038eb305032ba8865ea8db995842e15d7cb65c269/auto_round-0.5.1-py3-none-any.whl.metadata\n","  Downloading auto_round-0.5.1-py3-none-any.whl.metadata (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (1.17.1)\n","Collecting cpplint (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for cpplint from https://files.pythonhosted.org/packages/66/65/08d3a5039b565231c501b31d1a973d4222e9803c03b2c31a9c08bdec3e30/cpplint-2.0.2-py3-none-any.whl.metadata\n","  Downloading cpplint-2.0.2-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (3.0.12)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (4.4.2)\n","Requirement already satisfied: docutils in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (0.21.2)\n","Collecting dtlib (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for dtlib from https://files.pythonhosted.org/packages/b3/b7/c1fcd4887373094fd5f6a007db33f61b4c4f1e88e9b685ce3fe9a41726ea/dtlib-0.0.0.dev2-py3-none-any.whl.metadata\n","  Downloading dtlib-0.0.0.dev2-py3-none-any.whl.metadata (1.8 kB)\n","Collecting pytest-xdist>=2.2.1 (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for pytest-xdist>=2.2.1 from https://files.pythonhosted.org/packages/6d/82/1d96bf03ee4c0fdc3c0cbe61470070e659ca78dc0086fb88b66c185e2449/pytest_xdist-3.6.1-py3-none-any.whl.metadata\n","  Downloading pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (4.13.2)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (25.3.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (3.1.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (0.4.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (5.9.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (1.15.2)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (6.4.2)\n","Collecting thefuzz (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for thefuzz from https://files.pythonhosted.org/packages/82/4f/1695e70ceb3604f19eda9908e289c687ea81c4fecef4d90a9d1d0f2f7ae9/thefuzz-0.22.1-py3-none-any.whl.metadata\n","  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (0.9.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from auto_round>=0.3->gptqmodel==3.1.0.dev0) (9.0.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from auto_round>=0.3->gptqmodel==3.1.0.dev0) (0.2.0)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/3a/be/650f9c091ef71cb01d735775d554e068752d3ff63d7943b26316dc401749/numpy-1.21.2.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/5f/d6/ad58ded26556eaeaa8c971e08b6466f17c4ac4d786cd3d800e26ce59cc01/numpy-1.21.3.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/fb/48/b0708ebd7718a8933f0d3937513ef8ef2f4f04529f1f66ca86d873043921/numpy-1.21.4.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/c2/a8/a924a09492bdfee8c2ec3094d0a13f2799800b4fdc9c890738aeeb12c72e/numpy-1.21.5.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/45/b7/de7b8e67f2232c26af57c205aaad29fe17754f793404f59c8a730c7a191a/numpy-1.21.6.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","Collecting numpy>=1.26.4 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for numpy>=1.26.4 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from auto_round>=0.3->gptqmodel==3.1.0.dev0) (0.60.0)\n","Requirement already satisfied: tbb in /usr/local/lib/python3.11/dist-packages (from auto_round>=0.3->gptqmodel==3.1.0.dev0) (2022.1.0)\n","Collecting lm-eval<0.5,>=0.4.2 (from auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for lm-eval<0.5,>=0.4.2 from https://files.pythonhosted.org/packages/c3/0b/36d6117f644f3685e6b87005ecd7051d01e9cdcf617e8e671102c1546de2/lm_eval-0.4.8-py3-none-any.whl.metadata\n","  Downloading lm_eval-0.4.8-py3-none-any.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.5.0->gptqmodel==3.1.0.dev0) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.5.0->gptqmodel==3.1.0.dev0) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.5.0->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for dill<0.3.9,>=0.3.0 from https://files.pythonhosted.org/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl.metadata\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.5.0->gptqmodel==3.1.0.dev0) (2.2.2)\n","Collecting xxhash (from datasets>=3.5.0->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/d9/72/9256303f10e41ab004799a4aa74b80b3c5977d6383ae4550548b24bd1971/xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=3.5.0->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for multiprocess<0.70.17 from https://files.pythonhosted.org/packages/50/15/b56e50e8debaf439f44befec5b2af11db85f6e0f344c3113ae0be0593a91/multiprocess-0.70.16-py311-none-any.whl.metadata\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.5.0->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for fsspec<=2025.3.0,>=2023.1.0 from https://files.pythonhosted.org/packages/56/53/eb690efa8513166adef3e0669afd31e95ffde69fb3c52ec2ac7223ed6018/fsspec-2025.3.0-py3-none-any.whl.metadata\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=3.5.0->gptqmodel==3.1.0.dev0) (3.11.15)\n","Collecting ninja (from flashinfer-python>=0.2.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/eb/7a/455d2877fe6cf99886849c7f9755d897df32eaf3a0fba47b56e615f880f7/ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n","  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->gptqmodel==3.1.0.dev0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->gptqmodel==3.1.0.dev0) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-cuda-nvrtc-cu12==12.4.127 from https://files.pythonhosted.org/packages/2c/14/91ae57cd4db3f9ef7aa99f4019cfa8d54cb4caa7e00975df6467e9725a9f/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-cuda-runtime-cu12==12.4.127 from https://files.pythonhosted.org/packages/ea/27/1795d86fe88ef397885f2e580ac37628ed058a92ed2c39dc8eac3adf0619/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-cuda-cupti-cu12==12.4.127 from https://files.pythonhosted.org/packages/67/42/f4f60238e8194a3106d06a058d494b18e006c10bb2b915655bd9f6ea4cb1/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-cudnn-cu12==9.1.0.70 from https://files.pythonhosted.org/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-cublas-cu12==12.4.5.8 from https://files.pythonhosted.org/packages/ae/71/1c91302526c45ab494c23f61c7a84aa568b8c1f9d196efa5993957faf906/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-cufft-cu12==11.2.1.3 from https://files.pythonhosted.org/packages/27/94/3266821f65b92b3138631e9c8e7fe1fb513804ac934485a8d05776e1dd43/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-curand-cu12==10.3.5.147 from https://files.pythonhosted.org/packages/8a/6d/44ad094874c6f1b9c654f8ed939590bdc408349f137f9b98a3a23ccec411/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-cusolver-cu12==11.6.1.9 from https://files.pythonhosted.org/packages/3a/e1/5b9089a4b2a4790dfdea8b3a006052cfecff58139d5a4e34cb1a51df8d6f/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-cusparse-cu12==12.3.1.170 from https://files.pythonhosted.org/packages/db/f7/97a9ea26ed4bbbfc2d470994b8b4f338ef663be97b8f677519ac195e113d/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->gptqmodel==3.1.0.dev0) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->gptqmodel==3.1.0.dev0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->gptqmodel==3.1.0.dev0) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.1->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nvidia-nvjitlink-cu12==12.4.127 from https://files.pythonhosted.org/packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->gptqmodel==3.1.0.dev0) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->gptqmodel==3.1.0.dev0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.1->gptqmodel==3.1.0.dev0) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.2->gptqmodel==3.1.0.dev0) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.2->gptqmodel==3.1.0.dev0) (0.21.1)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (5.5.2)\n","Collecting blake3 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for blake3 from https://files.pythonhosted.org/packages/f0/d6/6377bd058a0e7aa7c33debcc8370e6c9769b6c6fa2f4a9583f07ec91d50a/blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for fastapi>=0.115.0 from https://files.pythonhosted.org/packages/50/b3/b51f09c2ba432a576fe63758bddc81f78f0c6309d9e5c10d194313bf021e/fastapi-0.115.12-py3-none-any.whl.metadata\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.76.0)\n","Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (2.11.3)\n","Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.21.1)\n","Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for prometheus-fastapi-instrumentator>=7.0.0 from https://files.pythonhosted.org/packages/27/72/0824c18f3bc75810f55dacc2dd933f6ec829771180245ae3cc976195dec0/prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata\n","  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n","Collecting tiktoken>=0.6.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for tiktoken>=0.6.0 from https://files.pythonhosted.org/packages/b1/73/41591c525680cd460a6becf56c9b17468d3711b1df242c53d2c7b2183d16/tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for lm-format-enforcer<0.11,>=0.10.11 from https://files.pythonhosted.org/packages/06/cb/bf172960241842e953b3354247f792aae2fc5221552a0741a1c98f35b6f7/lm_format_enforcer-0.10.11-py3-none-any.whl.metadata\n","  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n","Collecting llguidance<0.8.0,>=0.7.9 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for llguidance<0.8.0,>=0.7.9 from https://files.pythonhosted.org/packages/bc/7d/f884291c0e52fb2c8d999fd6c3971bade3fda2b975a57a2d9047f05155ba/llguidance-0.7.19-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading llguidance-0.7.19-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Collecting outlines==0.1.11 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for outlines==0.1.11 from https://files.pythonhosted.org/packages/13/b4/99ea4a122bef60e3fd6402d19665aff1f928e0daf8fac3044d0b73f72003/outlines-0.1.11-py3-none-any.whl.metadata\n","  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n","Collecting lark==1.2.2 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for lark==1.2.2 from https://files.pythonhosted.org/packages/2d/00/d90b10b962b4277f5e64a78b6609968859ff86889f5b898c1a778c06ec00/lark-1.2.2-py3-none-any.whl.metadata\n","  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n","Collecting xgrammar==0.1.18 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for xgrammar==0.1.18 from https://files.pythonhosted.org/packages/56/73/ba7bd8db631d3bbf224599d32587a2b94c4b4c539c47aa7b0ee2f8764d72/xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting partial-json-parser (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for partial-json-parser from https://files.pythonhosted.org/packages/8c/ee/a9476f01f27c74420601be208c6c2c0dd3486681d515e9d765931b89851c/partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata\n","  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n","Collecting pyzmq>=25.0.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for pyzmq>=25.0.0 from https://files.pythonhosted.org/packages/4e/6e/159cbf2055ef36aa2aa297e01b24523176e5b48ead283c23a94179fb2ba2/pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n","  Downloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n","Collecting msgspec (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for msgspec from https://files.pythonhosted.org/packages/85/2e/db7e189b57901955239f7689b5dcd6ae9458637a9c66747326726c650523/msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Collecting gguf>=0.13.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for gguf>=0.13.0 from https://files.pythonhosted.org/packages/15/18/89697e4996920aa1e60f0061d0bb110f738a5ba3de12ed74309f51a10a0a/gguf-0.16.2-py3-none-any.whl.metadata\n","  Downloading gguf-0.16.2-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (8.6.1)\n","Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for mistral_common>=1.5.4 from https://files.pythonhosted.org/packages/80/7a/421819257cd642b33d71819e2ff259fb019a49ea48e830e5a32558c52cb7/mistral_common-1.5.4-py3-none-any.whl.metadata\n","  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n","Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (4.11.0.86)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.8.1)\n","Collecting compressed-tensors==0.9.3 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for compressed-tensors==0.9.3 from https://files.pythonhosted.org/packages/79/87/9c7eb4b57f89a51a65bee166cc079cd1bc1b398823da4f3b3c12f1021af8/compressed_tensors-0.9.3-py3-none-any.whl.metadata\n","  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n","Collecting depyf==0.18.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for depyf==0.18.0 from https://files.pythonhosted.org/packages/e7/d8/efc291d5c69a9905515055d23977643dd0d482ebfeb0dbabef1947ee75d8/depyf-0.18.0-py3-none-any.whl.metadata\n","  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting watchfiles (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for watchfiles from https://files.pythonhosted.org/packages/71/87/6dc5ec6882a2254cfdd8b0718b684504e737273903b65d7338efaba08b52/watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting python-json-logger (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for python-json-logger from https://files.pythonhosted.org/packages/08/20/0f2523b9e50a8052bc6a8b732dfc8568abbdc42010aef03a2d750bdab3b2/python_json_logger-3.3.0-py3-none-any.whl.metadata\n","  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n","Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for opentelemetry-sdk<1.27.0,>=1.26.0 from https://files.pythonhosted.org/packages/92/f1/a9b550d0f9c049653dd2eab45cecf8fe4baa9795ed143d87834056ffabaf/opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata\n","  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for opentelemetry-api<1.27.0,>=1.26.0 from https://files.pythonhosted.org/packages/e3/a7/6322d1d7a1fb926e8b99208c27730f21217da2f1e0e11dab48a78a0427a4/opentelemetry_api-1.26.0-py3-none-any.whl.metadata\n","  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n","Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for opentelemetry-exporter-otlp<1.27.0,>=1.26.0 from https://files.pythonhosted.org/packages/87/71/b9221af6af61213c522401b5f46a5eaa41d8dd7daeb0740dc5604f5c3980/opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata\n","  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 from https://files.pythonhosted.org/packages/b3/b5/299c8a0a4bf855a8c2b39869ebfa655a501c6a434c4973e81f0b032132f7/opentelemetry_semantic_conventions_ai-0.4.5-py3-none-any.whl.metadata\n","  Downloading opentelemetry_semantic_conventions_ai-0.4.5-py3-none-any.whl.metadata (1.2 kB)\n","  Link requires a different Python (3.11.12 not in: '>=3.6,<3.9'): https://files.pythonhosted.org/packages/d1/68/d872f91bcb57c00c54835beb950a9d9ceb99e497f167fa333e8eba968ecc/numba-0.52.0rc3.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.9)\n","  Link requires a different Python (3.11.12 not in: '>=3.6,<3.9'): https://files.pythonhosted.org/packages/46/e1/cbbc7c7967d9b10e54c852bf5bece0222a63bfb809d3354014c957ef1bda/numba-0.52.0.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.9)\n","  Link requires a different Python (3.11.12 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/c8/e6/681c43623f362d6c504eb29944184c0df6357be10ed2fad6071fd1b7e143/numba-0.53.0rc1.post1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/d4/b2/d6e507259f4630b319811b57c2bb3364d2737ae297a972a055cf40df36a5/numba-0.53.0rc2.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/5e/ef/d761365ea63f28b85574069e953664e9fe218d50b85b3f84849ebecf953c/numba-0.53.0rc3.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/b0/6d/bb1204879726d6db6dc92de995bdbd64792369f0be3f8a36710cc2d93f78/numba-0.53.0.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/e3/7d/3d61160836e49f40913741c464f119551c15ed371c1d91ea50308495b93b/numba-0.53.1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/f2/76/00e4f3443c093f6064044357b8f07abde5ed7a15d6c43988a68c184b62a5/numba-0.54.0rc2.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/ec/74/f6ff055664ac01adac37ad8f5ab5c94d75badfd264fdab209e0f5f1fafef/numba-0.54.0rc3.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/24/66/4720b6f70b42c74f10296a9803f8ba28c284f55cee6839f457bc67588277/numba-0.54.0.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/d3/93/05c88fc9f17655a93428f49646d1086c8b2b98e8531033f13f3fe464fae5/numba-0.54.1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/05/d9/5a3bc6549fe7ea8336f06cd72dac0ad69b18c8089930e560467cf9de359d/numba-0.55.0rc1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/cf/e2/8213c08fc9392c99b37de9823119a83576469354154eb08ad653b6ab5213/numba-0.55.0.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/69/df/bd36068b2c1d0d34794f8ac0c222f9c4ad88dc710b400e65dbb3b59ea57e/numba-0.55.1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/39/dd/7109030bb584e8f0c4c8796bfd39fc5811cb77368a8c5db335f99c1fec9e/numba-0.55.2.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.11)\n","Collecting numba (from auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/97/c8/8740616c8436c86c1b9a62e72cb891177d2c34c2d24ddcde4c390371bf4c/numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n","  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n","Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for ray!=2.44.*,>=2.43.0 from https://files.pythonhosted.org/packages/95/15/52d54293b820251ba2b374275fc60a7603aff48c2f6da86fc4ce75ed7af1/ray-2.45.0-cp311-cp311-manylinux2014_x86_64.whl.metadata\n","  Downloading ray-2.45.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (2.6.0+cu124)\n","Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.21.0+cu124)\n","Collecting xformers==0.0.29.post2 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for xformers==0.0.29.post2 from https://files.pythonhosted.org/packages/8d/a1/2433df25c425de6186f9359831cb0d401075810f473c5ba24beec2c51efc/xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n","  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Collecting astor (from depyf==0.18.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for astor from https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl.metadata\n","  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n","  Link requires a different Python (3.11.12 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/19/66/6b2c49c7c68da48d17059882fdb9ad9ac9e5ac3f22b00874d7996e3c44a8/llvmlite-0.36.0.tar.gz (from https://pypi.org/simple/llvmlite/) (requires-python:>=3.6,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/55/21/f7df5d35f3f5d0637d64a89f6b0461f2adf78e22916d6372486f8fc2193d/llvmlite-0.37.0.tar.gz (from https://pypi.org/simple/llvmlite/) (requires-python:>=3.7,<3.10)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/d8/e3/bd329a96549809598acd5daaccd35fd9d0883185cfe7f681a9e3e54beaa0/llvmlite-0.38.0.tar.gz (from https://pypi.org/simple/llvmlite/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/90/fc/313c916fb49495ac7c1f9ab213cd3d3285342691b860a2810a51c6c1a10e/llvmlite-0.38.1.tar.gz (from https://pypi.org/simple/llvmlite/) (requires-python:>=3.7,<3.11)\n","Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for llvmlite<0.45,>=0.44.0dev0 from https://files.pythonhosted.org/packages/99/fe/d030f1849ebb1f394bb3f7adad5e729b634fb100515594aca25c354ffc62/llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n","Collecting interegular (from outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for interegular from https://files.pythonhosted.org/packages/c4/01/72d6472f80651673716d1deda2a5bbb633e563ecf94f4479da5519d69d25/interegular-0.3.3-py37-none-any.whl.metadata\n","  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.6.0)\n","Collecting diskcache (from outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for diskcache from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.36.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (4.23.0)\n","Collecting pycountry (from outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for pycountry from https://files.pythonhosted.org/packages/b1/ec/1fb891d8a2660716aadb2143235481d15ed1cbfe3ad669194690b0604492/pycountry-24.6.1-py3-none-any.whl.metadata\n","  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n","Collecting airportsdata (from outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for airportsdata from https://files.pythonhosted.org/packages/19/c3/3fc94ab580f50f56a8f68fd4e619730fbc8c079f0028cf37664c1c7411de/airportsdata-20250224-py3-none-any.whl.metadata\n","  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n","Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for outlines_core==0.1.26 from https://files.pythonhosted.org/packages/92/f0/ad0074d6726fed86bb0bba1b9307cbbd67a2af5debd3540d66c69298a001/outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting pycodestyle>=2.12.0 (from autopep8<3.0.0,>=2.3.1->random_word==1.0.13->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for pycodestyle>=2.12.0 from https://files.pythonhosted.org/packages/07/be/b00116df1bfb3e0bb5b45e29d604799f7b91dd861637e4d448b4e09e6a3e/pycodestyle-2.13.0-py2.py3-none-any.whl.metadata\n","  Downloading pycodestyle-2.13.0-py2.py3-none-any.whl.metadata (4.5 kB)\n","Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for starlette<0.47.0,>=0.40.0 from https://files.pythonhosted.org/packages/8b/0c/9d30a4ebeb6db2b25a841afbb80f6ef9a854fc3b41be131d249a977b4959/starlette-0.46.2-py3-none-any.whl.metadata\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for fastapi-cli>=0.0.5 from https://files.pythonhosted.org/packages/a1/e6/5daefc851b514ce2287d8f5d358ae4341089185f78f3217a69d0ce3a390c/fastapi_cli-0.0.7-py3-none-any.whl.metadata\n","  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.28.1)\n","Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for python-multipart>=0.0.18 from https://files.pythonhosted.org/packages/45/58/38b5afbc1a800eeea951b9285d3912613f2603bdf897a4ab0f4bd7f405fc/python_multipart-0.0.20-py3-none-any.whl.metadata\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for email-validator>=2.0.0 from https://files.pythonhosted.org/packages/d7/ee/bf0adb559ad3c786f12bcbc9296b3f5675f529199bef03e2df281fa1fadb/email_validator-2.2.0-py3-none-any.whl.metadata\n","  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n","Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for uvicorn>=0.12.0 from https://files.pythonhosted.org/packages/b1/4b/4cef6ce21a2aaca9d852a6e84ef4f135d99fcd74fa75105e2fc0c8308acd/uvicorn-0.34.2-py3-none-any.whl.metadata\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (1.3.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (1.20.0)\n","Collecting hf-xet>=0.1.4 (from huggingface-hub[hf_xet]>=0.30.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for hf-xet>=0.1.4 from https://files.pythonhosted.org/packages/83/9a/d40d2a57b132d609d8a4ccc29e59ed69749021610616749cabcda2532158/hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.1->gptqmodel==3.1.0.dev0) (3.0.2)\n","Collecting evaluate (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/a2/e7/cbca9e2d2590eb9b5aa8f7ebabe1beb1498f9462d2ecede5c9fd9735faaf/evaluate-0.4.3-py3-none-any.whl.metadata\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Collecting jsonlines (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for jsonlines from https://files.pythonhosted.org/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl.metadata\n","  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (2.10.2)\n","Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (0.15.2)\n","Collecting pybind11>=2.6.2 (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for pybind11>=2.6.2 from https://files.pythonhosted.org/packages/13/2f/0f24b288e2ce56f51c920137620b4434a38fd80583dbbe24fc2a1656c388/pybind11-2.13.6-py3-none-any.whl.metadata\n","  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n","Collecting pytablewriter (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for pytablewriter from https://files.pythonhosted.org/packages/21/4c/c199512f01c845dfe5a7840ab3aae6c60463b5dc2a775be72502dfd9170a/pytablewriter-1.2.1-py3-none-any.whl.metadata\n","  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n","Collecting rouge-score>=0.0.4 (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Running command python setup.py egg_info\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-2ngquv__/rouge_score.egg-info\n","  writing /tmp/pip-pip-egg-info-2ngquv__/rouge_score.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-2ngquv__/rouge_score.egg-info/dependency_links.txt\n","  writing requirements to /tmp/pip-pip-egg-info-2ngquv__/rouge_score.egg-info/requires.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-2ngquv__/rouge_score.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-2ngquv__/rouge_score.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-2ngquv__/rouge_score.egg-info/SOURCES.txt'\n","  writing manifest file '/tmp/pip-pip-egg-info-2ngquv__/rouge_score.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sacrebleu>=1.5.0 (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for sacrebleu>=1.5.0 from https://files.pythonhosted.org/packages/cd/45/7b55a7bd7e5c5b573b40ad58ba43fa09962dc5c8d71b1f573d4aeaa54a7e/sacrebleu-2.5.1-py3-none-any.whl.metadata\n","  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (1.6.1)\n","Collecting sqlitedict (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n","  Running command python setup.py egg_info\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-m2mb_cyr/sqlitedict.egg-info\n","  writing /tmp/pip-pip-egg-info-m2mb_cyr/sqlitedict.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-m2mb_cyr/sqlitedict.egg-info/dependency_links.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-m2mb_cyr/sqlitedict.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-m2mb_cyr/sqlitedict.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-m2mb_cyr/sqlitedict.egg-info/SOURCES.txt'\n","  reading manifest template 'MANIFEST.in'\n","  adding license file 'LICENSE.md'\n","  writing manifest file '/tmp/pip-pip-egg-info-m2mb_cyr/sqlitedict.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tqdm-multiprocess (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for tqdm-multiprocess from https://files.pythonhosted.org/packages/25/7e/0d889fc6c84e3df6b69aaafe893fc77f69b3d968ac9ce574d1c62c688050/tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata\n","  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (0.23.0)\n","Collecting word2number (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Downloading word2number-1.1.zip (9.7 kB)\n","  Running command python setup.py egg_info\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-k2g96eyt/word2number.egg-info\n","  writing /tmp/pip-pip-egg-info-k2g96eyt/word2number.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-k2g96eyt/word2number.egg-info/dependency_links.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-k2g96eyt/word2number.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-k2g96eyt/word2number.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-k2g96eyt/word2number.egg-info/SOURCES.txt'\n","  reading manifest template 'MANIFEST.in'\n","  adding license file 'LICENSE.txt'\n","  writing manifest file '/tmp/pip-pip-egg-info-k2g96eyt/word2number.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (10.7.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.9.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.3.1)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.2.18)\n","Collecting importlib_metadata (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for importlib_metadata from https://files.pythonhosted.org/packages/dc/ef/38766b2edb096260d9b1b6ad35adaa0bce3b0567abb452b21eb074af88c4/importlib_metadata-8.0.0-py3-none-any.whl.metadata\n","  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (3.21.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for opentelemetry-exporter-otlp-proto-grpc==1.26.0 from https://files.pythonhosted.org/packages/4d/0c/e4473692fec8076008c7926dfcef7223fc6d2785f04ad9d8402347a4eba9/opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for opentelemetry-exporter-otlp-proto-http==1.26.0 from https://files.pythonhosted.org/packages/cf/d3/0b7217b61903249035d219fbe93a8558287f86aead340c7b2dc1226b8ad4/opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.70.0)\n","Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.71.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.26.0 from https://files.pythonhosted.org/packages/25/2f/0f7e0a73fd901c9abc6ea680d7f19a803dac830c450f21e1123d3a3ec488/opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for opentelemetry-proto==1.26.0 from https://files.pythonhosted.org/packages/15/f4/66a3892eea913cded9bac0fdd3fb1a412fa2da8eb50014ec87a52648444a/opentelemetry_proto-1.26.0-py3-none-any.whl.metadata\n","  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n","INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n","Collecting vllm>=0.7.3 (from gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for vllm>=0.7.3 from https://files.pythonhosted.org/packages/8e/cb/03dc1299e0456ff3d58a11f63682ef29aaf5b1bd7f21bfe0690d7ce6fc40/vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl.metadata\n","  Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm>=0.7.3->gptqmodel==3.1.0.dev0) (24.0.1)\n","  Obtaining dependency information for vllm>=0.7.3 from https://files.pythonhosted.org/packages/2a/99/58ba40e42ec6358ff4da5b6b6ce2ac9f8b10329fcfd65c9ee12c124f37f9/vllm-0.8.3-cp38-abi3-manylinux1_x86_64.whl.metadata\n","  Downloading vllm-0.8.3-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n","Collecting xgrammar==0.1.17 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for xgrammar==0.1.17 from https://files.pythonhosted.org/packages/f1/05/a31e2f04b0cb510f867da3094b35dc893622debbe1254e02accf6683c7aa/xgrammar-0.1.17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading xgrammar-0.1.17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n","Collecting gguf==0.10.0 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for gguf==0.10.0 from https://files.pythonhosted.org/packages/1b/e4/c5f9bd71840ae9afb7e2b7c285ba209f2ef5e9cd83885f8c596c551d3026/gguf-0.10.0-py3-none-any.whl.metadata\n","  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n","Collecting compressed-tensors==0.9.2 (from vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for compressed-tensors==0.9.2 from https://files.pythonhosted.org/packages/bb/6e/dc0a80ce14802344e3f4d0520285e8773b83ec2fd864e7cab886718f55a9/compressed_tensors-0.9.2-py3-none-any.whl.metadata\n","  Downloading compressed_tensors-0.9.2-py3-none-any.whl.metadata (7.0 kB)\n","Collecting numba (from auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/14/91/18b9f64b34ff318a14d072251480547f89ebfb864b2b7168e5dc5f64f502/numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n","  Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n","Collecting nanobind>=2.0.0 (from xgrammar==0.1.17->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for nanobind>=2.0.0 from https://files.pythonhosted.org/packages/96/14/989883082b395146120d34ca7e484a2b24cb73b0e428576a3a4249bd4082/nanobind-2.7.0-py3-none-any.whl.metadata\n","  Downloading nanobind-2.7.0-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (2.33.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.4.0)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.3.3->random_word==1.0.13->gptqmodel==3.1.0.dev0) (2.1.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.3.3->random_word==1.0.13->gptqmodel==3.1.0.dev0) (1.5.0)\n","Collecting execnet>=2.1 (from pytest-xdist>=2.2.1->bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for execnet>=2.1 from https://files.pythonhosted.org/packages/43/09/2aea36ff60d16dd8879bdb2f5b3ee0ba8d08cbbdcdfe870e695ce3784385/execnet-2.1.1-py3-none-any.whl.metadata\n","  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (8.1.8)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.1.0)\n","Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (13.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->random_word==1.0.13->gptqmodel==3.1.0.dev0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->random_word==1.0.13->gptqmodel==3.1.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->random_word==1.0.13->gptqmodel==3.1.0.dev0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->random_word==1.0.13->gptqmodel==3.1.0.dev0) (2025.1.31)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0) (2.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (2025.2)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb->auto_round>=0.3->gptqmodel==3.1.0.dev0) (1.3.0)\n","Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz->bitblas==0.0.1-dev13->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for rapidfuzz<4.0.0,>=3.0.0 from https://files.pythonhosted.org/packages/3d/2c/4b2f8aafdf9400e5599b6ed2f14bc26ca75f5a923571926ccbc998d4246a/rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/68/1b/e0a87d256e40e8c888847551b20a017a6b98139178505dc7ffb96f04e954/dnspython-2.7.0-py3-none-any.whl.metadata\n","  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.15.2)\n","  Link requires a different Python (3.11.12 not in: '>=3.12'): https://files.pythonhosted.org/packages/c4/54/562d3fd758ae3b8318b6534db56e0fd57c73a0caf9b1186aa069aa20d4af/rich_toolkit-0.1.0-py3-none-any.whl (from https://pypi.org/simple/rich-toolkit/) (requires-python:>=3.12)\n","  Link requires a different Python (3.11.12 not in: '>=3.12'): https://files.pythonhosted.org/packages/70/ba/a15e45b87e6e8597845945e153cef21002607d45d217b389eab9ea0a682c/rich_toolkit-0.1.0.tar.gz (from https://pypi.org/simple/rich-toolkit/) (requires-python:>=3.12)\n","Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for rich-toolkit>=0.11.1 from https://files.pythonhosted.org/packages/44/48/c6d43d4c56c45c0171c771b2b73deeec493efb57795b651319201e7c4638/rich_toolkit-0.14.4-py3-none-any.whl.metadata\n","  Downloading rich_toolkit-0.14.4-py3-none-any.whl.metadata (999 bytes)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.16.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (2025.4.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.24.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.5.0->gptqmodel==3.1.0.dev0) (1.17.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (3.9.1)\n","Collecting portalocker (from sacrebleu>=1.5.0->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/f7/60/1974cfdd5bb770568ddc6f89f3e0df4cfdd1acffd5a609dff5e95f48c6e2/portalocker-3.1.1-py3-none-any.whl.metadata\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Collecting colorama (from sacrebleu>=1.5.0->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for colorama from https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl.metadata\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (5.4.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (1.4.2)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for httptools>=0.6.3 from https://files.pythonhosted.org/packages/b1/2f/205d1f2a190b72da6ffb5f41a3736c26d6fa7871101212b15e9b5cd8f61d/httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for python-dotenv>=0.13 from https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl.metadata\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for uvloop!=0.15.0,!=0.15.1,>=0.14.0 from https://files.pythonhosted.org/packages/8a/ca/0864176a649838b838f36d44bf31c451597ab363b60dc9e09c9630619d41/uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (15.0.1)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.8.3)\n","Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (75.2.0)\n","Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for DataProperty<2,>=1.1.0 from https://files.pythonhosted.org/packages/21/c2/e12e95e289e6081a40454199ab213139ef16a528c7c86432de545b05a23a/DataProperty-1.1.0-py3-none-any.whl.metadata\n","  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n","Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for mbstrdecoder<2,>=1.0.0 from https://files.pythonhosted.org/packages/30/ac/5ce64a1d4cce00390beab88622a290420401f1cabf05caf2fc0995157c21/mbstrdecoder-1.1.4-py3-none-any.whl.metadata\n","  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n","Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for pathvalidate<4,>=2.3.0 from https://files.pythonhosted.org/packages/50/14/c5a0e1a947909810fc4c043b84cac472b70e438148d34f5393be1bac663f/pathvalidate-3.2.3-py3-none-any.whl.metadata\n","  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n","Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for tabledata<2,>=1.3.1 from https://files.pythonhosted.org/packages/08/64/fa4160151976ee4b2cf0c1217a99443ffaeb991956feddfeac9eee9952f8/tabledata-1.3.4-py3-none-any.whl.metadata\n","  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n","Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for tcolorpy<1,>=0.0.5 from https://files.pythonhosted.org/packages/05/a2/ed023f2edd1e011b4d99b6727bce8253842d66c3fbf9ed0a26fc09a92571/tcolorpy-0.1.7-py3-none-any.whl.metadata\n","  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n","Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0)\n","  Obtaining dependency information for typepy<2,>=1.3.2 from https://files.pythonhosted.org/packages/ee/31/e393c3830bdedd01735bd195c85ac3034b6bcaf6c18142bab60a4047ca36/typepy-1.3.4-py3-none-any.whl.metadata\n","  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval<0.5,>=0.4.2->auto_round>=0.3->gptqmodel==3.1.0.dev0) (5.2.0)\n","Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (13.9.4)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (1.5.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm>=0.7.3->gptqmodel==3.1.0.dev0) (0.1.2)\n","Downloading random_word-1.0.13-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitblas-0.0.1.dev13-py3-none-manylinux1_x86_64.whl (63.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading auto_round-0.5.1-py3-none-any.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.0/308.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.5.1-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading intel_extension_for_pytorch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (104.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.7/104.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading vllm-0.8.3-cp38-abi3-manylinux1_x86_64.whl (294.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.0/294.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading compressed_tensors-0.9.2-py3-none-any.whl (97 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n","Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl (44.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xgrammar-0.1.17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading autopep8-2.3.2-py2.py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llguidance-0.7.19-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lm_eval-0.4.8-py3-none-any.whl (3.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n","Downloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ray-2.45.0-cp311-cp311-manylinux2014_x86_64.whl (68.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cpplint-2.0.2-py3-none-any.whl (81 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dtlib-0.0.0.dev2-py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n","Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n","Downloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n","Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading execnet-2.1.1-py3-none-any.whl (40 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n","Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n","Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nanobind-2.7.0-py3-none-any.whl (241 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.7/241.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycodestyle-2.13.0-py2.py3-none-any.whl (31 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading airportsdata-20250224-py3-none-any.whl (913 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m130.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n","Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n","Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n","Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n","Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Downloading rich_toolkit-0.14.4-py3-none-any.whl (24 kB)\n","Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n","Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n","Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n","Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: gptqmodel, device-smi, logbar, tokenicer, flashinfer-python, rouge-score, sqlitedict, word2number\n","  Running command python setup.py bdist_wheel\n","  conda_cuda_include_dir /usr/lib/python3.11/site-packages/nvidia/cuda_runtime/include\n","  /usr/local/lib/python3.11/dist-packages/setuptools/dist.py:333: InformationOnly: Normalizing '3.1.0-dev' to '3.1.0.dev0'\n","    self.metadata.version = self._normalize_version(self.metadata.version)\n","  running bdist_wheel\n","  Guessing wheel URL: https://github.com/ModelCloud/GPTQModel/releases/download/v3.1.0-dev/gptqmodel-3.1.0-dev+cu125torch2.6-cp311-cp311-linux_x86_64.whl\n","  wheel name=gptqmodel-3.1.0-dev+cu125torch2.6-cp311-cp311-linux_x86_64.whl\n","  Precompiled wheel not found in url: https://github.com/ModelCloud/GPTQModel/releases/download/v3.1.0-dev/gptqmodel-3.1.0-dev+cu125torch2.6-cp311-cp311-linux_x86_64.whl. Building from source...\n","  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:529: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","    warnings.warn(msg.format('we could not find ninja.'))\n","  running build\n","  running build_py\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel\n","  copying gptqmodel/version.py -> build/lib.linux-x86_64-cpython-311/gptqmodel\n","  copying gptqmodel/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/eora_processor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/gptq_processor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/module_looper.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/loop_processor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/named_module.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/native_processor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/input_cache.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/dequantize_processor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  copying gptqmodel/looper/qqq_processor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/looper\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/eora\n","  copying gptqmodel/eora/eora.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/eora\n","  copying gptqmodel/eora/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/eora\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/adapter\n","  copying gptqmodel/adapter/peft.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/adapter\n","  copying gptqmodel/adapter/remote.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/adapter\n","  copying gptqmodel/adapter/adapter.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/adapter\n","  copying gptqmodel/adapter/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/adapter\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/perplexity.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/sglang.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/model.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/exllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/tensor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/evalplus.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/marlin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/logger.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/mlx.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/data.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/device.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/backend.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/image.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/vram.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/openai_server.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/plotly.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/calibration.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/torch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/rocm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/hf.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/safetensor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/terminal.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/importer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/vllm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/eval.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/mmlupro.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  copying gptqmodel/utils/bitblas.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n","  copying gptqmodel/nn_modules/hooked_linear.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n","  copying gptqmodel/nn_modules/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n","  copying gptqmodel/quantization/qqq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n","  copying gptqmodel/quantization/gptqv2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n","  copying gptqmodel/quantization/config.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n","  copying gptqmodel/quantization/gptq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n","  copying gptqmodel/quantization/quantizer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n","  copying gptqmodel/quantization/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/models\n","  copying gptqmodel/models/base.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n","  copying gptqmodel/models/writer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n","  copying gptqmodel/models/auto.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n","  copying gptqmodel/models/_const.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n","  copying gptqmodel/models/loader.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n","  copying gptqmodel/models/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/ipex.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/qqq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/exllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/exllama_eora.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/marlin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/torch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/bitblas_target_detector.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/tritonv2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/exllamav2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  copying gptqmodel/nn_modules/qlinear/bitblas.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n","  copying gptqmodel/nn_modules/triton_utils/mixin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n","  copying gptqmodel/nn_modules/triton_utils/dequant.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n","  copying gptqmodel/nn_modules/triton_utils/custom_autotune.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n","  copying gptqmodel/nn_modules/triton_utils/kernels.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n","  copying gptqmodel/nn_modules/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/quantization/rotation\n","  copying gptqmodel/quantization/rotation/rotation.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization/rotation\n","  copying gptqmodel/quantization/rotation/hadamard_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization/rotation\n","  copying gptqmodel/quantization/rotation/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization/rotation\n","  creating build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/ovis.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/mistral.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/stablelmepoch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/qwen3_moe.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/cohere.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/minicpm3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/xverse.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/instella.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/qwen.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/dream.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/moss.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/gpt2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/starcoder2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/gemma2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/minicpm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/decilm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/yi.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/gptj.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/deepseek_v3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/hymba.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/granite.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/qwen2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/mobilellm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/internlm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/olmo2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/qwen3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/glm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/mllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/cohere2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/chatglm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/base_qwen2_vl.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/dbrx_converted.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/rw.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/deepseek_v2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/mpt.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/gpt_neox.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/bloom.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/gemma3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/phi4.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/mimo.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/exaone.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/qwen2_moe.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/codegen.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/opt.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/baichuan.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/llama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/dbrx.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/telechat2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/gemma.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/qwen2_5_vl.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/phi.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/mixtral.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/qwen2_vl.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/longllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/phi3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/grinmoe.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  copying gptqmodel/models/definitions/internlm2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n","  running build_ext\n","  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:448: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\n","    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n","  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n","    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n","  building 'gptqmodel_marlin_kernels' extension\n","  creating build/temp.linux-x86_64-cpython-311/gptqmodel_ext/marlin\n","  x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -Igptqmodel_cuda -I/usr/include/python3.11 -c gptqmodel_ext/marlin/marlin_cuda.cpp -o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/marlin/marlin_cuda.o -O3 -std=c++17 -fopenmp -lgomp -DENABLE_BF16 -D_GLIBCXX_USE_CXX11_ABI=0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=gptqmodel_marlin_kernels -D_GLIBCXX_USE_CXX11_ABI=0\n","  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.\n","  If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n","    warnings.warn(\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -Igptqmodel_cuda -I/usr/include/python3.11 -c gptqmodel_ext/marlin/marlin_cuda_kernel.cu -o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/marlin/marlin_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -std=c++17 -DENABLE_BF16 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -D_GLIBCXX_USE_CXX11_ABI=0 --threads 8 --optimize=3 -lineinfo --resource-usage -Xfatbin -compress-all --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -diag-suppress=179,39 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=gptqmodel_marlin_kernels -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80\n","  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      16 bytes stack frame, 32 bytes spill stores, 20 bytes spill loads\n","  ptxas info    : Used 255 registers, 16 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      16 bytes stack frame, 60 bytes spill stores, 40 bytes spill loads\n","  ptxas info    : Used 255 registers, 16 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      16 bytes stack frame, 60 bytes spill stores, 40 bytes spill loads\n","  ptxas info    : Used 255 registers, 16 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 8 bytes spill stores, 4 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 210 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 210 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 212 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 206 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 128 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 138 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 138 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      160 bytes stack frame, 402 bytes spill stores, 712 bytes spill loads\n","  ptxas info    : Used 255 registers, 160 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 244 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 162 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      48 bytes stack frame, 68 bytes spill stores, 56 bytes spill loads\n","  ptxas info    : Used 255 registers, 48 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 252 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 194 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 132 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 132 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 130 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 118 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi4ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      200 bytes stack frame, 458 bytes spill stores, 620 bytes spill loads\n","  ptxas info    : Used 255 registers, 200 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi3ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi2ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 232 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi128ELi1ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 164 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 194 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 148 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 150 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 150 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 142 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      192 bytes stack frame, 434 bytes spill stores, 596 bytes spill loads\n","  ptxas info    : Used 255 registers, 192 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 238 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 182 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 20 bytes spill stores, 16 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      24 bytes stack frame, 40 bytes spill stores, 28 bytes spill loads\n","  ptxas info    : Used 255 registers, 24 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 252 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 192 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 126 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 125 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 128 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 118 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi4ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      160 bytes stack frame, 414 bytes spill stores, 588 bytes spill loads\n","  ptxas info    : Used 255 registers, 160 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi3ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi2ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 238 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li8ELi256ELi1ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 164 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      24 bytes stack frame, 44 bytes spill stores, 28 bytes spill loads\n","  ptxas info    : Used 255 registers, 24 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 208 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 210 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 210 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 212 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 124 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 126 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 126 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      136 bytes stack frame, 434 bytes spill stores, 532 bytes spill loads\n","  ptxas info    : Used 255 registers, 136 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 234 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 156 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 123 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi4ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      176 bytes stack frame, 474 bytes spill stores, 488 bytes spill loads\n","  ptxas info    : Used 255 registers, 176 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi3ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi2ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 222 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi128ELi1ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 163 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 8 bytes spill stores, 4 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 202 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 148 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 140 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 140 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 142 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      160 bytes stack frame, 466 bytes spill stores, 496 bytes spill loads\n","  ptxas info    : Used 255 registers, 160 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 224 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 164 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 8 bytes spill stores, 4 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 252 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 252 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 199 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 120 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 120 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 121 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi4ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      128 bytes stack frame, 446 bytes spill stores, 452 bytes spill loads\n","  ptxas info    : Used 255 registers, 128 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi3ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi2ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 236 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI13__nv_bfloat16Li4ELi256ELi1ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 156 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      16 bytes stack frame, 32 bytes spill stores, 20 bytes spill loads\n","  ptxas info    : Used 255 registers, 16 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      16 bytes stack frame, 60 bytes spill stores, 40 bytes spill loads\n","  ptxas info    : Used 255 registers, 16 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      16 bytes stack frame, 60 bytes spill stores, 40 bytes spill loads\n","  ptxas info    : Used 255 registers, 16 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 8 bytes spill stores, 4 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 210 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 210 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 212 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 206 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 128 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 138 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 138 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      160 bytes stack frame, 398 bytes spill stores, 700 bytes spill loads\n","  ptxas info    : Used 255 registers, 160 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 244 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 162 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      48 bytes stack frame, 60 bytes spill stores, 56 bytes spill loads\n","  ptxas info    : Used 255 registers, 48 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 252 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 192 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 132 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 132 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 126 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 118 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi4ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      208 bytes stack frame, 482 bytes spill stores, 648 bytes spill loads\n","  ptxas info    : Used 255 registers, 208 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi3ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi2ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 232 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi128ELi1ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 161 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 194 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 148 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 150 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 150 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 142 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      184 bytes stack frame, 422 bytes spill stores, 584 bytes spill loads\n","  ptxas info    : Used 255 registers, 184 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 238 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 182 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 20 bytes spill stores, 16 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      24 bytes stack frame, 40 bytes spill stores, 28 bytes spill loads\n","  ptxas info    : Used 255 registers, 24 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 252 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 192 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 130 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 130 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 124 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 118 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi4ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      168 bytes stack frame, 438 bytes spill stores, 612 bytes spill loads\n","  ptxas info    : Used 255 registers, 168 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi3ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi2ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 238 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi8ELi256ELi1ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 162 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 16 bytes spill stores, 12 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      24 bytes stack frame, 44 bytes spill stores, 28 bytes spill loads\n","  ptxas info    : Used 255 registers, 24 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 208 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 210 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 210 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 212 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 124 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 126 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 126 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      136 bytes stack frame, 434 bytes spill stores, 472 bytes spill loads\n","  ptxas info    : Used 255 registers, 136 bytes cumulative stack size, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 234 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi4ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 156 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 196 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 123 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi4ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      176 bytes stack frame, 474 bytes spill stores, 444 bytes spill loads\n","  ptxas info    : Used 255 registers, 176 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi3ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi2ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 222 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi128ELi1ELi8ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 158 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 8 bytes spill stores, 4 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 198 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 202 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 148 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 140 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 140 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 142 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      160 bytes stack frame, 466 bytes spill stores, 436 bytes spill loads\n","  ptxas info    : Used 255 registers, 160 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 224 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi8ELi8ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 164 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      8 bytes stack frame, 8 bytes spill stores, 4 bytes spill loads\n","  ptxas info    : Used 255 registers, 8 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 252 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 253 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 252 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 200 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 199 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi8EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 120 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi4EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 122 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELi2EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 120 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb0ELb0ELin1EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 121 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi4ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      128 bytes stack frame, 446 bytes spill stores, 420 bytes spill loads\n","  ptxas info    : Used 255 registers, 128 bytes cumulative stack size, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi3ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 433 bytes cmem[0], 8 bytes cmem[2]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi2ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 236 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin6MarlinI6__halfLi4ELi256ELi1ELi16ELi4ELi4ELb1ELb0ELi0EEEvPK4int4S4_PS2_S5_S4_S4_PKiiiiiPib\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 158 registers, 433 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin19permute_cols_kernelEPK4int4PKiPS0_iii' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin19permute_cols_kernelEPK4int4PKiPS0_iii\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 32 registers, 388 bytes cmem[0]\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -Igptqmodel_cuda -I/usr/include/python3.11 -c gptqmodel_ext/marlin/marlin_repack.cu -o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/marlin/marlin_repack.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -std=c++17 -DENABLE_BF16 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -D_GLIBCXX_USE_CXX11_ABI=0 --threads 8 --optimize=3 -lineinfo --resource-usage -Xfatbin -compress-all --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -diag-suppress=179,39 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=gptqmodel_marlin_kernels -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80\n","  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n","  ptxas info    : Compiling entry function '_ZN6marlin25gptq_marlin_repack_kernelILi256ELi8ELi32ELb1EEEvPKjS2_Pjii' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin25gptq_marlin_repack_kernelILi256ELi8ELi32ELb1EEEvPKjS2_Pjii\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 38 registers, 384 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin25gptq_marlin_repack_kernelILi256ELi8ELi32ELb0EEEvPKjS2_Pjii' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin25gptq_marlin_repack_kernelILi256ELi8ELi32ELb0EEEvPKjS2_Pjii\n","      32 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 32 registers, 32 bytes cumulative stack size, 384 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin25gptq_marlin_repack_kernelILi256ELi4ELi32ELb1EEEvPKjS2_Pjii' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin25gptq_marlin_repack_kernelILi256ELi4ELi32ELb1EEEvPKjS2_Pjii\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 38 registers, 384 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_ZN6marlin25gptq_marlin_repack_kernelILi256ELi4ELi32ELb0EEEvPKjS2_Pjii' for 'sm_80'\n","  ptxas info    : Function properties for _ZN6marlin25gptq_marlin_repack_kernelILi256ELi4ELi32ELb0EEEvPKjS2_Pjii\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 29 registers, 384 bytes cmem[0]\n","  x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-311/gptqmodel_ext/marlin/marlin_cuda.o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/marlin/marlin_cuda_kernel.o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/marlin/marlin_repack.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/gptqmodel_marlin_kernels.cpython-311-x86_64-linux-gnu.so\n","  building 'gptqmodel_qqq_kernels' extension\n","  creating build/temp.linux-x86_64-cpython-311/gptqmodel_ext/qqq\n","  x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -Igptqmodel_cuda -I/usr/include/python3.11 -c gptqmodel_ext/qqq/qqq.cpp -o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/qqq/qqq.o -O3 -std=c++17 -fopenmp -lgomp -DENABLE_BF16 -D_GLIBCXX_USE_CXX11_ABI=0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=gptqmodel_qqq_kernels -D_GLIBCXX_USE_CXX11_ABI=0\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -Igptqmodel_cuda -I/usr/include/python3.11 -c gptqmodel_ext/qqq/qqq_gemm.cu -o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/qqq/qqq_gemm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -std=c++17 -DENABLE_BF16 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -D_GLIBCXX_USE_CXX11_ABI=0 --threads 8 --optimize=3 -lineinfo --resource-usage -Xfatbin -compress-all --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -diag-suppress=179,39 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=gptqmodel_qqq_kernels -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80\n","  gptqmodel_ext/qqq/qqq_gemm.cu(837): warning #177-D: variable \"tile_size\" was declared but never referenced\n","    static constexpr int tile_size = 16;\n","                         ^\n","\n","  Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n","\n","  gptqmodel_ext/qqq/qqq_gemm.cu(838): warning #177-D: variable \"max_par\" was declared but never referenced\n","    static constexpr int max_par = 16;\n","                         ^\n","\n","  gptqmodel_ext/qqq/qqq_gemm.cu(840): warning #177-D: variable \"pack_factor_4bit\" was declared but never referenced\n","    static constexpr int pack_factor_4bit =\n","                         ^\n","\n","  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi4ELi4ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi4ELi4ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      56 bytes stack frame, 88 bytes spill stores, 76 bytes spill loads\n","  ptxas info    : Used 255 registers, 56 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi4ELi4ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi4ELi4ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      80 bytes stack frame, 140 bytes spill stores, 128 bytes spill loads\n","  ptxas info    : Used 255 registers, 80 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi3ELi4ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi3ELi4ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      80 bytes stack frame, 92 bytes spill stores, 84 bytes spill loads\n","  ptxas info    : Used 255 registers, 80 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi3ELi4ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi3ELi4ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      88 bytes stack frame, 116 bytes spill stores, 100 bytes spill loads\n","  ptxas info    : Used 255 registers, 88 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi2ELi4ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi2ELi4ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi2ELi4ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi2ELi4ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 179 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi1ELi4ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi1ELi4ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 168 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi1ELi4ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi1ELi4ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 130 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi4ELi8ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi4ELi8ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      24 bytes stack frame, 96 bytes spill stores, 72 bytes spill loads\n","  ptxas info    : Used 254 registers, 24 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi4ELi8ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi4ELi8ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      24 bytes stack frame, 96 bytes spill stores, 80 bytes spill loads\n","  ptxas info    : Used 255 registers, 24 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi3ELi8ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi3ELi8ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi3ELi8ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi3ELi8ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi2ELi8ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi2ELi8ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 214 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi2ELi8ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi2ELi8ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 174 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi1ELi8ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi1ELi8ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 150 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi128ELi1ELi8ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi128ELi1ELi8ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 128 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi4ELi16ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi4ELi16ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      48 bytes stack frame, 64 bytes spill stores, 56 bytes spill loads\n","  ptxas info    : Used 255 registers, 48 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi4ELi16ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi4ELi16ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      56 bytes stack frame, 84 bytes spill stores, 72 bytes spill loads\n","  ptxas info    : Used 255 registers, 56 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi3ELi16ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi3ELi16ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 255 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi3ELi16ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi3ELi16ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 254 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi2ELi16ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi2ELi16ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 214 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi2ELi16ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi2ELi16ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 174 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi1ELi16ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi1ELi16ELi4ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 150 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi1ELi16ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi1ELi16ELi4ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 128 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi4ELi8ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi4ELi8ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      24 bytes stack frame, 96 bytes spill stores, 72 bytes spill loads\n","  ptxas info    : Used 254 registers, 24 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi4ELi8ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi4ELi8ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      40 bytes stack frame, 160 bytes spill stores, 128 bytes spill loads\n","  ptxas info    : Used 254 registers, 40 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi3ELi8ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi3ELi8ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      16 bytes stack frame, 64 bytes spill stores, 48 bytes spill loads\n","  ptxas info    : Used 254 registers, 16 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi3ELi8ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi3ELi8ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      24 bytes stack frame, 96 bytes spill stores, 80 bytes spill loads\n","  ptxas info    : Used 254 registers, 24 bytes cumulative stack size, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi2ELi8ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi2ELi8ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 250 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi2ELi8ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi2ELi8ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 182 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi1ELi8ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi1ELi8ELi8ELi4ELi8EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 166 registers, 432 bytes cmem[0]\n","  ptxas info    : Compiling entry function '_Z6MarlinILi256ELi1ELi8ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi' for 'sm_80'\n","  ptxas info    : Function properties for _Z6MarlinILi256ELi1ELi8ELi8ELi4ELin1EEvPK4int4S2_PS0_S3_PKfS2_S2_iiiPi\n","      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","  ptxas info    : Used 128 registers, 432 bytes cmem[0]\n","  x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-311/gptqmodel_ext/qqq/qqq.o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/qqq/qqq_gemm.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/gptqmodel_qqq_kernels.cpython-311-x86_64-linux-gnu.so\n","  building 'gptqmodel_exllama_eora' extension\n","  creating build/temp.linux-x86_64-cpython-311/gptqmodel_ext/exllama_eora/eora\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -Igptqmodel_cuda -I/usr/include/python3.11 -c gptqmodel_ext/exllama_eora/eora/pybind.cu -o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/exllama_eora/eora/pybind.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -std=c++17 -DENABLE_BF16 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -D_GLIBCXX_USE_CXX11_ABI=0 --threads 8 --optimize=3 -lineinfo --resource-usage -Xfatbin -compress-all --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -diag-suppress=179,39 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=gptqmodel_exllama_eora -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80\n","  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n","  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -Igptqmodel_cuda -I/usr/include/python3.11 -c gptqmodel_ext/exllama_eora/eora/q_gemm.cu -o build/temp.linux-x86_64-cpython-311/gptqmodel_ext/exllama_eora/eora/q_gemm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -std=c++17 -DENABLE_BF16 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -D_GLIBCXX_USE_CXX11_ABI=0 --threads 8 --optimize=3 -lineinfo --resource-usage -Xfatbin -compress-all --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -diag-suppress=179,39 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=gptqmodel_exllama_eora -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80\n"]}],"source":["!# clone repo\n","!git clone https://github.com/ModelCloud/GPTQModel.git\n","!cd GPTQModel && pip install -v --no-build-isolation .[vllm,bitblas,ipex,auto_round]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7KOu8wbLwZ_s"},"outputs":[],"source":["from datasets import load_dataset\n","from gptqmodel import GPTQModel, QuantizeConfig\n","from transformers import AutoTokenizer\n","\n","model_id = \"google/gemma-3-27b-it-qat-q4_0-unquantized\"\n","quant_path = \"gptqmodel-4bit\"\n","\n","calibration_dataset = load_dataset(\n","    \"allenai/c4\",\n","    data_files=\"en/c4-train.00001-of-01024.json.gz\",\n","    split=\"train\"\n","  ).select(range(1024))[\"text\"]\n","\n","quant_config = QuantizeConfig(bits=4, group_size=128)\n","\n","model = GPTQModel.load(model_id, quant_config)\n","tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n","\n","# increase `batch_size` to match gpu/vram specs to speed up quantization\n","model.quantize(calibration_dataset, batch_size=1)\n","\n","model.save(quant_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2GBUYvDAI8m"},"outputs":[],"source":["# repo_name = \"Gunulhona/Gemma-System-9B-MoRA-SimPO-AWQ\"\n","repo_name = \"Gunulhona/gemma-3-27b-it-qat-q4_0-GPTQ\"\n","model.push_to_hub(repo_name)\n","tokenizer.push_to_hub(repo_name)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"mount_file_id":"1B76NAjB51NbQfhtHvTU7WbNTWISMvAhl","authorship_tag":"ABX9TyMMkyPnIBLYvRm7ucW9z4B+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0079e32b0cb64ba088dc7667b27163ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01db25ebaa584f1ea13e1dfefb20ba43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9d46dace4404393acb7bf5821989788","IPY_MODEL_cbb7fce6e2014917aea72068d32e5cde","IPY_MODEL_75e32d5750c94b54b7500211f7e25e25"],"layout":"IPY_MODEL_a1e985c6a5cf44ca9e309dbb5fda5181"}},"03a31c58cede44788f68333a4a9ed97f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"048fdf8bd4144256b590cf891482ca66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fd06061b42b4883907eb9b1b933a0ed","max":503,"min":0,"orientation":"horizontal","style":"IPY_MODEL_271905d3f72849faafb23bb54cade703","value":503}},"05c53b75268743f299b19991d241f72e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a22fa254fdd749489e61720c23dfee47","placeholder":"​","style":"IPY_MODEL_3f0207f55d6645efbdb5185859d59eb8","value":" 236/236 [00:00&lt;00:00, 18.9kB/s]"}},"05cacd64f0874b5784875a80f2c31898":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07e5ff27b6b24f5cbbe93562c574b945":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b32a8d6c5a254138a2bf8d1d37c4faab","max":470907480,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e01d43b2f5448078ef009d35b6143ef","value":470907480}},"085f90eefced42028b1e042db09d4e61":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08f70c9ba5f54f5c8db0c444aad4e0ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09db184c8c6e4b678bfe24a2f4c6bad6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a8c1864808f4b4aaac32025025b9254":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aa301aeef5a4b4a9e3319d52fb90d09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a2100b514b645a4be517295a71ce0da","placeholder":"​","style":"IPY_MODEL_e7950701ebb349fb93e7a3258b8484f2","value":" 11.4M/11.4M [00:02&lt;00:00, 8.40MB/s]"}},"0b18666e18114853aadb6acf77275b51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db312959225425ebb1618936ef69c3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7cd87c1198347218b2154b8ed62ec45","IPY_MODEL_07e5ff27b6b24f5cbbe93562c574b945","IPY_MODEL_51d29331f7aa495fa9f15f5c4bf26df2"],"layout":"IPY_MODEL_d7d5f90c980d446b9f9765d87715d777"}},"0e01d43b2f5448078ef009d35b6143ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e4b3678c3b64607828517e2c12bf913":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f751611020f47328a1e20c398c05fc2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1037170738084fddb4dcd0244048be7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"105d7c0d88d245dfb3b783132b17cabd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"122cdf484a444af093661e031c737f1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd22bef0a5a94a1b9db7dda3ff1466aa","IPY_MODEL_e37021ca26a641fc8a183b7473e00a93","IPY_MODEL_97d3be8b2e5f459ca241e75bf66b398f"],"layout":"IPY_MODEL_7ee95536bb874f32b8f50b0f0d568071"}},"1250be42b2924dc5a129c120aa9a6e37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9bd160da391a40079f5ee5236e070ded","IPY_MODEL_b83e722445c044df98921eb523c10326","IPY_MODEL_d5a540f0ae554ca5a0a224e77a723c3c"],"layout":"IPY_MODEL_ebeb22c4c6ce4ad89042c0498ce75a5b"}},"12f54a34ccaf43218825ad0c9ae2a5b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"134f790e9c9043f49eb310a104ce6712":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"137da20dc49e4f48bbbc863ddc51da93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"144b0d3a77114619b4e5efba35c4538a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_134f790e9c9043f49eb310a104ce6712","placeholder":"​","style":"IPY_MODEL_af700317f5b549eaa40d0363733eb473","value":"Loading checkpoint shards: 100%"}},"17a29d963aa549fda98b68477129f55d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18dd080dc14848b2872c9fbd76af7015":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39f5b21c32134e43bb52b96a2ba1c4b0","IPY_MODEL_6a96952edbb14ca08572a4ba44572571","IPY_MODEL_4f4c25a7e0be402ea3466f38d5d72b4c"],"layout":"IPY_MODEL_8d58d2e9ff6d407c8c52acae933bafdb"}},"197f1e48e12a43cc9d4b676adb468720":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1acf18ef4e2b44f0a3f776e502d866ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b22e3a7bfe6412696542c7bb076dcaf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e39994307d141bc8736f392f5859f91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b22e3a7bfe6412696542c7bb076dcaf","placeholder":"​","style":"IPY_MODEL_8be488fd81c14bbdac16058c5d10a5d3","value":" 4.97G/4.97G [03:44&lt;00:00, 27.3MB/s]"}},"1f874a426fa049118dd57ffe189e5106":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21c8536c6843493fa1fa4ccf936442b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22a4b14727b8457390fe133f375af0a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25423c2f912d4c1a90695b7dc8c72219","placeholder":"​","style":"IPY_MODEL_24b253c76aab4cd8a79c465c864639dd","value":"README.md: 100%"}},"24a06af73b024eab8b64723b8cf2df6b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24b253c76aab4cd8a79c465c864639dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25423c2f912d4c1a90695b7dc8c72219":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"258432df09754afeb91106a60993447f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"271905d3f72849faafb23bb54cade703":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"279ed0a4d9b04c1ebfe7da72e293c150":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d3372d6a39242198855a3c155219ebe","max":6088802697,"min":0,"orientation":"horizontal","style":"IPY_MODEL_137da20dc49e4f48bbbc863ddc51da93","value":6088802697}},"2c9307631ded4c4da02735ca025e8142":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e081a53574124d26914298bb26c3a84d","placeholder":"​","style":"IPY_MODEL_1f874a426fa049118dd57ffe189e5106","value":" 5.17k/5.17k [00:00&lt;00:00, 658kB/s]"}},"2cbbe5058acc4ecf9725e77ffabd7ac5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d2d0873e38e49d689aa9aba5f2b1e34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e8e8ad8b1134717990e2d0bb4bd04d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99bf4012b65b4de8878761d2e89f832f","placeholder":"​","style":"IPY_MODEL_197f1e48e12a43cc9d4b676adb468720","value":"Upload 4 LFS files: 100%"}},"2ecc8d45fb0f43f4bc05fd2c95b1ee7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fd06061b42b4883907eb9b1b933a0ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"307cd30565234a96b384b9eebac2d226":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3093e44ce71f4b1184c6ad41f9366828":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f88f6a06723c4c26a51520d4c1f38e09","IPY_MODEL_048fdf8bd4144256b590cf891482ca66","IPY_MODEL_4c93244f86144a629de856530d8cf57c"],"layout":"IPY_MODEL_105d7c0d88d245dfb3b783132b17cabd"}},"315004cb004c47629a6a41b02ddf18f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"316b0929b0ca4aa3a9d3f042bd82bdad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31d2939315d54017b7cdc413b8c0d085":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"327243bb8e7348cfa846c1d52174c588":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3343fd1ff7fd41278e191f9ab1c573b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_364418d7afdb4b229f60fbbbc2e91617","IPY_MODEL_7ef09edcad7041269f5f20ec31ef01c2","IPY_MODEL_5f730705c1e545f79f19d5e660b02edd"],"layout":"IPY_MODEL_866355f0e97c4eddb30dcc508e30595e"}},"364418d7afdb4b229f60fbbbc2e91617":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05cacd64f0874b5784875a80f2c31898","placeholder":"​","style":"IPY_MODEL_a1d14d3fafb94609905fc79fa2bedcd1","value":"model-00003-of-00004.safetensors: 100%"}},"3733f79962024c969156c22aee99bebc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37344bea3ea9444181ce13fd6d693db0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39475f620182432facc0874b70a069e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9da06749e8a46d9b81d54946ae003a6","placeholder":"​","style":"IPY_MODEL_2ecc8d45fb0f43f4bc05fd2c95b1ee7f","value":" 116/116 [00:00&lt;00:00, 7.94kB/s]"}},"39f5b21c32134e43bb52b96a2ba1c4b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cbbe5058acc4ecf9725e77ffabd7ac5","placeholder":"​","style":"IPY_MODEL_ab06dfed2c1d481eb843b63daa50e86a","value":"Loading checkpoint shards: 100%"}},"3aa3e8b7bda64f0884e5fb2772c102f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c8af2e43c6842158ecef9632b401538":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d31ca43a7494a8890104e4c1bc57090":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51a356cd86f84f2ab685ba274e855e23","IPY_MODEL_a08d331060304951b93a6ce4750d2e3e","IPY_MODEL_05c53b75268743f299b19991d241f72e"],"layout":"IPY_MODEL_b0b983e2e0b0422b9359dc072b15cb71"}},"3dec33cd6b1e4b598113299c3aca9032":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50e72b6991b24edab0dcfc95582ef1dc","max":2689059,"min":0,"orientation":"horizontal","style":"IPY_MODEL_587fa5004af64cb8ae38cf21098d4a9d","value":2689059}},"3dfa51e077ff44dd9b165c241e2d89db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a8c1864808f4b4aaac32025025b9254","placeholder":"​","style":"IPY_MODEL_790f68676eb24742bbc954a6584e8aa9","value":"pytorch_model.bin: 100%"}},"3e1d32656e34480d9ba035a927e2559b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b316cf5d7bf14a7da993cbdc4e1517c8","placeholder":"​","style":"IPY_MODEL_4981e5daedc74e8a9f76def793e3b776","value":" 6.09G/6.09G [02:47&lt;00:00, 32.3MB/s]"}},"3f0207f55d6645efbdb5185859d59eb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3faacff9ab974932884102d616a54675":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b18666e18114853aadb6acf77275b51","placeholder":"​","style":"IPY_MODEL_6dc46a819e42488f9378ca1a9b645463","value":" 167/167 [00:00&lt;00:00, 21.4kB/s]"}},"4022aa5e0d1149f9bf91cdecdec2b794":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"408e1572664b48b89b78e922df7eee67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6435dd10e624cbc90bb60cd3166dd0e","placeholder":"​","style":"IPY_MODEL_5562a7fd47d2480eab596fe54d2028fb","value":"README.md: 100%"}},"4147acf49ab74e7b8ee5c09552d8ea3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e55a9640e8984295a191cd930934bcf8","placeholder":"​","style":"IPY_MODEL_acb6e270a66248b9a5bb24a1ec3478c6","value":"tokenizer.json: 100%"}},"4173d0b4083c45b0a78b592284691708":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b9271792b5646dca3d6c956f193c84b","max":167,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2fb856c576f46868f74e27a84a630fc","value":167}},"42f0212b80024f049a1290d74dc00bfd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433445fa58744b5bb21fde29eb1c18cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44d7486d7f814413a4c2a8367a40e175":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46ba727e2ffa4926947664589444e3da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46ce82f30eb54b638ec7b9c2b296d175":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21c8536c6843493fa1fa4ccf936442b9","placeholder":"​","style":"IPY_MODEL_315004cb004c47629a6a41b02ddf18f1","value":" 5.00G/5.00G [03:15&lt;00:00, 20.2MB/s]"}},"4981e5daedc74e8a9f76def793e3b776":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b9271792b5646dca3d6c956f193c84b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c4e565fb1df439884bf1a7073b8f705":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c93244f86144a629de856530d8cf57c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e57158efc35540f3931b1eb03ec222a0","placeholder":"​","style":"IPY_MODEL_316b0929b0ca4aa3a9d3f042bd82bdad","value":" 503/503 [00:00&lt;00:00, 41.4kB/s]"}},"4d3372d6a39242198855a3c155219ebe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4da767faa1e94df0b917d36069803c7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_258432df09754afeb91106a60993447f","max":17,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c4e565fb1df439884bf1a7073b8f705","value":17}},"4df6230c4c824fc4861b7ca090c82d77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24a06af73b024eab8b64723b8cf2df6b","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfe175edf8a44de786cdf1159b1d922b","value":4}},"4f4c25a7e0be402ea3466f38d5d72b4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42f0212b80024f049a1290d74dc00bfd","placeholder":"​","style":"IPY_MODEL_ee90862a2ea6460d9c89597c2a2b8773","value":" 4/4 [00:01&lt;00:00,  3.49it/s]"}},"50e72b6991b24edab0dcfc95582ef1dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51a356cd86f84f2ab685ba274e855e23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4022aa5e0d1149f9bf91cdecdec2b794","placeholder":"​","style":"IPY_MODEL_fc121834f82b4444ad34b180a93e0831","value":"tokenizer_config.json: 100%"}},"51d29331f7aa495fa9f15f5c4bf26df2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b88c16b0ac3e40849e6a5ea3cf0f4b4f","placeholder":"​","style":"IPY_MODEL_81225223f16441e8af0e0b7bf1a77e07","value":" 471M/471M [00:01&lt;00:00, 235MB/s]"}},"5562a7fd47d2480eab596fe54d2028fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55cec9f47a1b4631a923707f5e69f7e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5669cb09e6464babab4a7a1414f11754":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22a4b14727b8457390fe133f375af0a6","IPY_MODEL_8a1fb056147e442a853084cd1050d5f9","IPY_MODEL_2c9307631ded4c4da02735ca025e8142"],"layout":"IPY_MODEL_b405140afd5348a2a568cc3f59ebac51"}},"587fa5004af64cb8ae38cf21098d4a9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ed9954fd9714a40bbaec897c9466537":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f730705c1e545f79f19d5e660b02edd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_433445fa58744b5bb21fde29eb1c18cc","placeholder":"​","style":"IPY_MODEL_44d7486d7f814413a4c2a8367a40e175","value":" 4.95G/4.95G [03:38&lt;00:00, 23.3MB/s]"}},"64fc8f0ff4094710b3493b1eff90251e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d84c158175294ee992d69cef0e73d95e","placeholder":"​","style":"IPY_MODEL_3aa3e8b7bda64f0884e5fb2772c102f7","value":"tokenizer.json: 100%"}},"6625ee772bdb432f99316ccc700ed523":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f60797d5e4d74b6482ea56087841fb50","max":4966384688,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1037170738084fddb4dcd0244048be7f","value":4966384688}},"66e131eaad794ad7aa43f00d9a705990":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67ac877348894aa3b200afd273475110":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3b294ebf3294db8bb97729007611353","max":93,"min":0,"orientation":"horizontal","style":"IPY_MODEL_307cd30565234a96b384b9eebac2d226","value":93}},"6a8de695f35a4202b8124b775a3c11d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a96952edbb14ca08572a4ba44572571":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad9d08d505484306a00876a1a163bbd5","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cad0e6699f8342e78f5984650a76b5d6","value":4}},"6dc46a819e42488f9378ca1a9b645463":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ff0da55f425452b99dcaf0d65aa4343":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c12595ebd34481bcfc6e6dfb3d840b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75e32d5750c94b54b7500211f7e25e25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_937745596ad245c3be8b49370ee1e258","placeholder":"​","style":"IPY_MODEL_d87dcb12d77946b7ae259e266b5a05a4","value":" 26/26 [00:00&lt;00:00, 2693.97it/s]"}},"790f68676eb24742bbc954a6584e8aa9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7977dc9ff0124a85b424b9fbf9550fb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a2100b514b645a4be517295a71ce0da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ad7fef57fec4fd2bc69f8dbf7d19a85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ee95536bb874f32b8f50b0f0d568071":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ef09edcad7041269f5f20ec31ef01c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7977dc9ff0124a85b424b9fbf9550fb2","max":4949671152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be68f823edfe4f6daad44f7b3323b239","value":4949671152}},"7f15667c49c04c0f8d989428cefc6c42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80244154e07e4c4d820ce4f733363000":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81225223f16441e8af0e0b7bf1a77e07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"818cef3bf98d492fbe7a204f316b81de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5f1d96d4dc64c508a0a28c0309f128d","placeholder":"​","style":"IPY_MODEL_96df4692ff47452e8f88a1ee77dd4e81","value":"special_tokens_map.json: 100%"}},"8311db8fcda749a388e1d9df7cec44f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37344bea3ea9444181ce13fd6d693db0","placeholder":"​","style":"IPY_MODEL_8ea7a0dadb064d8b9e71dffa0eb99c37","value":"generation_config.json: 100%"}},"84904a7d4fa44ef289946b8e2a535bc8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"850121a0da4140c2a7a59f420768f2cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"866355f0e97c4eddb30dcc508e30595e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86c9f7831e6340719d69ca4087fac3d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc2fbf91b935448fa48425e52a0d9520","placeholder":"​","style":"IPY_MODEL_c07bfda1069f440ca62e2c244c9d53cd","value":" 4/4 [03:44&lt;00:00, 38.45s/it]"}},"8a1fb056147e442a853084cd1050d5f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7af7d5489d14342b7e4bd7153a07659","max":5174,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a14d574e35a847df93a5e5b63b0bee75","value":5174}},"8be488fd81c14bbdac16058c5d10a5d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d58d2e9ff6d407c8c52acae933bafdb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ea7a0dadb064d8b9e71dffa0eb99c37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9100593b71af4354ad098f1f765951ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"937745596ad245c3be8b49370ee1e258":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96df4692ff47452e8f88a1ee77dd4e81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97d3be8b2e5f459ca241e75bf66b398f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e4b3678c3b64607828517e2c12bf913","placeholder":"​","style":"IPY_MODEL_97e07dec60c349afbed88fbe7edc5f26","value":" 214670/214670 [00:13&lt;00:00, 28980.18 examples/s]"}},"97e07dec60c349afbed88fbe7edc5f26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9891fb318acf4318bb1c1a13e1e02d50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99bf4012b65b4de8878761d2e89f832f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a52464692004c63b82b10771a0e2625":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bd160da391a40079f5ee5236e070ded":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09db184c8c6e4b678bfe24a2f4c6bad6","placeholder":"​","style":"IPY_MODEL_f69dd1622f514179a00151c93f0030f3","value":"model-00004-of-00004.safetensors: 100%"}},"a08d331060304951b93a6ce4750d2e3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1682931e96f41ee821f8abf35430413","max":236,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ed9954fd9714a40bbaec897c9466537","value":236}},"a14d574e35a847df93a5e5b63b0bee75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1d14d3fafb94609905fc79fa2bedcd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1e985c6a5cf44ca9e309dbb5fda5181":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a22fa254fdd749489e61720c23dfee47":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2fb856c576f46868f74e27a84a630fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6435dd10e624cbc90bb60cd3166dd0e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a78f69b7088c4106a466f0c14ec5376a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8cc249168a54afc9e363c78a7e85d3a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9a0e595d6f249d68ecad4609610c723":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a78f69b7088c4106a466f0c14ec5376a","placeholder":"​","style":"IPY_MODEL_17a29d963aa549fda98b68477129f55d","value":" 17/17 [00:01&lt;00:00, 11.80it/s]"}},"a9da06749e8a46d9b81d54946ae003a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab06dfed2c1d481eb843b63daa50e86a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acb6e270a66248b9a5bb24a1ec3478c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad9d08d505484306a00876a1a163bbd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae7a0531b72f46909fa9286a981632d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7f3cb1a847645d69ad71db604a77922","placeholder":"​","style":"IPY_MODEL_0079e32b0cb64ba088dc7667b27163ad","value":" 93.0/93.0 [00:00&lt;00:00, 7.26kB/s]"}},"af700317f5b549eaa40d0363733eb473":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0b983e2e0b0422b9359dc072b15cb71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b316cf5d7bf14a7da993cbdc4e1517c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b31f036b859f4613a3f3203b5f1f6a6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80244154e07e4c4d820ce4f733363000","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55cec9f47a1b4631a923707f5e69f7e7","value":116}},"b32a8d6c5a254138a2bf8d1d37c4faab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b405140afd5348a2a568cc3f59ebac51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b65216a5f3d4458b8639839cd343c084":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d92f72f4c3b74b1fa9bfe5b6c48d6e29","IPY_MODEL_ecc9661d8f844b42ab2102d7e3e78e1b","IPY_MODEL_46ce82f30eb54b638ec7b9c2b296d175"],"layout":"IPY_MODEL_3733f79962024c969156c22aee99bebc"}},"b7af7d5489d14342b7e4bd7153a07659":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7cd87c1198347218b2154b8ed62ec45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03a31c58cede44788f68333a4a9ed97f","placeholder":"​","style":"IPY_MODEL_0f751611020f47328a1e20c398c05fc2","value":"val.jsonl.zst: 100%"}},"b7f3cb1a847645d69ad71db604a77922":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b83e722445c044df98921eb523c10326":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_085f90eefced42028b1e042db09d4e61","max":4410702792,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f15667c49c04c0f8d989428cefc6c42","value":4410702792}},"b88c16b0ac3e40849e6a5ea3cf0f4b4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be64018d3a2c4a19a26d38b710116f09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a8de695f35a4202b8124b775a3c11d7","placeholder":"​","style":"IPY_MODEL_7ad7fef57fec4fd2bc69f8dbf7d19a85","value":" 2.69M/2.69M [00:00&lt;00:00, 5.54MB/s]"}},"be68f823edfe4f6daad44f7b3323b239":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c07bfda1069f440ca62e2c244c9d53cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1510b0bebf04555ba0b21969962e9a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_818cef3bf98d492fbe7a204f316b81de","IPY_MODEL_67ac877348894aa3b200afd273475110","IPY_MODEL_ae7a0531b72f46909fa9286a981632d3"],"layout":"IPY_MODEL_fd20878d760146608cad0efa6c6a79e0"}},"c27620e0710e4a8e859d2ed70fc3bfa3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3b294ebf3294db8bb97729007611353":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c585fbbff57a4db78053b107bd685332":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5f1d96d4dc64c508a0a28c0309f128d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9d46dace4404393acb7bf5821989788":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c8af2e43c6842158ecef9632b401538","placeholder":"​","style":"IPY_MODEL_f8fb343668c345b4ad0a085167aa6b0e","value":"Fetching 26 files: 100%"}},"c9fad8a53d284e3d9eaa8adb157b379b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64fc8f0ff4094710b3493b1eff90251e","IPY_MODEL_3dec33cd6b1e4b598113299c3aca9032","IPY_MODEL_be64018d3a2c4a19a26d38b710116f09"],"layout":"IPY_MODEL_f94b0344782f4829ba14cc99775d52ca"}},"cad0e6699f8342e78f5984650a76b5d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb2b66d89c574385ba52b1b45263c5f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbb7fce6e2014917aea72068d32e5cde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c585fbbff57a4db78053b107bd685332","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa9d34458f6a43e69115e295fae6d615","value":26}},"cd22bef0a5a94a1b9db7dda3ff1466aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_327243bb8e7348cfa846c1d52174c588","placeholder":"​","style":"IPY_MODEL_dec11545ff04478eabd1be53d2c386d9","value":"Generating validation split: 100%"}},"ce547895eb154e00a5d0a92ab35612c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_408e1572664b48b89b78e922df7eee67","IPY_MODEL_4173d0b4083c45b0a78b592284691708","IPY_MODEL_3faacff9ab974932884102d616a54675"],"layout":"IPY_MODEL_84904a7d4fa44ef289946b8e2a535bc8"}},"d4ec32eb8126489497513347cd22714f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d593a76d9e684257ba57aff818e5985f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5a540f0ae554ca5a0a224e77a723c3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_850121a0da4140c2a7a59f420768f2cb","placeholder":"​","style":"IPY_MODEL_08f70c9ba5f54f5c8db0c444aad4e0ce","value":" 4.41G/4.41G [02:52&lt;00:00, 28.6MB/s]"}},"d7d5f90c980d446b9f9765d87715d777":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d84c158175294ee992d69cef0e73d95e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d87dcb12d77946b7ae259e266b5a05a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d92f72f4c3b74b1fa9bfe5b6c48d6e29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12f54a34ccaf43218825ad0c9ae2a5b0","placeholder":"​","style":"IPY_MODEL_cb2b66d89c574385ba52b1b45263c5f6","value":"model-00002-of-00004.safetensors: 100%"}},"dc2fbf91b935448fa48425e52a0d9520":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec11545ff04478eabd1be53d2c386d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfe175edf8a44de786cdf1159b1d922b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e081a53574124d26914298bb26c3a84d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e13667aee47b4254b2df273f71e3f71e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e8e8ad8b1134717990e2d0bb4bd04d2","IPY_MODEL_4df6230c4c824fc4861b7ca090c82d77","IPY_MODEL_86c9f7831e6340719d69ca4087fac3d2"],"layout":"IPY_MODEL_d4ec32eb8126489497513347cd22714f"}},"e158a4d56adc4aea8f193b283e85f8c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46ba727e2ffa4926947664589444e3da","placeholder":"​","style":"IPY_MODEL_9a52464692004c63b82b10771a0e2625","value":"model-00001-of-00004.safetensors: 100%"}},"e1682931e96f41ee821f8abf35430413":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e37021ca26a641fc8a183b7473e00a93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8cc249168a54afc9e363c78a7e85d3a","max":214670,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9100593b71af4354ad098f1f765951ad","value":214670}},"e4859f8439c24bd0a25cf95ec4e3f84d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_144b0d3a77114619b4e5efba35c4538a","IPY_MODEL_4da767faa1e94df0b917d36069803c7b","IPY_MODEL_a9a0e595d6f249d68ecad4609610c723"],"layout":"IPY_MODEL_74c12595ebd34481bcfc6e6dfb3d840b"}},"e55a9640e8984295a191cd930934bcf8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e57158efc35540f3931b1eb03ec222a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6fbf261839042f882cbc540ffb81d65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffbae49e989e49b8b16f63264f304952","max":11422654,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31d2939315d54017b7cdc413b8c0d085","value":11422654}},"e7950701ebb349fb93e7a3258b8484f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebeb22c4c6ce4ad89042c0498ce75a5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecc9661d8f844b42ab2102d7e3e78e1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c27620e0710e4a8e859d2ed70fc3bfa3","max":4998723112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66e131eaad794ad7aa43f00d9a705990","value":4998723112}},"ee90862a2ea6460d9c89597c2a2b8773":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef2bf0bf1adf4ff3952d03ee9725274f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3dfa51e077ff44dd9b165c241e2d89db","IPY_MODEL_279ed0a4d9b04c1ebfe7da72e293c150","IPY_MODEL_3e1d32656e34480d9ba035a927e2559b"],"layout":"IPY_MODEL_fa423d05dc834f96b3374498045ab662"}},"f0fb074f7ae34a00961f14fe2247c968":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8311db8fcda749a388e1d9df7cec44f7","IPY_MODEL_b31f036b859f4613a3f3203b5f1f6a6a","IPY_MODEL_39475f620182432facc0874b70a069e2"],"layout":"IPY_MODEL_2d2d0873e38e49d689aa9aba5f2b1e34"}},"f60797d5e4d74b6482ea56087841fb50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f69dd1622f514179a00151c93f0030f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7cef7cae860442888c1323837bc007a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4147acf49ab74e7b8ee5c09552d8ea3f","IPY_MODEL_e6fbf261839042f882cbc540ffb81d65","IPY_MODEL_0aa301aeef5a4b4a9e3319d52fb90d09"],"layout":"IPY_MODEL_9891fb318acf4318bb1c1a13e1e02d50"}},"f88f6a06723c4c26a51520d4c1f38e09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ff0da55f425452b99dcaf0d65aa4343","placeholder":"​","style":"IPY_MODEL_1acf18ef4e2b44f0a3f776e502d866ae","value":"config.json: 100%"}},"f8e5d4cac90c44679c0d718415d5a496":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e158a4d56adc4aea8f193b283e85f8c1","IPY_MODEL_6625ee772bdb432f99316ccc700ed523","IPY_MODEL_1e39994307d141bc8736f392f5859f91"],"layout":"IPY_MODEL_d593a76d9e684257ba57aff818e5985f"}},"f8fb343668c345b4ad0a085167aa6b0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f94b0344782f4829ba14cc99775d52ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa423d05dc834f96b3374498045ab662":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa9d34458f6a43e69115e295fae6d615":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc121834f82b4444ad34b180a93e0831":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd20878d760146608cad0efa6c6a79e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffbae49e989e49b8b16f63264f304952":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}