{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1959,"status":"ok","timestamp":1724816848873,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"iCRpjtCdPPRx","outputId":"74c6cd0b-e238-4f46-9541-1f6a097771f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid (permission: write).\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["#@title Huggingface Login\n","#@markdown huggingface weight 를 이용하고 싶다면 로그인 필수\n","from google.colab import userdata\n","import os\n","\n","os.environ['HF_WRITE_TOKEN'] = userdata.get('HF_WRITE_TOKEN')\n","\n","!huggingface-cli login --add-to-git-credential --token $HF_WRITE_TOKEN\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1z1G3XeBr8AtBS7aiZ_8Ks19RDx8v2Ujb"},"executionInfo":{"elapsed":247341,"status":"ok","timestamp":1724802147813,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"XxebrhrVtVSH","outputId":"54866cd6-39f2-4ded-91ea-989ba5414f42"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#@markdown install with openvino\n","%%sh\n","# apt-get update  -y\n","# apt-get install -y gcc-12 g++-12\n","# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n","# pip install --upgrade pip\n","pip install wheel packaging ninja \"setuptools>=49.4.0\" numpy gguf\n","git clone https://github.com/vllm-project/vllm.git\n","cd vllm && pip install -r requirements-build.txt --extra-index-url https://download.pytorch.org/whl/cpu\n","PIP_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu https://storage.openvinotoolkit.org/simple/wheels/pre-release\" && \\\n","    VLLM_TARGET_DEVICE=openvino pip install -U -v -e ."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nOjoNxHkuJ2v","outputId":"6f47deb7-0009-4671-b2bf-ad6b1fcf153f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Ign:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Get:4 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,251 kB]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,560 kB]\n","Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Hit:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,498 kB]\n","Fetched 13.6 MB in 2s (7,579 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  cpp-12 libasan8 libgcc-12-dev libstdc++-12-dev libtsan2\n","Suggested packages:\n","  gcc-12-locales cpp-12-doc g++-12-multilib gcc-12-doc gcc-12-multilib libstdc++-12-doc\n","The following NEW packages will be installed:\n","  cpp-12 g++-12 gcc-12 libasan8 libgcc-12-dev libstdc++-12-dev libtsan2 ninja-build\n","0 upgraded, 8 newly installed, 0 to remove and 50 not upgraded.\n","Need to get 54.6 MB of archives.\n","After this operation, 197 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-12 amd64 12.3.0-1ubuntu1~22.04 [10.8 MB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan8 amd64 12.3.0-1ubuntu1~22.04 [2,442 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan2 amd64 12.3.0-1ubuntu1~22.04 [2,477 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,618 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-12 amd64 12.3.0-1ubuntu1~22.04 [21.7 MB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libstdc++-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,192 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 g++-12 amd64 12.3.0-1ubuntu1~22.04 [12.2 MB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ninja-build amd64 1.10.1-1 [111 kB]\n","Fetched 54.6 MB in 3s (16.8 MB/s)\n","Selecting previously unselected package cpp-12.\n","(Reading database ... 123595 files and directories currently installed.)\n","Preparing to unpack .../0-cpp-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking cpp-12 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package libasan8:amd64.\n","Preparing to unpack .../1-libasan8_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package libtsan2:amd64.\n","Preparing to unpack .../2-libtsan2_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package libgcc-12-dev:amd64.\n","Preparing to unpack .../3-libgcc-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package gcc-12.\n","Preparing to unpack .../4-gcc-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking gcc-12 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package libstdc++-12-dev:amd64.\n","Preparing to unpack .../5-libstdc++-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking libstdc++-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package g++-12.\n","Preparing to unpack .../6-g++-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n","Unpacking g++-12 (12.3.0-1ubuntu1~22.04) ...\n","Selecting previously unselected package ninja-build.\n","Preparing to unpack .../7-ninja-build_1.10.1-1_amd64.deb ...\n","Unpacking ninja-build (1.10.1-1) ...\n","Setting up cpp-12 (12.3.0-1ubuntu1~22.04) ...\n","Setting up ninja-build (1.10.1-1) ...\n","Setting up libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Setting up libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Setting up libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Setting up libstdc++-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n","Setting up gcc-12 (12.3.0-1ubuntu1~22.04) ...\n","Setting up g++-12 (12.3.0-1ubuntu1~22.04) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","update-alternatives: using /usr/bin/gcc-12 to provide /usr/bin/gcc (gcc) in auto mode\n","Collecting gguf\n","  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.44.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.1)\n","Collecting ninja\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: setuptools>=49.4.0 in /usr/local/lib/python3.10/dist-packages (71.0.4)\n","Collecting setuptools>=49.4.0\n","  Downloading setuptools-74.0.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Collecting numpy\n","  Downloading numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m737.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pynvml\n","  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n","Collecting ray\n","  Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from gguf) (6.0.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from gguf) (4.66.5)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.15.4)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.7.4)\n","Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setuptools-74.0.0-py3-none-any.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl (65.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ninja, setuptools, pynvml, numpy, gguf, ray\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 71.0.4\n","    Uninstalling setuptools-71.0.4:\n","      Successfully uninstalled setuptools-71.0.4\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","accelerate 0.32.1 requires numpy<2.0.0,>=1.17, but you have numpy 2.1.0 which is incompatible.\n","albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 2.1.0 which is incompatible.\n","arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you have numpy 2.1.0 which is incompatible.\n","cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.0 which is incompatible.\n","cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.0 which is incompatible.\n","gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.0 which is incompatible.\n","ibis-framework 8.0.0 requires numpy<2,>=1, but you have numpy 2.1.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.0 which is incompatible.\n","pandas 2.1.4 requires numpy<2,>=1.22.4; python_version < \"3.11\", but you have numpy 2.1.0 which is incompatible.\n","rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.0 which is incompatible.\n","scikit-learn 1.3.2 requires numpy<2.0,>=1.17.3, but you have numpy 2.1.0 which is incompatible.\n","tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.0 which is incompatible.\n","thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.0 which is incompatible.\n","transformers 4.42.4 requires numpy<2.0,>=1.17, but you have numpy 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gguf-0.10.0 ninja-1.11.1.1 numpy-2.1.0 pynvml-11.5.3 ray-2.35.0 setuptools-74.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","pkg_resources","setuptools"]},"id":"ca43ae0cc7e4415d99f01b654a197a02"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Cloning into 'vllm'...\n","remote: Enumerating objects: 30235, done.\u001b[K\n","remote: Counting objects: 100% (6549/6549), done.\u001b[K\n","remote: Compressing objects: 100% (769/769), done.\u001b[K\n","remote: Total 30235 (delta 6127), reused 5879 (delta 5779), pack-reused 23686 (from 1)\u001b[K\n","Receiving objects: 100% (30235/30235), 25.42 MiB | 36.82 MiB/s, done.\n","Resolving deltas: 100% (22928/22928), done.\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m613.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["#@markdown install with cpu\n","# %%sh\n","!apt-get update  -y\n","!apt-get install -y gcc-12 g++-12 ninja-build\n","!update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n","!pip install -U gguf wheel packaging ninja \"setuptools>=49.4.0\" numpy pynvml ray\n","!git clone https://github.com/vllm-project/vllm.git\n","!cd vllm && pip install -U -q -r requirements-cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu\n","!VLLM_TARGET_DEVICE=cpu pip install -v -e vllm/. -U"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"elapsed":409,"status":"error","timestamp":1724828731806,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"2_7-fkpu5djM","outputId":"f41c373e-ebce-4623-a674-bf4b390ecfe2"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'LLM' from 'vllm' (unknown location)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-dc119b35953c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamplingParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VLLM_CPU_KVCACHE_SPACE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"20\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VLLM_CPU_OMP_THREADS_BIND\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0-27\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'LLM' from 'vllm' (unknown location)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from vllm import LLM, SamplingParams\n","import os\n","\n","os.environ[\"VLLM_CPU_KVCACHE_SPACE\"] = \"20\"\n","os.environ[\"VLLM_CPU_OMP_THREADS_BIND\"] = \"0-27\"\n","\n","if \"model\" in locals():\n","    del model\n","\n","model_id = \"microsoft/Phi-3.5-mini-instruct\"\n","model_id = \"KISTI-KONI/KONI-Llama3-8B-Instruct-20240729\"\n","model_id = \"Gunulhona/Llama-Merge-Small\"\n","model_id = \"akjindal53244/Llama-3.1-Storm-8B\"\n","model_id = \"Gunulhona/Gemma-Ko-Merge\"\n","\n","model  = LLM(\n","    model=model_id,\n","    max_model_len=4096,\n","    trust_remote_code=True,\n","    # quantization=\"bitsandbytes\",\n","    # load_format=\"bitsandbytes\",\n","    dtype=\"bfloat16\",\n","    distributed_executor_backend=\"ray\",\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Qg2Os5SI6pF","executionInfo":{"status":"aborted","timestamp":1724816056544,"user_tz":-540,"elapsed":5,"user":{"displayName":"정권환","userId":"03859214150473665717"}}},"outputs":[],"source":["import gc\n","import os\n","from typing import List, Dict\n","from vllm import LLM, SamplingParams\n","from transformers import AutoTokenizer\n","\n","def chat_format(prompt:List[Dict])->str:\n","    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n","    try:\n","        check = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","        print(\"tokenizer has format\")\n","    except:\n","        tokenizer.bos_token = \"<|begin_of_text|>\"\n","        tokenizer.chat_template= \"{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \\\"26 Jul 2024\\\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0]['role'] == 'system' %}\\n    {%- set system_message = messages[0]['content']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \\\"\\\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \\\"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\\\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \\\"Environment: ipython\\\\n\\\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \\\"Tools: \\\" + builtin_tools | reject('equalto', 'code_interpreter') | join(\\\", \\\") + \\\"\\\\n\\\\n\\\"}}\\n{%- endif %}\\n{{- \\\"Cutting Knowledge Date: December 2023\\\\n\\\" }}\\n{{- \\\"Today Date: \\\" + date_string + \\\"\\\\n\\\\n\\\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \\\"You have access to the following functions. To call a function, please respond with JSON for a function call.\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \\\"<|eot_id|>\\\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0]['content']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\\\"Cannot put tools in the first user message when there's no first user message!\\\") }}\\n{%- endif %}\\n    {{- '<|start_header_id|>user<|end_header_id|>\\\\n\\\\n' -}}\\n    {{- \\\"Given the following functions, please respond with a JSON for a function call \\\" }}\\n    {{- \\\"with its proper arguments that best answers the given prompt.\\\\n\\\\n\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \\\"<|eot_id|>\\\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\\\n\\\\n'+ message['content'] | trim + '<|eot_id|>' }}\\n    {%- elif 'tool_calls' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\\\"This model only supports single tool-calls at once!\\\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- \\\"<|python_tag|>\\\" + tool_call.name + \\\".call(\\\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + '=\\\"' + arg_val + '\\\"' }}\\n                {%- if not loop.last %}\\n                    {{- \\\", \\\" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \\\")\\\" }}\\n        {%- else  %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- '{\\\"name\\\": \\\"' + tool_call.name + '\\\", ' }}\\n            {{- '\\\"parameters\\\": ' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\\"}\\\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we're in ipython mode #}\\n            {{- \\\"<|eom_id|>\\\" }}\\n        {%- else %}\\n            {{- \\\"<|eot_id|>\\\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\\"tool\\\" or message.role == \\\"ipython\\\" %}\\n        {{- \\\"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\\\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \\\"<|eot_id|>\\\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' }}\\n{%- endif %}\\n\"\n","        tokenizer.clean_up_tokenization_spaces =True\n","        # tokenizer.eos_token = \"<|eot_id|>\"\n","        print(\"tokenizer doesn't have format\")\n","    finally:\n","        prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","\n","    return prompt\n","\n","os.environ[\"VLLM_USE_MODELSCOPE\"] = \"True\"\n","\n","prompt = \"\"\"\n","---\n","[대화]\n","참석자_1: 안녕하세요, 선생님.\n","참석자_2: 안녕하세요, 의사 선생님.\n","참석자_1: 마흔 넷이시죠?\n","참석자_2: 네, 선생님.\n","참석자_1: 좋아요, 오늘은 무슨 문제가 있는 것 같나요?\n","참석자_2: 의사 선생님, 한동안 허리 통증이 있었습니다.\n","참석자_1: 통증이 다리로 내려가나요?\n","참석자_2: 네, 오른쪽 허벅지에도 통증이 있습니다.\n","참석자_1: 이 통증과 관련된 부상이 있습니까?\n","참석자_2: 네, 1994년에 사고가 있었습니다.\n","참석자_1: 최초 부상 당시의 서류나 의료 기록이 있습니까?\n","참석자_2: 아니요, 오늘은 없습니다.\n","참석자_1: 직업이 어떻게 되십니까?\n","참석자_2: 지금은 타코벨에서 일합니다. 산재 보험 청구가 열려 있습니다.\n","참석자_1: 거기서 일하다가 통증이 재발했죠?\n","참석자_2: 네, 맞습니다.\n","참석자_1: 마지막으로 이곳에서 진료를 받은 것이 언제였는지 기억하십니까?\n","참석자_2: 음, 네, 4월 12일 2005년이었습니다.\n","참석자_1: 10이 상상할 수 있는 최악의 통증이라면, 마지막 방문 시 통증은 10점 만점에 어느 정도였습니까?\n","참석자_2: 음, 10점 만점에 8점 정도였어요.\n","참석자_1: 이 통증 때문에 약을 복용하셨나요?\n","참석자_2: 음, 지난번 방문했을 때 메드롤 도스팩을 처방받았습니다.\n","참석자_1: 도세팍에 통증이 어떻게 반응했나요?\n","참석자_2: 통증이 10점 만점에 4~5점 정도로 줄었습니다.\n","참석자_1: 통증이 있는 곳을 가리켜 주시겠습니까?\n","참석자_2: 네, 바로 여기입니다.\n","참석자_1: 여기 이 밴드요?\n","참석자_2: 네, 바로 그 자리입니다.\n","참석자_1: 좋아요, 여기는 요추 4번과 천골 사이입니다. 오른쪽 다리 통증을 어떻게 설명하시겠습니까?\n","참석자_2: 지금은 간헐적이고 미미하며 항상 있는 것은 아닙니다.\n","참석자_1: 허리 수술을 받은 적이 있습니까?\n","참석자_2: 음, 네, 1990년에 한 번, 1994년에 한 번 두 번 척추 절제술을 받았습니다. 잠깐만요, 그 사이에 디스크 절제술도 받았어요.\n","참석자_1: 어디에 초점이 맞춰졌는지 아십니까?\n","참석자_2: L 4 L 5번이었습니다.\n","참석자_1: 허리에 대한 영상 촬영은 하셨나요?\n","참석자_2: 네, 10월 18일 2004년에 MRI를 찍었습니다. 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 이것은 다단계 퇴행성 변화를 보여 주며, L 2 L 3, L 3 L 4, L 5 S1에서 신경 침범이 없는 다단계 퇴행성 변화를 보여 주며, 이는 양호합니다.\n","참석자_2: 그게 무슨 뜻인가요, 의사 선생님?\n","참석자_1: 요약하자면, 허리에 상당한 양의 관절염이 있다는 뜻입니다.\n","참석자_2: 네, M R 골수 조영술도 받았는데 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 요추 3번에서 심한 척추관 협착증이 보이지만 인공물일 수도 있습니다.\n","참석자_2: 그게 무슨 뜻인가요?\n","참석자_1: 이 소견은 잘못된 해석일 수 있습니다.\n"," ---\n","[요약]\n","\"\"\"\n","\n","DEFAULT_SUMMARY_SYSTEM_PROMPT = '''\n","You will be provided with a conversation transcript.\n","Your task is to summarize the content by extracting the key information and presenting it concisely.\n","The summary should capture the most important points discussed in the conversation, focusing on essential details.\n","When summarizing, highlight the most important keywords that capture the essence of the conversation.\n","\n","Follow these steps to complete the task:\n","\n","Step 1: Comprehension - Carefully read the entire conversation transcript from start to finish.\n","\n","Step 2: Identification - Identify the main ideas and critical pieces of information, focusing on the core elements of the discussion.\n","\n","Step 3: Condensation - Write a summary that condenses the content into 3 sentences. Ensure that the summary is clear, coherent, and accurately reflects the core of the conversation without including unnecessary details.\n","\n","Finally, present the summary in the following format:\n","---\n","[대화] (this is the given dialogue to summarize)\n","참석자_1: ...\n","참석자_2: ...\n","참석자_1: ...\n","...\n","중략\n","...\n","참석자_1: ...\n","참석자_2: ... (the dialouge must not be generated)\n","---\n","[요약]\n","* (핵심 키워드 중심 요약)\n","* (핵심 키워드 중심 요약)\n","* (핵심 키워드 중심 요약)\n","---\n","'''\n","\n","template = chat_format([\n","    {\"role\": \"system\",\n","     \"content\": DEFAULT_SUMMARY_SYSTEM_PROMPT},\n","    {\"role\": \"user\",\n","     \"content\": prompt}\n","    ])\n","output_list = model.generate(\n","    prompts=[template] * 3,\n","    sampling_params=SamplingParams(\n","        repetition_penalty=0.3,\n","        frequency_penalty=1.1,\n","        presence_penalty=1.0,\n","        temperature=0.7,\n","        top_p=0.9,\n","        max_tokens=500,\n","    ))\n","for result in output_list:\n","    print(f'''\n","--- Result ---\n","\n","{result.outputs[0].text}\n","\n","--- end ---\n","    ''')\n","\n","gc.collect()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446,"status":"ok","timestamp":1722574777352,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"DnvlVJymJ8ae","outputId":"29a1b8f4-ab11-4270-a563-a259c3487efb"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Blue whale. The blue whale is not only the largest animal but also the largest\n"]}],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"17C7UGm8w0pEano-Eb6RdJP4c-9KrgdbM","authorship_tag":"ABX9TyPURNtE5rZs5LBKYJ0vDJ5C"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}