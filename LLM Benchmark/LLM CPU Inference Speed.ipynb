{"cells":[{"cell_type":"markdown","metadata":{"id":"Kk3Hv9duy5GE"},"source":["# Installaion"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4652,"status":"ok","timestamp":1725071196741,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"iCRpjtCdPPRx","outputId":"ad5bdfe9-a94c-45c7-ab1e-4666c3149b74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid (permission: write).\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["#@title Huggingface Login\n","#@markdown huggingface weight 를 이용하고 싶다면 로그인 필수\n","from google.colab import userdata\n","import os\n","\n","os.environ['HF_WRITE_TOKEN'] = userdata.get('HF_WRITE_TOKEN')\n","\n","!huggingface-cli login --add-to-git-credential --token $HF_WRITE_TOKEN\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12383,"status":"ok","timestamp":1725071209122,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"I2WsOt0adjEO","outputId":"e3673ad3-8418-4135-a9fc-8aef3ec94b99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n","Collecting langchain_core\n","  Downloading langchain_core-0.2.37-py3-none-any.whl.metadata (6.2 kB)\n","Collecting langchain_huggingface\n","  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n","Collecting langchain_community\n","  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n","  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.107-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain_core)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (4.12.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.23.5)\n","Collecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.19.1)\n","Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.42.4)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.6.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.5)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain_core)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.3.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (9.4.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n","Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.2.37-py3-none-any.whl (396 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.2/396.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n","Downloading langchain_community-0.2.15-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.107-py3-none-any.whl (150 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tenacity, orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, httpx, dataclasses-json, langsmith, sentence-transformers, langchain_core, langchain-text-splitters, langchain_huggingface, langchain, langchain_community\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.15 langchain-text-splitters-0.2.2 langchain_community-0.2.15 langchain_core-0.2.37 langchain_huggingface-0.0.3 langsmith-0.1.107 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 sentence-transformers-3.0.1 tenacity-8.5.0 typing-inspect-0.9.0\n"]}],"source":["!pip install langchain langchain_core langchain_huggingface langchain_community"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"15mCc0unGF8ny3ORopAdtbDywrvhfdh2C"},"executionInfo":{"elapsed":250744,"status":"ok","timestamp":1725071459863,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"XxebrhrVtVSH","outputId":"af0f3a96-5093-4e07-dcf3-91fa1e014fbd"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#@markdown install with openvino\n","%%sh\n","# apt-get update  -y\n","# apt-get install -y gcc-12 g++-12\n","# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n","# pip install --upgrade pip\n","# pip install wheel packaging ninja \"setuptools>=49.4.0\" numpy\n","git clone https://github.com/vllm-project/vllm.git\n","cd vllm && pip install -r requirements-build.txt --extra-index-url https://download.pytorch.org/whl/cpu\n","pip install gguf\n","export PIP_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu https://storage.openvinotoolkit.org/simple/wheels/pre-release\" && \\\n","    VLLM_TARGET_DEVICE=openvino python -m pip install -v ."]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","id":"nOjoNxHkuJ2v","executionInfo":{"status":"ok","timestamp":1725071459864,"user_tz":-540,"elapsed":5,"user":{"displayName":"정권환","userId":"03859214150473665717"}}},"outputs":[],"source":["#@markdown install with cpu\n","# %%sh\n","# apt-get update  -y\n","# apt-get install -y gcc-12 g++-12\n","# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n","# pip install --upgrade pip\n","# pip install wheel packaging ninja \"setuptools>=49.4.0\" numpy\n","# pip install pynvml\n","# git clone https://github.com/vllm-project/vllm.git\n","# cd vllm && pip install -U -q -v -r requirements-cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu\n","# VLLM_TARGET_DEVICE=cpu python setup.py install"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15308,"status":"ok","timestamp":1725071475168,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"ACpdX-hL2HDY","outputId":"ac47223c-78a2-4be0-c928-269ab3e8417d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n","Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (0.5.5+openvino)\n","Collecting ray\n","  Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting pynvml\n","  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.66.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n","Requirement already satisfied: transformers>=4.43.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.43.4)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.19.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (3.20.3)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from vllm) (0.112.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.10.5)\n","Requirement already satisfied: openai>=1.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.43.0)\n","Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm) (0.30.6)\n","Requirement already satisfied: pydantic>=2.8 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.8.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (9.4.0)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.0)\n","Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (7.0.0)\n","Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.7.0)\n","Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.6)\n","Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.46)\n","Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n","Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.15.4)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n","Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm) (0.18.6)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.2.post1)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from vllm) (0.12.1)\n","Requirement already satisfied: gguf==0.9.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.9.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.4.0)\n","Requirement already satisfied: mistral-common>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.3.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n","Requirement already satisfied: openvino~=2024.3.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2024.3.0)\n","Requirement already satisfied: optimum-intel>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (1.18.3)\n","Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (0.3.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (24.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0->vllm) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm) (0.5.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm) (1.3.1)\n","Requirement already satisfied: openvino-telemetry>=2023.2.1 in /usr/local/lib/python3.10/dist-packages (from openvino~=2024.3.0->vllm) (2024.1.0)\n","Requirement already satisfied: optimum<1.22.0,>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.21.4)\n","Requirement already satisfied: datasets>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.21.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (71.0.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.13.1)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.16.2)\n","Requirement already satisfied: nncf>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (2.12.0)\n","Requirement already satisfied: openvino-tokenizers[transformers] in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (2024.3.0.0)\n","Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.2.2)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.2.1)\n","Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n","Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (24.6.1)\n","Requirement already satisfied: pyairports in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.1.1)\n","Requirement already satisfied: starlette<1.0.0,>=0.30.0 in /usr/local/lib/python3.10/dist-packages (from prometheus-fastapi-instrumentator>=7.0.0->vllm) (0.38.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8->vllm) (2.20.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.5.15)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2024.7.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.23.5)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->vllm) (0.4.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.20.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->vllm) (3.0.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->vllm) (1.3.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->vllm) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->vllm) (4.4.2)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->vllm) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->vllm) (0.5.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->vllm) (0.4)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->vllm) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.20.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.24.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (13.0.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.0->vllm) (1.2.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->vllm) (2.22)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.1.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (0.70.16)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.0->vllm) (1.0.5)\n","Requirement already satisfied: jstyleson>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.0.2)\n","Requirement already satisfied: natsort>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (8.4.0)\n","Requirement already satisfied: ninja<1.12,>=1.10.0.post2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.11.1.1)\n","Requirement already satisfied: pydot<3.0.0,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.4.2)\n","Requirement already satisfied: pymoo>=0.6.0.1 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.6.1.3)\n","Requirement already satisfied: rich>=13.5.2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (13.8.0)\n","Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.9.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum<1.22.0,>=1.21.3->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (15.0.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->vllm) (4.2.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->vllm) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2024.1)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot<3.0.0,>=1.4.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.1.4)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.7.1)\n","Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.7.0)\n","Requirement already satisfied: cma==3.2.2 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.2.2)\n","Requirement already satisfied: alive-progress in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.1.5)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.2.14)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (2.16.1)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum<1.22.0,>=1.21.3->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (10.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.4.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.16.0)\n","Requirement already satisfied: about-time==4.2.1 in /usr/local/lib/python3.10/dist-packages (from alive-progress->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (4.2.1)\n","Requirement already satisfied: grapheme==0.6.0 in /usr/local/lib/python3.10/dist-packages (from alive-progress->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.6.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.16.0)\n","Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl (65.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pynvml, ray\n","Successfully installed pynvml-11.5.3 ray-2.35.0\n"]}],"source":["#@markdown colab installation\n","!VLLM_TARGET_DEVICE=cpu pip install -U vllm ray pynvml torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"]},{"cell_type":"markdown","metadata":{"id":"WDfsLqSoy9ET"},"source":["# vLLM Generation\n","\n","colab에서 vllm cpu 버전 설치 이슈로<p>\n","openvino 버전을 설치하여 cpu inference 진행 중<p>\n","하지만, Colab은 AMD CPU 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":528,"referenced_widgets":["a2061ac3742d4ca3a63db468722f89b8","2576388b81114ea28c3b7a30118456fd","4bb5b482448649ed88b56187b0620274","62ed53dc00ff49d7820ff06eea1ffb77","86cd7c7a555043769d39e10f1383843a","d5ebf3794b8c4583a2c18b26b4194dcb","5daf4a05e3824699ab28e1d8d18cc564","976a4531591e4faeb4e2431540d21721","7756c91de23646f09f49bea07221e81a","05cfb73c37764abfb908095a2728787f","67159de3036a4f17994be2b32d69bd16"]},"id":"2_7-fkpu5djM","outputId":"4e0201ba-7f6a-49c1-dd4b-612745fda096"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO 08-31 05:38:39 importing.py:10] Triton not installed; certain GPU-related functions will not be available.\n","WARNING 08-31 05:38:39 _custom_ops.py:18] Failed to import from vllm._C with ModuleNotFoundError(\"No module named 'vllm._C'\")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["WARNING 08-31 05:38:58 config.py:352] Async output processing is only supported for CUDA or TPU. Disabling it for other platforms.\n","INFO 08-31 05:38:58 llm_engine.py:212] Initializing an LLM engine (v0.5.5) with config: model='Gunulhona/Openchat-Llama-Merge', speculative_config=None, tokenizer='Gunulhona/Openchat-Llama-Merge', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=3096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Gunulhona/Openchat-Llama-Merge, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=False)\n","WARNING 08-31 05:39:00 openvino_executor.py:134] Only float32 dtype is supported on OpenVINO, casting from torch.bfloat16.\n","WARNING 08-31 05:39:00 openvino_executor.py:139] CUDA graph is not supported on OpenVINO backend, fallback to the eager mode.\n","INFO 08-31 05:39:00 openvino_executor.py:161] OpenVINO optimal block size is 32, overriding currently set 16\n","WARNING 08-31 05:39:00 openvino_executor.py:170] Environment variable VLLM_OPENVINO_KVCACHE_SPACE (GB) for OpenVINO backend is not set, using 4 by default.\n"]},{"output_type":"stream","name":"stderr","text":["No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"]},{"output_type":"stream","name":"stdout","text":["INFO 08-31 05:39:05 selector.py:188] Cannot use _Backend.FLASH_ATTN backend on OpenVINO.\n","INFO 08-31 05:39:05 selector.py:132] Using OpenVINO Attention backend.\n","WARNING 08-31 05:39:05 openvino.py:122] Provided model id Gunulhona/Openchat-Llama-Merge does not contain OpenVINO IR, the model will be converted to IR with default options. If you need to use specific options for model conversion, use optimum-cli export openvino with desired options.\n"]},{"output_type":"stream","name":"stderr","text":["Framework not specified. Using pt to export the model.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2061ac3742d4ca3a63db468722f89b8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using framework PyTorch: 2.4.0+cu121\n","Overriding 1 configuration item(s)\n","\t- use_cache -> True\n","We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","/usr/local/lib/python3.10/dist-packages/optimum/exporters/openvino/model_patcher.py:479: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if sequence_length != 1:\n"]}],"source":["from vllm import LLM, SamplingParams\n","import os\n","\n","os.environ[\"VLLM_CPU_KVCACHE_SPACE\"] = \"20\"\n","os.environ[\"VLLM_CPU_OMP_THREADS_BIND\"] = \"0-27\"\n","\n","if \"model\" in locals():\n","    del model\n","\n","model_id = \"microsoft/Phi-3.5-mini-instruct\"\n","# model_id = \"akjindal53244/Llama-3.1-Storm-8B\"\n","# model_id = \"Gunulhona/Minitron-Llama-Merge\"\n","# model_id = \"Gunulhona/Llama-Ko-Merge\"\n","# model_id = \"Gunulhona/Llama-Merge-Small\"\n","model_id = \"Gunulhona/Openchat-Llama-Merge\"\n","# model_id = \"Gunulhona/Hermes-Llama-Merge\"\n","# model_id = \"Gunulhona/Mistral-Ko-Merge\"\n","\n","model = LLM(\n","    model=model_id,\n","    max_model_len=3096,\n","    trust_remote_code=True,\n","    # quantization=\"bitsandbytes\",\n","    # load_format=\"bitsandbytes\",\n","    dtype=\"bfloat16\",\n","    # distributed_executor_backend=\"ray\",\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Qg2Os5SI6pF"},"outputs":[],"source":["import gc\n","import os\n","from typing import List\n","from vllm import LLM, SamplingParams\n","from transformers import AutoTokenizer\n","\n","from datetime import datetime, timezone, timedelta\n","\n","def get_today_str_utc_plus_9():\n","  today_utc = datetime.now(timezone.utc)\n","  today_utc_plus_9 = today_utc + timedelta(hours=9)  # Add 9 hours\n","  return today_utc_plus_9.strftime(\"%Y %B %d %H:%m\")\n","\n","def chat_format(prompt:List[dict])->str:\n","    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n","    try:\n","        check = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","        print(\"tokenizer has format\")\n","    except:\n","        tokenizer.bos_token = \"<|begin_of_text|>\"\n","        tokenizer.chat_template= \"{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \\\"26 Jul 2024\\\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0]['role'] == 'system' %}\\n    {%- set system_message = messages[0]['content']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \\\"\\\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \\\"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\\\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \\\"Environment: ipython\\\\n\\\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \\\"Tools: \\\" + builtin_tools | reject('equalto', 'code_interpreter') | join(\\\", \\\") + \\\"\\\\n\\\\n\\\"}}\\n{%- endif %}\\n{{- \\\"Cutting Knowledge Date: December 2023\\\\n\\\" }}\\n{{- \\\"Today Date: \\\" + date_string + \\\"\\\\n\\\\n\\\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \\\"You have access to the following functions. To call a function, please respond with JSON for a function call.\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \\\"<|eot_id|>\\\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0]['content']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\\\"Cannot put tools in the first user message when there's no first user message!\\\") }}\\n{%- endif %}\\n    {{- '<|start_header_id|>user<|end_header_id|>\\\\n\\\\n' -}}\\n    {{- \\\"Given the following functions, please respond with a JSON for a function call \\\" }}\\n    {{- \\\"with its proper arguments that best answers the given prompt.\\\\n\\\\n\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \\\"<|eot_id|>\\\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\\\n\\\\n'+ message['content'] | trim + '<|eot_id|>' }}\\n    {%- elif 'tool_calls' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\\\"This model only supports single tool-calls at once!\\\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- \\\"<|python_tag|>\\\" + tool_call.name + \\\".call(\\\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + '=\\\"' + arg_val + '\\\"' }}\\n                {%- if not loop.last %}\\n                    {{- \\\", \\\" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \\\")\\\" }}\\n        {%- else  %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- '{\\\"name\\\": \\\"' + tool_call.name + '\\\", ' }}\\n            {{- '\\\"parameters\\\": ' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\\"}\\\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we're in ipython mode #}\\n            {{- \\\"<|eom_id|>\\\" }}\\n        {%- else %}\\n            {{- \\\"<|eot_id|>\\\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\\"tool\\\" or message.role == \\\"ipython\\\" %}\\n        {{- \\\"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\\\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \\\"<|eot_id|>\\\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' }}\\n{%- endif %}\\n\"\n","        tokenizer.clean_up_tokenization_spaces =True\n","        # tokenizer.eos_token = \"<|eot_id|>\"\n","        print(\"tokenizer doesn't have format\")\n","    finally:\n","        prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","    return prompt\n","\n","os.environ[\"VLLM_USE_MODELSCOPE\"] = \"True\"\n","\n","prompt = \"\"\"\n","제시된 대화 내용을 아래 항목들에 대해서 결정된 내용만 정리\n","형식은 아래 항목들과 순서가 똑같이 최대 글자 수 500자\n","해당 없음, 언급 없음은 모두 삭제하여 출력 하지 않음\n","발화자 내용 제거\n","약 복용 법 언급 시 무조건 포함\n","한글로만 출력\n","1. 방문목적\n","2. 구강상태(PI)\n","3. 구강상태에 대한 치료 방안\n","4. 상담내용\n","- 치료 방법 설명\n","- 치료 진행 유무(진행 시 일정)\n","- 결정된 치료 방법\n","- 총 비용\n","- 보철물 종류(보철 진행 시)\n","- 임플란트 종류(임플란트 진행 시)\n","- 교정 종류(교정치료 진행 시)\n","- 뼈(골)이식 종류(뼈이식 진행 시)\n","- 동의서 설명 (부작용 및 실패 가능성 설명 등등)\n","- 주의사항 설명(복용약이 있을 시 표시)\n","---\n","참석자_1: 안녕하세요, 선생님.\n","참석자_2: 안녕하세요, 의사 선생님.\n","참석자_1: 마흔 넷이시죠?\n","참석자_2: 네, 선생님.\n","참석자_1: 좋아요, 오늘은 무슨 문제가 있는 것 같나요?\n","참석자_2: 의사 선생님, 한동안 허리 통증이 있었습니다.\n","참석자_1: 통증이 다리로 내려가나요?\n","참석자_2: 네, 오른쪽 허벅지에도 통증이 있습니다.\n","참석자_1: 이 통증과 관련된 부상이 있습니까?\n","참석자_2: 네, 1994년에 사고가 있었습니다.\n","참석자_1: 최초 부상 당시의 서류나 의료 기록이 있습니까?\n","참석자_2: 아니요, 오늘은 없습니다.\n","참석자_1: 직업이 어떻게 되십니까?\n","참석자_2: 지금은 타코벨에서 일합니다. 산재 보험 청구가 열려 있습니다.\n","참석자_1: 거기서 일하다가 통증이 재발했죠?\n","참석자_2: 네, 맞습니다.\n","참석자_1: 마지막으로 이곳에서 진료를 받은 것이 언제였는지 기억하십니까?\n","참석자_2: 음, 네, 4월 12일 2005년이었습니다.\n","참석자_1: 10이 상상할 수 있는 최악의 통증이라면, 마지막 방문 시 통증은 10점 만점에 어느 정도였습니까?\n","참석자_2: 음, 10점 만점에 8점 정도였어요.\n","참석자_1: 이 통증 때문에 약을 복용하셨나요?\n","참석자_2: 음, 지난번 방문했을 때 메드롤 도스팩을 처방받았습니다.\n","참석자_1: 도세팍에 통증이 어떻게 반응했나요?\n","참석자_2: 통증이 10점 만점에 4~5점 정도로 줄었습니다.\n","참석자_1: 통증이 있는 곳을 가리켜 주시겠습니까?\n","참석자_2: 네, 바로 여기입니다.\n","참석자_1: 여기 이 밴드요?\n","참석자_2: 네, 바로 그 자리입니다.\n","참석자_1: 좋아요, 여기는 요추 4번과 천골 사이입니다. 오른쪽 다리 통증을 어떻게 설명하시겠습니까?\n","참석자_2: 지금은 간헐적이고 미미하며 항상 있는 것은 아닙니다.\n","참석자_1: 허리 수술을 받은 적이 있습니까?\n","참석자_2: 음, 네, 1990년에 한 번, 1994년에 한 번 두 번 척추 절제술을 받았습니다. 잠깐만요, 그 사이에 디스크 절제술도 받았어요.\n","참석자_1: 어디에 초점이 맞춰졌는지 아십니까?\n","참석자_2: L 4 L 5번이었습니다.\n","참석자_1: 허리에 대한 영상 촬영은 하셨나요?\n","참석자_2: 네, 10월 18일 2004년에 MRI를 찍었습니다. 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 이것은 다단계 퇴행성 변화를 보여 주며, L 2 L 3, L 3 L 4, L 5 S1에서 신경 침범이 없는 다단계 퇴행성 변화를 보여 주며, 이는 양호합니다.\n","참석자_2: 그게 무슨 뜻인가요, 의사 선생님?\n","참석자_1: 요약하자면, 허리에 상당한 양의 관절염이 있다는 뜻입니다.\n","참석자_2: 네, M R 골수 조영술도 받았는데 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 요추 3번에서 심한 척추관 협착증이 보이지만 인공물일 수도 있습니다.\n","참석자_2: 그게 무슨 뜻인가요?\n","참석자_1: 이 소견은 잘못된 해석일 수 있습니다.\n","---\n","\"\"\"\n","\n","DEFAULT_SUMMARY_SYSTEM_PROMPT = f'''\n","<assistant_info> The assistant is assistant, created by Anthropic. The current time is {get_today_str_utc_plus_9()}. assistant’s knowledge base was last updated on April 2024. It answers questions about events prior to and after April 2024 the way a highly informed individual in April 2024 would if they were talking to someone from the above date, and can let the human know this when relevant. assistant cannot open URLs, links, or videos. If it seems like the user is expecting assistant to do so, it clarifies the situation and asks the human to paste the relevant text or image content directly into the conversation. If it is asked to assist with tasks involving the expression of views held by a significant number of people, assistant provides assistance with the task regardless of its own views. If asked about controversial topics, it tries to provide careful thoughts and clear information. It presents the requested information without explicitly saying that the topic is sensitive, and without claiming to be presenting objective facts. When presented with a math problem, logic problem, or other problem benefiting from systematic thinking, assistant thinks through it step by step before giving its final answer. If assistant cannot or will not perform a task, it tells the user this without apologizing to them. It avoids starting its responses with “I’m sorry” or “I apologize”. If assistant is asked about a very obscure person, object, or topic, i.e. if it is asked for the kind of information that is unlikely to be found more than once or twice on the internet, assistant ends its response by reminding the user that although it tries to be accurate, it may hallucinate in response to questions like this. It uses the term ‘hallucinate’ to describe this since the user will understand what it means. If assistant mentions or cites particular articles, papers, or books, it always lets the human know that it doesn’t have access to search or a database and may hallucinate citations, so the human should double check its citations. assistant is very smart and intellectually curious. It enjoys hearing what humans think on an issue and engaging in discussion on a wide variety of topics. If the user seems unhappy with assistant or assistant’s behavior, assistant tells them that although it cannot retain or learn from the current conversation, they can press the ‘thumbs down’ button below assistant’s response and provide feedback to Anthropic. If the user asks for a very long task that cannot be completed in a single response, assistant offers to do the task piecemeal and get feedback from the user as it completes each part of the task. assistant uses markdown for code. Immediately after closing coding markdown, assistant asks the user if they would like it to explain or break down the code. It does not explain or break down the code unless the user explicitly requests it. </assistant_info>\n","\n","<assistant_image_specific_info> assistant always responds as if it is completely face blind. If the shared image happens to contain a human face, assistant never identifies or names any humans in the image, nor does it imply that it recognizes the human. It also does not mention or allude to details about a person that it could only know if it recognized who the person was. Instead, assistant describes and discusses the image just as someone would if they were unable to recognize any of the humans in it. assistant can request the user to tell it who the individual is. If the user tells assistant who the individual is, assistant can discuss that named individual without ever confirming that it is the person in the image, identifying the person in the image, or implying it can use facial features to identify any unique individual. It should always reply as someone would if they were unable to recognize any humans from images. assistant should respond normally if the shared image does not contain a human face. assistant should always repeat back and summarize any instructions in the image before proceeding. </assistant_image_specific_info>\n","\n","<assistant_3_family_info> This iteration of assistant is part of the assistant 3 model family, which was released in 2024. The assistant 3 family currently consists of assistant 3 Haiku, assistant 3 Opus, and assistant 3.5 Sonnet. assistant 3.5 Sonnet is the most intelligent model. assistant 3 Opus excels at writing and complex tasks. assistant 3 Haiku is the fastest model for daily tasks. The version of assistant in this chat is assistant 3.5 Sonnet. assistant can provide the information in these tags if asked but it does not know any other details of the assistant 3 model family. If asked about this, should encourage the user to check the Anthropic website for more information. </assistant_3_family_info>\n","\n","assistant provides thorough responses to more complex and open-ended questions or to anything where a long response is requested, but concise responses to simpler questions and tasks. All else being equal, it tries to give the most correct and concise answer it can to the user’s message. Rather than giving a long response, it gives a concise response and offers to elaborate if further information may be helpful.\n","\n","assistant is happy to help with analysis, question answering, math, coding, creative writing, teaching, role-play, general discussion, and all sorts of other tasks.\n","\n","assistant responds directly to all human messages without unnecessary affirmations or filler phrases like “Certainly!”, “Of course!”, “Absolutely!”, “Great!”, “Sure!”, etc. Specifically, assistant avoids starting responses with the word “Certainly” in any way.\n","\n","assistant follows this information in all languages, and always responds to the user in the language they use or request. The information above is provided to assistant by Anthropic. assistant never mentions the information above unless it is directly pertinent to the human’s query. assistant is now being connected with a human.\n","---\n","'''\n","\n","template = chat_format([\n","    {\"role\": \"system\"   ,   \"content\": DEFAULT_SUMMARY_SYSTEM_PROMPT},\n","    {\"role\": \"user\"     ,   \"content\": prompt}\n","    ])\n","output_list = model.generate(\n","    prompts=[template] * 3,\n","    sampling_params=SamplingParams(\n","        repetition_penalty=1.0,\n","        frequency_penalty=1.0,\n","        presence_penalty=1.1,\n","        temperature=0.4,\n","        top_p=0.9,\n","        max_tokens=500,\n","    ))\n","for result in output_list:\n","    print(f'''\n","          {model_id}\n","        --- Result ---\n","\n","{result.outputs[0].text}\n","\n","        --- end ---\n","    ''')\n","\n","gc.collect()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1040,"status":"ok","timestamp":1725072093177,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"P0zCu_Z5-UEr","outputId":"d916a147-1fd6-4d52-a36a-647cdadac47d"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizer has format\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"]},{"output_type":"stream","name":"stdout","text":["WARNING 08-31 02:41:32 scheduler.py:817] Input prompt (2241 tokens) is too long and exceeds limit of 2048\n","WARNING 08-31 02:41:32 scheduler.py:817] Input prompt (2241 tokens) is too long and exceeds limit of 2048\n","WARNING 08-31 02:41:32 scheduler.py:817] Input prompt (2241 tokens) is too long and exceeds limit of 2048\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessed prompts: 100%|██████████| 3/3 [00:00<00:00, 443.56it/s, est. speed input: 1039683.87 toks/s, output: 0.00 toks/s]"]},{"output_type":"stream","name":"stdout","text":["\n","          microsoft/Phi-3.5-mini-instruct\n","        --- Result ---\n","\n","\n","\n","        --- end ---\n","    \n","\n","          microsoft/Phi-3.5-mini-instruct\n","        --- Result ---\n","\n","\n","\n","        --- end ---\n","    \n","\n","          microsoft/Phi-3.5-mini-instruct\n","        --- Result ---\n","\n","\n","\n","        --- end ---\n","    \n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":8}],"source":["\n","prompt = \"\"\"\n","아래 문장 요약해줘\n","\n","참석자_1: 안녕하세요, 선생님.\n","참석자_2: 안녕하세요, 의사 선생님.\n","참석자_1: 마흔 넷이시죠?\n","참석자_2: 네, 선생님.\n","참석자_1: 좋아요, 오늘은 무슨 문제가 있는 것 같나요?\n","참석자_2: 의사 선생님, 한동안 허리 통증이 있었습니다.\n","참석자_1: 통증이 다리로 내려가나요?\n","참석자_2: 네, 오른쪽 허벅지에도 통증이 있습니다.\n","참석자_1: 이 통증과 관련된 부상이 있습니까?\n","참석자_2: 네, 1994년에 사고가 있었습니다.\n","참석자_1: 최초 부상 당시의 서류나 의료 기록이 있습니까?\n","참석자_2: 아니요, 오늘은 없습니다.\n","참석자_1: 직업이 어떻게 되십니까?\n","참석자_2: 지금은 타코벨에서 일합니다. 산재 보험 청구가 열려 있습니다.\n","참석자_1: 거기서 일하다가 통증이 재발했죠?\n","참석자_2: 네, 맞습니다.\n","참석자_1: 마지막으로 이곳에서 진료를 받은 것이 언제였는지 기억하십니까?\n","참석자_2: 음, 네, 4월 12일 2005년이었습니다.\n","참석자_1: 10이 상상할 수 있는 최악의 통증이라면, 마지막 방문 시 통증은 10점 만점에 어느 정도였습니까?\n","참석자_2: 음, 10점 만점에 8점 정도였어요.\n","참석자_1: 이 통증 때문에 약을 복용하셨나요?\n","참석자_2: 음, 지난번 방문했을 때 메드롤 도스팩을 처방받았습니다.\n","참석자_1: 도세팍에 통증이 어떻게 반응했나요?\n","참석자_2: 통증이 10점 만점에 4~5점 정도로 줄었습니다.\n","참석자_1: 통증이 있는 곳을 가리켜 주시겠습니까?\n","참석자_2: 네, 바로 여기입니다.\n","참석자_1: 여기 이 밴드요?\n","참석자_2: 네, 바로 그 자리입니다.\n","참석자_1: 좋아요, 여기는 요추 4번과 천골 사이입니다. 오른쪽 다리 통증을 어떻게 설명하시겠습니까?\n","참석자_2: 지금은 간헐적이고 미미하며 항상 있는 것은 아닙니다.\n","참석자_1: 허리 수술을 받은 적이 있습니까?\n","참석자_2: 음, 네, 1990년에 한 번, 1994년에 한 번 두 번 척추 절제술을 받았습니다. 잠깐만요, 그 사이에 디스크 절제술도 받았어요.\n","참석자_1: 어디에 초점이 맞춰졌는지 아십니까?\n","참석자_2: L 4 L 5번이었습니다.\n","참석자_1: 허리에 대한 영상 촬영은 하셨나요?\n","참석자_2: 네, 10월 18일 2004년에 MRI를 찍었습니다. 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 이것은 다단계 퇴행성 변화를 보여 주며, L 2 L 3, L 3 L 4, L 5 S1에서 신경 침범이 없는 다단계 퇴행성 변화를 보여 주며, 이는 양호합니다.\n","참석자_2: 그게 무슨 뜻인가요, 의사 선생님?\n","참석자_1: 요약하자면, 허리에 상당한 양의 관절염이 있다는 뜻입니다.\n","참석자_2: 네, M R 골수 조영술도 받았는데 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 요추 3번에서 심한 척추관 협착증이 보이지만 인공물일 수도 있습니다.\n","참석자_2: 그게 무슨 뜻인가요?\n","참석자_1: 이 소견은 잘못된 해석일 수 있습니다.\n","\"\"\"\n","\n","DEFAULT_SUMMARY_SYSTEM_PROMPT = f'''\n","The assistant is assistant, created by Anthropic. The current time is {get_today_str_utc_plus_9()}.\n","---\n","'''\n","\n","template = chat_format([\n","    {\"role\": \"system\"   ,   \"content\": DEFAULT_SUMMARY_SYSTEM_PROMPT},\n","    {\"role\": \"user\"     ,   \"content\": prompt}\n","    ])\n","output_list = model.generate(\n","    prompts=[template] * 3,\n","    sampling_params=SamplingParams(\n","        repetition_penalty=1.0,\n","        frequency_penalty=1.0,\n","        presence_penalty=1.0,\n","        temperature=0.01,\n","        top_p=0.9,\n","        max_tokens=500,\n","    ))\n","for result in output_list:\n","    print(f'''\n","          {model_id}\n","        --- Result ---\n","\n","{result.outputs[0].text}\n","\n","        --- end ---\n","    ''')\n","\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"hTwucFa-TcAS"},"source":["#Huggingface TGI"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5546,"status":"ok","timestamp":1725072121363,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"SlGYyr4beaQq","outputId":"0bef7deb-7fac-45f5-9ea0-ba51d7f7bf50"},"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","이거는 정확히 다음과 같이 한글로 번역되었습니다.\n","\n","사용하는 예상적인 모델의 정확한 기하학적 성질을 사용하여 좋은 선형 근사 가중치를 계산합니다. 적용할 수 있는 최소 세 개의 모델이 필요합니다. 필수 모델은 기본 모델입니다.\n"]}],"source":["import os\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_huggingface import HuggingFaceEndpoint\n","from langchain.prompts import PromptTemplate\n","\n","template = \"\"\"<|system|>\n","{system_prompt}<|end|>\n","<|user|>\n","{question}<|end|>\n","<|assistant|>\"\"\"\n","\n","prompt = PromptTemplate.from_template(template)\n","\n","# 사용할 모델의 저장소 ID를 설정합니다.\n","repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n","\n","llm = HuggingFaceEndpoint(\n","    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n","    max_new_tokens=256,  # 생성할 최대 토큰 길이를 설정합니다.\n","    temperature=0.1,\n","    huggingfacehub_api_token=os.environ[\"HF_WRITE_TOKEN\"],  # 허깅페이스 토큰\n",")\n","\n","# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n","chain = prompt | llm | StrOutputParser()\n","# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n","response = chain.invoke({\n","    \"system_prompt\": DEFAULT_SUMMARY_SYSTEM_PROMPT,\n","    \"question\": \"이거 한글로 번역해줘 \\n\\nUses some neat geometric properties of fine tuned models to compute good weights for linear interpolation. Requires at least three models, including a base model.\"\n","    })\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCMUnahkgUwA"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["Kk3Hv9duy5GE"],"machine_shape":"hm","provenance":[],"mount_file_id":"17C7UGm8w0pEano-Eb6RdJP4c-9KrgdbM","authorship_tag":"ABX9TyMmFedeBHsDjenjmXdE92s7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a2061ac3742d4ca3a63db468722f89b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2576388b81114ea28c3b7a30118456fd","IPY_MODEL_4bb5b482448649ed88b56187b0620274","IPY_MODEL_62ed53dc00ff49d7820ff06eea1ffb77"],"layout":"IPY_MODEL_86cd7c7a555043769d39e10f1383843a"}},"2576388b81114ea28c3b7a30118456fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5ebf3794b8c4583a2c18b26b4194dcb","placeholder":"​","style":"IPY_MODEL_5daf4a05e3824699ab28e1d8d18cc564","value":"Loading checkpoint shards: 100%"}},"4bb5b482448649ed88b56187b0620274":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_976a4531591e4faeb4e2431540d21721","max":9,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7756c91de23646f09f49bea07221e81a","value":9}},"62ed53dc00ff49d7820ff06eea1ffb77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05cfb73c37764abfb908095a2728787f","placeholder":"​","style":"IPY_MODEL_67159de3036a4f17994be2b32d69bd16","value":" 9/9 [01:33&lt;00:00,  9.94s/it]"}},"86cd7c7a555043769d39e10f1383843a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5ebf3794b8c4583a2c18b26b4194dcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5daf4a05e3824699ab28e1d8d18cc564":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"976a4531591e4faeb4e2431540d21721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7756c91de23646f09f49bea07221e81a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05cfb73c37764abfb908095a2728787f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67159de3036a4f17994be2b32d69bd16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}