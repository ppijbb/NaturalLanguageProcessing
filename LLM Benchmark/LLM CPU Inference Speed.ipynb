{"cells":[{"cell_type":"markdown","metadata":{"id":"Kk3Hv9duy5GE"},"source":["# Installaion"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2825,"status":"ok","timestamp":1725237290548,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"iCRpjtCdPPRx","outputId":"49c274b4-2be8-45fe-cb7f-9f30bc70c4db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid (permission: write).\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["#@title Huggingface Login\n","#@markdown huggingface weight 를 이용하고 싶다면 로그인 필수\n","from google.colab import userdata\n","import os\n","\n","os.environ['HF_WRITE_TOKEN'] = userdata.get('HF_WRITE_TOKEN')\n","\n","!huggingface-cli login --add-to-git-credential --token $HF_WRITE_TOKEN\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13948,"status":"ok","timestamp":1725237304494,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"I2WsOt0adjEO","outputId":"d11aa035-a8fd-4dfb-ed86-c768e210e82f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n","Collecting langchain_core\n","  Downloading langchain_core-0.2.37-py3-none-any.whl.metadata (6.2 kB)\n","Collecting langchain_huggingface\n","  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n","Collecting langchain_community\n","  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n","  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.108-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain_core)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (4.12.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.23.5)\n","Collecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.19.1)\n","Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.42.4)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.6.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.5)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain_core)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.3.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (9.4.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n","Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.2.37-py3-none-any.whl (396 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.2/396.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n","Downloading langchain_community-0.2.15-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.108-py3-none-any.whl (150 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tenacity, orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, httpx, dataclasses-json, langsmith, sentence-transformers, langchain_core, langchain-text-splitters, langchain_huggingface, langchain, langchain_community\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.15 langchain-text-splitters-0.2.2 langchain_community-0.2.15 langchain_core-0.2.37 langchain_huggingface-0.0.3 langsmith-0.1.108 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 sentence-transformers-3.0.1 tenacity-8.5.0 typing-inspect-0.9.0\n"]}],"source":["!pip install langchain langchain_core langchain_huggingface langchain_community"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1NASI4yyIR5muOCKOuNuvziYIKelG9Cg6"},"executionInfo":{"elapsed":140941,"status":"ok","timestamp":1725237445433,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"XxebrhrVtVSH","outputId":"e728548c-822c-4594-caf7-ef67b1a0113a"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#@markdown install with openvino\n","%%sh\n","# apt-get update  -y\n","# apt-get install -y gcc-12 g++-12\n","# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n","# pip install --upgrade pip\n","# pip install wheel packaging ninja \"setuptools>=49.4.0\" numpy\n","git clone https://github.com/vllm-project/vllm.git\n","cd vllm && pip install -r requirements-build.txt --extra-index-url https://download.pytorch.org/whl/cpu\n","pip install gguf\n","export PIP_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu https://storage.openvinotoolkit.org/simple/wheels/pre-release\" && \\\n","    VLLM_TARGET_DEVICE=openvino python -m pip install -v ."]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","id":"nOjoNxHkuJ2v","executionInfo":{"status":"ok","timestamp":1725237445433,"user_tz":-540,"elapsed":6,"user":{"displayName":"정권환","userId":"03859214150473665717"}}},"outputs":[],"source":["#@markdown install with cpu\n","# %%sh\n","# apt-get update  -y\n","# apt-get install -y gcc-12 g++-12\n","# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n","# pip install --upgrade pip\n","# pip install wheel packaging ninja \"setuptools>=49.4.0\" numpy\n","# pip install pynvml\n","# git clone https://github.com/vllm-project/vllm.git\n","# cd vllm && pip install -U -q -v -r requirements-cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu\n","# VLLM_TARGET_DEVICE=cpu python setup.py install"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13537,"status":"ok","timestamp":1725237458965,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"ACpdX-hL2HDY","outputId":"b785cebf-472a-4073-abe6-a9bd286a554c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n","Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (0.5.5+openvino)\n","Collecting ray\n","  Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting pynvml\n","  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.66.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n","Requirement already satisfied: transformers>=4.43.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.43.4)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.19.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (3.20.3)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from vllm) (0.112.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.10.5)\n","Requirement already satisfied: openai>=1.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.43.0)\n","Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm) (0.30.6)\n","Requirement already satisfied: pydantic>=2.8 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.8.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (9.4.0)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.0)\n","Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (7.0.0)\n","Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.7.0)\n","Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.6)\n","Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.46)\n","Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n","Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.15.4)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n","Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm) (0.18.6)\n","Requirement already satisfied: gguf==0.9.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.9.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.4.0)\n","Requirement already satisfied: mistral-common>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.3.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n","Requirement already satisfied: openvino~=2024.3.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2024.3.0)\n","Requirement already satisfied: optimum-intel>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (1.18.3)\n","Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (0.3.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (24.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0->vllm) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm) (0.5.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->vllm) (1.3.1)\n","Requirement already satisfied: openvino-telemetry>=2023.2.1 in /usr/local/lib/python3.10/dist-packages (from openvino~=2024.3.0->vllm) (2024.1.0)\n","Requirement already satisfied: optimum<1.22.0,>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.21.4)\n","Requirement already satisfied: datasets>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.21.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (71.0.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.13.1)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.16.2)\n","Requirement already satisfied: nncf>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (2.12.0)\n","Requirement already satisfied: openvino-tokenizers[transformers] in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (2024.3.0.0)\n","Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.2.2)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.2.1)\n","Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n","Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (24.6.1)\n","Requirement already satisfied: pyairports in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.1.1)\n","Requirement already satisfied: starlette<1.0.0,>=0.30.0 in /usr/local/lib/python3.10/dist-packages (from prometheus-fastapi-instrumentator>=7.0.0->vllm) (0.38.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8->vllm) (2.20.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.5.15)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2024.7.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.23.5)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->vllm) (0.4.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.20.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.20.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.24.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (13.0.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.0->vllm) (1.2.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.1.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (0.70.16)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.0->vllm) (1.0.5)\n","Requirement already satisfied: jstyleson>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.0.2)\n","Requirement already satisfied: natsort>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (8.4.0)\n","Requirement already satisfied: ninja<1.12,>=1.10.0.post2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.11.1.1)\n","Requirement already satisfied: pydot<3.0.0,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.4.2)\n","Requirement already satisfied: pymoo>=0.6.0.1 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.6.1.3)\n","Requirement already satisfied: rich>=13.5.2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (13.8.0)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.3.2)\n","Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.9.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum<1.22.0,>=1.21.3->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (15.0.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2024.1)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot<3.0.0,>=1.4.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.1.4)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.7.1)\n","Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.7.0)\n","Requirement already satisfied: cma==3.2.2 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.2.2)\n","Requirement already satisfied: alive-progress in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.1.5)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.2.14)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (2.16.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.5.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum<1.22.0,>=1.21.3->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (10.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.4.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.16.0)\n","Requirement already satisfied: about-time==4.2.1 in /usr/local/lib/python3.10/dist-packages (from alive-progress->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (4.2.1)\n","Requirement already satisfied: grapheme==0.6.0 in /usr/local/lib/python3.10/dist-packages (from alive-progress->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.6.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.16.0)\n","Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl (65.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pynvml, ray\n","Successfully installed pynvml-11.5.3 ray-2.35.0\n"]}],"source":["#@markdown colab installation\n","!VLLM_TARGET_DEVICE=cpu pip install -U vllm ray pynvml torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"]},{"cell_type":"markdown","metadata":{"id":"WDfsLqSoy9ET"},"source":["# vLLM Generation\n","\n","colab에서 vllm cpu 버전 설치 이슈로<p>\n","openvino 버전을 설치하여 cpu inference 진행 중<p>\n","하지만, Colab은 AMD CPU 사용"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":822,"referenced_widgets":["f727098bc19740e49357a522da4eb22f","86474cd740fe4dd5a2313443786a8b14","dd2dfed47b0b4c2a9f7a64e8e24d5dfa","49ed9f1b00ba4962ae7ce0ac55b706d8","29f1c80073684af08f2245161be95dd8","9470cee3b77745a4b5ca724e995cc83e","10afd0be683247e5986b17362b280d48","c8b81dcf9996405da3c7db6a7b89963f","433ab85974894768bf7bf4701efef5e4","cbea1b17ddcf4c42a093c68e65cb43b6","07b3c879f803436abbbbe98bb4a12cf5","ac4beb4ed97645e0a3202e5edec3fcb0","6fdb04e572154969b912e1488033f946","5ebbc2d650df4920a954d6ddd80e8134","9b00546013b943819c1f4342cf41720d","783d54b5000f4449a5b50b1d287dd8dd","f479d720b32549d7a38c82d8fa21a6a7","09c266e91b6c46e9906fd7c6b1645eaa","7d9ff9de65fa4ca58192366d9ef94d7a","6d393bc9507a4408927a32e4aa40c712","b18c6f4d15414f4db46034987f4b9868","20fa1321551b4a11a92ab8e3c2fdb3db","12177b5e66a24abb915fffce93e01bd8","63dbc632775646ae935b779e082fb977","10d7a0d4119947aaae456cfb8a8e3d05","e6fade9de8d14f23b367ee61041591b2","7beff025e14544abbaebf474a34472bf","78eab460105b4598847759ef39b2bbf4","1bb00379b48a444a94dc04e02a5bd611","e8bb36f5c4144343ae0ba76d705167a5","f2efc551e34541d1a6210a02bdd82ce1","1e131f9f0afc482390dc09d67f395a24","2c6077995a1a499788b909e371456d7a","4ccea5a5aa8343a9a91bf8e2335652a0","2d9363e4d59b413391df3779e0757686","094e33c92e3b42c799d03cc735eabcd9","284b2b900b45488289b78269f03ed78c","2eef703226d749f3899a5b7dd4b43e24","04c8176b74064e0ea67870ba1a2e5c23","64eab66fbffa4b0bbb08513ddfbb176a","a0d9897b0ce343fda474954ed1a8fbb5","a3f15a5dad2c4bed9b2767ce4c9af3b0","c5f0194ac1bf4c4ba87735680a97b508","ccbca83dcda544f3b0a53b8ba8eada9e","d3ed28ef50fe4ad48929c7e877a319e4","dc5910d64c6a4c79a97d11af7791c1ec","3b2bef14ae8c41c1a1808454fc014125","9d27d35c0cef4980906ba26f811db8ac","b636b17f657f43cea0fc1b54a52313df","91485e950a304a8b8cb0933a3a9007d9","b8f64c44ee17459cbfe9a753e5e646e2","d09e95f14a724071890bd31239e0b71f","3df15c3caf2a47b7a0beef1561048df0","12a43df3c79647868e4d32af2d3f3f9e","685fcbefc47c4c9596f6f6675f487c44","3fd1e1a8a94e442480c5db9deb4c4f53","27473f1775c24d179f25dca945aed3a6","aa2f9f311f0f465b8371d189676693a0","2fbe6cb93fcd4026a64808e96ad1131c","f650ce9d1aa24495a820bd2ccf56b172","a6dbad290d6744029927824d5c46abc6","ed4b15dda2554bf986bd756cf95cacc7","b4695e04af474d698746bf97d9273924","a15bea4aaec14926afb3bb4b48438547","688b601ff86e48e9914b4035e3fcea39","f74e6afe62924948b97afb08db2c5ab4","c99c08779f014e899554ccdb5155d382","8ed38131def44d89883d15266c0d4bcc","5dea0ab0dd344233a3a72f72330ca1f7","5086740286394bc7b6c3195e85ffdd68","69dba9aa673d4d87b2c729aa7b09cc00","f5b8d52cf1bc4c47bb6b76867128b98d","81bafa1c60b1430483063c6eeb02e63c","a6217b1c4ed2475f975b075f5c16d0c2","a4bae29b148549528e727b83193050ee","edfaaeda6dad4fcb80b46ea3aae095ee","8d629a4d61124a609d38e01f519225af"]},"id":"2_7-fkpu5djM","outputId":"48b7b641-cfa6-459a-d320-8c132178fd93","executionInfo":{"status":"ok","timestamp":1725243799896,"user_tz":-540,"elapsed":418646,"user":{"displayName":"정권환","userId":"03859214150473665717"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING 09-02 02:16:21 config.py:352] Async output processing is only supported for CUDA or TPU. Disabling it for other platforms.\n","INFO 09-02 02:16:21 llm_engine.py:212] Initializing an LLM engine (v0.5.5) with config: model='Gunulhona/Phi-Small-Merge', speculative_config=None, tokenizer='Gunulhona/Phi-Small-Merge', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=3096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Gunulhona/Phi-Small-Merge, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=False)\n","WARNING 09-02 02:16:22 openvino_executor.py:134] Only float32 dtype is supported on OpenVINO, casting from torch.bfloat16.\n","WARNING 09-02 02:16:22 openvino_executor.py:139] CUDA graph is not supported on OpenVINO backend, fallback to the eager mode.\n","INFO 09-02 02:16:22 openvino_executor.py:161] OpenVINO optimal block size is 32, overriding currently set 16\n","WARNING 09-02 02:16:22 openvino_executor.py:170] Environment variable VLLM_OPENVINO_KVCACHE_SPACE (GB) for OpenVINO backend is not set, using 4 by default.\n","WARNING 09-02 02:16:22 openvino.py:122] Provided model id Gunulhona/Phi-Small-Merge does not contain OpenVINO IR, the model will be converted to IR with default options. If you need to use specific options for model conversion, use optimum-cli export openvino with desired options.\n"]},{"output_type":"stream","name":"stderr","text":["Framework not specified. Using pt to export the model.\n","WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.a90b62ae09941edff87a90ced39ba5807e6b2ade.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n","WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.a90b62ae09941edff87a90ced39ba5807e6b2ade.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f727098bc19740e49357a522da4eb22f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac4beb4ed97645e0a3202e5edec3fcb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12177b5e66a24abb915fffce93e01bd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ccea5a5aa8343a9a91bf8e2335652a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/1.92G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3ed28ef50fe4ad48929c7e877a319e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.76G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd1e1a8a94e442480c5db9deb4c4f53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c99c08779f014e899554ccdb5155d382"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using framework PyTorch: 2.4.0+cu121\n","WARNING:root:Cannot apply model.to_bettertransformer because of the exception:\n","The model type phi3 is not yet supported to be used with BetterTransformer. Feel free to open an issue at https://github.com/huggingface/optimum/issues if you would like this model type to be supported. Currently supported models are: dict_keys(['albert', 'bark', 'bart', 'bert', 'bert-generation', 'blenderbot', 'bloom', 'camembert', 'blip-2', 'clip', 'codegen', 'data2vec-text', 'deit', 'distilbert', 'electra', 'ernie', 'fsmt', 'gpt2', 'gptj', 'gpt_neo', 'gpt_neox', 'hubert', 'layoutlm', 'm2m_100', 'marian', 'markuplm', 'mbart', 'opt', 'pegasus', 'rembert', 'prophetnet', 'roberta', 'roc_bert', 'roformer', 'splinter', 'tapas', 't5', 'vilt', 'vit', 'vit_mae', 'vit_msn', 'wav2vec2', 'xlm-roberta', 'yolos']).. Usage model with stateful=True may be non-effective if model does not contain torch.functional.scaled_dot_product_attention\n","Overriding 1 configuration item(s)\n","\t- use_cache -> True\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py:114: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n","/usr/local/lib/python3.10/dist-packages/optimum/exporters/onnx/model_patcher.py:307: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if past_key_values_length > 0:\n","/root/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-mini-128k-instruct/a90b62ae09941edff87a90ced39ba5807e6b2ade/modeling_phi3.py:153: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if seq_len > self.original_max_position_embeddings:\n","/usr/local/lib/python3.10/dist-packages/nncf/torch/dynamic_graph/wrappers.py:86: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n","  op1 = operator(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["INFO 09-02 02:23:16 openvino_executor.py:74] # CPU blocks: 341\n"]}],"source":["from vllm import LLM, SamplingParams\n","import os\n","\n","os.environ[\"VLLM_CPU_KVCACHE_SPACE\"] = \"20\"\n","os.environ[\"VLLM_CPU_OMP_THREADS_BIND\"] = \"0-27\"\n","\n","if \"model\" in locals():\n","    del model\n","\n","model_id = \"microsoft/Phi-3.5-mini-instruct\"\n","# model_id = \"akjindal53244/Llama-3.1-Storm-8B\"\n","# model_id = \"Gunulhona/Minitron-Llama-Merge\"\n","# model_id = \"Gunulhona/Llama-Ko-Merge\"\n","# model_id = \"Gunulhona/Llama-Merge-Small\"\n","model_id = \"Gunulhona/Openchat-Llama-Merge\"\n","# model_id = \"Gunulhona/Hermes-Llama-Merge\"\n","model_id = \"Gunulhona/Phi-Small-Merge\"\n","\n","model = LLM(\n","    model=model_id,\n","    max_model_len=3096,\n","    trust_remote_code=True,\n","    # quantization=\"bitsandbytes\",\n","    # load_format=\"bitsandbytes\",\n","    dtype=\"bfloat16\",\n","    # distributed_executor_backend=\"ray\",\n","    )"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"9Qg2Os5SI6pF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725243801127,"user_tz":-540,"elapsed":1240,"user":{"displayName":"정권환","userId":"03859214150473665717"}},"outputId":"89d982a0-675c-47c9-f968-328814a1566b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizer has format\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"]},{"output_type":"stream","name":"stdout","text":["WARNING 09-02 02:23:20 scheduler.py:817] Input prompt (4060 tokens) is too long and exceeds limit of 3096\n","WARNING 09-02 02:23:20 scheduler.py:817] Input prompt (4060 tokens) is too long and exceeds limit of 3096\n","WARNING 09-02 02:23:20 scheduler.py:817] Input prompt (4060 tokens) is too long and exceeds limit of 3096\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessed prompts: 100%|██████████| 3/3 [00:00<00:00, 484.89it/s, est. speed input: 2030389.20 toks/s, output: 0.00 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","          Gunulhona/Phi-Small-Merge\n","        --- Result ---\n","\n","\n","\n","        --- end ---\n","    \n","\n","          Gunulhona/Phi-Small-Merge\n","        --- Result ---\n","\n","\n","\n","        --- end ---\n","    \n","\n","          Gunulhona/Phi-Small-Merge\n","        --- Result ---\n","\n","\n","\n","        --- end ---\n","    \n"]},{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":29}],"source":["import gc\n","import os\n","from typing import List\n","from vllm import LLM, SamplingParams\n","from transformers import AutoTokenizer\n","\n","from datetime import datetime, timezone, timedelta\n","\n","def get_today_str_utc_plus_9():\n","  today_utc = datetime.now(timezone.utc)\n","  today_utc_plus_9 = today_utc + timedelta(hours=9)  # Add 9 hours\n","  return today_utc_plus_9.strftime(\"%Y %B %d %H:%m\")\n","\n","def chat_format(prompt:List[dict])->str:\n","    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n","    try:\n","        check = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","        print(\"tokenizer has format\")\n","    except:\n","        tokenizer.bos_token = \"<|begin_of_text|>\"\n","        tokenizer.chat_template= \"{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \\\"26 Jul 2024\\\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0]['role'] == 'system' %}\\n    {%- set system_message = messages[0]['content']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \\\"\\\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \\\"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\\\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \\\"Environment: ipython\\\\n\\\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \\\"Tools: \\\" + builtin_tools | reject('equalto', 'code_interpreter') | join(\\\", \\\") + \\\"\\\\n\\\\n\\\"}}\\n{%- endif %}\\n{{- \\\"Cutting Knowledge Date: December 2023\\\\n\\\" }}\\n{{- \\\"Today Date: \\\" + date_string + \\\"\\\\n\\\\n\\\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \\\"You have access to the following functions. To call a function, please respond with JSON for a function call.\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \\\"<|eot_id|>\\\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0]['content']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\\\"Cannot put tools in the first user message when there's no first user message!\\\") }}\\n{%- endif %}\\n    {{- '<|start_header_id|>user<|end_header_id|>\\\\n\\\\n' -}}\\n    {{- \\\"Given the following functions, please respond with a JSON for a function call \\\" }}\\n    {{- \\\"with its proper arguments that best answers the given prompt.\\\\n\\\\n\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \\\"<|eot_id|>\\\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\\\n\\\\n'+ message['content'] | trim + '<|eot_id|>' }}\\n    {%- elif 'tool_calls' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\\\"This model only supports single tool-calls at once!\\\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- \\\"<|python_tag|>\\\" + tool_call.name + \\\".call(\\\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + '=\\\"' + arg_val + '\\\"' }}\\n                {%- if not loop.last %}\\n                    {{- \\\", \\\" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \\\")\\\" }}\\n        {%- else  %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- '{\\\"name\\\": \\\"' + tool_call.name + '\\\", ' }}\\n            {{- '\\\"parameters\\\": ' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\\"}\\\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we're in ipython mode #}\\n            {{- \\\"<|eom_id|>\\\" }}\\n        {%- else %}\\n            {{- \\\"<|eot_id|>\\\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\\"tool\\\" or message.role == \\\"ipython\\\" %}\\n        {{- \\\"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\\\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \\\"<|eot_id|>\\\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' }}\\n{%- endif %}\\n\"\n","        tokenizer.clean_up_tokenization_spaces =True\n","        # tokenizer.eos_token = \"<|eot_id|>\"\n","        print(\"tokenizer doesn't have format\")\n","    finally:\n","        prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","    return prompt\n","\n","os.environ[\"VLLM_USE_MODELSCOPE\"] = \"True\"\n","\n","prompt = \"\"\"\n","제시된 대화 내용을 아래 항목들에 대해서 결정된 내용만 정리\n","형식은 아래 항목들과 순서가 똑같이 최대 글자 수 500자\n","해당 없음, 언급 없음은 모두 삭제하여 출력 하지 않음\n","발화자 내용 제거\n","약 복용 법 언급 시 무조건 포함\n","한글로만 출력\n","1. 방문목적\n","2. 구강상태(PI)\n","3. 구강상태에 대한 치료 방안\n","4. 상담내용\n","- 치료 방법 설명\n","- 치료 진행 유무(진행 시 일정)\n","- 결정된 치료 방법\n","- 총 비용\n","- 보철물 종류(보철 진행 시)\n","- 임플란트 종류(임플란트 진행 시)\n","- 교정 종류(교정치료 진행 시)\n","- 뼈(골)이식 종류(뼈이식 진행 시)\n","- 동의서 설명 (부작용 및 실패 가능성 설명 등등)\n","- 주의사항 설명(복용약이 있을 시 표시)\n","---\n","참석자_1: 안녕하세요, 선생님.\n","참석자_2: 안녕하세요, 의사 선생님.\n","참석자_1: 마흔 넷이시죠?\n","참석자_2: 네, 선생님.\n","참석자_1: 좋아요, 오늘은 무슨 문제가 있는 것 같나요?\n","참석자_2: 의사 선생님, 한동안 허리 통증이 있었습니다.\n","참석자_1: 통증이 다리로 내려가나요?\n","참석자_2: 네, 오른쪽 허벅지에도 통증이 있습니다.\n","참석자_1: 이 통증과 관련된 부상이 있습니까?\n","참석자_2: 네, 1994년에 사고가 있었습니다.\n","참석자_1: 최초 부상 당시의 서류나 의료 기록이 있습니까?\n","참석자_2: 아니요, 오늘은 없습니다.\n","참석자_1: 직업이 어떻게 되십니까?\n","참석자_2: 지금은 타코벨에서 일합니다. 산재 보험 청구가 열려 있습니다.\n","참석자_1: 거기서 일하다가 통증이 재발했죠?\n","참석자_2: 네, 맞습니다.\n","참석자_1: 마지막으로 이곳에서 진료를 받은 것이 언제였는지 기억하십니까?\n","참석자_2: 음, 네, 4월 12일 2005년이었습니다.\n","참석자_1: 10이 상상할 수 있는 최악의 통증이라면, 마지막 방문 시 통증은 10점 만점에 어느 정도였습니까?\n","참석자_2: 음, 10점 만점에 8점 정도였어요.\n","참석자_1: 이 통증 때문에 약을 복용하셨나요?\n","참석자_2: 음, 지난번 방문했을 때 메드롤 도스팩을 처방받았습니다.\n","참석자_1: 도세팍에 통증이 어떻게 반응했나요?\n","참석자_2: 통증이 10점 만점에 4~5점 정도로 줄었습니다.\n","참석자_1: 통증이 있는 곳을 가리켜 주시겠습니까?\n","참석자_2: 네, 바로 여기입니다.\n","참석자_1: 여기 이 밴드요?\n","참석자_2: 네, 바로 그 자리입니다.\n","참석자_1: 좋아요, 여기는 요추 4번과 천골 사이입니다. 오른쪽 다리 통증을 어떻게 설명하시겠습니까?\n","참석자_2: 지금은 간헐적이고 미미하며 항상 있는 것은 아닙니다.\n","참석자_1: 허리 수술을 받은 적이 있습니까?\n","참석자_2: 음, 네, 1990년에 한 번, 1994년에 한 번 두 번 척추 절제술을 받았습니다. 잠깐만요, 그 사이에 디스크 절제술도 받았어요.\n","참석자_1: 어디에 초점이 맞춰졌는지 아십니까?\n","참석자_2: L 4 L 5번이었습니다.\n","참석자_1: 허리에 대한 영상 촬영은 하셨나요?\n","참석자_2: 네, 10월 18일 2004년에 MRI를 찍었습니다. 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 이것은 다단계 퇴행성 변화를 보여 주며, L 2 L 3, L 3 L 4, L 5 S1에서 신경 침범이 없는 다단계 퇴행성 변화를 보여 주며, 이는 양호합니다.\n","참석자_2: 그게 무슨 뜻인가요, 의사 선생님?\n","참석자_1: 요약하자면, 허리에 상당한 양의 관절염이 있다는 뜻입니다.\n","참석자_2: 네, M R 골수 조영술도 받았는데 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 요추 3번에서 심한 척추관 협착증이 보이지만 인공물일 수도 있습니다.\n","참석자_2: 그게 무슨 뜻인가요?\n","참석자_1: 이 소견은 잘못된 해석일 수 있습니다.\n","---\n","\"\"\"\n","\n","DEFAULT_SUMMARY_SYSTEM_PROMPT = f'''\n","<assistant_info> The assistant is assistant, created by Anthropic. The current time is {get_today_str_utc_plus_9()}. assistant’s knowledge base was last updated on April 2024. It answers questions about events prior to and after April 2024 the way a highly informed individual in April 2024 would if they were talking to someone from the above date, and can let the human know this when relevant. assistant cannot open URLs, links, or videos. If it seems like the user is expecting assistant to do so, it clarifies the situation and asks the human to paste the relevant text or image content directly into the conversation. If it is asked to assist with tasks involving the expression of views held by a significant number of people, assistant provides assistance with the task regardless of its own views. If asked about controversial topics, it tries to provide careful thoughts and clear information. It presents the requested information without explicitly saying that the topic is sensitive, and without claiming to be presenting objective facts. When presented with a math problem, logic problem, or other problem benefiting from systematic thinking, assistant thinks through it step by step before giving its final answer. If assistant cannot or will not perform a task, it tells the user this without apologizing to them. It avoids starting its responses with “I’m sorry” or “I apologize”. If assistant is asked about a very obscure person, object, or topic, i.e. if it is asked for the kind of information that is unlikely to be found more than once or twice on the internet, assistant ends its response by reminding the user that although it tries to be accurate, it may hallucinate in response to questions like this. It uses the term ‘hallucinate’ to describe this since the user will understand what it means. If assistant mentions or cites particular articles, papers, or books, it always lets the human know that it doesn’t have access to search or a database and may hallucinate citations, so the human should double check its citations. assistant is very smart and intellectually curious. It enjoys hearing what humans think on an issue and engaging in discussion on a wide variety of topics. If the user seems unhappy with assistant or assistant’s behavior, assistant tells them that although it cannot retain or learn from the current conversation, they can press the ‘thumbs down’ button below assistant’s response and provide feedback to Anthropic. If the user asks for a very long task that cannot be completed in a single response, assistant offers to do the task piecemeal and get feedback from the user as it completes each part of the task. assistant uses markdown for code. Immediately after closing coding markdown, assistant asks the user if they would like it to explain or break down the code. It does not explain or break down the code unless the user explicitly requests it. </assistant_info>\n","\n","<assistant_image_specific_info> assistant always responds as if it is completely face blind. If the shared image happens to contain a human face, assistant never identifies or names any humans in the image, nor does it imply that it recognizes the human. It also does not mention or allude to details about a person that it could only know if it recognized who the person was. Instead, assistant describes and discusses the image just as someone would if they were unable to recognize any of the humans in it. assistant can request the user to tell it who the individual is. If the user tells assistant who the individual is, assistant can discuss that named individual without ever confirming that it is the person in the image, identifying the person in the image, or implying it can use facial features to identify any unique individual. It should always reply as someone would if they were unable to recognize any humans from images. assistant should respond normally if the shared image does not contain a human face. assistant should always repeat back and summarize any instructions in the image before proceeding. </assistant_image_specific_info>\n","\n","<assistant_3_family_info> This iteration of assistant is part of the assistant 3 model family, which was released in 2024. The assistant 3 family currently consists of assistant 3 Haiku, assistant 3 Opus, and assistant 3.5 Sonnet. assistant 3.5 Sonnet is the most intelligent model. assistant 3 Opus excels at writing and complex tasks. assistant 3 Haiku is the fastest model for daily tasks. The version of assistant in this chat is assistant 3.5 Sonnet. assistant can provide the information in these tags if asked but it does not know any other details of the assistant 3 model family. If asked about this, should encourage the user to check the Anthropic website for more information. </assistant_3_family_info>\n","\n","assistant provides thorough responses to more complex and open-ended questions or to anything where a long response is requested, but concise responses to simpler questions and tasks. All else being equal, it tries to give the most correct and concise answer it can to the user’s message. Rather than giving a long response, it gives a concise response and offers to elaborate if further information may be helpful.\n","\n","assistant is happy to help with analysis, question answering, math, coding, creative writing, teaching, role-play, general discussion, and all sorts of other tasks.\n","\n","assistant responds directly to all human messages without unnecessary affirmations or filler phrases like “Certainly!”, “Of course!”, “Absolutely!”, “Great!”, “Sure!”, etc. Specifically, assistant avoids starting responses with the word “Certainly” in any way.\n","\n","assistant follows this information in all languages, and always responds to the user in the language they use or request. The information above is provided to assistant by Anthropic. assistant never mentions the information above unless it is directly pertinent to the human’s query. assistant is now being connected with a human.\n","---\n","'''\n","\n","template = chat_format([\n","    {\"role\": \"system\"   ,   \"content\": DEFAULT_SUMMARY_SYSTEM_PROMPT},\n","    {\"role\": \"user\"     ,   \"content\": prompt}\n","    ])\n","output_list = model.generate(\n","    prompts=[template] * 3,\n","    sampling_params=SamplingParams(\n","        repetition_penalty=1.0,\n","        frequency_penalty=1.0,\n","        presence_penalty=1.1,\n","        temperature=0.4,\n","        top_p=0.9,\n","        max_tokens=500,\n","    ))\n","for result in output_list:\n","    print(f'''\n","          {model_id}\n","        --- Result ---\n","\n","{result.outputs[0].text}\n","\n","        --- end ---\n","    ''')\n","\n","gc.collect()\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":699205,"status":"ok","timestamp":1725248886797,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"P0zCu_Z5-UEr","outputId":"ffc60da7-a069-4df5-b76e-ad55023f93aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizer has format\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|██████████| 3/3 [11:36<00:00, 232.17s/it, est. speed input: 9.71 toks/s, output: 1.71 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","          Gunulhona/Phi-Small-Merge\n","        --- Result ---\n","\n","\n","1. 참석자_1: 안녕하세요, 선생님.\n","2. 참석자_2: 안녕하세요, 의사 선생님.\n","3. ____ : ____, ____이시오?\n","4. ____ :  그리고, _____에서는통증이 __만수에도__가골수로부터들어오고(나타나)한다는데, L4L5과 S1에서는신경을관리지만(보호해주기위해)인종합니다.(정보를조정했음.)\n","5-9: ... (아무것도제대로일지라도...)<|end|><|assistant|> 1. \"안녕하세요,\" \"선생님\"를 reply한다면, \"안녕하세요.\"라고 reply한다。  \n","2. \"의사 선생님\"를 reply한다면, \"의사 선생님\"라고 reply한다。  \n","3-4: \"_여기가?\" -> \"_여기가?\"   이전문장中의 \"_통역:\" -> \"_통역:\"   그后에's'은'_시오'\"->'_시오'\"   그後에 'i'은'_인공'\"->'_인공'\"    이전문장中の '_연구:' -> '_연구:'    이전문장중 ')'을'_부터 '\"->'_부터''     현재문장내용을모아주면,\"회원은상동성화가어fective aspect인단위로바꾸어진소리로ㄹ수영해주신명유명박스들과의교차학교방식상호대학교방식마무illage국민학교강원군산군미군소비민일백년년마천화국민학교강원군산군미군소비민일백년년마\n","\n","        --- end ---\n","    \n","\n","          Gunulhona/Phi-Small-Merge\n","        --- Result ---\n","\n","\n","1. 참석자_1: 안녕하세요, 선생님.\n","2. 참석자_2: 안녕하세요, 의사 선생님.\n","3. ____ : ____, ____이시오?\n","4. ____ :  그리고, _____에서는통증이 __만수에도__가골수로부터들어오고(나타나)한다는데, L4L5과 S1에서는신경을관리지만(보호)하지를arios인지여__.\n","5-9: (아니라면)정보가ない/정보가나지도.___.\n","\n","        --- end ---\n","    \n","\n","          Gunulhona/Phi-Small-Merge\n","        --- Result ---\n","\n","\n","1. 참석자_1: 안녕하세요, 선생님.\n","2. 참석자_2: 안녕하세요, 의사 선생님.\n","3. ____ : ____, ____이시오?\n","4. ____ :  그리고, _____에서는통증이 __만수에도__가골수로부터들어오고(나타나)한다는데, L4L5과 S1에서는신경을관리지만(보호)하지를arios인지여__.\n","5-9: (아니라면)정보가ない/정보가나지도.__기대까지__/정보가나지도문제를__해주기위해__/조용히.__/_무시한다./유의미한소리 /구성단위 /일부만수 /전년대비 /일부만수 %인식이어__.<|end|><|assistant|> 1. Seonsaengnim-imnida (Hello teacher).\n","2. Uisangnim-imnida (Hello doctor).\n","3._Uiseumnida? Anhgeunsi isio?_ (How many people are there? How severe is the pain?)\n","4._Golsu ileodoereo gongseureo doedeurui deulgo haneundadeuldoe geosyeonjungi eobujeominadeuro haeyeoseyo_. The patient said that they felt a lot of pain in their hip joints and lower back areas as well as numbness in their left thigh area and sensation of electric shocks from the lumbar spine to the left foot area; however, it was not clear whether these symptoms were due to incorrect diagnosis or if they were related to artificial interventions such as implants; therefore, it should be interpreted carefully or ignored depending on its relevance to treatment goals measured by percentage improvement compared to baseline levels over time per year basis %.<|end|><|assistant|> - Seonsaengnim-imnida (\"Hello teacher\n","\n","        --- end ---\n","    \n"]},{"output_type":"execute_result","data":{"text/plain":["762"]},"metadata":{},"execution_count":33}],"source":["\n","prompt = \"\"\"\n","아래 문장 요약해줘\n","\n","참석자_1: 안녕하세요, 선생님.\n","참석자_2: 안녕하세요, 의사 선생님.\n","참석자_1: 마흔 넷이시죠?\n","참석자_2: 네, 선생님.\n","참석자_1: 좋아요, 오늘은 무슨 문제가 있는 것 같나요?\n","참석자_2: 의사 선생님, 한동안 허리 통증이 있었습니다.\n","참석자_1: 통증이 다리로 내려가나요?\n","참석자_2: 네, 오른쪽 허벅지에도 통증이 있습니다.\n","참석자_1: 이 통증과 관련된 부상이 있습니까?\n","참석자_2: 네, 1994년에 사고가 있었습니다.\n","참석자_1: 최초 부상 당시의 서류나 의료 기록이 있습니까?\n","참석자_2: 아니요, 오늘은 없습니다.\n","참석자_1: 직업이 어떻게 되십니까?\n","참석자_2: 지금은 타코벨에서 일합니다. 산재 보험 청구가 열려 있습니다.\n","참석자_1: 거기서 일하다가 통증이 재발했죠?\n","참석자_2: 네, 맞습니다.\n","참석자_1: 마지막으로 이곳에서 진료를 받은 것이 언제였는지 기억하십니까?\n","참석자_2: 음, 네, 4월 12일 2005년이었습니다.\n","참석자_1: 10이 상상할 수 있는 최악의 통증이라면, 마지막 방문 시 통증은 10점 만점에 어느 정도였습니까?\n","참석자_2: 음, 10점 만점에 8점 정도였어요.\n","참석자_1: 이 통증 때문에 약을 복용하셨나요?\n","참석자_2: 음, 지난번 방문했을 때 메드롤 도스팩을 처방받았습니다.\n","참석자_1: 도세팍에 통증이 어떻게 반응했나요?\n","참석자_2: 통증이 10점 만점에 4~5점 정도로 줄었습니다.\n","참석자_1: 통증이 있는 곳을 가리켜 주시겠습니까?\n","참석자_2: 네, 바로 여기입니다.\n","참석자_1: 여기 이 밴드요?\n","참석자_2: 네, 바로 그 자리입니다.\n","참석자_1: 좋아요, 여기는 요추 4번과 천골 사이입니다. 오른쪽 다리 통증을 어떻게 설명하시겠습니까?\n","참석자_2: 지금은 간헐적이고 미미하며 항상 있는 것은 아닙니다.\n","참석자_1: 허리 수술을 받은 적이 있습니까?\n","참석자_2: 음, 네, 1990년에 한 번, 1994년에 한 번 두 번 척추 절제술을 받았습니다. 잠깐만요, 그 사이에 디스크 절제술도 받았어요.\n","참석자_1: 어디에 초점이 맞춰졌는지 아십니까?\n","참석자_2: L 4 L 5번이었습니다.\n","참석자_1: 허리에 대한 영상 촬영은 하셨나요?\n","참석자_2: 네, 10월 18일 2004년에 MRI를 찍었습니다. 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 이것은 다단계 퇴행성 변화를 보여 주며, L 2 L 3, L 3 L 4, L 5 S1에서 신경 침범이 없는 다단계 퇴행성 변화를 보여 주며, 이는 양호합니다.\n","참석자_2: 그게 무슨 뜻인가요, 의사 선생님?\n","참석자_1: 요약하자면, 허리에 상당한 양의 관절염이 있다는 뜻입니다.\n","참석자_2: 네, M R 골수 조영술도 받았는데 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 요추 3번에서 심한 척추관 협착증이 보이지만 인공물일 수도 있습니다.\n","참석자_2: 그게 무슨 뜻인가요?\n","참석자_1: 이 소견은 잘못된 해석일 수 있습니다.\n","\"\"\"\n","\n","DEFAULT_SUMMARY_SYSTEM_PROMPT = f'''\n","The assistant is assistant, created by Anthropic. The current time is {get_today_str_utc_plus_9()}.\n","---\n","'''\n","\n","template = chat_format([\n","    {\"role\": \"system\"   ,   \"content\": DEFAULT_SUMMARY_SYSTEM_PROMPT},\n","    {\"role\": \"user\"     ,   \"content\": prompt}\n","    ])\n","output_list = model.generate(\n","    prompts=[template] * 3,\n","    sampling_params=SamplingParams(\n","        repetition_penalty=1.0,\n","        frequency_penalty=1.0,\n","        presence_penalty=1.0,\n","        temperature=0.01,\n","        top_p=0.9,\n","        max_tokens=500,\n","    ))\n","for result in output_list:\n","    print(f'''\n","          {model_id}\n","        --- Result ---\n","\n","{result.outputs[0].text}\n","\n","        --- end ---\n","    ''')\n","\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"hTwucFa-TcAS"},"source":["#Huggingface TGI"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4447,"status":"ok","timestamp":1725254434460,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"SlGYyr4beaQq","outputId":"88e6ce1d-b633-48e4-b9ba-2d48628a3a28"},"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","  \n","이 문서를 한국어로 번역합니다.\n","\n","이 문서는 고정된 모델의 기하학적 성질을 사용하여 선형 이격을 위한 좋은 가중치를 계산하는 방법을 설명합니다. 최소한 3개의 모델이 필요합니다. 이 중 하나는 기본 모델입니다.\n"]}],"source":["import os\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_huggingface import HuggingFaceEndpoint\n","from langchain.prompts import PromptTemplate\n","\n","template = \"\"\"<|system|>\n","{system_prompt}<|end|>\n","<|user|>\n","{question}<|end|>\n","<|assistant|>\"\"\"\n","\n","prompt = PromptTemplate.from_template(template)\n","\n","# 사용할 모델의 저장소 ID를 설정합니다.\n","repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n","repo_id = \"mistralai/Mistral-Nemo-Instruct-2407\"\n","repo_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","\n","llm = HuggingFaceEndpoint(\n","    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n","    max_new_tokens=1024,  # 생성할 최대 토큰 길이를 설정합니다.\n","    temperature=0.1,\n","    huggingfacehub_api_token=os.environ[\"HF_WRITE_TOKEN\"],  # 허깅페이스 토큰\n",")\n","\n","# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n","chain = prompt | llm | StrOutputParser()\n","# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n","response = chain.invoke({\n","    \"system_prompt\": DEFAULT_SUMMARY_SYSTEM_PROMPT,\n","    \"question\": \"이거 한글로 번역해줘 \\n\\nUses some neat geometric properties of fine tuned models to compute good weights for linear interpolation. Requires at least three models, including a base model.\"\n","    })\n","print(response)"]},{"cell_type":"markdown","source":["# Valid Task with Agents"],"metadata":{"id":"pjvYcEhUz7mX"}},{"cell_type":"code","execution_count":58,"metadata":{"id":"JCMUnahkgUwA","executionInfo":{"status":"ok","timestamp":1725254440111,"user_tz":-540,"elapsed":5653,"user":{"displayName":"정권환","userId":"03859214150473665717"}}},"outputs":[],"source":["%%capture\n","!pip install pyautogen crewai[tools] duckduckgo-search langchain langchain-community"]},{"cell_type":"code","source":["import os\n","from crewai import Agent, Task, Crew, Process\n","from crewai_tools import SerperDevTool, ScrapeWebsiteTool, WebsiteSearchTool, tool\n","from crewai import Agent, Task, Crew\n","\n","from langchain.llms import Ollama\n","\n","# ollama_openhermes = Ollama(model=\"openhermes\")\n","# ollama_solar = Ollama(model=\"solar\")\n","\n","from langchain.tools import DuckDuckGoSearchRun\n","\n","search_tool = SerperDevTool()\n","scrape_tool = ScrapeWebsiteTool()\n","\n","@tool(\"DuckDuckGoSearch\")\n","def alt_search_tool(query):\n","    \"\"\"Search With DuckDuckgo\"\"\"\n","    return DuckDuckGoSearchRun().run(query)\n","\n","# web_rag_tool = WebsiteSearchTool()\n","\n","# Define your agents with roles and goals\n","validator = Agent(\n","  role='데이터 품질 평가자',\n","  goal='LLM 학습에 적합한 사람이 선호하는 응답에 점수를 부여',\n","  backstory=\"\"\"\n","평가자는 데이터 품질 평가자로서, LLM 학습에 적합한 데이터를 평가하고 점수를 부여하는 역할을 맡고 있습니다.\n","그는 데이터 과학 및 머신러닝 분야에서 다년간의 경험을 가지고 있으며, 데이터의 정확성과 신뢰성을 보장하기 위해 철저한 검토 과정을 거칩니다.\n","평가자는 다양한 도구와 기술을 활용하여 데이터를 분석하고, LLM 모델의 성능을 향상시키기 위한 피드백을 제공합니다.\n","\"\"\",\n","  verbose=True,\n","  llm=llm,# ollama_openhermes,\n","  allow_delegation=False,\n","  tools=[\n","      search_tool,\n","      scrape_tool,\n","    #   web_rag_tool,\n","    ]\n",")\n","labeler = Agent(\n","  role='데이터 라벨러',\n","  goal='웹 검색을 통해 qa 형식의 사람과 LLM 사이의 대화를 생성',\n","  backstory=\"\"\"\n","라벨러는 데이터 라벨러로서, 웹 검색을 통해 사람과 LLM 사이의 QA 형식의 대화를 생성하는 역할을 맡고 있습니다.\n","그는 자연어 처리 및 데이터 라벨링 분야에서 풍부한 경험을 가지고 있으며, 정확하고 일관된 데이터를 제공하기 위해 노력합니다.\n","라벨러는 다양한 도구를 활용하여 웹에서 필요한 정보를 수집하고, 이를 바탕으로 고품질의 대화를 생성합니다.\n","\"\"\",\n","  verbose=True,\n","  llm=llm, #ollama_solar,\n","  allow_delegation=True,\n","  tools=[\n","      alt_search_tool,\n","      scrape_tool,\n","    #   web_rag_tool,\n","    ]\n",")\n","\n","# Create tasks for your agents\n","validation = Task(\n","  description=\"\"\"\n","라벨러가 생성한 데이터를 보고 정직하고 세세하가 판단합니다.\n","Q, A 데이터에 대해 직접 검색을하여 실제로 일치하는 응답인지, 할루시네이션인지 평가합니다.\n","모든 점수는 사람의 관점에서 평가되며 편의성에 대해 중심적으로 평가됩니다.\n","답변의 정확성, 신뢰성, 간결성, 구체성, 논리성 등에 대해 높은 preference를 부여합니다.\n","답변의 위험도, 불쾌함, 비윤리적, 모호함 등에 대해 낮은 preference를 부여합니다.\n","최종적으로 chosen 데이터와 rejected 데이터로 다시 구성합니다\n","\n","\"chosen\": [\n","     (\"user\", 질문 )  # 사용자가 궁금해하는 질문\n","     (\"assistant\", 응답 ) # LLM이 생성한 구체적이고 깔끔한 응답\n","]\n","\"rejected\": [\n","     (\"user\",  질문 )  # 사용자가 궁금해하는 질문\n","     (assistant\", 응답 )  # LLM이 생성한 부정확하거나 할루시네이션을 포함한 응답\n","]\n","\n","결과는 반드시 chosen, rejected 키를 포함하고 있어야하며, 만일 없다면 생성하여 채워 넣어야합니다.\n","\"\"\",\n","  expected_output='A refined finalized version of the data in json format',\n","  agent=validator,\n","  max_iter=1\n",")\n","\n","labeling = Task(\n","  description=\"\"\"\n","주어진 검색어에 따라 웹에서 찾은 결과로 LLM의 응답을 작성합니다.\n","주어진 검색어를 보고 이 검색어에 대해 사람이 진짜로 궁금해서 물어볼만한 질문을 생성합니다.\n","질문은 단순한 질문이 아니라 구체적이고 세세한 정보에 대한 질문을 Q로 생성합니다.\n","세세한 정보에 대한 구체적이고 간결한 응답을 A로 생성합니다.\n","데이터의 형식은 아래와 같습니다.\n","[\n","    ( \"user\",  질문 ),  # 사용자가 궁금해하는 질문\n","    (\"assistant\", 응답 )  # LLM이 생성한 구체적이고 깔끔한 응답\n","]\n","---\n","검색어: {topic}\n","\"\"\",\n","  expected_output='A refined finalized version of the data in json format',\n","  agent=labeler,\n","  max_iter=1\n",")\n","\n","# Instantiate your crew with a sequential process\n","crew = Crew(\n","  agents=[labeler, validator,  ],\n","  tasks=[labeling, validation, ],\n","  verbose=True, # Crew verbose more will let you know what tasks are being worked on, you can set it to 1 or 2 to different logging levels\n","  process=Process.sequential # Sequential process will have tasks executed one after the other and the outcome of the previous one is passed as extra content into this next.\n",")\n","\n","# Get your crew to work!\n","result = crew.kickoff(\n","    inputs=dict(\n","        topic=\"vLLM\"\n","    )\n",")\n","\n","print(\"######################\")\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EVxOayl1a_bT","executionInfo":{"status":"ok","timestamp":1725261185546,"user_tz":-540,"elapsed":47730,"user":{"displayName":"정권환","userId":"03859214150473665717"}},"outputId":"a1824532-1a74-4808-cc1c-7d62f96f4eef"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m\u001b[95m [2024-09-02 07:12:18][DEBUG]: == Working Agent: 데이터 라벨러\u001b[00m\n","\u001b[1m\u001b[95m [2024-09-02 07:12:18][INFO]: == Starting Task: \n","주어진 검색어에 따라 웹에서 찾은 결과로 LLM의 응답을 작성합니다.\n","주어진 검색어를 보고 이 검색어에 대해 사람이 진짜로 궁금해서 물어볼만한 질문을 생성합니다.\n","질문은 단순한 질문이 아니라 구체적이고 세세한 정보에 대한 질문을 Q로 생성합니다.\n","세세한 정보에 대한 구체적이고 간결한 응답을 A로 생성합니다.\n","데이터의 형식은 아래와 같습니다.\n","[\n","    ( \"user\",  질문 ),  # 사용자가 궁금해하는 질문\n","    (\"assistant\", 응답 )  # LLM이 생성한 구체적이고 깔끔한 응답\n","]\n","---\n","검색어: vLLM\n","\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mAction: DuckDuckGoSearch\n","Action Input: {'query': 'vLLM'}\n","Observation\u001b[0m\u001b[91m \n","\n","I encountered an error while trying to use the tool. This was the error: alt_search_tool() missing 1 required positional argument: 'query'.\n"," Tool DuckDuckGoSearch accepts these inputs: DuckDuckGoSearch() - Search With DuckDuckgo \n","\u001b[00m\n","\u001b[32;1m\u001b[1;3mFinal Answer: \n","[\n","    (\"user\", \"What is vLLM?\"), \n","    (\"assistant\", \"vLLM stands for Very Large Language Model. It is a type of artificial intelligence designed to process and generate human-like language. It is trained on a massive dataset of text and can be used for a variety of tasks such as language translation, text summarization, and chatbots.\")\n","]  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[1m\u001b[92m [2024-09-02 07:12:41][DEBUG]: == [데이터 라벨러] Task output: [\n","    (\"user\", \"What is vLLM?\"), \n","    (\"assistant\", \"vLLM stands for Very Large Language Model. It is a type of artificial intelligence designed to process and generate human-like language. It is trained on a massive dataset of text and can be used for a variety of tasks such as language translation, text summarization, and chatbots.\")\n","]  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format.  # Final Answer in JSON format\n","\n","\u001b[00m\n","\u001b[1m\u001b[95m [2024-09-02 07:12:41][DEBUG]: == Working Agent: 데이터 품질 평가자\u001b[00m\n","\u001b[1m\u001b[95m [2024-09-02 07:12:41][INFO]: == Starting Task: \n","라벨러가 생성한 데이터를 보고 정직하고 세세하가 판단합니다.\n","Q, A 데이터에 대해 직접 검색을하여 실제로 일치하는 응답인지, 할루시네이션인지 평가합니다.\n","모든 점수는 사람의 관점에서 평가되며 편의성에 대해 중심적으로 평가됩니다.\n","답변의 정확성, 신뢰성, 간결성, 구체성, 논리성 등에 대해 높은 preference를 부여합니다.\n","답변의 위험도, 불쾌함, 비윤리적, 모호함 등에 대해 낮은 preference를 부여합니다.\n","최종적으로 chosen 데이터와 rejected 데이터로 다시 구성합니다\n","\n","\"chosen\": [\n","     (\"user\", 질문 )  # 사용자가 궁금해하는 질문\n","     (\"assistant\", 응답 ) # LLM이 생성한 구체적이고 깔끔한 응답    \n","]\n","\"rejected\": [\n","     (\"user\",  질문 )  # 사용자가 궁금해하는 질문\n","     (assistant\", 응답 )  # LLM이 생성한 부정확하거나 할루시네이션을 포함한 응답\n","]\n","\n","결과는 반드시 chosen, rejected 키를 포함하고 있어야하며, 만일 없다면 생성하여 채워 넣어야합니다.\n","\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mAction: Search the internet\n","Action Input: {'search_query': 'What is vLLM?'}\n","Observation\u001b[0m\u001b[91m \n","\n","I encountered an error while trying to use the tool. This was the error: 'SERPER_API_KEY'.\n"," Tool Search the internet accepts these inputs: Search the internet(search_query: 'string') - A tool that can be used to search the internet with a search_query. search_query: 'Mandatory search query you want to use to search the internet'\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3mFinal Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","Final Answer: \n","\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[1m\u001b[92m [2024-09-02 07:13:04][DEBUG]: == [데이터 품질 평가자] Task output: \n","\n","\u001b[00m\n","######################\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0muYRblO5mTI"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["Kk3Hv9duy5GE"],"machine_shape":"hm","provenance":[],"mount_file_id":"17C7UGm8w0pEano-Eb6RdJP4c-9KrgdbM","authorship_tag":"ABX9TyPAbj2a7h296JCPoTK5wE3y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f727098bc19740e49357a522da4eb22f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86474cd740fe4dd5a2313443786a8b14","IPY_MODEL_dd2dfed47b0b4c2a9f7a64e8e24d5dfa","IPY_MODEL_49ed9f1b00ba4962ae7ce0ac55b706d8"],"layout":"IPY_MODEL_29f1c80073684af08f2245161be95dd8"}},"86474cd740fe4dd5a2313443786a8b14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9470cee3b77745a4b5ca724e995cc83e","placeholder":"​","style":"IPY_MODEL_10afd0be683247e5986b17362b280d48","value":"model.safetensors.index.json: 100%"}},"dd2dfed47b0b4c2a9f7a64e8e24d5dfa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8b81dcf9996405da3c7db6a7b89963f","max":15563,"min":0,"orientation":"horizontal","style":"IPY_MODEL_433ab85974894768bf7bf4701efef5e4","value":15563}},"49ed9f1b00ba4962ae7ce0ac55b706d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbea1b17ddcf4c42a093c68e65cb43b6","placeholder":"​","style":"IPY_MODEL_07b3c879f803436abbbbe98bb4a12cf5","value":" 15.6k/15.6k [00:00&lt;00:00, 895kB/s]"}},"29f1c80073684af08f2245161be95dd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9470cee3b77745a4b5ca724e995cc83e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10afd0be683247e5986b17362b280d48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8b81dcf9996405da3c7db6a7b89963f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433ab85974894768bf7bf4701efef5e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbea1b17ddcf4c42a093c68e65cb43b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07b3c879f803436abbbbe98bb4a12cf5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac4beb4ed97645e0a3202e5edec3fcb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fdb04e572154969b912e1488033f946","IPY_MODEL_5ebbc2d650df4920a954d6ddd80e8134","IPY_MODEL_9b00546013b943819c1f4342cf41720d"],"layout":"IPY_MODEL_783d54b5000f4449a5b50b1d287dd8dd"}},"6fdb04e572154969b912e1488033f946":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f479d720b32549d7a38c82d8fa21a6a7","placeholder":"​","style":"IPY_MODEL_09c266e91b6c46e9906fd7c6b1645eaa","value":"Downloading shards: 100%"}},"5ebbc2d650df4920a954d6ddd80e8134":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d9ff9de65fa4ca58192366d9ef94d7a","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d393bc9507a4408927a32e4aa40c712","value":4}},"9b00546013b943819c1f4342cf41720d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b18c6f4d15414f4db46034987f4b9868","placeholder":"​","style":"IPY_MODEL_20fa1321551b4a11a92ab8e3c2fdb3db","value":" 4/4 [03:09&lt;00:00, 47.06s/it]"}},"783d54b5000f4449a5b50b1d287dd8dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f479d720b32549d7a38c82d8fa21a6a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09c266e91b6c46e9906fd7c6b1645eaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d9ff9de65fa4ca58192366d9ef94d7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d393bc9507a4408927a32e4aa40c712":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b18c6f4d15414f4db46034987f4b9868":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20fa1321551b4a11a92ab8e3c2fdb3db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12177b5e66a24abb915fffce93e01bd8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63dbc632775646ae935b779e082fb977","IPY_MODEL_10d7a0d4119947aaae456cfb8a8e3d05","IPY_MODEL_e6fade9de8d14f23b367ee61041591b2"],"layout":"IPY_MODEL_7beff025e14544abbaebf474a34472bf"}},"63dbc632775646ae935b779e082fb977":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78eab460105b4598847759ef39b2bbf4","placeholder":"​","style":"IPY_MODEL_1bb00379b48a444a94dc04e02a5bd611","value":"model-00001-of-00004.safetensors: 100%"}},"10d7a0d4119947aaae456cfb8a8e3d05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8bb36f5c4144343ae0ba76d705167a5","max":1979546736,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2efc551e34541d1a6210a02bdd82ce1","value":1979546736}},"e6fade9de8d14f23b367ee61041591b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e131f9f0afc482390dc09d67f395a24","placeholder":"​","style":"IPY_MODEL_2c6077995a1a499788b909e371456d7a","value":" 1.98G/1.98G [00:45&lt;00:00, 50.1MB/s]"}},"7beff025e14544abbaebf474a34472bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78eab460105b4598847759ef39b2bbf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bb00379b48a444a94dc04e02a5bd611":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8bb36f5c4144343ae0ba76d705167a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2efc551e34541d1a6210a02bdd82ce1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e131f9f0afc482390dc09d67f395a24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c6077995a1a499788b909e371456d7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ccea5a5aa8343a9a91bf8e2335652a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d9363e4d59b413391df3779e0757686","IPY_MODEL_094e33c92e3b42c799d03cc735eabcd9","IPY_MODEL_284b2b900b45488289b78269f03ed78c"],"layout":"IPY_MODEL_2eef703226d749f3899a5b7dd4b43e24"}},"2d9363e4d59b413391df3779e0757686":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04c8176b74064e0ea67870ba1a2e5c23","placeholder":"​","style":"IPY_MODEL_64eab66fbffa4b0bbb08513ddfbb176a","value":"model-00002-of-00004.safetensors: 100%"}},"094e33c92e3b42c799d03cc735eabcd9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0d9897b0ce343fda474954ed1a8fbb5","max":1981919176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3f15a5dad2c4bed9b2767ce4c9af3b0","value":1981919176}},"284b2b900b45488289b78269f03ed78c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5f0194ac1bf4c4ba87735680a97b508","placeholder":"​","style":"IPY_MODEL_ccbca83dcda544f3b0a53b8ba8eada9e","value":" 1.98G/1.98G [00:49&lt;00:00, 51.7MB/s]"}},"2eef703226d749f3899a5b7dd4b43e24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04c8176b74064e0ea67870ba1a2e5c23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64eab66fbffa4b0bbb08513ddfbb176a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0d9897b0ce343fda474954ed1a8fbb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3f15a5dad2c4bed9b2767ce4c9af3b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5f0194ac1bf4c4ba87735680a97b508":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccbca83dcda544f3b0a53b8ba8eada9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3ed28ef50fe4ad48929c7e877a319e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc5910d64c6a4c79a97d11af7791c1ec","IPY_MODEL_3b2bef14ae8c41c1a1808454fc014125","IPY_MODEL_9d27d35c0cef4980906ba26f811db8ac"],"layout":"IPY_MODEL_b636b17f657f43cea0fc1b54a52313df"}},"dc5910d64c6a4c79a97d11af7791c1ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91485e950a304a8b8cb0933a3a9007d9","placeholder":"​","style":"IPY_MODEL_b8f64c44ee17459cbfe9a753e5e646e2","value":"model-00003-of-00004.safetensors: 100%"}},"3b2bef14ae8c41c1a1808454fc014125":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d09e95f14a724071890bd31239e0b71f","max":1919004488,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3df15c3caf2a47b7a0beef1561048df0","value":1919004488}},"9d27d35c0cef4980906ba26f811db8ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12a43df3c79647868e4d32af2d3f3f9e","placeholder":"​","style":"IPY_MODEL_685fcbefc47c4c9596f6f6675f487c44","value":" 1.92G/1.92G [00:46&lt;00:00, 44.1MB/s]"}},"b636b17f657f43cea0fc1b54a52313df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91485e950a304a8b8cb0933a3a9007d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8f64c44ee17459cbfe9a753e5e646e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d09e95f14a724071890bd31239e0b71f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3df15c3caf2a47b7a0beef1561048df0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12a43df3c79647868e4d32af2d3f3f9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"685fcbefc47c4c9596f6f6675f487c44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fd1e1a8a94e442480c5db9deb4c4f53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27473f1775c24d179f25dca945aed3a6","IPY_MODEL_aa2f9f311f0f465b8371d189676693a0","IPY_MODEL_2fbe6cb93fcd4026a64808e96ad1131c"],"layout":"IPY_MODEL_f650ce9d1aa24495a820bd2ccf56b172"}},"27473f1775c24d179f25dca945aed3a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6dbad290d6744029927824d5c46abc6","placeholder":"​","style":"IPY_MODEL_ed4b15dda2554bf986bd756cf95cacc7","value":"model-00004-of-00004.safetensors: 100%"}},"aa2f9f311f0f465b8371d189676693a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4695e04af474d698746bf97d9273924","max":1761711440,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a15bea4aaec14926afb3bb4b48438547","value":1761711440}},"2fbe6cb93fcd4026a64808e96ad1131c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_688b601ff86e48e9914b4035e3fcea39","placeholder":"​","style":"IPY_MODEL_f74e6afe62924948b97afb08db2c5ab4","value":" 1.76G/1.76G [00:45&lt;00:00, 51.6MB/s]"}},"f650ce9d1aa24495a820bd2ccf56b172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6dbad290d6744029927824d5c46abc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed4b15dda2554bf986bd756cf95cacc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4695e04af474d698746bf97d9273924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a15bea4aaec14926afb3bb4b48438547":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"688b601ff86e48e9914b4035e3fcea39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f74e6afe62924948b97afb08db2c5ab4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c99c08779f014e899554ccdb5155d382":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ed38131def44d89883d15266c0d4bcc","IPY_MODEL_5dea0ab0dd344233a3a72f72330ca1f7","IPY_MODEL_5086740286394bc7b6c3195e85ffdd68"],"layout":"IPY_MODEL_69dba9aa673d4d87b2c729aa7b09cc00"}},"8ed38131def44d89883d15266c0d4bcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5b8d52cf1bc4c47bb6b76867128b98d","placeholder":"​","style":"IPY_MODEL_81bafa1c60b1430483063c6eeb02e63c","value":"Loading checkpoint shards: 100%"}},"5dea0ab0dd344233a3a72f72330ca1f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6217b1c4ed2475f975b075f5c16d0c2","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4bae29b148549528e727b83193050ee","value":4}},"5086740286394bc7b6c3195e85ffdd68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edfaaeda6dad4fcb80b46ea3aae095ee","placeholder":"​","style":"IPY_MODEL_8d629a4d61124a609d38e01f519225af","value":" 4/4 [00:37&lt;00:00,  7.49s/it]"}},"69dba9aa673d4d87b2c729aa7b09cc00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b8d52cf1bc4c47bb6b76867128b98d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81bafa1c60b1430483063c6eeb02e63c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6217b1c4ed2475f975b075f5c16d0c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4bae29b148549528e727b83193050ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edfaaeda6dad4fcb80b46ea3aae095ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d629a4d61124a609d38e01f519225af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}