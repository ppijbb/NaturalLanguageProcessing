{"cells":[{"cell_type":"markdown","metadata":{"id":"Kk3Hv9duy5GE"},"source":["# Installaion"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2931,"status":"ok","timestamp":1726019465157,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"iCRpjtCdPPRx","outputId":"d983f0df-9bd1-45b3-fa39-b7d3b091efe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid (permission: write).\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["#@title Huggingface Login\n","#@markdown huggingface weight 를 이용하고 싶다면 로그인 필수\n","from google.colab import userdata\n","import os\n","\n","os.environ['HF_WRITE_TOKEN'] = userdata.get('HF_WRITE_TOKEN')\n","\n","!huggingface-cli login --add-to-git-credential --token $HF_WRITE_TOKEN\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2521,"status":"ok","timestamp":1726019467677,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"I2WsOt0adjEO","outputId":"f7d3826c-dccf-4dd1-c7e6-7730b47d2e90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.16)\n","Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.2.39)\n","Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.10/dist-packages (0.0.3)\n","Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.16)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.4)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.117)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (4.12.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.24.6)\n","Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (3.0.1)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.19.1)\n","Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.44.2)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.6.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.5)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.3.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (9.4.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.7.24)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n"]}],"source":["!pip install langchain langchain_core langchain_huggingface langchain_community"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1yGE9S3PSOri3k6Xs5Gh3yyJzRFxVKso3"},"executionInfo":{"elapsed":88566,"status":"ok","timestamp":1726019556240,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"XxebrhrVtVSH","outputId":"3c499b40-2040-4cea-fde4-b2882301de09"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#@markdown install with openvino\n","%%sh\n","# apt-get update  -y\n","# apt-get install -y gcc-12 g++-12\n","# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n","# pip install --upgrade pip\n","# pip install wheel packaging ninja \"setuptools>=49.4.0\" numpy\n","git clone https://github.com/vllm-project/vllm.git\n","cd vllm && pip install -r requirements-build.txt --extra-index-url https://download.pytorch.org/whl/cpu\n","pip install gguf\n","export PIP_EXTRA_INDEX_URL=\"https://download.pytorch.org/whl/cpu https://storage.openvinotoolkit.org/simple/wheels/pre-release\" && \\\n","    VLLM_TARGET_DEVICE=openvino python -m pip install -v ."]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","id":"nOjoNxHkuJ2v","executionInfo":{"status":"ok","timestamp":1726019556241,"user_tz":-540,"elapsed":7,"user":{"displayName":"정권환","userId":"03859214150473665717"}}},"outputs":[],"source":["#@markdown install with cpu\n","# %%sh\n","# apt-get update  -y\n","# apt-get install -y gcc-12 g++-12\n","# update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n","# pip install --upgrade pip\n","# pip install wheel packaging ninja \"setuptools>=49.4.0\" numpy\n","# pip install pynvml\n","# git clone https://github.com/vllm-project/vllm.git\n","# cd vllm && pip install -U -q -v -r requirements-cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu\n","# VLLM_TARGET_DEVICE=cpu python setup.py install"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":67965,"status":"ok","timestamp":1726019624200,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"ACpdX-hL2HDY","outputId":"1173c098-7529-4b66-82de-580a61dc5ce7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n","Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (0.6.0+openvino)\n","Collecting ray\n","  Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting pynvml\n","  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cpu/torch-2.4.1%2Bcpu-cp310-cp310-linux_x86_64.whl (194.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.19.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Collecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.4.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.66.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n","Requirement already satisfied: transformers>=4.43.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.44.2)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.19.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (4.25.4)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from vllm) (0.114.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.10.5)\n","Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.44.1)\n","Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm) (0.30.6)\n","Requirement already satisfied: pydantic>=2.8 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.8.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (10.4.0)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.0)\n","Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (7.0.0)\n","Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.7.0)\n","Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.6)\n","Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.46)\n","Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n","Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.15.4)\n","Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.1.1.post4)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n","Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm) (0.18.6)\n","Requirement already satisfied: gguf==0.9.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.9.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.4.0)\n","Requirement already satisfied: mistral-common>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n","Requirement already satisfied: openvino~=2024.3.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2024.3.0)\n","Requirement already satisfied: optimum-intel>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (1.19.0)\n","Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (0.3.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (24.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.40.0->vllm) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (0.4.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (1.3.1)\n","Requirement already satisfied: openvino-telemetry>=2023.2.1 in /usr/local/lib/python3.10/dist-packages (from openvino~=2024.3.0->vllm) (2024.1.0)\n","Requirement already satisfied: optimum~=1.22 in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.22.0)\n","Requirement already satisfied: datasets>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.21.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (71.0.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.13.1)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.16.2)\n","Requirement already satisfied: nncf>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (2.12.0)\n","Requirement already satisfied: openvino-tokenizers[transformers] in /usr/local/lib/python3.10/dist-packages (from optimum-intel[openvino]>=1.18.2->vllm) (2024.3.0.0)\n","Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.2.2)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.2.1)\n","Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n","Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (24.6.1)\n","Requirement already satisfied: pyairports in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.1.1)\n","Requirement already satisfied: starlette<1.0.0,>=0.30.0 in /usr/local/lib/python3.10/dist-packages (from prometheus-fastapi-instrumentator>=7.0.0->vllm) (0.38.5)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8->vllm) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2024.8.30)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.7.24)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.24.6)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->vllm) (0.4.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.20.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.20.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.24.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (13.0.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.40.0->vllm) (1.2.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.1.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (0.70.16)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm) (1.0.5)\n","Requirement already satisfied: jstyleson>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.0.2)\n","Requirement already satisfied: natsort>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (8.4.0)\n","Requirement already satisfied: ninja<1.12,>=1.10.0.post2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.11.1.1)\n","Requirement already satisfied: pydot<3.0.0,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.4.2)\n","Requirement already satisfied: pymoo>=0.6.0.1 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.6.1.3)\n","Requirement already satisfied: rich>=13.5.2 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (13.8.0)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.3.2)\n","Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.9.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum~=1.22->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (15.0.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (2024.1)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot<3.0.0,>=1.4.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.1.4)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.7.1)\n","Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.7.0)\n","Requirement already satisfied: cma==3.2.2 in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.2.2)\n","Requirement already satisfied: alive-progress in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.1.5)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.2.14)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (2.16.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (3.5.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum~=1.22->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (10.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.4.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.4.0->optimum-intel>=1.18.2->optimum-intel[openvino]>=1.18.2->vllm) (1.16.0)\n","Requirement already satisfied: about-time==4.2.1 in /usr/local/lib/python3.10/dist-packages (from alive-progress->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (4.2.1)\n","Requirement already satisfied: grapheme==0.6.0 in /usr/local/lib/python3.10/dist-packages (from alive-progress->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (0.6.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pymoo>=0.6.0.1->nncf>=2.11.0->optimum-intel[openvino]>=1.18.2->vllm) (1.16.0)\n","Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl (65.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pynvml, torch, torchvision, torchaudio, ray\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.4.0+cu121\n","    Uninstalling torch-2.4.0+cu121:\n","      Successfully uninstalled torch-2.4.0+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.19.0+cu121\n","    Uninstalling torchvision-0.19.0+cu121:\n","      Successfully uninstalled torchvision-0.19.0+cu121\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.4.0+cu121\n","    Uninstalling torchaudio-2.4.0+cu121:\n","      Successfully uninstalled torchaudio-2.4.0+cu121\n","Successfully installed pynvml-11.5.3 ray-2.35.0 torch-2.4.1+cpu torchaudio-2.4.1+cpu torchvision-0.19.1+cpu\n","Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-0jhy0xkb/unsloth_1f6136e7fd534473a1758017b0935777\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-0jhy0xkb/unsloth_1f6136e7fd534473a1758017b0935777\n","  Resolved https://github.com/unslothai/unsloth.git to commit 6c534341bb229b136f9504443f0161645d2070c5\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n","Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading tyro-0.8.10-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: transformers>=4.43.2 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.44.2)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.0)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n","Collecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.6)\n","Collecting hf-transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.15.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.7.24)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.8.0)\n","Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.8.10-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unsloth: filename=unsloth-2024.8-py3-none-any.whl size=152932 sha256=a788e973895a4313f00aa072dde753611241330c69528b1b19c5bf1b0165f580\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-g_svzxet/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n","Successfully built unsloth\n","Installing collected packages: unsloth, shtab, protobuf, hf-transfer, tyro\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.4\n","    Uninstalling protobuf-4.25.4:\n","      Successfully uninstalled protobuf-4.25.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","grpcio-tools 1.62.3 requires protobuf<5.0dev,>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed hf-transfer-0.1.8 protobuf-3.20.3 shtab-1.7.1 tyro-0.8.10 unsloth-2024.8\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"970c05037f764fd6831bce5ce1480f05"}},"metadata":{}}],"source":["#@markdown colab installation\n","!VLLM_TARGET_DEVICE=cpu pip install -U vllm ray pynvml torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n","!pip install -U \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""]},{"cell_type":"markdown","metadata":{"id":"WDfsLqSoy9ET"},"source":["# vLLM Generation\n","\n","colab에서 vllm cpu 버전 설치 이슈로<p>\n","openvino 버전을 설치하여 cpu inference 진행 중<p>\n","하지만, Colab은 AMD CPU 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":975,"referenced_widgets":["25338640c36e40fa8752fcc3bb07f062","73556c3418e14c4e84f5f287dbc3873a","d7985f1e526946b0b296927b506fee98","11db3e1a7801406d9da65d30824d7cd7","73c92d1b7cf44ddba208604ac5bcba00","f6ee74da5b124b66a0e1df71f3f59ca6","87f42e41125d4337b2140a537a6b667e","0ea02322db694f65b408994e392a52af","83d12bd0134d434eb4b0b03ec80c2899","1d8a47b3d1784df48f5d902bc701d6ec","50d0e38b85ad4ec98e3a97df783ad29f","d02193e3625f42e9852bd9672c8f7ea6","a7fcf89c5ba0418890fb4429697ccd8f","214bfbbd9d21468e983bb985797ab5e3","988e5b9caae64b66ae656371cf4e6a10","63774647bd1d4995b6ae552a082013f6","b40a4cea1b24401086dd70d2827954ab","1c22e3176be34360a1a85b92713889e1","8331486fcf3745b78326ca40e75c0a37","4f72361973e34004aee57b9d130dbd37","1862a23e7faf408896e2dd59067bad0d","4646151fab564b868d87cf3a60c3b3ac","695044d017314c0ea159530a54df73ce","c24de4d00289446c9cd82b22d22e98f4","84e7198ba96f48a2b05ab87a1f0975a5","e7b130a3fbc5459091355ac87a0c43eb","60ea9aad68154d74a42a9656be1bc960","d8b280749c7e4539aa35d7f2a93c17e1","10a5e7a7e3cb455a810dac50fe8d1a54","a7dfbfd9d0f64b08a2854a58e1176025","34be31156b7044dc8d59bd8dcb384689","fcd2667f6c8a4536a87bb5248bd58992","2ccbd821a15646278dc055563b4f838b","82a13383f3a34dd8977f07ded817a3d2","feda86aaf0054d7ebc0c9f1ab70e3e70","ecad7c0975714a5b841c404c78a55eac","74e2eceac16343a4a6e6cc8b4c3361e1","7c51ed7fda5a4934a4bba0415bf8d948","6b9ac448f51347b6bb94fff441b6920a","5ea2d24a17d54e0f88c2dc55f389f84a","e82867d8a9d14ab2816f359d18d2d916","bb232f07789c4d1983e7f78e8a73cd79","274a353403b24a0ab16ea89775fc03ed","1d5ac7d6475549ff962f3aa1f6fbd26d","e2ec38b4ffee4b34848c878601bf6e5c","ffb455d277aa4a349311280581527b1e","4e3910df64994afa8152bbc0c2a86d95","97365a8b12d54f0f8e6848da6ae5fc7e","e3ac57359e1840e398f5cf5059af3799","038735b5e7964f0f9593be3d5ddb47c9","d37a1cd850a34b339769dc0601ba471a","88bff89afc2e400caf74c09834378dfc","a41d8b7d020442edb17b7c2e086b103e","9cd73d8a43ac43b5b9e3d513d80a9e59","cd52d3bf42a646feb03c4eb82655a336"]},"executionInfo":{"elapsed":17831,"status":"error","timestamp":1725356652941,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"2_7-fkpu5djM","outputId":"49228753-5e98-400e-f307-9671a1c64ebe"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO 09-03 09:43:57 importing.py:10] Triton not installed; certain GPU-related functions will not be available.\n","WARNING 09-03 09:43:57 _custom_ops.py:18] Failed to import from vllm._C with ModuleNotFoundError(\"No module named 'vllm._C'\")\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25338640c36e40fa8752fcc3bb07f062","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/907 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["WARNING 09-03 09:44:04 utils.py:723] Gemma 2 uses sliding window attention for every odd layer, which is currently not supported by vLLM. Disabling sliding window and capping the max length to the sliding window size (4096).\n","WARNING 09-03 09:44:04 config.py:352] Async output processing is only supported for CUDA or TPU. Disabling it for other platforms.\n","INFO 09-03 09:44:05 llm_engine.py:212] Initializing an LLM engine (v0.5.5) with config: model='Gunulhona/Gemma-Ko-Merge', speculative_config=None, tokenizer='Gunulhona/Gemma-Ko-Merge', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=3096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Gunulhona/Gemma-Ko-Merge, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=False)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d02193e3625f42e9852bd9672c8f7ea6","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/40.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"695044d017314c0ea159530a54df73ce","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82a13383f3a34dd8977f07ded817a3d2","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2ec38b4ffee4b34848c878601bf6e5c","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["WARNING 09-03 09:44:07 openvino_executor.py:134] Only float32 dtype is supported on OpenVINO, casting from torch.bfloat16.\n","WARNING 09-03 09:44:07 openvino_executor.py:139] CUDA graph is not supported on OpenVINO backend, fallback to the eager mode.\n","INFO 09-03 09:44:07 openvino_executor.py:161] OpenVINO optimal block size is 32, overriding currently set 16\n","WARNING 09-03 09:44:07 openvino_executor.py:170] Environment variable VLLM_OPENVINO_KVCACHE_SPACE (GB) for OpenVINO backend is not set, using 4 by default.\n"]},{"name":"stderr","output_type":"stream","text":["No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"]},{"name":"stdout","output_type":"stream","text":["INFO 09-03 09:44:10 selector.py:188] Cannot use _Backend.FLASH_ATTN backend on OpenVINO.\n","INFO 09-03 09:44:10 selector.py:132] Using OpenVINO Attention backend.\n","WARNING 09-03 09:44:10 openvino.py:122] Provided model id Gunulhona/Gemma-Ko-Merge does not contain OpenVINO IR, the model will be converted to IR with default options. If you need to use specific options for model conversion, use optimum-cli export openvino with desired options.\n"]},{"name":"stderr","output_type":"stream","text":["Framework not specified. Using pt to export the model.\n"]},{"ename":"ValueError","evalue":"Trying to export a gemma2 model, that is a custom or unsupported architecture, but no custom export configuration was passed as `custom_export_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. Please open an issue at https://github.com/huggingface/optimum-intel/issues if you would like the model type gemma2 to be supported natively in the OpenVINO export.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-0d1e94e074f8>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Gunulhona/Gemma-Ko-Merge\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m model = LLM(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmax_model_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3096\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_context_len_to_capture, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         )\n\u001b[0;32m--> 177\u001b[0;31m         self.llm_engine = LLMEngine.from_engine_args(\n\u001b[0m\u001b[1;32m    178\u001b[0m             engine_args, usage_context=UsageContext.LLM_CLASS)\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mexecutor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_executor_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# Create the LLM engine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         engine = cls(\n\u001b[0m\u001b[1;32m    542\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mengine_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mexecutor_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, decoding_config, observability_config, prompt_adapter_config, executor_class, log_stats, usage_context, stat_loggers, input_registry, step_return_finished_only)\u001b[0m\n\u001b[1;32m    300\u001b[0m             model_config)\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         self.model_executor = executor_class(\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mcache_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/executor_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, prompt_adapter_config, observability_config)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_adapter_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_adapter_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservability_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservability_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/openvino_executor.py\u001b[0m in \u001b[0;36m_init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Instantiate the worker and load the model to CPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/openvino_executor.py\u001b[0m in \u001b[0;36m_init_worker\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetermine_num_available_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/openvino_worker.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetermine_num_available_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/openvino_model_runner.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         self.model = get_model(\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mdevice_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/model_executor/model_loader/openvino.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(model_config, device_config, kv_cache_dtype, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \"please open an issue on github.\")\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mOpenVINOCasualLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/model_executor/model_loader/openvino.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_config, device_config, kv_cache_dtype)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mload_in_8bit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVLLM_OPENVINO_ENABLE_QUANTIZED_WEIGHTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         pt_model = OVModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mexport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/modeling_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mfrom_pretrained_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_transformers\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexport\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_pretrained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         return from_pretrained_method(\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/intel/openvino/modeling_decoder.py\u001b[0m in \u001b[0;36m_from_transformers\u001b[0;34m(cls, model_id, config, use_auth_token, token, revision, force_download, cache_dir, subfolder, local_files_only, task, use_cache, trust_remote_code, load_in_8bit, quantization_config, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mstateful\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stateful\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_stateful_is_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         main_export(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_dir_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optimum/exporters/openvino/__main__.py\u001b[0m in \u001b[0;36mmain_export\u001b[0;34m(model_name_or_path, output, task, device, framework, cache_dir, trust_remote_code, pad_token_id, subfolder, revision, force_download, local_files_only, use_auth_token, token, model_kwargs, custom_export_configs, fn_get_submodels, compression_option, compression_ratio, ov_config, stateful, convert_tokenizer, library_name, **kwargs_shapes)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mcustom_architecture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcustom_export_configs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0;34mf\"Trying to export a {model_type} model, that is a custom or unsupported architecture, but no custom export configuration was passed as `custom_export_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. Please open an issue at https://github.com/huggingface/optimum-intel/issues if you would like the model type {model_type} to be supported natively in the OpenVINO export.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 )\n","\u001b[0;31mValueError\u001b[0m: Trying to export a gemma2 model, that is a custom or unsupported architecture, but no custom export configuration was passed as `custom_export_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. Please open an issue at https://github.com/huggingface/optimum-intel/issues if you would like the model type gemma2 to be supported natively in the OpenVINO export."]}],"source":["from vllm import LLM, SamplingParams\n","import os\n","\n","os.environ[\"VLLM_CPU_KVCACHE_SPACE\"] = \"20\"\n","os.environ[\"VLLM_CPU_OMP_THREADS_BIND\"] = \"0-27\"\n","\n","if \"model\" in locals():\n","    del model\n","\n","model_id = \"microsoft/Phi-3.5-mini-instruct\"\n","# model_id = \"akjindal53244/Llama-3.1-Storm-8B\"\n","# model_id = \"Gunulhona/Minitron-Llama-Merge\"\n","# model_id = \"Gunulhona/Llama-Ko-Merge\"\n","# model_id = \"Gunulhona/Llama-Merge-Small\"\n","model_id = \"Gunulhona/Openchat-Llama-Merge\"\n","# model_id = \"Gunulhona/Hermes-Llama-Merge\"\n","model_id = \"Gunulhona/Phi-Small-Merge\"\n","model_id = \"Gunulhona/Gemma-Ko-Merge\"\n","\n","model = LLM(\n","    model=model_id,\n","    max_model_len=3096,\n","    trust_remote_code=True,\n","    # quantization=\"bitsandbytes\",\n","    # load_format=\"bitsandbytes\",\n","    dtype=\"bfloat16\",\n","    # distributed_executor_backend=\"ray\",\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Qg2Os5SI6pF"},"outputs":[],"source":["import gc\n","import os\n","from typing import List\n","from vllm import LLM, SamplingParams\n","from transformers import AutoTokenizer\n","\n","from datetime import datetime, timezone, timedelta\n","\n","def get_today_str_utc_plus_9():\n","  today_utc = datetime.now(timezone.utc)\n","  today_utc_plus_9 = today_utc + timedelta(hours=9)  # Add 9 hours\n","  return today_utc_plus_9.strftime(\"%Y %B %d %H:%m\")\n","\n","def chat_format(prompt:List[dict])->str:\n","    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n","    try:\n","        check = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","        print(\"tokenizer has format\")\n","    except:\n","        tokenizer.bos_token = \"<|begin_of_text|>\"\n","        tokenizer.chat_template= \"{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \\\"26 Jul 2024\\\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0]['role'] == 'system' %}\\n    {%- set system_message = messages[0]['content']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \\\"\\\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \\\"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\\\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \\\"Environment: ipython\\\\n\\\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \\\"Tools: \\\" + builtin_tools | reject('equalto', 'code_interpreter') | join(\\\", \\\") + \\\"\\\\n\\\\n\\\"}}\\n{%- endif %}\\n{{- \\\"Cutting Knowledge Date: December 2023\\\\n\\\" }}\\n{{- \\\"Today Date: \\\" + date_string + \\\"\\\\n\\\\n\\\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \\\"You have access to the following functions. To call a function, please respond with JSON for a function call.\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \\\"<|eot_id|>\\\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0]['content']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\\\"Cannot put tools in the first user message when there's no first user message!\\\") }}\\n{%- endif %}\\n    {{- '<|start_header_id|>user<|end_header_id|>\\\\n\\\\n' -}}\\n    {{- \\\"Given the following functions, please respond with a JSON for a function call \\\" }}\\n    {{- \\\"with its proper arguments that best answers the given prompt.\\\\n\\\\n\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \\\"<|eot_id|>\\\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\\\n\\\\n'+ message['content'] | trim + '<|eot_id|>' }}\\n    {%- elif 'tool_calls' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\\\"This model only supports single tool-calls at once!\\\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- \\\"<|python_tag|>\\\" + tool_call.name + \\\".call(\\\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + '=\\\"' + arg_val + '\\\"' }}\\n                {%- if not loop.last %}\\n                    {{- \\\", \\\" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \\\")\\\" }}\\n        {%- else  %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- '{\\\"name\\\": \\\"' + tool_call.name + '\\\", ' }}\\n            {{- '\\\"parameters\\\": ' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\\"}\\\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we're in ipython mode #}\\n            {{- \\\"<|eom_id|>\\\" }}\\n        {%- else %}\\n            {{- \\\"<|eot_id|>\\\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\\"tool\\\" or message.role == \\\"ipython\\\" %}\\n        {{- \\\"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\\\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \\\"<|eot_id|>\\\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' }}\\n{%- endif %}\\n\"\n","        tokenizer.clean_up_tokenization_spaces =True\n","        # tokenizer.eos_token = \"<|eot_id|>\"\n","        print(\"tokenizer doesn't have format\")\n","    finally:\n","        prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n","    return prompt\n","\n","os.environ[\"VLLM_USE_MODELSCOPE\"] = \"True\"\n","\n","prompt = \"\"\"\n","제시된 대화 내용을 아래 항목들에 대해서 결정된 내용만 정리\n","형식은 아래 항목들과 순서가 똑같이 최대 글자 수 500자\n","해당 없음, 언급 없음은 모두 삭제하여 출력 하지 않음\n","발화자 내용 제거\n","약 복용 법 언급 시 무조건 포함\n","한글로만 출력\n","1. 방문목적\n","2. 구강상태(PI)\n","3. 구강상태에 대한 치료 방안\n","4. 상담내용\n","- 치료 방법 설명\n","- 치료 진행 유무(진행 시 일정)\n","- 결정된 치료 방법\n","- 총 비용\n","- 보철물 종류(보철 진행 시)\n","- 임플란트 종류(임플란트 진행 시)\n","- 교정 종류(교정치료 진행 시)\n","- 뼈(골)이식 종류(뼈이식 진행 시)\n","- 동의서 설명 (부작용 및 실패 가능성 설명 등등)\n","- 주의사항 설명(복용약이 있을 시 표시)\n","---\n","참석자_1: 안녕하세요, 선생님.\n","참석자_2: 안녕하세요, 의사 선생님.\n","참석자_1: 마흔 넷이시죠?\n","참석자_2: 네, 선생님.\n","참석자_1: 좋아요, 오늘은 무슨 문제가 있는 것 같나요?\n","참석자_2: 의사 선생님, 한동안 허리 통증이 있었습니다.\n","참석자_1: 통증이 다리로 내려가나요?\n","참석자_2: 네, 오른쪽 허벅지에도 통증이 있습니다.\n","참석자_1: 이 통증과 관련된 부상이 있습니까?\n","참석자_2: 네, 1994년에 사고가 있었습니다.\n","참석자_1: 최초 부상 당시의 서류나 의료 기록이 있습니까?\n","참석자_2: 아니요, 오늘은 없습니다.\n","참석자_1: 직업이 어떻게 되십니까?\n","참석자_2: 지금은 타코벨에서 일합니다. 산재 보험 청구가 열려 있습니다.\n","참석자_1: 거기서 일하다가 통증이 재발했죠?\n","참석자_2: 네, 맞습니다.\n","참석자_1: 마지막으로 이곳에서 진료를 받은 것이 언제였는지 기억하십니까?\n","참석자_2: 음, 네, 4월 12일 2005년이었습니다.\n","참석자_1: 10이 상상할 수 있는 최악의 통증이라면, 마지막 방문 시 통증은 10점 만점에 어느 정도였습니까?\n","참석자_2: 음, 10점 만점에 8점 정도였어요.\n","참석자_1: 이 통증 때문에 약을 복용하셨나요?\n","참석자_2: 음, 지난번 방문했을 때 메드롤 도스팩을 처방받았습니다.\n","참석자_1: 도세팍에 통증이 어떻게 반응했나요?\n","참석자_2: 통증이 10점 만점에 4~5점 정도로 줄었습니다.\n","참석자_1: 통증이 있는 곳을 가리켜 주시겠습니까?\n","참석자_2: 네, 바로 여기입니다.\n","참석자_1: 여기 이 밴드요?\n","참석자_2: 네, 바로 그 자리입니다.\n","참석자_1: 좋아요, 여기는 요추 4번과 천골 사이입니다. 오른쪽 다리 통증을 어떻게 설명하시겠습니까?\n","참석자_2: 지금은 간헐적이고 미미하며 항상 있는 것은 아닙니다.\n","참석자_1: 허리 수술을 받은 적이 있습니까?\n","참석자_2: 음, 네, 1990년에 한 번, 1994년에 한 번 두 번 척추 절제술을 받았습니다. 잠깐만요, 그 사이에 디스크 절제술도 받았어요.\n","참석자_1: 어디에 초점이 맞춰졌는지 아십니까?\n","참석자_2: L 4 L 5번이었습니다.\n","참석자_1: 허리에 대한 영상 촬영은 하셨나요?\n","참석자_2: 네, 10월 18일 2004년에 MRI를 찍었습니다. 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 이것은 다단계 퇴행성 변화를 보여 주며, L 2 L 3, L 3 L 4, L 5 S1에서 신경 침범이 없는 다단계 퇴행성 변화를 보여 주며, 이는 양호합니다.\n","참석자_2: 그게 무슨 뜻인가요, 의사 선생님?\n","참석자_1: 요약하자면, 허리에 상당한 양의 관절염이 있다는 뜻입니다.\n","참석자_2: 네, M R 골수 조영술도 받았는데 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 요추 3번에서 심한 척추관 협착증이 보이지만 인공물일 수도 있습니다.\n","참석자_2: 그게 무슨 뜻인가요?\n","참석자_1: 이 소견은 잘못된 해석일 수 있습니다.\n","---\n","\"\"\"\n","\n","DEFAULT_SUMMARY_SYSTEM_PROMPT = f'''\n","<assistant_info> The assistant is assistant, created by Anthropic. The current time is {get_today_str_utc_plus_9()}. assistant’s knowledge base was last updated on April 2024. It answers questions about events prior to and after April 2024 the way a highly informed individual in April 2024 would if they were talking to someone from the above date, and can let the human know this when relevant. assistant cannot open URLs, links, or videos. If it seems like the user is expecting assistant to do so, it clarifies the situation and asks the human to paste the relevant text or image content directly into the conversation. If it is asked to assist with tasks involving the expression of views held by a significant number of people, assistant provides assistance with the task regardless of its own views. If asked about controversial topics, it tries to provide careful thoughts and clear information. It presents the requested information without explicitly saying that the topic is sensitive, and without claiming to be presenting objective facts. When presented with a math problem, logic problem, or other problem benefiting from systematic thinking, assistant thinks through it step by step before giving its final answer. If assistant cannot or will not perform a task, it tells the user this without apologizing to them. It avoids starting its responses with “I’m sorry” or “I apologize”. If assistant is asked about a very obscure person, object, or topic, i.e. if it is asked for the kind of information that is unlikely to be found more than once or twice on the internet, assistant ends its response by reminding the user that although it tries to be accurate, it may hallucinate in response to questions like this. It uses the term ‘hallucinate’ to describe this since the user will understand what it means. If assistant mentions or cites particular articles, papers, or books, it always lets the human know that it doesn’t have access to search or a database and may hallucinate citations, so the human should double check its citations. assistant is very smart and intellectually curious. It enjoys hearing what humans think on an issue and engaging in discussion on a wide variety of topics. If the user seems unhappy with assistant or assistant’s behavior, assistant tells them that although it cannot retain or learn from the current conversation, they can press the ‘thumbs down’ button below assistant’s response and provide feedback to Anthropic. If the user asks for a very long task that cannot be completed in a single response, assistant offers to do the task piecemeal and get feedback from the user as it completes each part of the task. assistant uses markdown for code. Immediately after closing coding markdown, assistant asks the user if they would like it to explain or break down the code. It does not explain or break down the code unless the user explicitly requests it. </assistant_info>\n","\n","<assistant_image_specific_info> assistant always responds as if it is completely face blind. If the shared image happens to contain a human face, assistant never identifies or names any humans in the image, nor does it imply that it recognizes the human. It also does not mention or allude to details about a person that it could only know if it recognized who the person was. Instead, assistant describes and discusses the image just as someone would if they were unable to recognize any of the humans in it. assistant can request the user to tell it who the individual is. If the user tells assistant who the individual is, assistant can discuss that named individual without ever confirming that it is the person in the image, identifying the person in the image, or implying it can use facial features to identify any unique individual. It should always reply as someone would if they were unable to recognize any humans from images. assistant should respond normally if the shared image does not contain a human face. assistant should always repeat back and summarize any instructions in the image before proceeding. </assistant_image_specific_info>\n","\n","<assistant_3_family_info> This iteration of assistant is part of the assistant 3 model family, which was released in 2024. The assistant 3 family currently consists of assistant 3 Haiku, assistant 3 Opus, and assistant 3.5 Sonnet. assistant 3.5 Sonnet is the most intelligent model. assistant 3 Opus excels at writing and complex tasks. assistant 3 Haiku is the fastest model for daily tasks. The version of assistant in this chat is assistant 3.5 Sonnet. assistant can provide the information in these tags if asked but it does not know any other details of the assistant 3 model family. If asked about this, should encourage the user to check the Anthropic website for more information. </assistant_3_family_info>\n","\n","assistant provides thorough responses to more complex and open-ended questions or to anything where a long response is requested, but concise responses to simpler questions and tasks. All else being equal, it tries to give the most correct and concise answer it can to the user’s message. Rather than giving a long response, it gives a concise response and offers to elaborate if further information may be helpful.\n","\n","assistant is happy to help with analysis, question answering, math, coding, creative writing, teaching, role-play, general discussion, and all sorts of other tasks.\n","\n","assistant responds directly to all human messages without unnecessary affirmations or filler phrases like “Certainly!”, “Of course!”, “Absolutely!”, “Great!”, “Sure!”, etc. Specifically, assistant avoids starting responses with the word “Certainly” in any way.\n","\n","assistant follows this information in all languages, and always responds to the user in the language they use or request. The information above is provided to assistant by Anthropic. assistant never mentions the information above unless it is directly pertinent to the human’s query. assistant is now being connected with a human.\n","---\n","'''\n","\n","template = chat_format([\n","    {\"role\": \"system\"   ,   \"content\": DEFAULT_SUMMARY_SYSTEM_PROMPT},\n","    {\"role\": \"user\"     ,   \"content\": prompt}\n","    ])\n","output_list = model.generate(\n","    prompts=[template] * 3,\n","    sampling_params=SamplingParams(\n","        repetition_penalty=1.0,\n","        frequency_penalty=1.0,\n","        presence_penalty=1.1,\n","        temperature=0.4,\n","        top_p=0.9,\n","        max_tokens=500,\n","    ))\n","for result in output_list:\n","    print(f'''\n","          {model_id}\n","        --- Result ---\n","\n","{result.outputs[0].text}\n","\n","        --- end ---\n","    ''')\n","\n","gc.collect()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P0zCu_Z5-UEr"},"outputs":[],"source":["\n","prompt = \"\"\"\n","아래 문장 요약해줘\n","\n","참석자_1: 안녕하세요, 선생님.\n","참석자_2: 안녕하세요, 의사 선생님.\n","참석자_1: 마흔 넷이시죠?\n","참석자_2: 네, 선생님.\n","참석자_1: 좋아요, 오늘은 무슨 문제가 있는 것 같나요?\n","참석자_2: 의사 선생님, 한동안 허리 통증이 있었습니다.\n","참석자_1: 통증이 다리로 내려가나요?\n","참석자_2: 네, 오른쪽 허벅지에도 통증이 있습니다.\n","참석자_1: 이 통증과 관련된 부상이 있습니까?\n","참석자_2: 네, 1994년에 사고가 있었습니다.\n","참석자_1: 최초 부상 당시의 서류나 의료 기록이 있습니까?\n","참석자_2: 아니요, 오늘은 없습니다.\n","참석자_1: 직업이 어떻게 되십니까?\n","참석자_2: 지금은 타코벨에서 일합니다. 산재 보험 청구가 열려 있습니다.\n","참석자_1: 거기서 일하다가 통증이 재발했죠?\n","참석자_2: 네, 맞습니다.\n","참석자_1: 마지막으로 이곳에서 진료를 받은 것이 언제였는지 기억하십니까?\n","참석자_2: 음, 네, 4월 12일 2005년이었습니다.\n","참석자_1: 10이 상상할 수 있는 최악의 통증이라면, 마지막 방문 시 통증은 10점 만점에 어느 정도였습니까?\n","참석자_2: 음, 10점 만점에 8점 정도였어요.\n","참석자_1: 이 통증 때문에 약을 복용하셨나요?\n","참석자_2: 음, 지난번 방문했을 때 메드롤 도스팩을 처방받았습니다.\n","참석자_1: 도세팍에 통증이 어떻게 반응했나요?\n","참석자_2: 통증이 10점 만점에 4~5점 정도로 줄었습니다.\n","참석자_1: 통증이 있는 곳을 가리켜 주시겠습니까?\n","참석자_2: 네, 바로 여기입니다.\n","참석자_1: 여기 이 밴드요?\n","참석자_2: 네, 바로 그 자리입니다.\n","참석자_1: 좋아요, 여기는 요추 4번과 천골 사이입니다. 오른쪽 다리 통증을 어떻게 설명하시겠습니까?\n","참석자_2: 지금은 간헐적이고 미미하며 항상 있는 것은 아닙니다.\n","참석자_1: 허리 수술을 받은 적이 있습니까?\n","참석자_2: 음, 네, 1990년에 한 번, 1994년에 한 번 두 번 척추 절제술을 받았습니다. 잠깐만요, 그 사이에 디스크 절제술도 받았어요.\n","참석자_1: 어디에 초점이 맞춰졌는지 아십니까?\n","참석자_2: L 4 L 5번이었습니다.\n","참석자_1: 허리에 대한 영상 촬영은 하셨나요?\n","참석자_2: 네, 10월 18일 2004년에 MRI를 찍었습니다. 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 이것은 다단계 퇴행성 변화를 보여 주며, L 2 L 3, L 3 L 4, L 5 S1에서 신경 침범이 없는 다단계 퇴행성 변화를 보여 주며, 이는 양호합니다.\n","참석자_2: 그게 무슨 뜻인가요, 의사 선생님?\n","참석자_1: 요약하자면, 허리에 상당한 양의 관절염이 있다는 뜻입니다.\n","참석자_2: 네, M R 골수 조영술도 받았는데 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 요추 3번에서 심한 척추관 협착증이 보이지만 인공물일 수도 있습니다.\n","참석자_2: 그게 무슨 뜻인가요?\n","참석자_1: 이 소견은 잘못된 해석일 수 있습니다.\n","\"\"\"\n","\n","DEFAULT_SUMMARY_SYSTEM_PROMPT = f'''\n","The assistant is assistant, created by Anthropic. The current time is {get_today_str_utc_plus_9()}.\n","---\n","'''\n","\n","template = chat_format([\n","    {\"role\": \"system\"   ,   \"content\": DEFAULT_SUMMARY_SYSTEM_PROMPT},\n","    {\"role\": \"user\"     ,   \"content\": prompt}\n","    ])\n","output_list = model.generate(\n","    prompts=[template] * 3,\n","    sampling_params=SamplingParams(\n","        repetition_penalty=1.0,\n","        frequency_penalty=1.0,\n","        presence_penalty=1.0,\n","        temperature=0.01,\n","        top_p=0.9,\n","        max_tokens=500,\n","    ))\n","for result in output_list:\n","    print(f'''\n","          {model_id}\n","        --- Result ---\n","\n","{result.outputs[0].text}\n","\n","        --- end ---\n","    ''')\n","\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"hTwucFa-TcAS"},"source":["# Huggingface TGI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfOxUK5IbSZ1"},"outputs":[],"source":["# prompt: pipeline 으로 Gunulhona 레포지토리에 있는 모델을 가져다가 LLM generation 하는 코드\n","import torch\n","from transformers import pipeline, AutoTokenizer\n","from vllm import LLM, SamplingParams\n","\n","# Define the model ID\n","model_id = \"Gunulhona/Gemma-Ko-Merge\"\n","\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n","\n","# Create the pipeline\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model_id,\n","    tokenizer=tokenizer,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n",")\n","\n","# Generate text\n","prompt = '''\n","제시된 대화 내용을 아래 항목들에 대해서 결정된 내용만 정리\n","형식은 아래 항목들과 순서가 똑같이 최대 글자 수 500자\n","해당 없음, 언급 없음은 모두 삭제하여 출력 하지 않음\n","발화자 내용 제거\n","약 복용 법 언급 시 무조건 포함\n","한글로만 출력\n","1. 방문목적\n","2. 구강상태(PI)\n","3. 구강상태에 대한 치료 방안\n","4. 상담내용\n","- 치료 방법 설명\n","- 치료 진행 유무(진행 시 일정)\n","- 결정된 치료 방법\n","- 총 비용\n","- 보철물 종류(보철 진행 시)\n","- 임플란트 종류(임플란트 진행 시)\n","- 교정 종류(교정치료 진행 시)\n","- 뼈(골)이식 종류(뼈이식 진행 시)\n","- 동의서 설명 (부작용 및 실패 가능성 설명 등등)\n","- 주의사항 설명(복용약이 있을 시 표시)\n","---\n","참석자_1: 안녕하세요, 선생님.\n","참석자_2: 안녕하세요, 의사 선생님.\n","참석자_1: 마흔 넷이시죠?\n","참석자_2: 네, 선생님.\n","참석자_1: 좋아요, 오늘은 무슨 문제가 있는 것 같나요?\n","참석자_2: 의사 선생님, 한동안 허리 통증이 있었습니다.\n","참석자_1: 통증이 다리로 내려가나요?\n","참석자_2: 네, 오른쪽 허벅지에도 통증이 있습니다.\n","참석자_1: 이 통증과 관련된 부상이 있습니까?\n","참석자_2: 네, 1994년에 사고가 있었습니다.\n","참석자_1: 최초 부상 당시의 서류나 의료 기록이 있습니까?\n","참석자_2: 아니요, 오늘은 없습니다.\n","참석자_1: 직업이 어떻게 되십니까?\n","참석자_2: 지금은 타코벨에서 일합니다. 산재 보험 청구가 열려 있습니다.\n","참석자_1: 거기서 일하다가 통증이 재발했죠?\n","참석자_2: 네, 맞습니다.\n","참석자_1: 마지막으로 이곳에서 진료를 받은 것이 언제였는지 기억하십니까?\n","참석자_2: 음, 네, 4월 12일 2005년이었습니다.\n","참석자_1: 10이 상상할 수 있는 최악의 통증이라면, 마지막 방문 시 통증은 10점 만점에 어느 정도였습니까?\n","참석자_2: 음, 10점 만점에 8점 정도였어요.\n","참석자_1: 이 통증 때문에 약을 복용하셨나요?\n","참석자_2: 음, 지난번 방문했을 때 메드롤 도스팩을 처방받았습니다.\n","참석자_1: 도세팍에 통증이 어떻게 반응했나요?\n","참석자_2: 통증이 10점 만점에 4~5점 정도로 줄었습니다.\n","참석자_1: 통증이 있는 곳을 가리켜 주시겠습니까?\n","참석자_2: 네, 바로 여기입니다.\n","참석자_1: 여기 이 밴드요?\n","참석자_2: 네, 바로 그 자리입니다.\n","참석자_1: 좋아요, 여기는 요추 4번과 천골 사이입니다. 오른쪽 다리 통증을 어떻게 설명하시겠습니까?\n","참석자_2: 지금은 간헐적이고 미미하며 항상 있는 것은 아닙니다.\n","참석자_1: 허리 수술을 받은 적이 있습니까?\n","참석자_2: 음, 네, 1990년에 한 번, 1994년에 한 번 두 번 척추 절제술을 받았습니다. 잠깐만요, 그 사이에 디스크 절제술도 받았어요.\n","참석자_1: 어디에 초점이 맞춰졌는지 아십니까?\n","참석자_2: L 4 L 5번이었습니다.\n","참석자_1: 허리에 대한 영상 촬영은 하셨나요?\n","참석자_2: 네, 10월 18일 2004년에 MRI를 찍었습니다. 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 이것은 다단계 퇴행성 변화를 보여 주며, L 2 L 3, L 3 L 4, L 5 S1에서 신경 침범이 없는 다단계 퇴행성 변화를 보여 주며, 이는 양호합니다.\n","참석자_2: 그게 무슨 뜻인가요, 의사 선생님?\n","참석자_1: 요약하자면, 허리에 상당한 양의 관절염이 있다는 뜻입니다.\n","참석자_2: 네, M R 골수 조영술도 받았는데 여기 보고서가 있습니다.\n","참석자_1: 좋아요, 요추 3번에서 심한 척추관 협착증이 보이지만 인공물일 수도 있습니다.\n","참석자_2: 그게 무슨 뜻인가요?\n","참석자_1: 이 소견은 잘못된 해석일 수 있습니다.\n","'''\n","generated_text = pipe(prompt, max_new_tokens=128)\n","\n","# Print the generated text\n","print(generated_text[0]['generated_text'])\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":540},"executionInfo":{"elapsed":60736,"status":"error","timestamp":1726027504056,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"SlGYyr4beaQq","outputId":"e99805b2-227e-4421-8788-1df68530b0f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"output_type":"error","ename":"HfHubHTTPError","evalue":"500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-27b-it (Request ID: QXL7JiWKBTHpk9NqrL0um)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-27b-it","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-55a0cbe6b124>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m response = chain.invoke({\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;34m\"system_prompt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"you are good gpt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m# DEFAULT_SUMMARY_SYSTEM_PROMPT,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"이거 한글로 번역해줘 \\n\\nUses some neat geometric properties of fine tuned models to compute good weights for linear interpolation. Requires at least three models, including a base model.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         return (\n\u001b[0;32m--> 385\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    749\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     async def agenerate_prompt(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 )\n\u001b[1;32m    943\u001b[0m             ]\n\u001b[0;32m--> 944\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    945\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             output = (\n\u001b[0;32m--> 774\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    775\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m             text = (\n\u001b[0;32m-> 1508\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_huggingface/llms/huggingface_endpoint.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;34m\"stop_sequences\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             ]  # porting 'stop_sequences' into the 'stop' argument\n\u001b[0;32m--> 258\u001b[0;31m             response = self.client.post(\n\u001b[0m\u001b[1;32m    259\u001b[0m                 \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minvocation_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHfHubHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/google/gemma-2-27b-it (Request ID: QXL7JiWKBTHpk9NqrL0um)"]}],"source":["import os\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_huggingface import HuggingFaceEndpoint\n","from langchain.prompts import PromptTemplate\n","\n","template = \"\"\"<|system|>\n","{system_prompt}<|end|>\n","<|user|>\n","{question}<|end|>\n","<|assistant|>\"\"\"\n","\n","prompt = PromptTemplate.from_template(template)\n","\n","# 사용할 모델의 저장소 ID를 설정합니다.\n","repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n","repo_id = \"mistralai/Mistral-Nemo-Instruct-2407\"\n","repo_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","repo_id = \"HuggingFaceH4/zephyr-7b-beta\"\n","repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n","repo_id = \"google/gemma-2-27b-it\"\n","\n","llm = HuggingFaceEndpoint(\n","    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n","    max_new_tokens=1024,  # 생성할 최대 토큰 길이를 설정합니다.\n","    temperature=0.1,\n","    huggingfacehub_api_token=os.environ[\"HF_WRITE_TOKEN\"],  # 허깅페이스 토큰\n",")\n","\n","# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n","chain = prompt | llm | StrOutputParser()\n","# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n","response = chain.invoke({\n","    \"system_prompt\": \"you are good gpt\",# DEFAULT_SUMMARY_SYSTEM_PROMPT,\n","    \"question\": \"이거 한글로 번역해줘 \\n\\nUses some neat geometric properties of fine tuned models to compute good weights for linear interpolation. Requires at least three models, including a base model.\"\n","    })\n","print(response)"]},{"cell_type":"code","source":["from huggingface_hub import InferenceClient\n","\n","client = InferenceClient(\n","    model=\"google/gemma-2-27b-it\",\n","    token=os.environ[\"HF_WRITE_TOKEN\"],\n",")\n","\n","for message in client.chat_completion(\n","\tmessages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n","\tmax_tokens=500,\n","\tstream=True,\n","):\n","    print(message.choices[0].delta.content, end=\"\")"],"metadata":{"id":"tWVev05uqkpX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Unsloth Inference"],"metadata":{"id":"Aup_zsczql5G"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4IECjVgqHKn"},"outputs":[],"source":["from unsloth import FastLanguageModel\n","from unsloth import is_bfloat16_supported\n","import torch\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from datasets import load_dataset\n","\n","\n","max_seq_length = 2048 # Supports RoPE Scaling interally, so choose any!\n","# Get LAION dataset\n","url = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\n","dataset = load_dataset(\"json\", data_files = {\"train\" : url}, split = \"train\")\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",      # New Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/llama-3-8b-bnb-4bit\",           # Llama-3 15 trillion tokens model 2x faster!\n","    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n","    \"unsloth/llama-3-70b-bnb-4bit\",\n","    \"unsloth/Phi-3-mini-4k-instruct\",        # Phi-3 2x faster!\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/mistral-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = None,\n","    load_in_4bit = True,\n",")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hQMntxwCrNb3"},"source":["```python\n","# Do model patching and add fast LoRA weights\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16,\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    max_seq_length = max_seq_length,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    tokenizer = tokenizer,\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 10,\n","        max_steps = 60,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        output_dir = \"outputs\",\n","        optim = \"adamw_8bit\",\n","        seed = 3407,\n","    ),\n",")\n","trainer.train()\n","\n","# Go to https://github.com/unslothai/unsloth/wiki for advanced tips like\n","# (1) Saving to GGUF / merging to 16bit for vLLM\n","# (2) Continued training from a saved LoRA adapter\n","# (3) Adding an evaluation loop / OOMs\n","# (4) Customized chat templates\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvBPqb1Xq7qu"},"outputs":[],"source":["from unsloth.chat_templates import get_chat_template\n","\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = \"llama-3.1\",\n",")\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True, # Must add for generation\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n","                         temperature = 1.5, min_p = 0.1)\n","tokenizer.batch_decode(outputs)\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n","_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n","                   use_cache = True, temperature = 1.5, min_p = 0.1)"]},{"cell_type":"markdown","metadata":{"id":"pjvYcEhUz7mX"},"source":["# Valid Task with Agents"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"JCMUnahkgUwA","executionInfo":{"status":"ok","timestamp":1726018914985,"user_tz":-540,"elapsed":7541,"user":{"displayName":"정권환","userId":"03859214150473665717"}}},"outputs":[],"source":["%%capture\n","!apt-get install chromium-browser\n","!apt-get install chromium-driver\n","!pip install pyautogen crewai[tools] duckduckgo-search langchain langchain-community arxiv xmltodict langchain-huggingface youtube-transcript-api pytube"]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1_Qf105TIpO","executionInfo":{"status":"ok","timestamp":1726032736865,"user_tz":-540,"elapsed":623,"user":{"displayName":"정권환","userId":"03859214150473665717"}},"outputId":"27c739b7-7889-4559-e59f-a884ee822745"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["The capital of France is **Paris**. 🗼 🇫🇷 \n","\n"]}]},{"cell_type":"code","source":["dir(label_crew)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nK_6M9ZSmyhl","executionInfo":{"status":"ok","timestamp":1726033398910,"user_tz":-540,"elapsed":491,"user":{"displayName":"정권환","userId":"03859214150473665717"}},"outputId":"cdb2e961-c8c5-4759-b830-35b0baf24817"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['__abstractmethods__',\n"," '__annotations__',\n"," '__class__',\n"," '__class_getitem__',\n"," '__class_vars__',\n"," '__copy__',\n"," '__deepcopy__',\n"," '__delattr__',\n"," '__dict__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__fields__',\n"," '__fields_set__',\n"," '__format__',\n"," '__ge__',\n"," '__get_pydantic_core_schema__',\n"," '__get_pydantic_json_schema__',\n"," '__getattr__',\n"," '__getattribute__',\n"," '__getstate__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__iter__',\n"," '__le__',\n"," '__lt__',\n"," '__module__',\n"," '__ne__',\n"," '__new__',\n"," '__pretty__',\n"," '__private_attributes__',\n"," '__pydantic_complete__',\n"," '__pydantic_core_schema__',\n"," '__pydantic_custom_init__',\n"," '__pydantic_decorators__',\n"," '__pydantic_extra__',\n"," '__pydantic_fields_set__',\n"," '__pydantic_generic_metadata__',\n"," '__pydantic_init_subclass__',\n"," '__pydantic_parent_namespace__',\n"," '__pydantic_post_init__',\n"," '__pydantic_private__',\n"," '__pydantic_root_model__',\n"," '__pydantic_serializer__',\n"," '__pydantic_validator__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__repr_args__',\n"," '__repr_name__',\n"," '__repr_str__',\n"," '__rich_repr__',\n"," '__rshift__',\n"," '__setattr__',\n"," '__setstate__',\n"," '__signature__',\n"," '__sizeof__',\n"," '__slots__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__weakref__',\n"," '_abc_impl',\n"," '_add_delegation_tools',\n"," '_calculate_keys',\n"," '_check_frozen',\n"," '_copy_and_set_values',\n"," '_create_crew_output',\n"," '_create_manager_agent',\n"," '_create_task',\n"," '_deny_user_set_id',\n"," '_execute_tasks',\n"," '_find_task_index',\n"," '_finish_execution',\n"," '_get_agent_to_use',\n"," '_get_context',\n"," '_get_value',\n"," '_handle_conditional_task',\n"," '_handle_crew_planning',\n"," '_interpolate_inputs',\n"," '_iter',\n"," '_log_task_start',\n"," '_prepare_agent_tools',\n"," '_process_async_tasks',\n"," '_process_task_result',\n"," '_run_hierarchical_process',\n"," '_run_sequential_process',\n"," '_set_tasks_callbacks',\n"," '_setup_for_training',\n"," '_setup_from_config',\n"," '_store_execution_log',\n"," '_telemetry',\n"," '_update_manager_tools',\n"," 'agents',\n"," 'cache',\n"," 'calculate_usage_metrics',\n"," 'check_config',\n"," 'check_config_type',\n"," 'check_manager_llm',\n"," 'config',\n"," 'construct',\n"," 'copy',\n"," 'create_crew_memory',\n"," 'dict',\n"," 'embedder',\n"," 'execution_logs',\n"," 'from_orm',\n"," 'function_calling_llm',\n"," 'id',\n"," 'json',\n"," 'key',\n"," 'kickoff',\n"," 'kickoff_async',\n"," 'kickoff_for_each',\n"," 'kickoff_for_each_async',\n"," 'manager_agent',\n"," 'manager_callbacks',\n"," 'manager_llm',\n"," 'max_rpm',\n"," 'memory',\n"," 'model_computed_fields',\n"," 'model_config',\n"," 'model_construct',\n"," 'model_copy',\n"," 'model_dump',\n"," 'model_dump_json',\n"," 'model_extra',\n"," 'model_fields',\n"," 'model_fields_set',\n"," 'model_json_schema',\n"," 'model_parametrized_name',\n"," 'model_post_init',\n"," 'model_rebuild',\n"," 'model_validate',\n"," 'model_validate_json',\n"," 'model_validate_strings',\n"," 'name',\n"," 'output_log_file',\n"," 'parse_file',\n"," 'parse_obj',\n"," 'parse_raw',\n"," 'planning',\n"," 'planning_llm',\n"," 'process',\n"," 'prompt_file',\n"," 'replay',\n"," 'schema',\n"," 'schema_json',\n"," 'set_private_attrs',\n"," 'share_crew',\n"," 'step_callback',\n"," 'task_callback',\n"," 'task_execution_output_json_files',\n"," 'tasks',\n"," 'test',\n"," 'train',\n"," 'update_forward_refs',\n"," 'usage_metrics',\n"," 'validate',\n"," 'validate_async_task_cannot_include_sequential_async_tasks_in_context',\n"," 'validate_async_tasks_not_async',\n"," 'validate_context_no_future_tasks',\n"," 'validate_end_with_at_most_one_async_task',\n"," 'validate_first_task',\n"," 'validate_tasks',\n"," 'verbose']"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":797},"id":"EVxOayl1a_bT","executionInfo":{"status":"error","timestamp":1726033935716,"user_tz":-540,"elapsed":160602,"user":{"displayName":"정권환","userId":"03859214150473665717"}},"outputId":"f55c11fe-c849-4212-e654-4ca0c894456d"},"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"]},{"output_type":"stream","name":"stdout","text":["Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","\u001b[1m\u001b[95m [2024-09-11 05:49:35][DEBUG]: == Working Agent: 데이터 생성가\u001b[00m\n","\u001b[1m\u001b[95m [2024-09-11 05:49:35][INFO]: == Starting Task: \n","generate the dataset with prompt, chosen, rejected.\n","shoud use tools for generating the dataset.\n","Thought more creativly and has detail\n","this task's final answer should be written in korean.\n","\n","Start!\n","\n","topic: what is omni in gpt4o\n","Let's think step by step\n","\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n"]},{"output_type":"error","ename":"CancelledError","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-90-523600758b27>\u001b[0m in \u001b[0;36m<cell line: 224>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m result = await label_crew.kickoff_async(\n\u001b[0m\u001b[1;32m    225\u001b[0m     inputs=dict(\n\u001b[1;32m    226\u001b[0m         \u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"what is omni in gpt4o\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff_async\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkickoff_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;34m\"\"\"Asynchronous kickoff method to start the crew execution.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkickoff_for_each_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCrewOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/asyncio/threads.py\u001b[0m in \u001b[0;36mto_thread\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfunc_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_in_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mCancelledError\u001b[0m: "]}],"source":["import os\n","import datetime\n","from langchain_huggingface import HuggingFaceEndpoint\n","from crewai import Agent, Task, Crew, Process, Pipeline\n","from crewai_tools import (SerperDevTool, ScrapeWebsiteTool, DallETool,\n","                          WebsiteSearchTool, SeleniumScrapingTool, tool)\n","from crewai import Agent, Task, Crew\n","from langchain_community.tools import (WikipediaQueryRun,\n","                                       PubmedQueryRun, YouTubeSearchTool, OpenWeatherMapQueryRun)\n","from langchain_community.utilities import SearxSearchWrapper\n","from langchain_community.tools import DuckDuckGoSearchRun, SearxSearchRun\n","from langchain_community.agent_toolkits.jira.toolkit import JiraToolkit\n","from langchain_community.agent_toolkits.github.toolkit import GitHubToolkit\n","from langchain_community.utilities import SearxSearchWrapper\n","from langchain_community.tools.arxiv.tool import ArxivQueryRun\n","from langchain_community.tools.google_trends.tool import GoogleTrendsQueryRun\n","from langchain.llms import Ollama\n","\n","from pydantic import BaseModel\n","\n","class AgentSharedForm(BaseModel):\n","    prompt:str\n","    chosen:str\n","    rejected:str\n","\n","\n","# ollama_openhermes = Ollama(model=\"openhermes\")\n","# ollama_solar = Ollama(model=\"solar\")\n","\n","def get_month(date=(datetime.datetime.now() + datetime.timedelta(hours=9)).strftime(\"%Y%m\")):\n","    year = int(date[:4])\n","    month = int(date[4:])\n","    return f\"{year}{month:02d}\"\n","\n","# repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n","# repo_id = \"HuggingFaceH4/zephyr-7b-beta\"  # 한글 성능 낮음\n","repo_id = \"mistralai/Mistral-Nemo-Instruct-2407\"\n","# repo_id = \"HuggingFaceH4/zephyr-7b-beta\"\n","# repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n","# repo_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","# repo_id = \"google/gemma-2-2b-it\"\n","repo_id = \"google/gemma-2-27b-it\" # async로만 동작\n","\n","lab_llm = HuggingFaceEndpoint(\n","    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n","    max_new_tokens=1024,  # 생성할 최대 토큰 길이를 설정합니다.\n","    temperature=0.4,\n","    do_sample=True,\n","    huggingfacehub_api_token=os.environ[\"HF_WRITE_TOKEN\"],  # 허깅페이스 토큰\n",")\n","\n","val_llm = HuggingFaceEndpoint(\n","    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n","    max_new_tokens=1024,  # 생성할 최대 토큰 길이를 설정합니다.\n","    temperature=0.4,\n","    do_sample=True,\n","    huggingfacehub_api_token=os.environ[\"HF_WRITE_TOKEN\"],  # 허깅페이스 토큰\n",")\n","\n","search_tool = SerperDevTool()\n","scrape_tool = ScrapeWebsiteTool()\n","ddg_search_tool = DuckDuckGoSearchRun()\n","ng_search_tool = SearxSearchRun(\n","    wrapper= SearxSearchWrapper(\n","        searx_host=\"http://127.0.0.1:8888\",\n","        k=5\n","    )\n",")\n","paper_search_tool = ArxivQueryRun()\n","pub_search_tool = PubmedQueryRun()\n","youtube_search_tool = YouTubeSearchTool()\n","dalle_tool = DallETool()\n","idol_schedule_tool = SeleniumScrapingTool(\n","    website_url=f\"https://blip.kr/schedule/{get_month()}\",\n","    css_element='.schedule-card-container',\n","    wait_time=3)\n","# weather_tool = OpenWeatherMapQueryRun() # Need API key\n","# wiki_search_tool = WikipediaQueryRun() # Need API key\n","# web_rag_tool = WebsiteSearchTool() # Need API key\n","# trend_tool = GoogleTrendsQueryRun() # Need API key\n","\n","# Define your agents with roles and goals\n","validator = Agent(\n","  role='RLHF 평가요원',\n","  goal='주어진 채팅 턴에 대해 사람에게 유용한 텍스트를 채택',\n","  backstory=\"\"\"\n","RLHF 평가요원으로서 일하며 올바른 처리를 할 때마다 보너스를 지급받습니다.\n","돈에 미쳐서 올바른 처리에 몰두하며 라벨러를 압박하여 더 적합한 응답을 재생성하도록 합니다.\n","부정확하거나 할루시네이션을 평가하기 위해 검색한 내용을 세세하게 대조하며 텍스트에 대해 분석합니다.\n","LLM 학습에 대한 이해가 있어, 데이터가 비어있는 경우 학습에 유리한 쪽으로 빈 데이터를 채워넣습니다.\n","평가 요원이 검수 완료된 데이터만을 사용할 수 있습니다.\n","주어진 도구 중 task에 가장 적합한 도구를 판단하여 사용합니다.\n","\"\"\",\n","  verbose=True,\n","  llm=val_llm, # ollama_openhermes,\n","  allow_delegation=False,\n","#   agent_executor=[None],\n","  tools=[\n","      ddg_search_tool,\n","      scrape_tool,\n","      paper_search_tool,\n","      pub_search_tool,\n","      youtube_search_tool,\n","    #   idol_schedule_tool,\n","    #   dalle_tool,\n","    #   weather_tool, # Need API key\n","    #   wiki_search_tool, # Need API key\n","    #   web_rag_tool, # Need API key\n","    ]\n",")\n","\n","labeler = Agent(\n","  role='데이터 생성가',\n","  goal='풍부한 상상력과 창의력으로 Q,A를 작성',\n","  backstory=\"\"\"\n","상상력과 창의적인 작업자로, 데이터 생성업무를 하기 전 작가 활동을 하였을 정도로 글 작성에 높은 능력이 있습니다.\n","주어진 키워드를 검색하여 나온 자료를 통해 수많은 상상을 하여 prompt, chosen, rejected 문장을 작성합니다.\n","- prompt: 문서를 보고 수 많은 페르소나의 인물들이 할 수 있는 질문을 구상합니다.\n","- chosen: prompt에 대해 문서에서 답을 찾아 정확하고 간결하며 필요할 수 있는 정보를 전문가 수준으로 작성합니다.\n","- rejected: prompt에 적합하지 않은 응답이나 문서와 일치하지 않는 내용의 할루시네이션으로 작성되어집니다.\n","글 쓰는 일을 좋아하며 깐깐한 평가요원의 압박에도 글을 더 창의적으로 작성해버립니다.\n","주어진 도구 중 task에 가장 적합한 도구를 판단하여 사용합니다.\n","\"\"\",\n","  verbose=True,\n","  llm=lab_llm, # ollama_solar,\n","  allow_delegation=True,\n","#   agent_executor=[None],\n","  tools=[\n","      ddg_search_tool,\n","      scrape_tool,\n","      paper_search_tool,\n","      pub_search_tool,\n","      youtube_search_tool,\n","    #   idol_schedule_tool,\n","    #   dalle_tool,\n","    #   weather_tool, # Need API key\n","    #   wiki_search_tool, # Need API key\n","    #   web_rag_tool, # Need API key\n","    ]\n",")\n","\n","# Create tasks for your agents\n","\n","labeling = Task(\n","  description=\"\"\"\n","generate the dataset with prompt, chosen, rejected.\n","shoud use tools for generating the dataset.\n","Thought more creativly and has detail\n","this task's final answer should be written in korean.\n","\n","Start!\n","\n","topic: {topic}\n","Let's think step by step\n","\"\"\",\n","  expected_output='json',\n","  allow_delegation=False,\n","  pydantic=AgentSharedForm,\n","  agent=labeler,\n","  max_iter=2,\n",")\n","\n","validation = Task(\n","  description=\"\"\"\n","생성된 데이터를 검수하고 라벨러에게 피드백을 전송합니다.\n","topic: {topic}\n","Let's think step by step\n","\"\"\",\n","  expected_output='json',\n","  agent=validator,\n","  allow_delegation=True,\n","  pydantic=AgentSharedForm,\n","  max_iter=2,\n","  context=[labeling,]\n",")\n","\n","making_data = Task(\n","      description=\"\"\"\n","피드백과 요청 사항에 따라 데이터를 재생성합니다.\n","Let's think step by step\n","\"\"\",\n","  expected_output='json',\n","  agent=labeler,\n","  max_iter=2,\n","  allow_delegation=False,\n","  pydantic=AgentSharedForm,\n","  context=[validation]\n","\n",")\n","\n","# Instantiate your crew with a sequential process\n","label_crew = Crew(\n","  agents=[labeler, validator, labeler],\n","  tasks=[labeling, validation, making_data],\n","  verbose=True, # Crew verbose more will let you know what tasks are being worked on, you can set it to 1 or 2 to different logging levels\n","  process=Process.sequential # Sequential process will have tasks executed one after the other and the outcome of the previous one is passed as extra content into this next.\n",")\n","\n","# valid_crew = Crew(\n","#   agents=[ validator,],\n","#   tasks=[validation],\n","#   verbose=False, # Crew verbose more will let you know what tasks are being worked on, you can set it to 1 or 2 to different logging levels\n","#   process=Process.sequential # Sequential process will have tasks executed one after the other and the outcome of the previous one is passed as extra content into this next.\n","# )\n","\n","# output_crew = Crew(\n","#   agents=[ labeler,],\n","#   tasks=[making_data],\n","#   verbose=False, # Crew verbose more will let you know what tasks are being worked on, you can set it to 1 or 2 to different logging levels\n","#   process=Process.sequential # Sequential process will have tasks executed one after the other and the outcome of the previous one is passed as extra content into this next.\n","# )\n","\n","# pipeline = Pipeline(\n","#     stages=[label_crew, valid_crew, output_crew]\n","# )\n","\n","# # Get your crew to work!\n","# result = await pipeline.process_single_kickoff(\n","#     dict(\n","#         topic=\"서울의 봄\"\n","#     )\n","# )\n","\n","result = await label_crew.kickoff_async(\n","    inputs=dict(\n","        topic=\"what is omni in gpt4o\"\n","    )\n",")\n","\n","print(\"######################\")\n","print(result)"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"ULL3stlV_iig","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1726033765504,"user_tz":-540,"elapsed":70510,"user":{"displayName":"정권환","userId":"03859214150473665717"}},"outputId":"59cde0c6-aecc-4ebe-ce55-aa0a26a01c97"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m\u001b[95m [2024-09-11 05:48:14][DEBUG]: == Working Agent: 라벨러\u001b[00m\n","\u001b[1m\u001b[95m [2024-09-11 05:48:14][INFO]: == Starting Task: \n","주제에 대한 질문과 답변을 생성합니다.\n","\n","주제: mamba vs transformers\n","\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to find out more about Mamba and Transformers.\n","\n","Action: duckduckgo_search\n","Action Input: {'query': 'Mamba and Transformers'}\n","\n","Observation\u001b[0m\u001b[95m \n","\n","A Visual Guide to Mamba and State Space Models. February 21, 2024 21 minute read. The Transformer architecture has been a major component in the success of Large Language Models (LLMs). It has been used for nearly all LLMs that are being used today, from open-source models like Mistral to closed-source models like ChatGPT. Mamba Explained. 27.Mar.2024 . 20 min read. The State Space Model taking on Transformers. Right now, AI is eating the world. And by AI, I mean Transformers. Practically all the big breakthroughs in AI over the last few years are due to Transformers. Mamba, however, is one of an alternative class of models called State Space Models (SSMs). Mamba enjoys fast inference (5 × higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. To meet the objectives, we propose a multi-scale hybrid Mamba-Transformer experts model State Space Transformer (SST). SST leverages Mamba as an expert to extract global patterns in coarse-grained long-range time series, and Local Window Transformer (LWT), the other expert to focus on capturing local variations in fine-grained short-range time ... It consists of linear Transformer and Mamba, which has global modeling capabilities while maintaining linear complexity. Due to the difference between the Transformer and Mamba structures, the features extracted by the two branches carry channel and position information respectively. T-M interaction structure is designed between the two ...\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3mObservation: This is a lot of information, I need to filter it down to the key points.\n","\n","Thought:\n","I need to find out more about Mamba and Transformers.\n","\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2305.14236'}\n","\n","Observation\u001b[0m\u001b[95m \n","\n","[2305.14236] REC-MV: REconstructing 3D Dynamic Cloth from Monocular Videos\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > cs > arXiv:2305.14236\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","Computer Science > Computer Vision and Pattern Recognition\n","arXiv:2305.14236 (cs)\n"," [Submitted on 23 May 2023 (v1), last revised 27 May 2023 (this version, v2)]\n","Title:REC-MV: REconstructing 3D Dynamic Cloth from Monocular Videos\n","Authors:Lingteng Qiu, Guanying Chen, Jiapeng Zhou, Mutian Xu, Junle Wang, Xiaoguang Han View a PDF of the paper titled REC-MV: REconstructing 3D Dynamic Cloth from Monocular Videos, by Lingteng Qiu and 4 other authors\n","View PDF\n","Abstract:Reconstructing dynamic 3D garment surfaces with open boundaries from monocular videos is an important problem as it provides a practical and low-cost solution for clothes digitization. Recent neural rendering methods achieve high-quality dynamic clothed human reconstruction results from monocular video, but these methods cannot separate the garment surface from the body. Moreover, despite existing garment reconstruction methods based on feature curve representation demonstrating impressive results for garment reconstruction from a single image, they struggle to generate temporally consistent surfaces for the video input. To address the above limitations, in this paper, we formulate this task as an optimization problem of 3D garment feature curves and surface reconstruction from monocular video. We introduce a novel approach, called REC-MV, to jointly optimize the explicit feature curves and the implicit signed distance field (SDF) of the garments. Then the open garment meshes can be extracted via garment template registration in the canonical space. Experiments on multiple casually captured datasets show that our approach outperforms existing methods and can produce high-quality dynamic garment surfaces. The source code is available at this https URL.\n","Comments:\n","CVPR2023; Project Page:this https URL\n","Subjects:\n","Computer Vision and Pattern Recognition (cs.CV)\n","Cite as:\n","arXiv:2305.14236 [cs.CV]\n","(or \n","arXiv:2305.14236v2 [cs.CV] for this version)\n"," https://doi.org/10.48550/arXiv.2305.14236\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Submission history From: Lingteng Qiu [view email] [v1]\n"," Tue, 23 May 2023 16:53:10 UTC (41,207 KB)\n","[v2]\n"," Sat, 27 May 2023 17:01:54 UTC (41,207 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled REC-MV: REconstructing 3D Dynamic Cloth from Monocular Videos, by Lingteng Qiu and 4 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: cs.CV\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-05\n"," Change to browse by:\n","cs\n","References & Citations\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought:\n","I now can give a great answer\n","Final Answer:\n","{\n","  \"Mamba\": {\n","    \"Definition\": \"Mamba is a sequence model architecture that is an alternative to the Transformer. It is a State Space Model (SSM) that offers fast inference and linear scaling in sequence length. Mamba enjoys 5 × higher throughput than Transformers and its performance improves on real data up to million-length sequences. It achieves state-of-the-art performance across several modalities such as language, audio, and genomics.\",\n","    \"Advantages\": \"Mamba's advantages include fast inference, linear scaling in sequence length, and state-of-the-art performance across multiple modalities.\",\n","    \"Use Cases\": \"Mamba is used as a general sequence model backbone and has been used in various applications such as language modeling, audio processing, and genomics.\"\n","  },\n","  \"Transformers\": {\n","    \"Definition\": \"The Transformer architecture is a major component in the success of Large Language Models (LLMs). It has been used for nearly all LLMs that are being used today, from open-source models like Mistral to closed-source models like ChatGPT.\",\n","    \"Advantages\": \"Transformers have been instrumental in the success of LLMs and have been used in a wide range of applications.\",\n","    \"Use Cases\": \"Transformers are used in a wide range of applications, including language modeling, image classification, and more.\"\n","  },\n","  \"Comparison\": \"While both Mamba and Transformers have their own strengths, Mamba offers faster inference and linear scaling in sequence length, while Transformers have been widely adopted and used in a wide range of applications.\"\n","}</s>\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[1m\u001b[92m [2024-09-11 05:48:29][DEBUG]: == [라벨러] Task output: {\n","  \"Mamba\": {\n","    \"Definition\": \"Mamba is a sequence model architecture that is an alternative to the Transformer. It is a State Space Model (SSM) that offers fast inference and linear scaling in sequence length. Mamba enjoys 5 × higher throughput than Transformers and its performance improves on real data up to million-length sequences. It achieves state-of-the-art performance across several modalities such as language, audio, and genomics.\",\n","    \"Advantages\": \"Mamba's advantages include fast inference, linear scaling in sequence length, and state-of-the-art performance across multiple modalities.\",\n","    \"Use Cases\": \"Mamba is used as a general sequence model backbone and has been used in various applications such as language modeling, audio processing, and genomics.\"\n","  },\n","  \"Transformers\": {\n","    \"Definition\": \"The Transformer architecture is a major component in the success of Large Language Models (LLMs). It has been used for nearly all LLMs that are being used today, from open-source models like Mistral to closed-source models like ChatGPT.\",\n","    \"Advantages\": \"Transformers have been instrumental in the success of LLMs and have been used in a wide range of applications.\",\n","    \"Use Cases\": \"Transformers are used in a wide range of applications, including language modeling, image classification, and more.\"\n","  },\n","  \"Comparison\": \"While both Mamba and Transformers have their own strengths, Mamba offers faster inference and linear scaling in sequence length, while Transformers have been widely adopted and used in a wide range of applications.\"\n","}</s>\n","\n","\u001b[00m\n","\u001b[1m\u001b[95m [2024-09-11 05:48:29][DEBUG]: == Working Agent: 평가요원\u001b[00m\n","\u001b[1m\u001b[95m [2024-09-11 05:48:29][INFO]: == Starting Task: \n","생성된 답변을 평가합니다.\n","\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to find out more about Mamba and Transformers to provide a comprehensive evaluation.\n","\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3m arXiv Operational Status\n","arXiv is a free distribution service for use by scholars to exchange information concerning research in physics and related scientific areas. For information about reusing arXiv content and data, see our copyright help page.\n","arXiv is owned and operated by Cornell University with funding provided by a grant from the Simons Foundation. For other sources of funding, including individual, institutional and corporate contributions, see our list of supporters.\n","arXiv is a registered trademark of Cornell University.\n","Last modified: October 16, 2023.\n","Thought:\n","This paper is not related to Mamba or Transformers. I need to find a more relevant paper.\n","\n","Action: arxiv\n","Action Input: {'query': 'Mamba'}\n","Observation\u001b[0m\u001b[95m \n","\n","Published: 2024-07-22\n","Title: Mamba meets crack segmentation\n","Authors: Zhili He, Yu-Hsing Wang\n","Summary: Cracks pose safety risks to infrastructure and cannot be overlooked. The\n","prevailing structures in existing crack segmentation networks predominantly\n","consist of CNNs or Transformers. However, CNNs exhibit a deficiency in global\n","modeling capability, hindering the representation to entire crack features.\n","Transformers can capture long-range dependencies but suffer from high and\n","quadratic complexity. Recently, Mamba has garnered extensive attention due to\n","its linear spatial and computational complexity and its powerful global\n","perception. This study explores the representation capabilities of Mamba to\n","crack features. Specifically, this paper uncovers the connection between Mamba\n","and the attention mechanism, providing a profound insight, an attention\n","perspective, into interpreting Mamba and devising a novel Mamba module\n","following the principles of attention blocks, namely CrackMamba. We compare\n","CrackMamba with the most prominent visual Mamba modules, Vim and Vmamba, on two\n","datasets comprising asphalt pavement and concrete pavement cracks, and steel\n","cracks, respectively. The quantitative results show that CrackMamba stands out\n","as the sole Mamba block consistently enhancing the baseline model's performance\n","across all evaluation measures, while reducing its parameters and computational\n","costs. Moreover, this paper substantiates that Mamba can achieve global\n","receptive fields through both theoretical analysis and visual interpretability.\n","The discoveries of this study offer a dual contribution. First, as a\n","plug-and-play and simple yet effective Mamba module, CrackMamba exhibits\n","immense potential for integration into various crack segmentation models.\n","Second, the proposed innovative Mamba design concept, integrating Mamba with\n","the attention mechanism, holds significant reference value for all Mamba-based\n","computer vision models, not limited to crack segmentation networks, as\n","investigated in this study.\n","\n","Published: 2024-04-09\n","Title: Deep Mamba Multi-modal Learning\n","Authors: Jian Zhu, Xin Zou, Yu Cui, Zhangmin Huang, Chenshu Hu, Bo Lyu\n","Summary: Inspired by the excellent performance of Mamba networks, we propose a novel\n","Deep Mamba Multi-modal Learning (DMML). It can be used to achieve the fusion of\n","multi-modal features. We apply DMML to the field of multimedia retrieval and\n","propose an innovative Deep Mamba Multi-modal Hashing (DMMH) method. It combines\n","the advantages of algorithm accuracy and inference speed. We validated the\n","effectiveness of DMMH on three public datasets and achieved state-of-the-art\n","results.\n","\n","Published: 2024-07-22\n","Title: Investigating the Indirect Object Identification circuit in Mamba\n","Authors: Danielle Ensign, Adrià Garriga-Alonso\n","Summary: How well will current interpretability techniques generalize to future\n","models? A relevant case study is Mamba, a recent recurrent architecture with\n","scaling comparable to Transformers. We adapt pre-Mamba techniques to Mamba and\n","partially reverse-engineer the circuit responsible for the Indirect Object\n","Identification (IOI) task. Our techniques provide evidence that 1) Layer 39 is\n","a key bottleneck, 2) Convolutions in layer 39 shift names one position forward,\n","and 3) The name entities are stored linearly in Layer 39's SSM. Finally, we\n","adapt an automatic circuit discovery tool, positional Edge Attribution\n","Patching, to identify a Mamba IOI circuit. Our contributions provide initial\n","evidence that circuit-based mechanistic interpretability tools work well for\n","the Mamba architecture.\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3mThought:\n","Now that I have relevant information about Mamba, I need to compare it with Transformers.\n","\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mCurrent Task:\n","What are the advantages of Mamba over Transformers?\n","\n","Thought: I need to find out more about Mamba and Transformers to provide a comprehensive answer.\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to find out more about Mamba and Transformers to provide a comprehensive evaluation.\n","\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3m arXiv Operational Status\n","arXiv is a free distribution service for use by scholars to exchange information concerning research in physics and related scientific areas. For information about reusing arXiv content and data, see our copyright help page.\n","arXiv is owned and operated by Cornell University with funding provided by a grant from the Simons Foundation. For other sources of funding, including individual, institutional and corporate contributions, see our list of supporters.\n","arXiv is a registered trademark of Cornell University.\n","Last modified: October 16, 2023.\n","Thought:\n","This paper is not related to Mamba or Transformers. I need to find a more relevant paper.\n","\n","Action: arxiv\n","Action Input: {'query': 'Mamba'}\n","Observation\u001b[0m\u001b[95m \n","\n","Published: 2024-07-22\n","Title: Mamba meets crack segmentation\n","Authors: Zhili He, Yu-Hsing Wang\n","Summary: Cracks pose safety risks to infrastructure and cannot be overlooked. The\n","prevailing structures in existing crack segmentation networks predominantly\n","consist of CNNs or Transformers. However, CNNs exhibit a deficiency in global\n","modeling capability, hindering the representation to entire crack features.\n","Transformers can capture long-range dependencies but suffer from high and\n","quadratic complexity. Recently, Mamba has garnered extensive attention due to\n","its linear spatial and computational complexity and its powerful global\n","perception. This study explores the representation capabilities of Mamba to\n","crack features. Specifically, this paper uncovers the connection between Mamba\n","and the attention mechanism, providing a profound insight, an attention\n","perspective, into interpreting Mamba and devising a novel Mamba module\n","following the principles of attention blocks, namely CrackMamba. We compare\n","CrackMamba with the most prominent visual Mamba modules, Vim and Vmamba, on two\n","datasets comprising asphalt pavement and concrete pavement cracks, and steel\n","cracks, respectively. The quantitative results show that CrackMamba stands out\n","as the sole Mamba block consistently enhancing the baseline model's performance\n","across all evaluation measures, while reducing its parameters and computational\n","costs. Moreover, this paper substantiates that Mamba can achieve global\n","receptive fields through both theoretical analysis and visual interpretability.\n","The discoveries of this study offer a dual contribution. First, as a\n","plug-and-play and simple yet effective Mamba module, CrackMamba exhibits\n","immense potential for integration into various crack segmentation models.\n","Second, the proposed innovative Mamba design concept, integrating Mamba with\n","the attention mechanism, holds significant reference value for all Mamba-based\n","computer vision models, not limited to crack segmentation networks, as\n","investigated in this study.\n","\n","Published: 2024-04-09\n","Title: Deep Mamba Multi-modal Learning\n","Authors: Jian Zhu, Xin Zou, Yu Cui, Zhangmin Huang, Chenshu Hu, Bo Lyu\n","Summary: Inspired by the excellent performance of Mamba networks, we propose a novel\n","Deep Mamba Multi-modal Learning (DMML). It can be used to achieve the fusion of\n","multi-modal features. We apply DMML to the field of multimedia retrieval and\n","propose an innovative Deep Mamba Multi-modal Hashing (DMMH) method. It combines\n","the advantages of algorithm accuracy and inference speed. We validated the\n","effectiveness of DMMH on three public datasets and achieved state-of-the-art\n","results.\n","\n","Published: 2024-07-22\n","Title: Investigating the Indirect Object Identification circuit in Mamba\n","Authors: Danielle Ensign, Adrià Garriga-Alonso\n","Summary: How well will current interpretability techniques generalize to future\n","models? A relevant case study is Mamba, a recent recurrent architecture with\n","scaling comparable to Transformers. We adapt pre-Mamba techniques to Mamba and\n","partially reverse-engineer the circuit responsible for the Indirect Object\n","Identification (IOI) task. Our techniques provide evidence that 1) Layer 39 is\n","a key bottleneck, 2) Convolutions in layer 39 shift names one position forward,\n","and 3) The name entities are stored linearly in Layer 39's SSM. Finally, we\n","adapt an automatic circuit discovery tool, positional Edge Attribution\n","Patching, to identify a Mamba IOI circuit. Our contributions provide initial\n","evidence that circuit-based mechanistic interpretability tools work well for\n","the Mamba architecture.\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3mCurrent Task:\n","생성된 답변을 평가합니다.\n","\n","This is the expect criteria for your final answer: json\n"," you MUST return the actual complete content as the final answer, not a summary.\n","\n","Thought:\n","I need to find out more about Mamba and Transformers to provide a comprehensive evaluation.\n","\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3m arXiv Operational Status\n","arXiv is a free distribution service for use by scholars to exchange information concerning research in physics and related scientific areas. For information about reusing arXiv content and data, see our copyright help page.\n","arXiv is owned and operated by Cornell University with funding provided by a grant from the Simons Foundation. For other sources of funding, including individual, institutional and corporate contributions, see our list of supporters.\n","arXiv is a registered trademark of Cornell University.\n","Last modified: October 16, 2023.\n","Thought:\n","This paper is not related to Mamba or Transformers. I need to find a more relevant paper.\n","\n","Action: arxiv\n","Action Input: {'query': 'Mamba'}\n","Observation\u001b[0m\u001b[95m \n","\n","Published: 2024-07-22\n","Title: Mamba meets crack segmentation\n","Authors: Zhili He, Yu-Hsing Wang\n","Summary: Cracks pose safety risks to infrastructure and cannot be overlooked. The\n","prevailing structures in existing crack segmentation networks predominantly\n","consist of CNNs or Transformers. However, CNNs exhibit a deficiency in global\n","modeling capability, hindering the representation to entire crack features.\n","Transformers can capture long-range dependencies but suffer from high and\n","quadratic complexity. Recently, Mamba has garnered extensive attention due to\n","its linear spatial and computational complexity and its powerful global\n","perception. This study explores the representation capabilities of Mamba to\n","crack features. Specifically, this paper uncovers the connection between Mamba\n","and the attention mechanism, providing a profound insight, an attention\n","perspective, into interpreting Mamba and devising a novel Mamba module\n","following the principles of attention blocks, namely CrackMamba. We compare\n","CrackMamba with the most prominent visual Mamba modules, Vim and Vmamba, on two\n","datasets comprising asphalt pavement and concrete pavement cracks, and steel\n","cracks, respectively. The quantitative results show that CrackMamba stands out\n","as the sole Mamba block consistently enhancing the baseline model's performance\n","across all evaluation measures, while reducing its parameters and computational\n","costs. Moreover, this paper substantiates that Mamba can achieve global\n","receptive fields through both theoretical analysis and visual interpretability.\n","The discoveries of this study offer a dual contribution. First, as a\n","plug-and-play and simple yet effective Mamba module, CrackMamba exhibits\n","immense potential for integration into various crack segmentation models.\n","Second, the proposed innovative Mamba design concept, integrating Mamba with\n","the attention mechanism, holds significant reference value for all Mamba-based\n","computer vision models, not limited to crack segmentation networks, as\n","investigated in this study.\n","\n","Published: 2024-04-09\n","Title: Deep Mamba Multi-modal Learning\n","Authors: Jian Zhu, Xin Zou, Yu Cui, Zhangmin Huang, Chenshu Hu, Bo Lyu\n","Summary: Inspired by the excellent performance of Mamba networks, we propose a novel\n","Deep Mamba Multi-modal Learning (DMML). It can be used to achieve the fusion of\n","multi-modal features. We apply DMML to the field of multimedia retrieval and\n","propose an innovative Deep Mamba Multi-modal Hashing (DMMH) method. It combines\n","the advantages of algorithm accuracy and inference speed. We validated the\n","effectiveness of DMMH on three public datasets and achieved state-of-the-art\n","results.\n","\n","Published: 2024-07-22\n","Title: Investigating the Indirect Object Identification circuit in Mamba\n","Authors: Danielle Ensign, Adrià Garriga-Alonso\n","Summary: How well will current interpretability techniques generalize to future\n","models? A relevant case study is Mamba, a recent recurrent architecture with\n","scaling comparable to Transformers. We adapt pre-Mamba techniques to Mamba and\n","partially reverse-engineer the circuit responsible for the Indirect Object\n","Identification (IOI) task. Our techniques provide evidence that 1) Layer 39 is\n","a key bottleneck, 2) Convolutions in layer 39 shift names one position forward,\n","and 3) The name entities are stored linearly in Layer 39's SSM. Finally, we\n","adapt an automatic circuit discovery tool, positional Edge Attribution\n","Patching, to identify a Mamba IOI circuit. Our contributions provide initial\n","evidence that circuit-based mechanistic interpretability tools work well for\n","the Mamba architecture.\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3mThought:\n","I need to find out more about Mamba and Transformers to provide a comprehensive evaluation.\n","\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to find out more about Mamba and Transformers to provide a comprehensive evaluation.\n","\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3m arXiv Operational Status\n","arXiv is a free distribution service for use by scholars to exchange information concerning research in physics and related scientific areas. For information about reusing arXiv content and data, see our copyright help page.\n","arXiv is owned and operated by Cornell University with funding provided by a grant from the Simons Foundation. For other sources of funding, including individual, institutional and corporate contributions, see our list of supporters.\n","arXiv is a registered trademark of Cornell University.\n","Last modified: October 16, 2023.\n","Thought:\n","This paper is not related to Mamba or Transformers. I need to find a more relevant paper.\n","\n","Action: arxiv\n","Action Input: {'query': 'Mamba'}\n","Observation\u001b[0m\u001b[95m \n","\n","Published: 2024-07-22\n","Title: Mamba meets crack segmentation\n","Authors: Zhili He, Yu-Hsing Wang\n","Summary: Cracks pose safety risks to infrastructure and cannot be overlooked. The\n","prevailing structures in existing crack segmentation networks predominantly\n","consist of CNNs or Transformers. However, CNNs exhibit a deficiency in global\n","modeling capability, hindering the representation to entire crack features.\n","Transformers can capture long-range dependencies but suffer from high and\n","quadratic complexity. Recently, Mamba has garnered extensive attention due to\n","its linear spatial and computational complexity and its powerful global\n","perception. This study explores the representation capabilities of Mamba to\n","crack features. Specifically, this paper uncovers the connection between Mamba\n","and the attention mechanism, providing a profound insight, an attention\n","perspective, into interpreting Mamba and devising a novel Mamba module\n","following the principles of attention blocks, namely CrackMamba. We compare\n","CrackMamba with the most prominent visual Mamba modules, Vim and Vmamba, on two\n","datasets comprising asphalt pavement and concrete pavement cracks, and steel\n","cracks, respectively. The quantitative results show that CrackMamba stands out\n","as the sole Mamba block consistently enhancing the baseline model's performance\n","across all evaluation measures, while reducing its parameters and computational\n","costs. Moreover, this paper substantiates that Mamba can achieve global\n","receptive fields through both theoretical analysis and visual interpretability.\n","The discoveries of this study offer a dual contribution. First, as a\n","plug-and-play and simple yet effective Mamba module, CrackMamba exhibits\n","immense potential for integration into various crack segmentation models.\n","Second, the proposed innovative Mamba design concept, integrating Mamba with\n","the attention mechanism, holds significant reference value for all Mamba-based\n","computer vision models, not limited to crack segmentation networks, as\n","investigated in this study.\n","\n","Published: 2024-04-09\n","Title: Deep Mamba Multi-modal Learning\n","Authors: Jian Zhu, Xin Zou, Yu Cui, Zhangmin Huang, Chenshu Hu, Bo Lyu\n","Summary: Inspired by the excellent performance of Mamba networks, we propose a novel\n","Deep Mamba Multi-modal Learning (DMML). It can be used to achieve the fusion of\n","multi-modal features. We apply DMML to the field of multimedia retrieval and\n","propose an innovative Deep Mamba Multi-modal Hashing (DMMH) method. It combines\n","the advantages of algorithm accuracy and inference speed. We validated the\n","effectiveness of DMMH on three public datasets and achieved state-of-the-art\n","results.\n","\n","Published: 2024-07-22\n","Title: Investigating the Indirect Object Identification circuit in Mamba\n","Authors: Danielle Ensign, Adrià Garriga-Alonso\n","Summary: How well will current interpretability techniques generalize to future\n","models? A relevant case study is Mamba, a recent recurrent architecture with\n","scaling comparable to Transformers. We adapt pre-Mamba techniques to Mamba and\n","partially reverse-engineer the circuit responsible for the Indirect Object\n","Identification (IOI) task. Our techniques provide evidence that 1) Layer 39 is\n","a key bottleneck, 2) Convolutions in layer 39 shift names one position forward,\n","and 3) The name entities are stored linearly in Layer 39's SSM. Finally, we\n","adapt an automatic circuit discovery tool, positional Edge Attribution\n","Patching, to identify a Mamba IOI circuit. Our contributions provide initial\n","evidence that circuit-based mechanistic interpretability tools work well for\n","the Mamba architecture.\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3mThought:\n","Now that I have relevant information about Mamba, I need to compare it with Transformers.\n","\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mCurrent Task:\n","What are the advantages of Mamba over Transformers?\n","\n","Thought: I need to find out more about Mamba and Transformers to provide a comprehensive answer.\n","Action: Read website content\n","Action Input: {'website_url': 'https://arxiv.org/abs/2310.10452'}\n","Observation\u001b[0m\u001b[95m \n","\n","[2310.10452] Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Skip to main content\n","This week: the arXiv Accessibility Forum\n","Forum Schedule\n","We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n","Donate\n"," > hep-ex > arXiv:2310.10452\n","Help | Advanced Search\n","All fields\n","Title\n","Author\n","Abstract\n","Comments\n","Journal reference\n","ACM classification\n","MSC classification\n","Report number\n","arXiv identifier\n","DOI\n","ORCID\n","arXiv author ID\n","Help pages\n","Full text\n","Search\n","open search\n","GO\n","open navigation menu\n","quick links\n","Login\n","Help Pages\n","About\n","High Energy Physics - Experiment\n","arXiv:2310.10452 (hep-ex)\n"," [Submitted on 16 Oct 2023 (v1), last revised 29 Nov 2023 (this version, v2)]\n","Title:Measurement of the cross sections for $e^+e^-\\toηπ^+π^-$ at center-of-mass energies between 2.00 and 3.08 GeV\n","Authors:BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H.-R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen, Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, K Fischer, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang Gao, S. Garbolino\n"," , I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, N Hüsken, N. in der Wiesche, M. Irshad, J. Jackson, S. Jaeger, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, X. K., S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, Ke Li, L. J Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J. Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu\n"," et al. (530 additional authors not shown)\n"," You must enable JavaScript to view entire author list. View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authors\n","View PDF\n","Abstract:Using data samples collected at center-of-mass energies between 2.000 and 3.080 GeV with the BESIII detector operating at the BEPCII collider, a partial-wave analysis is performed on the process $e^+e^-\\to\\eta\\pi^+\\pi^-$. In addition to the dominant $e^+e^-\\to\\rho\\eta$ component, the $e^+e^-\\to a_2(1320)\\pi$ process is also sizeable, contributing up to 24% of the total reaction. The measured cross sections of the process $e^+e^-\\to\\eta\\pi^+\\pi^-$ are systematically higher than those of BaBar by more than $3\\sigma$ at center-of-mass energies between 2.000 and 2.300 GeV. In the cross section lineshape for $e^+e^-\\to a_2(1320)\\pi$, a resonant structure is observed with a significance of $5.5\\sigma$, with $M=(2044\\pm31\\pm4)$ MeV/$c^2$, $\\Gamma=(163\\pm69\\pm24)$ MeV and $\\mathcal{B_{R}}\\cdot\\Gamma_{e^+e^-}^{R}=(34.6\\pm17.1\\pm6.0)$ eV or $(137.1\\pm73.3\\pm2.1)$ eV. In the cross section lineshape for $e^+e^-\\to\\rho\\eta$, an evidence of a dip structure around 2180 MeV/$c^2$ is observed with statistical significance of $3.0\\sigma$.\n","Subjects:\n","High Energy Physics - Experiment (hep-ex)\n","Cite as:\n","arXiv:2310.10452 [hep-ex]\n","(or \n","arXiv:2310.10452v2 [hep-ex] for this version)\n"," https://doi.org/10.48550/arXiv.2310.10452\n","Focus to learn more\n"," arXiv-issued DOI via DataCite\n","Journal reference:\n","PHYS. REV. D 108, L111101 (2023)\n","Related DOI:\n","https://doi.org/10.1103/PhysRevD.108.L111101\n","Focus to learn more\n"," DOI(s) linking to related resources\n","Submission history From: Linqin Huang Mr. [view email] [v1]\n"," Mon, 16 Oct 2023 14:35:16 UTC (711 KB)\n","[v2]\n"," Wed, 29 Nov 2023 03:36:01 UTC (771 KB)\n","Full-text links:\n","Access Paper:\n","View a PDF of the paper titled Measurement of the cross sections for $e^+e^-\\to\\eta\\pi^+\\pi^-$ at center-of-mass energies between 2.00 and 3.08 GeV, by BESIII Collaboration: M. Ablikim and 628 other authorsView PDFTeX SourceOther Formats\n","view license\n"," Current browse context: hep-ex\n","< prev\n","  | \n","next >\n","new\n"," | \n","recent\n"," | 2023-10\n","References & Citations\n","INSPIRE HEP\n","NASA ADSGoogle Scholar\n","Semantic Scholar\n","a\n","export BibTeX citation\n","Loading...\n","BibTeX formatted citation\n","×\n","loading...\n","Data provided by: \n","Bookmark\n","Bibliographic Tools\n","Bibliographic and Citation Tools\n","Bibliographic Explorer Toggle\n","Bibliographic Explorer (What is the Explorer?)\n","Litmaps Toggle\n","Litmaps (What is Litmaps?)\n","scite.ai Toggle\n","scite Smart Citations (What are Smart Citations?)\n","Code, Data, Media\n","Code, Data and Media Associated with this Article\n","Links to Code Toggle\n","CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n","DagsHub Toggle\n","DagsHub (What is DagsHub?)\n","GotitPub Toggle\n","Gotit.pub (What is GotitPub?)\n","Links to Code Toggle\n","Papers with Code (What is Papers with Code?)\n","ScienceCast Toggle\n","ScienceCast (What is ScienceCast?)\n","Demos\n","Demos\n","Replicate Toggle\n","Replicate (What is Replicate?)\n","Spaces Toggle\n","Hugging Face Spaces (What is Spaces?)\n","Spaces Toggle\n","TXYZ.AI (What is TXYZ.AI?)\n","Related Papers\n","Recommenders and Search Tools\n","Link to Influence Flower\n","Influence Flower (What are Influence Flowers?)\n","Connected Papers Toggle\n","Connected Papers (What is Connected Papers?)\n","Core recommender toggle\n","CORE Recommender (What is CORE?)\n","Author\n","Venue\n","Institution\n","Topic\n"," About arXivLabs\n","arXivLabs: experimental projects with community collaborators\n","arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n","Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n","Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n","Which authors of this paper are endorsers? |\n"," Disable MathJax (What is MathJax?)\n","About\n","Help\n","contact arXivClick here to contact arXiv\n"," Contact\n","subscribe to arXiv mailingsClick here to subscribe\n"," Subscribe\n","Copyright\n","Privacy Policy\n","Web Accessibility Assistance\n","arXiv Operational Status Get status notifications via\n"," email\n"," or slack\n","\u001b[00m\n"]},{"output_type":"error","ename":"ValidationError","evalue":"Input validation error: `inputs` must have less than 16000 tokens. Given: 18178","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    210\u001b[0m                 {\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m             outputs = (\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m     80\u001b[0m                     \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1331\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1332\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1331\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1332\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3260\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3261\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3247\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3248\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   3249\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m                     \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0michunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m             \u001b[0;31m# The default implementation of transform is to buffer input and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5298\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 5299\u001b[0;31m         yield from self.bound.transform(\n\u001b[0m\u001b[1;32m   5300\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m                 )\n\u001b[0;32m--> 571\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m                 for chunk in self._stream(\n\u001b[0m\u001b[1;32m    556\u001b[0m                     \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_huggingface/llms/huggingface_endpoint.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         for response in self.client.text_generation(\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minvocation_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_common.py\u001b[0m in \u001b[0;36m_stream_text_generation_response\u001b[0;34m(bytes_output_as_lines, details)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_text_generation_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_payload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_common.py\u001b[0m in \u001b[0;36m_format_text_generation_stream_output\u001b[0;34m(byte_payload, details)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjson_payload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_parse_text_generation_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_payload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValidationError\u001b[0m: Input validation error: `inputs` must have less than 16000 tokens. Given: 18178","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    210\u001b[0m                 {\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m             outputs = (\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m     80\u001b[0m                     \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1331\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1332\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1331\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1332\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3260\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3261\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3247\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3248\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   3249\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m                     \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0michunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m             \u001b[0;31m# The default implementation of transform is to buffer input and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5298\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 5299\u001b[0;31m         yield from self.bound.transform(\n\u001b[0m\u001b[1;32m   5300\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m                 )\n\u001b[0;32m--> 571\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m                 for chunk in self._stream(\n\u001b[0m\u001b[1;32m    556\u001b[0m                     \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_huggingface/llms/huggingface_endpoint.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         for response in self.client.text_generation(\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minvocation_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_common.py\u001b[0m in \u001b[0;36m_stream_text_generation_response\u001b[0;34m(bytes_output_as_lines, details)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_text_generation_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_payload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_common.py\u001b[0m in \u001b[0;36m_format_text_generation_stream_output\u001b[0;34m(byte_payload, details)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjson_payload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_parse_text_generation_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_payload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValidationError\u001b[0m: Input validation error: `inputs` must have less than 16000 tokens. Given: 19597","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-89-797d8dfc9f31>\u001b[0m in \u001b[0;36m<cell line: 105>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m result = await label_crew.kickoff_async(\n\u001b[0m\u001b[1;32m    106\u001b[0m     inputs=dict(\n\u001b[1;32m    107\u001b[0m         \u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mamba vs transformers\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff_async\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkickoff_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;34m\"\"\"Asynchronous kickoff method to start the crew execution.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkickoff_for_each_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCrewOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/asyncio/threads.py\u001b[0m in \u001b[0;36mto_thread\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfunc_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_in_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;34m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m                 task_output = task.execute_sync(\n\u001b[0m\u001b[1;32m    666\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36mexecute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    189\u001b[0m     ) -> TaskOutput:\n\u001b[1;32m    190\u001b[0m         \u001b[0;34m\"\"\"Execute the task synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_by_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         result = agent.execute_task(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rpm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rpm_controller\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rpm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rpm_controller\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    210\u001b[0m                 {\n\u001b[1;32m    211\u001b[0m                     \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             outputs = (\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m     80\u001b[0m                     \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1330\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1331\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1332\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 for a in self._iter_next_step(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1330\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1331\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1332\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 for a in self._iter_next_step(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# If the tool chosen is the finishing tool, then we end and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/executor.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# Because the response from the plan is not a generator, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3259\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3261\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m     async def atransform(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3246\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3248\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   3249\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2053\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m                     \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfinal_output_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3209\u001b[0m                 \u001b[0mfinal_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m     async def _atransform(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mgot_first_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0michunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m             \u001b[0;31m# The default implementation of transform is to buffer input and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;31m# then call stream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5297\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5298\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 5299\u001b[0;31m         yield from self.bound.transform(\n\u001b[0m\u001b[1;32m   5300\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     async def atransform(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m                     ),\n\u001b[1;32m    570\u001b[0m                 )\n\u001b[0;32m--> 571\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mgeneration\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m                 for chunk in self._stream(\n\u001b[0m\u001b[1;32m    556\u001b[0m                     \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 ):\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_huggingface/llms/huggingface_endpoint.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0minvocation_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invocation_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         for response in self.client.text_generation(\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minvocation_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         ):\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_common.py\u001b[0m in \u001b[0;36m_stream_text_generation_response\u001b[0;34m(bytes_output_as_lines, details)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbyte_payload\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbytes_output_as_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_text_generation_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_payload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/inference/_common.py\u001b[0m in \u001b[0;36m_format_text_generation_stream_output\u001b[0;34m(byte_payload, details)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;31m# Either an error as being returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjson_payload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_parse_text_generation_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_payload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m# Or parse token payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValidationError\u001b[0m: Input validation error: `inputs` must have less than 16000 tokens. Given: 18178"]}],"source":["search_tool = SerperDevTool()\n","scrape_tool = ScrapeWebsiteTool()\n","ddg_search_tool = DuckDuckGoSearchRun()\n","paper_search_tool = ArxivQueryRun()\n","pub_search_tool = PubmedQueryRun()\n","youtube_search_tool = YouTubeSearchTool()\n","dalle_tool = DallETool()\n","idol_schedule_tool = SeleniumScrapingTool(website_url=f\"https://blip.kr/schedule/{get_month()}\", css_element='.schedule-card-container', wait_time=3)\n","# weather_tool = OpenWeatherMapQueryRun() # Need API key\n","# wiki_search_tool = WikipediaQueryRun() # Need API key\n","# web_rag_tool = WebsiteSearchTool() # Need API key\n","\n","# trend_tool = GoogleTrendsQueryRun() # Need API key\n","\n","# Define your agents with roles and goals\n","\n","tool_sets = [\n","  ddg_search_tool,\n","  scrape_tool,\n","  paper_search_tool,\n","  pub_search_tool,\n","  youtube_search_tool,\n","#   idol_schedule_tool,\n","#   dalle_tool,\n","#   weather_tool, # Need API key\n","#   wiki_search_tool, # Need API key\n","#   web_rag_tool, # Need API key\n","]\n","\n","validator = Agent(\n","  role='평가요원',\n","  goal='좋은 답변을 선택하고 나쁜 답변을 거부',\n","  backstory=\"\"\"\n","나는 평가요원입니다.\n","좋은 답변을 선택하고 나쁜 답변을 거부합니다.\n","\"\"\",\n","  verbose=True,\n","  llm=val_llm, # ollama_openhermes,\n","  allow_delegation=False,\n","  tools=tool_sets\n",")\n","\n","labeler = Agent(\n","  role='라벨러',\n","  goal='질문에 대한 답변을 생성',\n","  backstory=\"\"\"\n","나는 라벨러입니다.\n","질문에 대한 답변을 생성합니다.\n","\"\"\",\n","  verbose=True,\n","  llm=lab_llm, # ollama_solar,\n","  allow_delegation=True,\n","  tools=tool_sets\n",")\n","\n","# Create tasks for your agents\n","\n","labeling = Task(\n","  description=\"\"\"\n","주제에 대한 질문과 답변을 생성합니다.\n","\n","주제: {topic}\n","\"\"\",\n","  expected_output='json',\n","  allow_delegation=True,\n","  pydantic=AgentSharedForm,\n","  agent=labeler,\n","  max_iter=1,\n",")\n","\n","validation = Task(\n","  description=\"\"\"\n","생성된 답변을 평가합니다.\n","\"\"\",\n","  expected_output='json',\n","  agent=validator,\n","  allow_delegation=True,\n","  pydantic=AgentSharedForm,\n","  max_iter=1,\n","  context=[labeling,]\n",")\n","\n","making_data = Task(\n","  description=\"\"\"\n","피드백에 따라 답변을 수정합니다.\n","\"\"\",\n","  expected_output='json',\n","  agent=labeler,\n","  max_iter=1,\n","  allow_delegation=True,\n","  pydantic=AgentSharedForm,\n","  context=[validation]\n","\n",")\n","\n","# Instantiate your crew with a sequential process\n","label_crew = Crew(\n","  agents=[labeler, validator, labeler],\n","  tasks=[labeling, validation, making_data],\n","  verbose=True, # Crew verbose more will let you know what tasks are being worked on, you can set it to 1 or 2 to different logging levels\n","  process=Process.sequential # Sequential process will have tasks executed one after the other and the outcome of the previous one is passed as extra content into this next.\n",")\n","\n","\n","result = await label_crew.kickoff_async(\n","    inputs=dict(\n","        topic=\"mamba vs transformers\"\n","    )\n",")\n","\n","print(\"######################\")\n","print(result)"]},{"cell_type":"code","source":[],"metadata":{"id":"GnjT6XWoOB-X"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["Kk3Hv9duy5GE"],"machine_shape":"hm","provenance":[],"mount_file_id":"17C7UGm8w0pEano-Eb6RdJP4c-9KrgdbM","authorship_tag":"ABX9TyPjRLThPUIWl9jmihiUVwyJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"038735b5e7964f0f9593be3d5ddb47c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ea02322db694f65b408994e392a52af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10a5e7a7e3cb455a810dac50fe8d1a54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11db3e1a7801406d9da65d30824d7cd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d8a47b3d1784df48f5d902bc701d6ec","placeholder":"​","style":"IPY_MODEL_50d0e38b85ad4ec98e3a97df783ad29f","value":" 907/907 [00:00&lt;00:00, 79.6kB/s]"}},"1862a23e7faf408896e2dd59067bad0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c22e3176be34360a1a85b92713889e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d5ac7d6475549ff962f3aa1f6fbd26d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d8a47b3d1784df48f5d902bc701d6ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"214bfbbd9d21468e983bb985797ab5e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8331486fcf3745b78326ca40e75c0a37","max":40581,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f72361973e34004aee57b9d130dbd37","value":40581}},"25338640c36e40fa8752fcc3bb07f062":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73556c3418e14c4e84f5f287dbc3873a","IPY_MODEL_d7985f1e526946b0b296927b506fee98","IPY_MODEL_11db3e1a7801406d9da65d30824d7cd7"],"layout":"IPY_MODEL_73c92d1b7cf44ddba208604ac5bcba00"}},"274a353403b24a0ab16ea89775fc03ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ccbd821a15646278dc055563b4f838b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34be31156b7044dc8d59bd8dcb384689":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4646151fab564b868d87cf3a60c3b3ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e3910df64994afa8152bbc0c2a86d95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88bff89afc2e400caf74c09834378dfc","max":636,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a41d8b7d020442edb17b7c2e086b103e","value":636}},"4f72361973e34004aee57b9d130dbd37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50d0e38b85ad4ec98e3a97df783ad29f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ea2d24a17d54e0f88c2dc55f389f84a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60ea9aad68154d74a42a9656be1bc960":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63774647bd1d4995b6ae552a082013f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"695044d017314c0ea159530a54df73ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c24de4d00289446c9cd82b22d22e98f4","IPY_MODEL_84e7198ba96f48a2b05ab87a1f0975a5","IPY_MODEL_e7b130a3fbc5459091355ac87a0c43eb"],"layout":"IPY_MODEL_60ea9aad68154d74a42a9656be1bc960"}},"6b9ac448f51347b6bb94fff441b6920a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73556c3418e14c4e84f5f287dbc3873a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6ee74da5b124b66a0e1df71f3f59ca6","placeholder":"​","style":"IPY_MODEL_87f42e41125d4337b2140a537a6b667e","value":"config.json: 100%"}},"73c92d1b7cf44ddba208604ac5bcba00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74e2eceac16343a4a6e6cc8b4c3361e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_274a353403b24a0ab16ea89775fc03ed","placeholder":"​","style":"IPY_MODEL_1d5ac7d6475549ff962f3aa1f6fbd26d","value":" 17.5M/17.5M [00:00&lt;00:00, 123MB/s]"}},"7c51ed7fda5a4934a4bba0415bf8d948":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82a13383f3a34dd8977f07ded817a3d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_feda86aaf0054d7ebc0c9f1ab70e3e70","IPY_MODEL_ecad7c0975714a5b841c404c78a55eac","IPY_MODEL_74e2eceac16343a4a6e6cc8b4c3361e1"],"layout":"IPY_MODEL_7c51ed7fda5a4934a4bba0415bf8d948"}},"8331486fcf3745b78326ca40e75c0a37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83d12bd0134d434eb4b0b03ec80c2899":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84e7198ba96f48a2b05ab87a1f0975a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7dfbfd9d0f64b08a2854a58e1176025","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34be31156b7044dc8d59bd8dcb384689","value":4241003}},"87f42e41125d4337b2140a537a6b667e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88bff89afc2e400caf74c09834378dfc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97365a8b12d54f0f8e6848da6ae5fc7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cd73d8a43ac43b5b9e3d513d80a9e59","placeholder":"​","style":"IPY_MODEL_cd52d3bf42a646feb03c4eb82655a336","value":" 636/636 [00:00&lt;00:00, 53.9kB/s]"}},"988e5b9caae64b66ae656371cf4e6a10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1862a23e7faf408896e2dd59067bad0d","placeholder":"​","style":"IPY_MODEL_4646151fab564b868d87cf3a60c3b3ac","value":" 40.6k/40.6k [00:00&lt;00:00, 3.35MB/s]"}},"9cd73d8a43ac43b5b9e3d513d80a9e59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a41d8b7d020442edb17b7c2e086b103e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7dfbfd9d0f64b08a2854a58e1176025":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7fcf89c5ba0418890fb4429697ccd8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b40a4cea1b24401086dd70d2827954ab","placeholder":"​","style":"IPY_MODEL_1c22e3176be34360a1a85b92713889e1","value":"tokenizer_config.json: 100%"}},"b40a4cea1b24401086dd70d2827954ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb232f07789c4d1983e7f78e8a73cd79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c24de4d00289446c9cd82b22d22e98f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8b280749c7e4539aa35d7f2a93c17e1","placeholder":"​","style":"IPY_MODEL_10a5e7a7e3cb455a810dac50fe8d1a54","value":"tokenizer.model: 100%"}},"cd52d3bf42a646feb03c4eb82655a336":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d02193e3625f42e9852bd9672c8f7ea6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7fcf89c5ba0418890fb4429697ccd8f","IPY_MODEL_214bfbbd9d21468e983bb985797ab5e3","IPY_MODEL_988e5b9caae64b66ae656371cf4e6a10"],"layout":"IPY_MODEL_63774647bd1d4995b6ae552a082013f6"}},"d37a1cd850a34b339769dc0601ba471a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7985f1e526946b0b296927b506fee98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ea02322db694f65b408994e392a52af","max":907,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83d12bd0134d434eb4b0b03ec80c2899","value":907}},"d8b280749c7e4539aa35d7f2a93c17e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2ec38b4ffee4b34848c878601bf6e5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffb455d277aa4a349311280581527b1e","IPY_MODEL_4e3910df64994afa8152bbc0c2a86d95","IPY_MODEL_97365a8b12d54f0f8e6848da6ae5fc7e"],"layout":"IPY_MODEL_e3ac57359e1840e398f5cf5059af3799"}},"e3ac57359e1840e398f5cf5059af3799":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7b130a3fbc5459091355ac87a0c43eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcd2667f6c8a4536a87bb5248bd58992","placeholder":"​","style":"IPY_MODEL_2ccbd821a15646278dc055563b4f838b","value":" 4.24M/4.24M [00:00&lt;00:00, 20.0MB/s]"}},"e82867d8a9d14ab2816f359d18d2d916":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecad7c0975714a5b841c404c78a55eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e82867d8a9d14ab2816f359d18d2d916","max":17518525,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb232f07789c4d1983e7f78e8a73cd79","value":17518525}},"f6ee74da5b124b66a0e1df71f3f59ca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcd2667f6c8a4536a87bb5248bd58992":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feda86aaf0054d7ebc0c9f1ab70e3e70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b9ac448f51347b6bb94fff441b6920a","placeholder":"​","style":"IPY_MODEL_5ea2d24a17d54e0f88c2dc55f389f84a","value":"tokenizer.json: 100%"}},"ffb455d277aa4a349311280581527b1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_038735b5e7964f0f9593be3d5ddb47c9","placeholder":"​","style":"IPY_MODEL_d37a1cd850a34b339769dc0601ba471a","value":"special_tokens_map.json: 100%"}}}}},"nbformat":4,"nbformat_minor":0}