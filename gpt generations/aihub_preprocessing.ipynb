{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/KevinJung/Datasets/AI허브/005.한영 혼합 인식 데이터\n",
      "C:/KevinJung/Datasets/AI허브/016.행정 문서 대상 기계독해 데이터\n",
      "C:/KevinJung/Datasets/AI허브/017.뉴스 기사 기계독해 데이터\n",
      "C:/KevinJung/Datasets/AI허브/018.비디오 네러티브 질의응답 데이터\n",
      "C:/KevinJung/Datasets/AI허브/019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터\n",
      "C:/KevinJung/Datasets/AI허브/022.요약문 및 레포트 생성 데이터\n",
      "C:/KevinJung/Datasets/AI허브/023.방송 콘텐츠 대본 요약 데이터\n",
      "C:/KevinJung/Datasets/AI허브/024.에세이 글 평가 데이터\n",
      "C:/KevinJung/Datasets/AI허브/026.기술과학 분야 한-영 번역 병렬 말뭉치 데이터\n",
      "C:/KevinJung/Datasets/AI허브/030.웹데이터 기반 한국어 말뭉치 데이터\n",
      "C:/KevinJung/Datasets/AI허브/142.학생 청소년 교육활동 역량 데이터\n",
      "C:/KevinJung/Datasets/AI허브/143.민원 업무 효율, 자동화를 위한 언어 AI 학습데이터\n",
      "C:/KevinJung/Datasets/AI허브/155.산업정보 연계 주요국 특허 영-한 데이터\n",
      "C:/KevinJung/Datasets/AI허브/156.전문분야 영-한, 중-한 번역 말뭉치(식품)\n",
      "C:/KevinJung/Datasets/AI허브/157.방송 콘텐츠 한-중, 한-일 번역 병렬 말뭉치 데이터\n",
      "C:/KevinJung/Datasets/AI허브/158.문학작품 낭송, 낭독 음성 데이터(시, 소설, 희곡, 시나리오)\n",
      "C:/KevinJung/Datasets/AI허브/159.숫자가 포함된 패턴 발화 데이터\n",
      "C:/KevinJung/Datasets/AI허브/186.복지 분야 콜센터 상담데이터\n",
      "C:/KevinJung/Datasets/AI허브/소상공인 고객 주문 질의-응답 텍스트\n",
      "C:/KevinJung/Datasets/AI허브/수학분야 학습자 역량 측정 데이터\n",
      "C:/KevinJung/Datasets/AI허브/한국인 외래어 발화\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/KevinJung/Datasets/AI허브\"\n",
    "file_list = os.listdir(path)\n",
    "for F in [file for file in file_list if not file.endswith(\".json\")]:\n",
    "    data_path = f'{path}/{F}'\n",
    "    if os.path.isdir(data_path):\n",
    "        print(data_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f'{path}/005.한영 혼합 인식 데이터/01.데이터'\n",
    "_datasets = []\n",
    "for datasets_path in os.listdir(data_path): # 01.Training 02.Validation\n",
    "    if os.path.isdir(f'{data_path}/{datasets_path}'):\n",
    "        for dataset_dir in os.listdir(f'{data_path}/{datasets_path}'): # 라벨링데이터 원천데이터\n",
    "            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}'):\n",
    "                for ij in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}'): # 일상 전문 \n",
    "                    if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                        for obj_dir in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'): # 미용뷰티 엔터테인먼트 여행 ... 직업교육\n",
    "                            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{obj_dir}'):\n",
    "                                _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{obj_dir}' # json files\n",
    "                                _datasets += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "print(\"num of files : \", len(_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282048fb12d248e8aa10235106f38731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at  C:/KevinJung/Datasets/AI허브/005.한영 혼합 인식 데이터/01.데이터/data.csv\n"
     ]
    }
   ],
   "source": [
    "temp = [[],[],[]]\n",
    "\n",
    "for jf in tqdm(_datasets):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    type_info = json_data[\"typeInfo\"]\n",
    "    speakers = type_info[\"speakers\"]\n",
    "    speakers_indexer = [speaker[\"speaker_id\"] for speaker in speakers]\n",
    "    dialogs = json_data[\"dialogs\"]\n",
    "    for dialog in dialogs:\n",
    "        if \"deleted\" in dialog.keys():\n",
    "            continue\n",
    "        else:\n",
    "            if \"expression\" in dialog.keys():\n",
    "                temp[0]+=[f\"chat\"]\n",
    "                temp[1]+=[f\"여기서 외국어 찾아줘. {dialog['text']}\"]\n",
    "                temp[2]+=[\" \".join([f'{expression[\"baseForm\"]}({expression[\"originalForm\"]})' for expression in dialog[\"expression\"]])]\n",
    "\n",
    "            temp[0]+=[f\"chat\"]\n",
    "            temp[1]+=[f\"이 문장 분석해줘. {dialog['text']}\"]\n",
    "            temp[2]+=[f'{type_info[\"category\"]} 주제에 관한 대화로 {type_info[\"subcategory\"]} 관련된 내용입니다.']\n",
    "\n",
    "            temp[0]+=[f'주제 맞추기\\n']\n",
    "            temp[1]+=[f\"문장: {dialog['text']} 주제: \"]\n",
    "            temp[2]+=[f'{type_info[\"category\"]}-{type_info[\"subcategory\"]}']\n",
    "\n",
    "            temp[0]+=[f'주어진 주제에 대한 문장 만들기\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"category\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "            temp[0]+=[f'주어진 주제에 대한 문장 만들기\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"subcategory\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "            temp[0]+=[f'주어진 주제에 대한 문장 만들기\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"category\"]}-{type_info[\"subcategory\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "\n",
    "            temp[0]+=[f'특정 주제에 맞는 문장작성하기\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"category\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "            temp[0]+=[f'특정 주제에 맞는 문장작성하기\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"subcategory\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "            temp[0]+=[f'특정 주제에 맞는 문장작성하기\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"category\"]}-{type_info[\"subcategory\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "\n",
    "            temp[0]+=[f'주제애 해당하는 문장 생성\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"category\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "            temp[0]+=[f'주제애 해당하는 문장 생성\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"subcategory\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "            temp[0]+=[f'주제애 해당하는 문장 생성\\n']\n",
    "            temp[1]+=[f'주제: {type_info[\"category\"]}-{type_info[\"subcategory\"]} 문장:']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "\n",
    "            temp[0]+=[f'chat']\n",
    "            temp[1]+=[f'주제로 문장 만들어줘. {type_info[\"category\"]}-{type_info[\"subcategory\"]}']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "            temp[0]+=[f'chat']\n",
    "            temp[1]+=[f'주제로 문장 만들어줘. {type_info[\"category\"]}']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "            temp[0]+=[f'chat']\n",
    "            temp[1]+=[f'주제로 문장 만들어줘. {type_info[\"subcategory\"]}']\n",
    "            temp[2]+=[f\"{dialog['text']}\"]\n",
    "\n",
    "data005 = pd.DataFrame({\"prompt\":temp[0],\"Q\":temp[1],\"A\":temp[2]})\n",
    "data005.to_csv(f\"{data_path}/data.csv\", index=False)\n",
    "print(\"saved at \", f\"{data_path}/data.csv\")\n",
    "del temp, data005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of files :  12\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{path}/016.행정 문서 대상 기계독해 데이터/01.데이터'\n",
    "_datasets = []\n",
    "for datasets_path in os.listdir(data_path): # 01.Training 02.Validation\n",
    "    if os.path.isdir(f'{data_path}/{datasets_path}'):\n",
    "        for dataset_dir in os.listdir(f'{data_path}/{datasets_path}'): # 라벨링데이터 원천데이터\n",
    "            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}'):\n",
    "                for ij in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}'): # train TL_multiple_choice.zip ... TL_unanswerable.zip\n",
    "                    if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                        _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}' # json files\n",
    "                        _datasets += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "print(\"num of files : \", len(_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc7b946cc9c411c96d712a47c21bf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at  C:/KevinJung/Datasets/AI허브/016.행정 문서 대상 기계독해 데이터/01.데이터/data.csv\n"
     ]
    }
   ],
   "source": [
    "temp = [[],[],[]]\n",
    "\n",
    "for jf in tqdm(_datasets):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    datas = json_data[\"data\"]\n",
    "    for data in datas:\n",
    "        data[\"doc_title\"]\n",
    "        data[\"doc_source\"]\n",
    "        doc_class = data[\"doc_class\"]\n",
    "        doc_class[\"class\"]\n",
    "        \n",
    "        for paragraph in data[\"paragraphs\"]:\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                answers = qa[\"answers\"]\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'{qa[\"question\"]}\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{answers[\"text\"]} 입니다.']\n",
    "\n",
    "                temp[0] += [f\"정답 찾기\"]\n",
    "                temp[1] += [f'질문: {qa[\"question\"]}\\n 본문: {paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{answers[\"text\"]}']\n",
    "\n",
    "                temp[0] += [f\"정답 문장 찾기\"]\n",
    "                temp[1] += [f'질문: {qa[\"question\"]}\\n 본문: {paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{answers[\"clue_text\"]}']\n",
    "\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'본문 분류해줘\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{doc_class[\"code\"]}']\n",
    "\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'제목 찾아줘\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{data[\"doc_title\"]}']\n",
    "\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'이거 어디서 작성 된거야?\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{data[\"doc_source\"]} 입니다']\n",
    "\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'이걸로 할 수 있는 질문 만들어줘\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{qa[\"question\"]}']\n",
    "\n",
    "data016 = pd.DataFrame({\"prompt\":temp[0],\"Q\":temp[1],\"A\":temp[2]})\n",
    "data016.to_csv(f\"{data_path}/data.csv\", index=False)\n",
    "print(\"saved at \", f\"{data_path}/data.csv\")\n",
    "del temp, data016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of files :  8\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{path}/017.뉴스 기사 기계독해 데이터/01.데이터'\n",
    "_datasets = []\n",
    "for datasets_path in os.listdir(data_path): # 01.Training 02.Validation\n",
    "    if os.path.isdir(f'{data_path}/{datasets_path}'):\n",
    "        for dataset_dir in os.listdir(f'{data_path}/{datasets_path}'): # 라벨링데이터 원천데이터\n",
    "            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}'):\n",
    "                for ij in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}'): # train TL_span_extraction.zip\n",
    "                    if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                        _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}' # json files\n",
    "                        _datasets += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "print(\"num of files : \", len(_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957c139c52fb448d904688dabd9bd3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at  C:/KevinJung/Datasets/AI허브/017.뉴스 기사 기계독해 데이터/01.데이터/data.csv\n"
     ]
    }
   ],
   "source": [
    "temp = [[],[],[]]\n",
    "\n",
    "for jf in tqdm(_datasets):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    datas = json_data[\"data\"]\n",
    "    for data in datas:\n",
    "        data[\"doc_title\"]\n",
    "        data[\"doc_source\"]\n",
    "        doc_class = data[\"doc_class\"]\n",
    "        doc_class[\"class\"]\n",
    "        \n",
    "        for paragraph in data[\"paragraphs\"]:\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                answers = qa[\"answers\"]\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'{qa[\"question\"]}\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{answers[\"text\"]} 입니다.']\n",
    "\n",
    "                temp[0] += [f\"정답 찾기\"]\n",
    "                temp[1] += [f'질문: {qa[\"question\"]}\\n 본문: {paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{answers[\"text\"]}']\n",
    "\n",
    "                if answers[\"clue_text\"]:\n",
    "                    temp[0] += [f\"정답 문장 찾기\"]\n",
    "                    temp[1] += [f'질문: {qa[\"question\"]}\\n 본문: {paragraph[\"context\"]}']\n",
    "                    temp[2] += [f'{answers[\"clue_text\"]}']\n",
    "\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'본문 분류해줘\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{doc_class[\"code\"]}']\n",
    "\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'제목 찾아줘\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{data[\"doc_title\"]}']\n",
    "\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'이거 어디서 작성 된거야?\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{data[\"doc_source\"]} 입니다']\n",
    "\n",
    "                temp[0] += [f\"chat\"]\n",
    "                temp[1] += [f'이걸로 할 수 있는 질문 만들어줘\\n{paragraph[\"context\"]}']\n",
    "                temp[2] += [f'{qa[\"question\"]}']\n",
    "data017 = pd.DataFrame({\"prompt\":temp[0],\"Q\":temp[1],\"A\":temp[2]})\n",
    "data017.to_csv(f\"{data_path}/data.csv\", index=False)\n",
    "print(\"saved at \", f\"{data_path}/data.csv\")\n",
    "del temp, data017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last file path :  C:/KevinJung/Datasets/AI허브/018.비디오 네러티브 질의응답 데이터/01.데이터/2.Validation/라벨링데이터/치안안전/대본X\n",
      "num of files :  40\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{path}/018.비디오 네러티브 질의응답 데이터/01.데이터'\n",
    "_datasets = []\n",
    "for datasets_path in os.listdir(data_path): # 01.Training 02.Validation\n",
    "    if os.path.isdir(f'{data_path}/{datasets_path}'):\n",
    "        for dataset_dir in os.listdir(f'{data_path}/{datasets_path}'): # 라벨링데이터 원천데이터\n",
    "            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}'):\n",
    "                for ij in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}'): # 건강 다큐 배구 사고발생 ... TL_예능교양.zip\n",
    "                    if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                        for cat in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'): # 대본O 대본X\n",
    "                            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}'):\n",
    "                                _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}'\n",
    "                                _datasets += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "print(\"last file path : \", _list)\n",
    "print(\"num of files : \", len(_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a798f062b437436fab532cdf910616cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at  C:/KevinJung/Datasets/AI허브/018.비디오 네러티브 질의응답 데이터/01.데이터/data.csv\n"
     ]
    }
   ],
   "source": [
    "temp = [[],[],[]]\n",
    "\n",
    "for jf in tqdm(_datasets):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    for data in json_data:\n",
    "        temp[0] += [f'문제 맞추기']\n",
    "        temp[1] += [f'본문: {data[\"sum\"]}\\r\\n문제: {data[\"que\"]}']\n",
    "        temp[2] += [f'정답: {data[\"answers\"][data[\"correct_idx\"]]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'다음 상황에서 {data[\"que\"]}?\\r\\n{data[\"sum\"]}']\n",
    "        temp[2] += [f'{data[\"answers\"][data[\"correct_idx\"]]} 입니다.']\n",
    "\n",
    "        temp[0] += [f'묘사된 상황 맞추기']\n",
    "        temp[1] += [f'{data[\"sum\"]}']\n",
    "        temp[2] += [f'{data[\"sum_vidSitu\"]}']\n",
    "\n",
    "        temp[0] += [f'묘사 유형 맞추기']\n",
    "        temp[1] += [f'{data[\"sum\"]}']\n",
    "        temp[2] += [f'{data[\"sumType\"]}']\n",
    "\n",
    "        temp[0] += [f'보기에서 고르기']\n",
    "        temp[1] += [f'문제: {data[\"que\"]}\\r\\n본문: {data[\"sum\"]}\\r\\n보기: [{\", \".join(data[\"answers\"])}]']\n",
    "        temp[2] += [f'{data[\"answers\"][data[\"correct_idx\"]]}']\n",
    "        \n",
    "        temp[0] += [f'상황에 맞는 감정 고르기']\n",
    "        temp[1] += [f'{data[\"sum\"]}']\n",
    "        temp[2] += [f'{data[\"sentiment\"]}']\n",
    "\n",
    "        temp[0] += [f'질문 유형 판단하기']\n",
    "        temp[1] += [f'{data[\"que\"]}']\n",
    "        temp[2] += [f'{data[\"QA_queTypeSub\"]}에 대한 {data[\"QA_queType\"]}']\n",
    "\n",
    "        temp[0] += [f'비슷한 단어 연상하기']\n",
    "        temp[1] += [f'{data[\"answers\"][data[\"correct_idx\"]]}']\n",
    "        del data[\"correct_idx\"]\n",
    "        temp[2] += [f'{\", \".join(data[\"answers\"])}']\n",
    "\n",
    "        temp[0] += [f'장소 맞추기']\n",
    "        temp[1] += [f'{data[\"sum\"]}']\n",
    "        temp[2] += [f'{data[\"sum_vidPlace\"]}']\n",
    "\n",
    "        temp[0] += [f'묘사된 상황의 영상 카테고리 맞추기']\n",
    "        temp[1] += [f'{data[\"sum\"]}']\n",
    "        temp[2] += [f'{data[\"category_name\"]}에 관한 {data[\"category_code\"]}']\n",
    "\n",
    "        if data[\"script\"]:\n",
    "            temp[0] += [f'상황에 맞는 자막달기']\n",
    "            temp[1] += [f'{data[\"sum\"]}']\n",
    "            temp[2] += [f'{data[\"script\"]}']\n",
    "\n",
    "data018 = pd.DataFrame({\"prompt\":temp[0],\"Q\":temp[1],\"A\":temp[2]})\n",
    "data018.to_csv(f\"{data_path}/data.csv\", index=False)\n",
    "print(\"saved at \", f\"{data_path}/data.csv\")\n",
    "del temp, data018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last file path :  C:/KevinJung/Datasets/AI허브/019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터/01.데이터/2.Validation/라벨링데이터/VL_2.약관/02.불리\n",
      "num of files :  450 9000\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{path}/019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터/01.데이터'\n",
    "_datasets = []\n",
    "_datasets2 = []\n",
    "for datasets_path in os.listdir(data_path): # 01.Training 02.Validation\n",
    "    if os.path.isdir(f'{data_path}/{datasets_path}'):\n",
    "        for dataset_dir in os.listdir(f'{data_path}/{datasets_path}'): # 라벨링데이터 원천데이터\n",
    "            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}'):\n",
    "                for ij in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}'): # TL_1.판결문 TL_2.약관 ... TL_2.약관.zip\n",
    "                    if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                        for cat in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'): # 01.민사 02.형사 03.행정\n",
    "                             if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                                for ox in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}'): # 2018\n",
    "                                    _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}/{ox}' # 판결문 json files\n",
    "                                    if os.path.isfile(_list):\n",
    "                                        _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}' # 약관 json files\n",
    "                                        _datasets2 += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "                                        break\n",
    "                                    _datasets += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "print(\"last file path : \", _list)\n",
    "print(\"num of files : \", len(_datasets), len(_datasets2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711962fc2d2e410dba771faaad880cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = [[],[],[]]\n",
    "Disposals = (\"손해배상금\", \"손실보상금\", \"재산분할액\", \"위자료\", \"양육비\", \"징역\", \"금고\", \"집행유예\", \"벌금\", \"취소\")\n",
    "Acusr_Debat = (\"자연인\", \"법인\", \"국가\", \"검사\", \"기타\")\n",
    "Case = (\"민사\",\"형사\", \"행정\")\n",
    "Case_Detail = (\"민사\", \"신청\", \"가사\", \"특허\", \"행정\", \"형사\")\n",
    "newline = \"\\n\"\n",
    "for jf in tqdm(_datasets):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    info = json_data[\"info\"]\n",
    "    org = json_data[\"org\"]\n",
    "    disposal = json_data[\"disposal\"]\n",
    "    mentionedItems = json_data[\"mentionedItems\"]\n",
    "    concerend = json_data[\"concerned\"]\n",
    "    assrs = json_data[\"assrs\"]\n",
    "    facts = json_data[\"facts\"]\n",
    "    courtDcss = json_data[\"dcss\"]\n",
    "    close = json_data[\"close\"]\n",
    "    \n",
    "    casefield = Case[int(info[\"caseField\"])-1]\n",
    "    detailfield = Case_Detail[int(info[\"detailField\"])-1]\n",
    "    trailfield = f'{info[\"trailField\"]}심'\n",
    "\n",
    "    acu = Acusr_Debat[int(concerend[\"acusr\"] if len(concerend[\"acusr\"]) <2 else 5)-1]\n",
    "    ded = Acusr_Debat[int(concerend[\"dedat\"] if len(concerend[\"dedat\"]) <2 else 5)-1]\n",
    "    disform = Disposals[int(disposal[\"disposalform\"])-1]\n",
    "\n",
    "    case = f'{info[\"caseNo\"]} {info[\"caseNm\"]} 사건 {trailfield} {trailfield} 재판, {info[\"courtNm\"]} 선고 {disform} 판결'\n",
    "\n",
    "    # print(f'{acu} 대 {ded} {casefield}-{detailfield} 소송 {trailfield} 재판의 {disform} 판결')\n",
    "    # print(case)\n",
    "    # print(f'{disform} 판결: {\" \".join(disposal[\"disposalcontent\"])}\\n{\" \".join(mentionedItems[\"rqestObjet\"])}')\n",
    "    # print(f'[관련 법령]\\n{newline.join([f\"{i+1}. {q}\" for i,q in enumerate(info[\"relateLaword\"])])}')\n",
    "    # print(f'[인용 판례]\\n{newline.join([f\"{i+1}. {q}\" for i,q in enumerate(info[\"qotatPrcdnt\"])])}')\n",
    "\n",
    "    # print(f'원고의 주장: {\" \".join(assrs[\"acusrAssrs\"])}')\n",
    "    # print(f'피고의 주장: {\" \".join(assrs[\"dedatAssrs\"])}')\n",
    "    # print(f'{\" \".join(facts[\"bsisFacts\"])}')\n",
    "    # print(f'{\" \".join(courtDcss[\"courtDcss\"])}')\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'관련 법령 찾아줘\\n사건: {\" \".join(facts[\"bsisFacts\"])}\\n재판부의 판단: {\" \".join(courtDcss[\"courtDcss\"])}']\n",
    "    temp[2] += [f'[관련 법령]\\n{newline.join([f\"{i+1}. {q}\" for i,q in enumerate(info[\"relateLaword\"])])}']\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'인용 판례 알려줘\\n사건: {\" \".join(facts[\"bsisFacts\"])}\\n재판부의 판단: {\" \".join(courtDcss[\"courtDcss\"])}']\n",
    "    temp[2] += [f'[인용 판례]\\n{newline.join([f\"{i+1}. {q}\" for i,q in enumerate(info[\"qotatPrcdnt\"])])}']\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'어떤 사건인지 알려줘\\n사건: {\" \".join(facts[\"bsisFacts\"])}\\n재판부의 판단: {\" \".join(courtDcss[\"courtDcss\"])}']\n",
    "    temp[2] += [f'{acu} 대 {ded} {casefield}-{detailfield} 소송 {trailfield} 재판의 {disform} 판결']\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'원고, 피고 주장 듣고 판단하기\\n원고의 주장: {\" \".join(assrs[\"acusrAssrs\"])}\\n피고의 주장: {\" \".join(assrs[\"dedatAssrs\"])}']\n",
    "    temp[2] += [f'{disform} 판결: {\" \".join(disposal[\"disposalcontent\"])}\\n{\" \".join(mentionedItems[\"rqestObjet\"])}']\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'사건: {\" \".join(facts[\"bsisFacts\"])}\\n재판부의 판단: {\" \".join(courtDcss[\"courtDcss\"])}']\n",
    "    temp[2] += [f'{case}']\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'판단하기\\n사건: {\" \".join(facts[\"bsisFacts\"])}']\n",
    "    temp[2] += [f'재판부의 판단: {\" \".join(courtDcss[\"courtDcss\"])}']\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'{\" \".join(assrs[\"acusrAssrs\"])}\\n{\" \".join(assrs[\"dedatAssrs\"])}\\n{\" \".join(facts[\"bsisFacts\"])}']\n",
    "    temp[2] += [f'{\" \".join(courtDcss[\"courtDcss\"])}']\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'판결 정리해줘.\\n{\" \".join(courtDcss[\"courtDcss\"])}']\n",
    "    temp[2] += [f'{disform} 판결: {\" \".join(disposal[\"disposalcontent\"])}\\n{\" \".join(mentionedItems[\"rqestObjet\"])}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478bbccbab4b42ec8c164d03e068e7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at  C:/KevinJung/Datasets/AI허브/019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터/01.데이터/data.csv\n"
     ]
    }
   ],
   "source": [
    "ClauseField = (\"가맹계약\", \"공급계약\", \"분양계약\", \"신탁계약\", \"임대차계약\", \"입소, 입주, 입점계약\", \"신용카드\", \"은행여신\",\n",
    "               \"은행전자금융서비스\", \"전자결제수단\", \"전자금육거래\", \"상해보험\", \"손해보험\", \"질병보험\", \"연금보험\", \"자동차보험\",\n",
    "               \"책임보험\", \"화재보험\" ,\"증권사1\", \"증권사2\", \"증권사3\", \"여객운송\", \"화물운송\", \"개인정보취급방침\", \"게임\", \"국내외여행\",\n",
    "               \"결혼정보서비스\", \"렌트(자도차 이외)\", \"마일리지/포인트\", \"보증\", \"사이버몰\", \"산후조리원\", \"상조서비스\", \"상품권\", \"생명보험\",\n",
    "               \"예식업\", \"온라인서비스\", \"자동차 리스 및 렌탈\", \"체육시설\", \"택배\", \"통신/방송서비스\", \"교육\", \"매매계약\")\n",
    "for jf in tqdm(_datasets2):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        # print(jf)\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    clausefield = ClauseField[int(json_data[\"clauseField\"])-1]\n",
    "\n",
    "    temp[0] += [f'chat']\n",
    "    temp[1] += [f'이 약관은 누구에게 유리해?\\n{\" \".join(json_data[\"clauseArticle\"])}']\n",
    "    temp[2] += [f'해당약관은 {clausefield}에 관한 약관으로 공정위 심결례 위반에 {\"해당하며\" if \"ftcCnclsns\" in json_data.keys() and json_data[\"ftcCnclsns\"] == \"1\" else \"해당하지 않으며\"}, '\n",
    "                f'소비자에게 {\"유리\" if json_data[\"dvAntageous\"]==\"1\" else \"불리\"}한 약관입니다.\\n비교 근거는 다음과 같습니다.\\n'\n",
    "                f'{\" \".join(json_data[\"comProvision\"]) if \"comProvision\" in json_data.keys() else \" \".join(json_data[\"illdcssBasiss\"])}\\n'\n",
    "                f'{\"관련 법령:\"+newline+\" \".join(json_data[\"relatedLaword\"])+newline if \"relatedLaword\" in json_data.keys() else \"\"}']\n",
    "\n",
    "    temp[0] += [f'약관 유불리 분류하기']\n",
    "    temp[1] += [f'{\" \".join(json_data[\"clauseArticle\"])}']\n",
    "    temp[2] += [f'{\"유리\" if json_data[\"dvAntageous\"]==\"1\" else \"불리\"}']\n",
    "\n",
    "    temp[0] += [f'공정위 심결례 분류하기']\n",
    "    temp[1] += [f'{\" \".join(json_data[\"clauseArticle\"])}']\n",
    "    temp[2] += [f'위반 {\"해당\" if \"ftcCnclsns\" in json_data.keys() and json_data[\"ftcCnclsns\"] == \"1\" else \"비해당\"}']\n",
    "\n",
    "    temp[0] += [f'약관 종류 분류하기']\n",
    "    temp[1] += [f'{\" \".join(json_data[\"clauseArticle\"])}']\n",
    "    temp[2] += [f'{clausefield}']\n",
    "\n",
    "data019 = pd.DataFrame({\"prompt\":temp[0],\"Q\":temp[1],\"A\":temp[2]})\n",
    "data019.to_csv(f\"{data_path}/data.csv\", index=False)\n",
    "print(\"saved at \", f\"{data_path}/data.csv\")\n",
    "del temp, data019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last file path :  C:/KevinJung/Datasets/AI허브/022.요약문 및 레포트 생성 데이터/01.데이터/2.Validation/라벨링데이터/10.narration/2~3sent\n",
      "num of files :  165071\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{path}/022.요약문 및 레포트 생성 데이터/01.데이터'\n",
    "_datasets = []\n",
    "for datasets_path in os.listdir(data_path): # 1.Training 2.Validation\n",
    "    if os.path.isdir(f'{data_path}/{datasets_path}'):\n",
    "        for dataset_dir in os.listdir(f'{data_path}/{datasets_path}'): # 라벨링데이터 원천데이터\n",
    "            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}'):\n",
    "                for ij in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}'): # 01.news_r 02.briefing 03..... 10.narration TL1.zip\n",
    "                    if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                        for cat in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'): # 2~3sent 20per\n",
    "                            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}'):\n",
    "                                _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}'  # json files\n",
    "                                _datasets += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "print(\"last file path : \", _list)\n",
    "print(\"num of files : \", len(_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450ff9596df24e04bed0a3c4611319e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/165071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at  C:/KevinJung/Datasets/AI허브/022.요약문 및 레포트 생성 데이터/01.데이터/data.csv\n"
     ]
    }
   ],
   "source": [
    "temp = [[],[],[]]\n",
    "DOC_TYPE = {\"news_r\": \"뉴스\",\n",
    "            \"briefing\":\"보도자료\",\n",
    "            \"his_cul\": \"역사기록물\", \n",
    "            \"paper\": \"보고서\",\n",
    "            \"minute\": \"회의록\",\n",
    "            \"edit\": \"사설\", \n",
    "            \"public\": \"간행물\", \n",
    "            \"speech\": \"연설문\", \n",
    "            \"literature\": \"문학\",\n",
    "            \"narration\": \"나래이션\"}\n",
    "\n",
    "for jf in tqdm(_datasets):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    acqusition = json_data[\"Meta(Acqusition)\"]\n",
    "    refine = json_data[\"Meta(Refine)\"]\n",
    "    annotation = json_data[\"Annotation\"]\n",
    "\n",
    "    if annotation[\"summary1\"]:\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'요약하기\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{annotation[\"summary1\"]}']\n",
    "\n",
    "        temp[0] +=  [f'chat']\n",
    "        temp[1] +=  [f'요약복구\\n{annotation[\"summary1\"]}']\n",
    "        temp[2] +=  [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] +=  [f'chat']\n",
    "        temp[1] +=  [f'이 내용의 {DOC_TYPE[acqusition[\"doc_type\"]]} 만들어줘\\n{annotation[\"summary1\"]}']\n",
    "        temp[2] +=  [f'{acqusition[\"doc_name\"]}\\n{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'글쓰기\\n{acqusition[\"doc_name\"]}\\n{annotation[\"summary1\"]}']\n",
    "        temp[2] += [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'주제로 글쓰기\\n{acqusition[\"doc_name\"]}']\n",
    "        temp[2] += [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'이 내용의 {DOC_TYPE[acqusition[\"doc_type\"]]} 문서 제목 지어줘\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{acqusition[\"doc_name\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'주제로 짧은 글쓰기\\n{acqusition[\"doc_name\"]}']\n",
    "        temp[2] += [f'{annotation[\"summary1\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'문서 유형 맞추기\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{DOC_TYPE[acqusition[\"doc_type\"]]}']\n",
    "\n",
    "    if annotation[\"summary2\"]:\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'요약해줘\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{annotation[\"summary2\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'요약자료에서 원본 작성하기\\n{annotation[\"summary2\"]}']\n",
    "        temp[2] += [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'이 내용의 {DOC_TYPE[acqusition[\"doc_type\"]]} 만들어줘\\n{annotation[\"summary2\"]}']\n",
    "        temp[2] += [f'{acqusition[\"doc_name\"]}\\n{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'글쓰기\\n{acqusition[\"doc_name\"]}\\n{annotation[\"summary2\"]}']\n",
    "        temp[2] += [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'다음 제목의 글쓰기\\n제목: {acqusition[\"doc_name\"]}']\n",
    "        temp[2] += [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'다음 제목의 짧은 글쓰기\\n제목: {acqusition[\"doc_name\"]}']\n",
    "        temp[2] += [f'{annotation[\"summary2\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'{DOC_TYPE[acqusition[\"doc_type\"]]} 문서 제목 만들기\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{acqusition[\"doc_name\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'문서 분류\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{DOC_TYPE[acqusition[\"doc_type\"]]}']\n",
    "\n",
    "    if annotation[\"summary3\"]:\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'요약\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{annotation[\"summary3\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'요약 내용 자세하게 알려줘\\n{annotation[\"summary3\"]}']\n",
    "        temp[2] += [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'글쓰기\\n{acqusition[\"doc_name\"]}\\n{annotation[\"summary3\"]}']\n",
    "        temp[2] += [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'이 내용의 {DOC_TYPE[acqusition[\"doc_type\"]]} 만들어줘\\n{annotation[\"summary3\"]}']\n",
    "        temp[2] += [f'{acqusition[\"doc_name\"]}\\n{refine[\"passage\"]}']\n",
    "        \n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'제목짓기\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{acqusition[\"doc_name\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'글쓰기\\n주제: {acqusition[\"doc_name\"]}']\n",
    "        temp[2] += [f'{refine[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'짧은 글쓰기\\n주제: {acqusition[\"doc_name\"]}']\n",
    "        temp[2] += [f'{annotation[\"summary3\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'문서 분류\\n{refine[\"passage\"]}']\n",
    "        temp[2] += [f'{DOC_TYPE[acqusition[\"doc_type\"]]}']\n",
    "\n",
    "\n",
    "data022 = pd.DataFrame({\"prompt\":temp[0],\"Q\":temp[1],\"A\":temp[2]})\n",
    "data022.to_csv(f\"{data_path}/data.csv\", index=False)\n",
    "print(\"saved at \", f\"{data_path}/data.csv\")\n",
    "del temp, data022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last file path :  C:/KevinJung/Datasets/AI허브/023.방송 콘텐츠 대본 요약 데이터/01.데이터/2.Validation/라벨링데이터/history/3sent\n",
      "num of files :  94364\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{path}/023.방송 콘텐츠 대본 요약 데이터/01.데이터'\n",
    "_datasets = []\n",
    "for datasets_path in os.listdir(data_path): # 1.Training 2.Validation\n",
    "    if os.path.isdir(f'{data_path}/{datasets_path}'):\n",
    "        for dataset_dir in os.listdir(f'{data_path}/{datasets_path}'): # 라벨링데이터 원천데이터\n",
    "            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}'):\n",
    "                for ij in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}'): # 01.news_r 02.briefing 03..... 10.narration TL1.zip\n",
    "                    if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                        for cat in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'): # 2~3sent 20per\n",
    "                            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}'):\n",
    "                                _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}/{cat}'  # json files\n",
    "                                _datasets += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "print(\"last file path : \", _list)\n",
    "print(\"num of files : \", len(_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e347ccecbf514a0786cf0b730f388b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at  C:/KevinJung/Datasets/AI허브/023.방송 콘텐츠 대본 요약 데이터/01.데이터/data.csv\n"
     ]
    }
   ],
   "source": [
    "temp = [[],[],[]]\n",
    "DOC_TYPE = {\"fm_drama\": \"가족관련방송\",\n",
    "            \"fs_drama\": \"현대 드라마\",\n",
    "            \"history\": \"역사극\", \n",
    "            \"c_event\": \"시사 프로그램\",\n",
    "            \"culture\": \"교양지식 프로그램\",\n",
    "            \"enter\": \"예능 프로그램\"}\n",
    "\n",
    "for jf in tqdm(_datasets):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    meta = json_data[\"Meta\"]\n",
    "    annotation = json_data[\"Annotation\"]\n",
    "\n",
    "    if annotation[\"Summary1\"]:\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'이런 내용의 {DOC_TYPE[meta[\"doc_type\"]]} 대본 짜줘\\n{annotation[\"Summary1\"]}']\n",
    "        temp[2] += [f'{meta[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'요약하기\\n{meta[\"passage\"]}']\n",
    "        temp[2] += [f'{annotation[\"Summary1\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'이런 프로그램 제목 만들어줘\\n{annotation[\"Summary1\"]}']\n",
    "        temp[2] += [f'{meta[\"doc_origin\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'방송 유형 맞추기\\n{meta[\"passage\"]}']\n",
    "        temp[2] += [f'{DOC_TYPE[meta[\"doc_type\"]]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'이런 프로그램 제목 지어줘\\n{meta[\"passage\"]}']\n",
    "        temp[2] += [f'{meta[\"doc_origin\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'{DOC_TYPE[meta[\"doc_type\"]]} 방송에서 다룰 수 있는 주제 알려줘']\n",
    "        temp[2] += [f'{annotation[\"Summary1\"]}']\n",
    "\n",
    "    if annotation[\"Summary2\"]:\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'이런 내용의 {DOC_TYPE[meta[\"doc_type\"]]} 대본 짜줘\\n{annotation[\"Summary2\"]}']\n",
    "        temp[2] += [f'{meta[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'요약하기\\n{meta[\"passage\"]}']\n",
    "        temp[2] += [f'{annotation[\"Summary2\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'프로그램 제목 짓기\\n예시: {meta[\"passage\"]}']\n",
    "        temp[2] += [f'{meta[\"doc_origin\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'프로그램 제목 짓기\\n예시: {annotation[\"Summary2\"]}']\n",
    "        temp[2] += [f'{meta[\"doc_origin\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'방송 유형 맞추기\\n{meta[\"passage\"]}']\n",
    "        temp[2] += [f'{DOC_TYPE[meta[\"doc_type\"]]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'{DOC_TYPE[meta[\"doc_type\"]]} 방송에서 다룰 수 있는 주제 알려줘']\n",
    "        temp[2] += [f'{annotation[\"Summary2\"]}']\n",
    "\n",
    "    if annotation[\"Summary3\"]:\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'이런 내용의 {DOC_TYPE[meta[\"doc_type\"]]} 대본 짜줘\\n{annotation[\"Summary3\"]}']\n",
    "        temp[2] += [f'{meta[\"passage\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'요약하기\\n{meta[\"passage\"]}']\n",
    "        temp[2] += [f'{annotation[\"Summary3\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'제목 짓기\\n{meta[\"passage\"]}']\n",
    "        temp[2] += [f'{meta[\"doc_origin\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'제목 짓기\\n{annotation[\"Summary3\"]}']\n",
    "        temp[2] += [f'{meta[\"doc_origin\"]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'방송 유형 맞추기\\n{meta[\"passage\"]}']\n",
    "        temp[2] += [f'{DOC_TYPE[meta[\"doc_type\"]]}']\n",
    "\n",
    "        temp[0] += [f'chat']\n",
    "        temp[1] += [f'{DOC_TYPE[meta[\"doc_type\"]]} 방송에서 다룰 수 있는 주제 알려줘']\n",
    "        temp[2] += [f'{annotation[\"Summary3\"]}']\n",
    "\n",
    "\n",
    "data023 = pd.DataFrame({\"prompt\":temp[0],\"Q\":temp[1],\"A\":temp[2]})\n",
    "data023.to_csv(f\"{data_path}/data.csv\", index=False)\n",
    "print(\"saved at \", f\"{data_path}/data.csv\")\n",
    "del temp, data023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last file path :  C:/KevinJung/Datasets/AI허브/024.에세이 글 평가 데이터/01.데이터/2.Validation/라벨링데이터/찬성반대\n",
      "num of files :  45497\n"
     ]
    }
   ],
   "source": [
    "data_path = f'{path}/024.에세이 글 평가 데이터/01.데이터'\n",
    "_datasets = []\n",
    "for datasets_path in os.listdir(data_path): # 1.Training 2.Validation\n",
    "    if os.path.isdir(f'{data_path}/{datasets_path}'):\n",
    "        for dataset_dir in os.listdir(f'{data_path}/{datasets_path}'): # 라벨링데이터 원천데이터\n",
    "            if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}'):\n",
    "                for ij in os.listdir(f'{data_path}/{datasets_path}/{dataset_dir}'): # 글짓기 대안제시 ... TL_찬성반대.zip\n",
    "                    if os.path.isdir(f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'):\n",
    "                        _list = f'{data_path}/{datasets_path}/{dataset_dir}/{ij}'  # json files\n",
    "                        _datasets += [f'{_list}/{file}' for file in os.listdir(_list) if file.endswith('.json')]\n",
    "print(\"last file path : \", _list)\n",
    "print(\"num of files : \", len(_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adcaa155e734acb8fcb30efeb88ff65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "익숙함에 속아 소중함을 잊지말자라는 명언은 매우 유명한 명언이다. 난 이 명언의 내용과 같은 것을 겪은 적이있다. 중학교 때였다. 초등학교때부터 알고 지내였던 7년 지기 친구가 있었다. 이 친구와는 중학교도 같이 올라와 계속 같이 다녔다. 이 친구와 둘이서만 다닌 것이 아니라 한8명 정도가 같이 다녔다. 근데 난 이친구와 가장 친하고 이 친구가 가장 소중하였지만 다른 친구들과 더 많이 놀고, 7년 동안 이 친구와 다녔어서 익숙했다. 이 친구에게는 짜증을 더 많이 내었고, 분풀이도 하곤 했던 것 같다. 그래서 많이 싸웠던 것 같다. 그리고 이 친구의 성격을 너무 잘알아서 내가 고민을 말해도 답은 정해져 있었다. 그래서 그랬던 것이였던건지.. 다른 친구에게 더욱 더 내 속마음을 잘 털어놓게 되었고, 내 7년지기친구는 나의 속마음들을 잘 알지 못했다. 그래서 다른 친구와 7년지기 친구가 같이 있었는데 7년 지기 친구만 모르는 이야기여서 그 친구가 서운해 했던 적도 있었다. 그리고 어느날 7년 지기 친구가 나에게 다른 친구의 뒷담화를 하였다. 그 친구는 날 너무 믿어서 말해 주었겠지만 나는 다른 친구와도 친했던 사이이고, 7년지기 친구는 날 다 이해해줄꺼라는 잘못된 생각으로 그 친구가 한 말들을 다른 친구에게 하고 말았다. 그래서 그 친구는 다른사람도 아닌 7년지기인 내가 말했기 때문에 더 배신감이 들었을테고 상처도 더 많이 받았을 것이다. 이 사건을 통해 그 친구와 멀어지게 되었다. 난 이 사건을 겪고 익숙함에 속아 소중함을 잊지말자는 명언에 공감하게 되었다. 그리고 그 친구의 소중함을 까닭과 다시 다가가기위해 사과도 해보고 지금까지 나와 친구가 주고 받았던 편지 대화내용을 되새겼다. 그래서 그 친구의 소중함을 난 찾았고, 그 친구에게 내 진심을 전달하고 사과하여 다시 잘 지낼 수 있었다.\n",
      "소중함을 잃었던 경험\n",
      "\n",
      "001 익숙함에 속아 소중함을 잊지말자라는 명언은 매우 유명한 명언이다. 난 이 명언의 내용과 같은 것을 겪은 적이있다. 중학교 때였다. 초등학교때부터 알고 지내였던 7년 지기 친구가 있었다. 이 친구와는 중학교도 같이 올라와 계속 같이 다녔다. 이 친구와 둘이서만 다닌 것이 아니라 한8명 정도가 같이 다녔다. 근데 난 이친구와 가장 친하고 이 친구가 가장 소중하였지만 다른 친구들과 더 많이 놀고, 7년 동안 이 친구와 다녔어서 익숙했다. 이 친구에게는 짜증을 더 많이 내었고, 분풀이도 하곤 했던 것 같다. 그래서 많이 싸웠던 것 같다. 그리고 이 친구의 성격을 너무 잘알아서 내가 고민을 말해도 답은 정해져 있었다. 그래서 그랬던 것이였던건지.. 다른 친구에게 더욱 더 내 속마음을 잘 털어놓게 되었고, 내 7년지기친구는 나의 속마음들을 잘 알지 못했다. 그래서 다른 친구와 7년지기 친구가 같이 있었는데 7년 지기 친구만 모르는 이야기여서 그 친구가 서운해 했던 적도 있었다. 그리고 어느날 7년 지기 친구가 나에게 다른 친구의 뒷담화를 하였다. 그 친구는 날 너무 믿어서 말해 주었겠지만 나는 다른 친구와도 친했던 사이이고, 7년지기 친구는 날 다 이해해줄꺼라는 잘못된 생각으로 그 친구가 한 말들을 다른 친구에게 하고 말았다. 그래서 그 친구는 다른사람도 아닌 7년지기인 내가 말했기 때문에 더 배신감이 들었을테고 상처도 더 많이 받았을 것이다. 이 사건을 통해 그 친구와 멀어지게 되었다. 난 이 사건을 겪고 익숙함에 속아 소중함을 잊지말자는 명언에 공감하게 되었다. 그리고 그 친구의 소중함을 까닭과 다시 다가가기위해 사과도 해보고 지금까지 나와 친구가 주고 받았던 편지 대화내용을 되새겼다. 그래서 그 친구의 소중함을 난 찾았고, 그 친구에게 내 진심을 전달하고 사과하여 다시 잘 지낼 수 있었다. \n",
      "\n",
      "001 2.5555553\n"
     ]
    }
   ],
   "source": [
    "temp = [[],[],[]]\n",
    "DOC_TYPE = {\"fm_drama\": \"가족관련방송\",\n",
    "            \"fs_drama\": \"현대 드라마\",\n",
    "            \"history\": \"역사극\", \n",
    "            \"c_event\": \"시사 프로그램\",\n",
    "            \"culture\": \"교양지식 프로그램\",\n",
    "            \"enter\": \"예능 프로그램\"}\n",
    "\n",
    "for jf in tqdm(_datasets):\n",
    "    with open(jf, 'r', encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        f.close()\n",
    "    paragraph = json_data[\"paragraph\"]\n",
    "    score = json_data[\"score\"]\n",
    "    student = json_data[\"student\"]\n",
    "    rubric = json_data[\"rubric\"]\n",
    "    correction = json_data[\"correction\"]\n",
    "    info = json_data[\"info\"]\n",
    "\n",
    "    print(\" \".join([para[\"paragraph_txt\"].replace(\"#@문장구분#\",\"\") for para in paragraph]))\n",
    "    print(info[\"essay_main_subject\"])\n",
    "    print()\n",
    "\n",
    "    for para in paragraph:\n",
    "        print(para[\"paragraph_id\"], para[\"paragraph_txt\"].replace(\"#@문장구분#\",\"\"), \"\\n\")\n",
    "\n",
    "\n",
    "    for ps in score[\"paragraph_score\"]:\n",
    "        print(ps[\"paragraph_id\"], ps[\"paragraph_scoreT_avg\"])\n",
    "\n",
    "    \n",
    "    for ps in score[\"paragraph_score\"]:\n",
    "        ps[\"paragraph_scoreT\"][0]\n",
    "        ps[\"paragraph_scoreT_detail\"][\"paragraph_scoreT_exp\"][0]\n",
    "\n",
    "        ps[\"paragraph_scoreT\"][1]\n",
    "        ps[\"paragraph_scoreT_detail\"][\"paragraph_scoreT_exp\"][1]\n",
    "\n",
    "        ps[\"paragraph_scoreT\"][2]\n",
    "        ps[\"paragraph_scoreT_detail\"][\"paragraph_scoreT_exp\"][2]\n",
    "\n",
    "    score[\"essay_scoreT\"][0]\n",
    "    score[\"essay_scoreT\"][1]\n",
    "    score[\"essay_scoreT\"][2]\n",
    "\n",
    "    for key in score[\"essay_scoreT_detail\"].keys():\n",
    "        score[\"essay_scoreT_detail\"][key][0]\n",
    "        score[\"essay_scoreT_detail\"][key][1]\n",
    "        score[\"essay_scoreT_detail\"][key][2]\n",
    "\n",
    "\n",
    "    break \n",
    "\n",
    "# data024 = pd.DataFrame({\"prompt\":temp[0],\"Q\":temp[1],\"A\":temp[2]})\n",
    "# data024.to_csv(f\"{data_path}/data.csv\", index=False)\n",
    "# print(\"saved at \", f\"{data_path}/data.csv\")\n",
    "# del temp, data024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 + 3*4 = 12\n",
      "12 + 2*2 = 16\n",
      "16 + 3*2 = 22\n",
      "22 + 3*1 = 25\n",
      "org : 25 / 9 * 2 = 5.555555555555555\n",
      "\n",
      "0 + 3*4 = 12\n",
      "12 + 2*3 = 18\n",
      "18 + 0*0 = 18\n",
      "18 + 3*1 = 21\n",
      "cont : 21 / 8 * 4 = 10.5\n",
      "\n",
      "0 + 3*2 = 6\n",
      "6 + 3*3 = 15\n",
      "15 + 2*1 = 17\n",
      "exp : 17 / 6 * 4 = 11.333333333333334\n",
      "\n",
      "[27.38889, 22.666666, 25.555555]\n"
     ]
    }
   ],
   "source": [
    "exp_sorted = (\"exp_grammar\", \"exp_vocab\", \"exp_style\")\n",
    "cont_sorted = (\"con_clearance\", \"con_novelty\", \"con_prompt\",\"con_description\")\n",
    "org_sorted = (\"org_essay\", \"org_paragraph\", \"org_coherence\", \"org_quantity\")\n",
    "\n",
    "org_weights = [rubric[\"organization_weight\"][weight] for weight in org_sorted if \"_\" in weight]\n",
    "cont_weights = [rubric[\"content_weight\"][weight] for weight in cont_sorted if \"_\" in weight]\n",
    "exp_weights = [rubric[\"expression_weight\"][weight] for weight in exp_sorted if \"_\" in weight]\n",
    "\n",
    "for short, full,weights in zip([\"org\", \"cont\", \"exp\"],\n",
    "                               [\"organization\", \"content\", \"expression\"],\n",
    "                               [org_weights, cont_weights, exp_weights]):\n",
    "    S = 0\n",
    "    sumw = sum(weights)\n",
    "    for a,b in zip(score[\"essay_scoreT_detail\"][f\"essay_scoreT_{short}\"][0], weights):\n",
    "        print(f'{S} + {a}*{b} = {S+a*b}')\n",
    "        S += a*b\n",
    "    print(f'{short} : {S} / {sumw} * {rubric[f\"{full}_weight\"][short[:-1] if short ==\"cont\" else short]} = '\n",
    "          f'{S/sumw*rubric[f\"{full}_weight\"][short[:-1] if short ==\"cont\" else short]}\\n')\n",
    "\n",
    "print(score[\"essay_scoreT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wri_exp={\n",
    "     \"grammar\": {\n",
    "          \"0\": \"글에 문법적 오류가 많습니다.\", \n",
    "          \"1\": \"글에 문법적 오류가 다소 많습니다.\",\n",
    "          \"2\": \"글이 문법적 오류가 일부 있습니다.\",\n",
    "          \"3\": \"글이 문법적 오류 없이 완벽합니다.\"},\n",
    "     \"style\": {\n",
    "          \"0\": \"문장 구조가 천편일률적입니다. 문장의 길이가 너무 길거나 짧습니다.\", \n",
    "          \"1\": \"문장 구조의 다양상이 다소 부족합니다. 의견제시한 길이의 문장이 종종 나타납니다.\",\n",
    "          \"2\": \"다양한 문장 구조의 시도가 보입니다. 문장 길이를 대체로 적절하게 구성되어있습니다.\",\n",
    "          \"3\": \"다양한 문장 구조를 유창하게 적절히 사용합니다. 문장 길이가 매우 적절합니다.\"},\n",
    "     \"vocab\": {\n",
    "          \"0\": \"상황에 맞지 않는 단어의 사용이 매우 많습니다. 단어의 사용이 제한적입니다.\",\n",
    "          \"1\": \"상황에 맞지 않는 단어 사용이 꽤 보입니다. 단어의 사용이 다양하지 못합니다.\",\n",
    "          \"2\": \"단어 사용이 많은 부분을 상황에 맞게 사용되었습니다. 사용 단어의 다양성이 높은 편입니다.\",\n",
    "          \"3\": \"단어 사용을 대부분 상황에 맞게 사용하였습니다. 단어의 사용이 매우 다양합니다.\"},\n",
    "          }\n",
    "wri_exp={\n",
    "     \"grammar\": {\n",
    "          \"0\": \"글에 문법적 오류가 많습니다.\", \n",
    "          \"1\": \"글에 문법적 오류가 다소 많습니다.\",\n",
    "          \"2\": \"글이 문법적 오류가 일부 있습니다.\",\n",
    "          \"3\": \"글이 문법적 오류 없이 완벽합니다.\"},\n",
    "     \"style\": {\n",
    "          \"0\": \"문장 구조가 천편일률적입니다. 문장의 길이가 너무 길거나 짧습니다.\", \n",
    "          \"1\": \"문장 구조의 다양상이 다소 부족합니다. 의견제시한 길이의 문장이 종종 나타납니다.\",\n",
    "          \"2\": \"다양한 문장 구조의 시도가 보입니다. 문장 길이를 대체로 적절하게 구성되어있습니다.\",\n",
    "          \"3\": \"다양한 문장 구조를 유창하게 적절히 사용합니다. 문장 길이가 매우 적절합니다.\"},\n",
    "     \"vocab\": {\n",
    "          \"0\": \"상황에 맞지 않는 단어의 사용이 매우 많습니다. 단어의 사용이 제한적입니다.\",\n",
    "          \"1\": \"상황에 맞지 않는 단어 사용이 꽤 보입니다. 단어의 사용이 다양하지 못합니다.\",\n",
    "          \"2\": \"단어 사용이 많은 부분을 상황에 맞게 사용되었습니다. 사용 단어의 다양성이 높은 편입니다.\",\n",
    "          \"3\": \"단어 사용을 대부분 상황에 맞게 사용하였습니다. 단어의 사용이 매우 다양합니다.\"},\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_exp={\"0\":\"\", \n",
    "         \"1\":\"\",\n",
    "         \"2\":\"\",\n",
    "         \"3\":\"\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
