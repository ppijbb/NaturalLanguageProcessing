{"cells":[{"cell_type":"markdown","metadata":{"id":"XfahULH_8nv3"},"source":["# installation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31504,"status":"ok","timestamp":1662011925018,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"Br4fQjam8APU","outputId":"a016f9f5-3bc3-4954-ded9-87a20edb2ed0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: setuptools 57.4.0\n","Uninstalling setuptools-57.4.0:\n","  Successfully uninstalled setuptools-57.4.0\n","\u001b[K     |████████████████████████████████| 952 kB 5.5 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n","\u001b[K     |████████████████████████████████| 57 kB 2.1 MB/s \n","\u001b[K     |████████████████████████████████| 96 kB 2.6 MB/s \n","\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s \n","\u001b[K     |████████████████████████████████| 126 kB 11.7 MB/s \n","\u001b[K     |████████████████████████████████| 138 kB 64.7 MB/s \n","\u001b[K     |████████████████████████████████| 92 kB 10.3 MB/s \n","\u001b[K     |████████████████████████████████| 50 kB 5.6 MB/s \n","\u001b[K     |████████████████████████████████| 2.3 MB 62.1 MB/s \n","\u001b[K     |████████████████████████████████| 379 kB 50.5 MB/s \n","\u001b[K     |████████████████████████████████| 357 kB 50.0 MB/s \n","\u001b[?25h"]}],"source":["!pip uninstall setuptools -y\n","!pip install -q setuptools==59.6.0\n","!pip install --quiet korpora\n","# 나무위키 데이터 mediafire 링크에서 받아온 주소\n","!pip install -q py7zr ijson namu-wiki-extractor\n","# import setuptools\n","# import os\n","\n","# setuptools.distutils.version\n","\n","# def restart_runtime():\n","#   os.kill(os.getpid(), 9)\n","\n","# restart_runtime()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183716,"status":"ok","timestamp":1662012108728,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"F1tHvu9S0bky","outputId":"4ee290f6-b85c-4f01-95b6-501e624f0f13"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 527 kB 5.1 MB/s \n","\u001b[K     |████████████████████████████████| 259 kB 41.2 MB/s \n","\u001b[K     |████████████████████████████████| 4.7 MB 50.1 MB/s \n","\u001b[K     |████████████████████████████████| 419 kB 47.4 MB/s \n","\u001b[K     |████████████████████████████████| 829 kB 52.7 MB/s \n","\u001b[K     |████████████████████████████████| 952 kB 42.2 MB/s \n","\u001b[K     |████████████████████████████████| 120 kB 45.2 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 6.5 MB/s \n","\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n"]},{"data":{"text/plain":["['\\x1b[?25l',\n"," '\\x1b[K     |                                | 10 kB 17.7 MB/s eta 0:00:09',\n"," '\\x1b[K     |                                | 20 kB 22.6 MB/s eta 0:00:07',\n"," '\\x1b[K     |                                | 30 kB 27.5 MB/s eta 0:00:06',\n"," '\\x1b[K     |                                | 40 kB 31.5 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 51 kB 33.9 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 61 kB 36.4 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 71 kB 35.8 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 81 kB 34.9 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 92 kB 35.5 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 102 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 112 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 122 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 133 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 143 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 153 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 163 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 174 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 184 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 194 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 204 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 215 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 225 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 235 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 245 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 256 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 266 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 276 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 286 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 296 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 307 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 317 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 327 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 337 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 348 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 358 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 368 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 378 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 389 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 399 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 409 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 419 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 430 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 440 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 450 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 460 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 471 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 481 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 491 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 501 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |                                | 512 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 522 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 532 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 542 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 552 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 563 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 573 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 583 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 593 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 604 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 614 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 624 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 634 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 645 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 655 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 665 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 675 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 686 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 696 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 706 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 716 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 727 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 737 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 747 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 757 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 768 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 778 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 788 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 798 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 808 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 819 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 829 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 839 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 849 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 860 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 870 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 880 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 890 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 901 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 911 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 921 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 931 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 942 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 952 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 962 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 972 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 983 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 993 kB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 1.0 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 1.0 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 1.0 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▏                               | 1.0 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.0 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.1 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.2 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.3 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.4 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.5 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▎                               | 1.6 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:05',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 1.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▍                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▌                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 2.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▋                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▊                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 3.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |▉                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 4.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█                               | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▏                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 5.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▎                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▍                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 6.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▌                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▋                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 7.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▊                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |█▉                              | 8.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 8.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.3 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.4 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.5 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.6 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.7 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.8 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██                              | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 9.9 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.0 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.1 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.2 MB 37.1 MB/s eta 0:00:04',\n"," '\\x1b[K     |██▏                             | 10.2 MB 37.1 MB/s eta 0:00:04',\n"," ...]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# 설치하고 세션 다시시작 해주고 설치해야 정상적으로 인스톨 됨\n","import IPython\n","!pip install -q  pytorch-lightning==1.5.10 pytorch-ignite transformers\n","!!pip install -q cloud-tpu-client==0.10\\\n"," torch==1.9.0\\\n"," torchtext==0.10.0\\\n"," torchvision==0.10.0\\\n"," https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17795,"status":"ok","timestamp":1662012126518,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"2cNKXkkJkWp2","outputId":"2f4080bc-17ed-4ab2-a7c4-afbbe55bf529"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.2-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 15.3 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (59.5.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry-sdk-1.9.6.tar.gz (122 kB)\n","\u001b[K     |████████████████████████████████| 122 kB 56.7 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 913 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 42.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 47.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 44.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 40.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 39.2 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 48.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=02af8c64c82663a085b564632dd0a00c4c99717a6793b5cfe69dc8971361096f\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.2\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30638,"status":"ok","timestamp":1662012157149,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"qCMEDZSiqGyr","outputId":"0502a0e5-349c-4231-bac6-a8e380a9c6f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Detected operating system as Ubuntu/bionic.\n","Checking for curl...\n","Detected curl...\n","Checking for gpg...\n","Detected gpg...\n","Running apt-get update... done.\n","Installing apt-transport-https... done.\n","Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n","Importing packagecloud gpg key... done.\n","Running apt-get update... done.\n","\n","The repository is setup! You can now install packages.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following packages will be upgraded:\n","  git-lfs\n","1 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n","Need to get 7,168 kB of archives.\n","After this operation, 7,962 kB of additional disk space will be used.\n","Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 3.2.0 [7,168 kB]\n","Fetched 7,168 kB in 1s (8,465 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","(Reading database ... 155680 files and directories currently installed.)\n","Preparing to unpack .../git-lfs_3.2.0_amd64.deb ...\n","Unpacking git-lfs (3.2.0) over (2.3.4-1) ...\n","Setting up git-lfs (3.2.0) ...\n","Git LFS initialized.\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Git LFS initialized.\n"]}],"source":["!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n","# Install\n","!sudo apt-get install git-lfs\n","!git lfs install\n","!git config --global user.email \"ppijbb@gmail.com\"\n","!git config --global user.name \"gunulhona\""]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":283,"status":"ok","timestamp":1662012157419,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"f9XUxVUmUdY_"},"outputs":[],"source":["# # kowiki 데이터 가져오기\n","# !wget https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-pages-articles.xml.bz2\n","# !bzip2 -kd /content/kowiki-latest-pages-articles.xml.bz2\n","# !pip install -q wikiextractor\n","# !python -m wikiextractor.WikiExtractor /content/kowiki-latest-pages-articles.xml.bz2\n","\n","# # 나무위키 데이터 mediafire 링크에서 받아온 주소\n","# !pip install -q py7zr namu-wiki-extractor ijson\n","# !wget https://obj.thewiki.kr/thecloud/dumps/37d51b7a67b1ab2e3ebf93eae75ee90a.7z\n","# !py7zr x /content/37d51b7a67b1ab2e3ebf93eae75ee90a.7z"]},{"cell_type":"markdown","metadata":{"id":"4u5or6kb4qE6"},"source":["# DataLoad"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6590,"status":"ok","timestamp":1662012164006,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"ltwJViY24y4O"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","df = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/data/chatbot/스타일변환.xlsx\")\n","train, test = train_test_split(df,\n","                               test_size=0.2,\n","                               random_state=42)\n","train.to_csv(\"train.csv\",\n","             index=False)\n","test.to_csv(\"test.csv\",\n","            index=False)"]},{"cell_type":"markdown","metadata":{"id":"b7mbKG8I4shl"},"source":["# Seq to Seq Style Transfer"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656895055390,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"daB4dhFU7itW","outputId":"2d14727f-24db-440d-8c56-10b3ef49eca6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing model_config.json\n"]}],"source":["#@title model config file\n","#@markdown activations : relu, gelu, gelu_new, silu\n","%%writefile model_config.json\n","{\n","  \"_name_or_path\": \"Gunulhona/tbSTmodel_v1\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"silu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"author\": \"Kevin Jung(kevin.jung@turingbio.com)\",\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.1,\n","  \"classifier_dropout\": 0.1,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 1,\n","  \"do_blenderbot_90_layernorm\": true,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"Negative\",\n","    \"1\": \"Positive\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"kobart_version\": 1.0,\n","  \"label2id\": {\n","    \"Negative\": 0,\n","    \"Positive\": 1\n","  },\n","  \"max_position_embeddings\": 1026,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_hidden_layers\": 6,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"pad_token_id\": 3,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 30000\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656895055390,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"Sc3Tos-X5RXV","outputId":"2184c9a7-1ab4-4f75-e818-589f08e49f85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing kobart_style_transfer.py\n"]}],"source":["#@title <b><i>Training 파일 저장<i/></b>\n","%%writefile kobart_style_transfer.py\n","import argparse\n","import logging\n","import os\n","import gc\n","\n","import numpy as np\n","import pandas as pd\n","import time\n","\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchsummary import summary\n","\n","from transformers import (BartForConditionalGeneration,\n","                          BartConfig,\n","                          PreTrainedTokenizerFast)\n","from transformers.optimization import (get_cosine_schedule_with_warmup ,AdamW, Adafactor,\n","                                       get_constant_schedule_with_warmup,\n","                                       get_cosine_with_hard_restarts_schedule_with_warmup)\n","# from torch.optim import AdamW\n","import pytorch_lightning as pl\n","from pytorch_lightning import loggers as pl_loggers\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.callbacks import (TQDMProgressBar,\n","                                         StochasticWeightAveraging,\n","                                         DeviceStatsMonitor,\n","                                         XLAStatsMonitor)\n","# import torch_xla.core.xla_model as xm\n","from torchmetrics.text.bleu import BLEUScore\n","\n","\n","parser = argparse.ArgumentParser(description='KoBART Style Transfer')\n","\n","parser.add_argument('--checkpoint_path',\n","                    type=str,\n","                    help='checkpoint path')\n","\n","parser.add_argument('--chat',\n","                    action='store_true',\n","                    default=False,\n","                    help='response generation on given user input')\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)\n","\n","CONFIG = BartConfig.from_json_file('model_config.json')\n","\n","def save_hf_repo(model, tokenizer):    \n","    MODEL_SAVE_REPO = 'Gunulhona/tbSTmodel_v1'#@param {type:\"string\"}\n","    HUGGINGFACE_AUTO_TOKEN = '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' \n","    model.config=CONFIG\n","    model.cpu().push_to_hub(MODEL_SAVE_REPO, \n","\t\t\t                # use_temp_dir=True, \n","\t\t\t                use_auth_token=HUGGINGFACE_AUTO_TOKEN)\n","    tokenizer.push_to_hub(MODEL_SAVE_REPO, \n","     \t\t\t\t\t  # use_temp_dir=True, \n","    \t\t\t\t\t  use_auth_token=HUGGINGFACE_AUTO_TOKEN)\n","    print(f'### torch kobart-chat model has saved at {MODEL_SAVE_REPO} ###')\n","\n","class ArgsBase():\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):\n","        parser = argparse.ArgumentParser(\n","            parents=[parent_parser], add_help=False)\n","        parser.add_argument('--train_file',\n","                            type=str,\n","                            default='train.csv',\n","                            help='train file')\n","\n","        parser.add_argument('--test_file',\n","                            type=str,\n","                            default='test.csv',\n","                            help='test file')\n","\n","        parser.add_argument('--tokenizer_path',\n","                            type=str,\n","                            default='tokenizer',\n","                            help='tokenizer')\n","        parser.add_argument('--max_seq_len',\n","                            type=int,\n","                            default=256,\n","                            help='max sequence len')\n","        return parser\n","\n","# few shot dialouge Generation\n","class StyleDataset(Dataset):\n","    def __init__(self, \n","                 filepath, \n","                 tok_vocab, \n","                 max_seq_len=256) -> None:\n","        self.filepath = filepath\n","        self.data = pd.read_csv(self.filepath).dropna()\n","        self.bos_token = '<s>'\n","        self.eos_token = '</s>'\n","        self.max_seq_len = max_seq_len\n","        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(tok_vocab,)\n","\n","    def _resize_token_embeddings(self):\n","        tokens = {\"additional_special_tokens\":[\"<P01>\",\"<P02>\",\"<P03>\",\"<P04>\",\"<P05>\",\"<P06>\",\"<P07>\",\"<P08>\",\"<P09>\"]}\n","        self.tokenizer.add_special_tokens(tokens)\n","        self.model.resize_token_embeddings(len(self.tokenizer))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def make_input_id_mask(self, tokens, index):\n","        input_id = self.tokenizer.convert_tokens_to_ids(tokens)\n","        attention_mask = [1] * len(input_id)\n","        if len(input_id) < self.max_seq_len:\n","            while len(input_id) < self.max_seq_len:\n","                input_id += [self.tokenizer.pad_token_id]\n","                attention_mask += [0]\n","        else:\n","            # logging.warning(f'exceed max_seq_len for given article : {index}')\n","            input_id = input_id[:self.max_seq_len - 1] + [self.tokenizer.eos_token_id]\n","            attention_mask = attention_mask[:self.max_seq_len]\n","        return input_id, attention_mask\n","\n","    def masking(self,input, mask):\n","        input = torch.tensor([input])\n","        rand = torch.rand(input.shape)\n","        mask_arr = (rand < 0.15) * (input != self.tokenizer.bos_token_id) * (input != self.tokenizer.eos_token_id)\n","        mask_ids = torch.flatten((mask_arr[0]).nonzero()).tolist()\n","        input[0,mask_ids] = mask\n","        del rand, mask_arr\n","        return input.tolist()[0]\n","\n","    def _labeling(self,label):\n","        tokens = [self.tokenizer.bos_token]+self.tokenizer.tokenize(label)+[self.tokenizer.eos_token]\n","        label_ids = self.tokenizer.convert_tokens_to_ids(tokens[1:])\n","        if len(label_ids) < self.max_seq_len:\n","            while len(label_ids)<self.max_seq_len:\n","                label_ids+=[-100]\n","        else:\n","            label_ids = label_ids[:self.max_seq_len-1] + [self.tokenizer.eos_token_id]\n","        del tokens\n","        return label_ids\n","\n","    def __getitem__(self, index):\n","        record = self.data.iloc[index]\n","        # samples = self.data.sample(n=3)\n","        q, a = record['text'], record['label']\n","        q_tokens = [self.eos_token] + self.tokenizer.tokenize(q) + [self.eos_token]\n","        a_tokens = [self.eos_token] + self.tokenizer.tokenize(a) + [self.eos_token]\n","        encoder_input_id, encoder_attention_mask = self.make_input_id_mask(q_tokens, index)\n","        decoder_input_id, decoder_attention_mask = self.make_input_id_mask(a_tokens[:-1], index)\n","        # labels = self._labeling(a)\n","        labels = self.tokenizer.convert_tokens_to_ids(a_tokens[1:(self.max_seq_len + 1)])\n","        # encoder_input_id = self.masking(encoder_input_id, self.tokenizer.mask_token_id)\n","        if len(labels) < self.max_seq_len:\n","            while len(labels) < self.max_seq_len:\n","                # for cross entropy loss masking\n","                labels += [-100]\n","        # encoder_input_id = self.masking(encoder_input_id, self.tokenizer.mask_token_id)\n","        del record, q, a, q_tokens, a_tokens\n","        return {'input_ids': np.array(encoder_input_id, dtype=np.int_),\n","                'attention_mask': np.array(encoder_attention_mask, dtype=np.float_),\n","                'decoder_input_ids': np.array(decoder_input_id, dtype=np.int_),\n","                'decoder_attention_mask': np.array(decoder_attention_mask, dtype=np.float_),\n","                'labels': np.array(labels, dtype=np.int_)}\n","\n","\n","class StyleDataModule(pl.LightningDataModule):\n","    def __init__(self,\n","                 train_file,\n","                 test_file,\n","                 tok_vocab,\n","                 max_seq_len=512,\n","                 batch_size=64,\n","                 num_workers=8):\n","        super().__init__()\n","        self.batch_size = batch_size #batch_size\n","        self.max_seq_len = max_seq_len\n","        self.train_file_path = train_file\n","        self.test_file_path = test_file\n","        self.tok_vocab = tok_vocab\n","        self.num_workers = num_workers\n","        self.prepare_data_pre_node = True\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):\n","        parser = argparse.ArgumentParser(\n","            parents=[parent_parser], add_help=False)\n","        parser.add_argument('--num_workers',\n","                            type=int,\n","                            default=8,\n","                            help='num of worker for dataloader')\n","        return parser\n","\n","    # OPTIONAL, called for every GPU/machine (assigning state is OK)\n","    def setup(self, stage):\n","        # split dataset\n","        self.train = StyleDataset(self.train_file_path,\n","                                 self.tok_vocab,\n","                                 self.max_seq_len)\n","        \n","        self.test = StyleDataset(self.test_file_path,\n","                                self.tok_vocab,\n","                                self.max_seq_len)\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.train,\n","                           batch_size=self.batch_size,\n","                           num_workers=self.num_workers,\n","                           pin_memory=True,\n","                           shuffle=True)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.test,\n","                         batch_size=self.batch_size,\n","                         num_workers= self.num_workers,\n","                         pin_memory=True, \n","                         shuffle=False)\n","\n","    def test_dataloader(self):\n","        return DataLoader(self.test,\n","                          batch_size=self.batch_size,\n","                          num_workers= self.num_workers,\n","                          pin_memory=True,\n","                          shuffle=False)\n","        \n","\n","\n","class Base(pl.LightningModule):\n","    def __init__(self, hparams, **kwargs) -> None:\n","        super(Base, self).__init__()\n","        self.save_hyperparameters(hparams)\n","\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):\n","        # add model specific args\n","        parser = argparse.ArgumentParser(\n","            parents=[parent_parser], add_help=False)\n","\n","        parser.add_argument('--batch-size',\n","                            type=int,\n","                            default=32,\n","                            help='batch size for training (default: 96)')\n","\n","        parser.add_argument('--lr',\n","                            type=float,\n","                            default=5e-7,\n","                            help='The initial learning rate')\n","\n","        parser.add_argument('--warmup_ratio',\n","                            type=float,\n","                            default=0.1,\n","                            help='warmup ratio')\n","\n","        parser.add_argument('--model_path',\n","                            type=str,\n","                            default=None,\n","                            help='kobart model path')\n","        return parser\n","\n","    def configure_optimizers(self):\n","        # Prepare optimizer\n","        param_optimizer = list(self.model.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {'params': [p for n, p in param_optimizer if not any(\n","                nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","            {'params': [p for n, p in param_optimizer if any(\n","                nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","        # optimizer = AdamW(optimizer_grouped_parameters,\n","        #                   lr = self.hparams.lr,\n","        #                   correct_bias=False)\n","        optimizer = Adafactor(optimizer_grouped_parameters,\n","                          lr=self.hparams.lr,\n","                          beta1=0.9,\n","                          relative_step=False,\n","                        #   warmup_init=True,\n","                          weight_decay=0.1,)\n","        # warm up lr\n","        num_workers = (self.hparams.gpus if self.hparams.gpus is not None else 1) * (self.hparams.num_nodes if self.hparams.num_nodes is not None else 1)\n","        data_len = len(self.trainer._data_connector._train_dataloader_source.dataloader().dataset)\n","        logging.info(f'number of workers {num_workers}, data length {data_len}')\n","        num_train_steps = int(data_len / (self.hparams.batch_size * num_workers) * self.hparams.max_epochs)\n","        logging.info(f'num_train_steps : {num_train_steps}')\n","        num_warmup_steps = int(num_train_steps * self.hparams.warmup_ratio)\n","        logging.info(f'num_warmup_steps : {num_warmup_steps}')\n","        #get_cosine_schedule_with_warmup get_cosine_with_hard_restarts_schedule_with_warmup\n","        #get_constant_schedule_with_warmup\n","        scheduler = \\\n","            get_constant_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps, )\n","            # num_training_steps=num_train_steps,\n","            # num_cycles=num_workers+1)\n","        lr_scheduler = {'scheduler': scheduler, \n","                        'monitor': 'loss', \n","                        'interval': 'step',\n","                        'frequency': 1}\n","        return [optimizer], [lr_scheduler]\n","        # return optimizer\n","\n","class KoBARTConditionalGeneration(Base):\n","    def __init__(self, hparams, **kwargs):\n","        super(KoBARTConditionalGeneration, self).__init__(hparams, **kwargs)\n","        try:\n","            self.model = BartForConditionalGeneration.from_pretrained(self.hparams.model_path,)\n","                                                                    #   revision=\"6ac339a9d204d912afbb3aaa28f0e4e8e9a25e8e\")\n","                                                                    #   revision=\"b6451e14d59c84af077bd5e1e6447437f4a21d0b\")\n","        except:\n","            print(f\"Error) Cannot read model from {self.hparams.model_path}\\n\"\n","                  f\"exception in porgress\")\n","            self.model = BartForConditionalGeneration.from_pretrained(self.hparams.model_path,\n","                                                                  revision=\"b6451e14d59c84af077bd5e1e6447437f4a21d0b\")\n","        self.model.config = CONFIG\n","        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(self.hparams.tokenizer_path)\n","        self.bos_token = '<s>'\n","        self.eos_token = '</s>'\n","        # self.model.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/data/chatbot/EMO_Model/KoBART_Chat_Model_V1.0.pth\"))\n","        # self.model.train().share_memory()\n","    \n","    def mle_loss(self,logits, labels):\n","        lprobs = F.log_softmax(logits, dim=-1)\n","        return -F.nll_loss(lprobs.view(-1, self.model.config.vocab_size),\n","                           labels.view(-1),\n","                           reduction='sum')\n","\n","    def _resize_token_embeddings(self):\n","        tokens = {\"additional_special_tokens\":[\"<P01>\",\"<P02>\",\"<P03>\",\"<P04>\",\"<P05>\",\"<P06>\",\"<P07>\",\"<P08>\",\"<P09>\"]}\n","        self.tokenizer.add_special_tokens(tokens)\n","        self.model.resize_token_embeddings(len(self.tokenizer))\n","\n","    def forward(self, inputs):\n","        return self.model(input_ids=inputs['input_ids'],\n","                            attention_mask=inputs['attention_mask'],\n","                            decoder_input_ids=inputs['decoder_input_ids'],\n","                            decoder_attention_mask=inputs['decoder_attention_mask'],\n","                            labels=inputs['labels'],\n","                            return_dict=True)\n","        # output.loss += self.mle_loss(output.logits, inputs['labels'])\n","        # return output\n","\n","    def training_step(self, batch, batch_idx):\n","        gc.collect()\n","        outs = self(batch)\n","        self.log('train_loss', outs.loss, prog_bar=True, on_step=True, on_epoch=True)\n","        self.log('perplexity', torch.exp(outs.loss),prog_bar=True, on_step=True, on_epoch=True)\n","        gc.collect()\n","        return outs.loss\n","\n","    # def training_step_end(self, training_step_outputs):\n","    #     return training_step_outputs\n","\n","    # def training_epoch_end(self, training_step_outputs):\n","    #     return training_step_outputs\n","\n","    def validation_step(self, batch, batch_idx):\n","        outs = self(batch)\n","        # self.log(\"batch_size\", outs[\"logits\"].shape[0], prog_bar=True, on_step=False, on_epoch=True)\n","        self.log('val_loss', outs['loss'], prog_bar=True, on_step=False, on_epoch=True)\n","        self.log('perplexity',torch.exp(outs['loss']),prog_bar=True, on_step=False, on_epoch=True)\n","\n","    # def validation_epoch_end(self, outputs):\n","    #     bleu = bleu_score(self.predictions, self.targets) \n","\n","    def chat(self, text):\n","        input_ids =  [self.tokenizer.eos_token_id] + self.tokenizer.encode(text) + [self.tokenizer.eos_token_id]\n","        res_ids = self.model.generate(torch.tensor([input_ids]),\n","                                      num_beams=1,\n","                                      top_p=0.8,\n","                                      top_k=0,\n","                                      temperature=1,\n","                                      max_length=60,\n","                                      min_length=20,\n","                                      length_penalty=0.65,\n","                                      do_sample=True,\n","                                      repetition_penalty=1.3,\n","                                      no_repeat_ngram_size=2,\n","                                      encoder_no_repeat_ngram_size=2,\n","                                      num_return_sequences=5)   \n","        a = self.tokenizer.batch_decode(res_ids.tolist())\n","        for x in a:\n","            print(\"생성 문장\",x)\n","        return a[0].replace(\"<s>\",\"\").replace(\"</s>\",\"\").replace(\"<usr>\",\"\").replace(\"<sys>\",\"\").replace(\"<pad>\",\"\")\n","\n","\n","#main만 고쳐서 실행\n","if __name__ == '__main__':\n","    parser = Base.add_model_specific_args(parser)\n","    parser = ArgsBase.add_model_specific_args(parser)\n","    parser = StyleDataModule.add_model_specific_args(parser)\n","    parser = pl.Trainer.add_argparse_args(parser)\n","    args = parser.parse_args()\n","    logging.info(args)\n","\n","    model = KoBARTConditionalGeneration(args)\n","\n","    dm = StyleDataModule(train_file=args.train_file,\n","                        test_file=args.test_file,\n","                        tok_vocab=args.tokenizer_path,\n","                        batch_size=args.batch_size,\n","                        max_seq_len=args.max_seq_len,\n","                        num_workers=args.num_workers)\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss',\n","                                                       dirpath=args.default_root_dir,\n","                                                       filename='best-checkpoint',\n","                                                       verbose=True,\n","                                                       save_last=True,\n","                                                       mode='min',\n","                                                       save_top_k=1,)\n","    tb_logger = pl_loggers.TensorBoardLogger(os.path.join(args.default_root_dir,'tb_logs'),\n","                                             log_graph=False,)\n","    lr_logger = pl.callbacks.LearningRateMonitor()\n","    trainer = pl.Trainer.from_argparse_args(args,\n","                                            logger=tb_logger,\n","                                            callbacks=[checkpoint_callback, \n","                                                       lr_logger,\n","                                                       # EarlyStopping(monitor=\"val_loss\",\n","                                                       #              stopping_threshold=1e-4,\n","                                                       #              min_delta=0.00,\n","                                                       #              patience=int(args.max_epochs/2),\n","                                                       #              divergence_threshold=9.0),])\n","                                                       ])\n","    trainer.fit(model, dm, )#ckpt_path=args.default_root_dir+\"/last.ckpt\")\n","    \n","    if args.chat:\n","        model.model.eval()\n","        # que=[]\n","        while 1:\n","            q = input('user > ').strip()\n","            # if len(que) > 5:\n","            #   que.pop(0)\n","            # que.append(\"<usr>\"+q)\n","            if q == 'quit':\n","                break\n","            elif q == 'save':\n","                torch.save(model.model.state_dict(),\"model.pth\")\n","                print(f'kobart-chat model.pth has saved at model.pth')\n","                save_hf_repo(model.model.cpu(), model.tokenizer)\n","            # else:\n","            #     text=\"\"\n","            #     for x in que:\n","            #         text+=x\n","            # print(text)\n","            result=model.chat(q)\n","            # que.append(result)\n","            print(\"Simsimi > {}\".format(result))\n","    else:\n","        # torch.save(model.model.state_dict(),save_path)\n","        print(f'### torch kobart-chat model.pth has saved at huggingface ###')"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1656895169965,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"TGWjrZn66hmD","outputId":"3efd76e9-15a2-43ee-a506-5af6bbde5a09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting trainer.sh\n"]}],"source":["#@title schema_trainer.sh : training hyperparameters\n","#@markdown gogamza/kobart-base-v1 / hyunwoongko/kobart / Gunulhona/tbsentmodel_v1 \\\n","#@markdown 181이 tpu 멀티코어에서 가능한 max sequence length?\\\n","#@markdown rm -rdf logs\n","#     python -m torch_xla.distributed.xla_dist \\\n","#       --strategy dp\\\n","#       --tpu_cores 8\\\n","#       --tpu $TPU_NAME\\\n","#       --fast_dev_run $FAST_DEV_RUN\\\n","#       --move_metrics_to_cpu true\\\n","#       --replace_sampler_ddp 1\\\n","#       --num_sanity_val_steps 5\\\n","#       --weights_summary top\\\n","#       --benchmark 1\\\n","#       --resume_from_checkpoint logs/last.ckpt\\\n","#       --sync_batchnorm true\\\n","%%writefile trainer.sh\n","TRAIN_FILE=$\"train.csv\" #@param \n","TEST_FILE=$\"test.csv\" #@param\n","MAX_SEQ_LEN=$\"128\" #@param [\"$\\\"128\\\"\", \"$\\\"181\\\"\", \"$\\\"256\\\"\", \"$\\\"512\\\"\", \"$\\\"768\\\"\"] {type:\"raw\", allow-input: true}\n","LEARNING_RATE=$\"5e-5\" #@param\n","GRADIENT_CLIP=$\"1.0\" #@param\n","BATCH_SIZE=$\"64\" #@param [\"$\\\"1\\\"\", \"$\\\"8\\\"\", \"$\\\"64\\\"\", \"$\\\"512\\\"\", \"$\\\"4096\\\"\", \"$\\\"32768\\\"\", \"$\\\"262144\\\"\", \"$\\\"2097152\\\"\", \"$\\\"16777216\\\"\", \"$\\\"134217728\\\"\", \"$\\\"1073741824\\\"\", \"$\\\"8589934592\\\"\", \"$\\\"68719476736\\\"\"] {type:\"raw\", allow-input: true}\n","MAXEPOCHS=$\"100\" #@param\n","STRATEGY=$\"dp\" #@param\n","MODEL_NAME=$\"Gunulhona/tbSTmodel_v1\" #@param [\"$\\\"gogamza/kobart-base-v1\\\"\", \"$\\\"Gunulhona/tbstmodel_v2\\\"\"] {type:\"raw\", allow-input: true}\n","TOKENIZER_PATH=$\"Gunulhona/tbbarttokenizer\" #@param\n","NUMWORKERS=$\"8\" #@param\n","PROFILE=$\"xla\" #@param\n","FAST_DEV_RUN=$\"false\" #@param \n","CORES=$\"8\" #@param\n","\n","python \\\n","        /content/kobart_style_transfer.py\\\n","        --gradient_clip_val $GRADIENT_CLIP\\\n","        --max_epochs $MAXEPOCHS\\\n","        --lr $LEARNING_RATE\\\n","        --batch-size $BATCH_SIZE\\\n","        --precision bf16\\\n","        --max_seq_len $MAX_SEQ_LEN\\\n","        --default_root_dir logs\\\n","        --train_file $TRAIN_FILE\\\n","        --test_file $TEST_FILE\\\n","        --model_path  $MODEL_NAME\\\n","        --tokenizer_path $TOKENIZER_PATH\\\n","        --accelerator tpu\\\n","        --strategy $STRATEGY\\\n","        --devices $CORES\\\n","        --num_nodes $CORES\\\n","        --num_processes $CORES\\\n","        --num_workers $NUMWORKERS\\\n","        --replace_sampler_ddp true\\\n","        --sync_batchnorm true\\\n","        --move_metrics_to_cpu false\\\n","        --profiler $PROFILE\\\n","        --chat"]},{"cell_type":"markdown","metadata":{"id":"DW7uJ6M06uLN"},"source":["<p>텐서보드 열기</p>\n","스크래치 셀에서 열어서 같이 보기 CTRL + ALT + \"N\"\n","\n","> xla profile default address => 0.0.0.0:9012 \n","\n","```shell\n","!echo $TPU_NAME\n","!export TPU_LOAD_LIBRARY=0\n","%load_ext tensorboard\n","%tensorboard --logdir=logs --load_fast=false --port 9012\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21016848,"status":"ok","timestamp":1656916619121,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"HJErWl0lYI-d","outputId":"25079d30-1013-46af-8f21-fcec3a4368c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["grpc://10.28.48.122:8470\n","  No data collected. Perhaps, nothing is being executed on the TPU?\n","\n","\n","WARNING:root:TPU has started up successfully with version pytorch-1.9\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'Negative', '1': 'Positive'}. The number of labels wil be overwritten to 2.\n","INFO:root:Namespace(accelerator='tpu', accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=64, benchmark=False, chat=True, check_val_every_n_epoch=1, checkpoint_callback=None, checkpoint_path=None, default_root_dir='logs', detect_anomaly=False, deterministic=False, devices='8', enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, fast_dev_run=False, flush_logs_every_n_steps=None, gpus=None, gradient_clip_algorithm=None, gradient_clip_val=1.0, ipus=None, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=5e-05, max_epochs=100, max_seq_len=128, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, model_path='Gunulhona/tbSTmodel_v1', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=8, num_processes=8, num_sanity_val_steps=2, num_workers=8, overfit_batches=0.0, plugins=None, precision='bf16', prepare_data_per_node=None, process_position=0, profiler='xla', progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, stochastic_weight_avg=False, strategy='dp', sync_batchnorm=True, terminate_on_nan=None, test_file='test.csv', tokenizer_path='Gunulhona/tbbarttokenizer', tpu_cores=None, track_grad_norm=-1, train_file='train.csv', val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'Negative', '1': 'Positive'}. The number of labels wil be overwritten to 2.\n","GPU available: False, used: False\n","TPU available: True, using: 8 TPU cores\n","IPU available: False, using: 0 IPUs\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","INFO:root:number of workers 8, data length 11763\n","INFO:root:num_train_steps : 2297\n","INFO:root:num_warmup_steps : 229\n","\n","  | Name  | Type                         | Params\n","-------------------------------------------------------\n","0 | model | BartForConditionalGeneration | 123 M \n","-------------------------------------------------------\n","123 M     Trainable params\n","0         Non-trainable params\n","123 M     Total params\n","495.440   Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /content/logs exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n","Epoch 0: 100% 29/29 [06:00<00:00, 12.44s/it, loss=0.926, v_num=1, train_loss_step=0.800, perplexity_step=2.230]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 0: 100% 29/29 [06:35<00:00, 13.64s/it, loss=0.94, v_num=1, train_loss_step=0.988, perplexity_step=2.690, val_loss=0.868, perplexity=2.390]\n","Epoch 0: 100% 29/29 [06:36<00:00, 13.66s/it, loss=0.94, v_num=1, train_loss_step=0.988, perplexity_step=2.690, val_loss=0.868, perplexity=2.390, train_loss_epoch=0.934, perplexity_epoch=2.550]Epoch 0, global step 22: val_loss reached 0.86798 (best 0.86798), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 1: 100% 29/29 [02:59<00:00,  6.20s/it, loss=0.942, v_num=1, train_loss_step=1.010, perplexity_step=2.740, val_loss=0.868, perplexity=2.390, train_loss_epoch=0.934, perplexity_epoch=2.550]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 1: 100% 29/29 [03:09<00:00,  6.52s/it, loss=0.946, v_num=1, train_loss_step=0.909, perplexity_step=2.480, val_loss=0.866, perplexity=2.380, train_loss_epoch=0.934, perplexity_epoch=2.550]\n","Epoch 1: 100% 29/29 [03:09<00:00,  6.52s/it, loss=0.946, v_num=1, train_loss_step=0.909, perplexity_step=2.480, val_loss=0.866, perplexity=2.380, train_loss_epoch=0.933, perplexity_epoch=2.550]Epoch 1, global step 45: val_loss reached 0.86571 (best 0.86571), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 2: 100% 29/29 [02:39<00:00,  5.51s/it, loss=0.949, v_num=1, train_loss_step=0.945, perplexity_step=2.570, val_loss=0.866, perplexity=2.380, train_loss_epoch=0.933, perplexity_epoch=2.550]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 2: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.923, v_num=1, train_loss_step=0.806, perplexity_step=2.240, val_loss=0.863, perplexity=2.380, train_loss_epoch=0.933, perplexity_epoch=2.550]\n","Epoch 2: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.923, v_num=1, train_loss_step=0.806, perplexity_step=2.240, val_loss=0.863, perplexity=2.380, train_loss_epoch=0.933, perplexity_epoch=2.550]Epoch 2, global step 68: val_loss reached 0.86307 (best 0.86307), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 3: 100% 29/29 [02:42<00:00,  5.59s/it, loss=0.954, v_num=1, train_loss_step=1.000, perplexity_step=2.730, val_loss=0.863, perplexity=2.380, train_loss_epoch=0.933, perplexity_epoch=2.550]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 3: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.947, v_num=1, train_loss_step=0.841, perplexity_step=2.320, val_loss=0.860, perplexity=2.370, train_loss_epoch=0.933, perplexity_epoch=2.550]\n","Epoch 3: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.947, v_num=1, train_loss_step=0.841, perplexity_step=2.320, val_loss=0.860, perplexity=2.370, train_loss_epoch=0.930, perplexity_epoch=2.540]Epoch 3, global step 91: val_loss reached 0.85970 (best 0.85970), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 4: 100% 29/29 [02:46<00:00,  5.74s/it, loss=0.962, v_num=1, train_loss_step=0.953, perplexity_step=2.590, val_loss=0.860, perplexity=2.370, train_loss_epoch=0.930, perplexity_epoch=2.540]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 4: 100% 29/29 [02:55<00:00,  6.04s/it, loss=0.949, v_num=1, train_loss_step=0.775, perplexity_step=2.170, val_loss=0.857, perplexity=2.360, train_loss_epoch=0.930, perplexity_epoch=2.540]\n","Epoch 4: 100% 29/29 [02:55<00:00,  6.04s/it, loss=0.949, v_num=1, train_loss_step=0.775, perplexity_step=2.170, val_loss=0.857, perplexity=2.360, train_loss_epoch=0.926, perplexity_epoch=2.530]Epoch 4, global step 114: val_loss reached 0.85739 (best 0.85739), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 5: 100% 29/29 [02:44<00:00,  5.66s/it, loss=0.914, v_num=1, train_loss_step=0.773, perplexity_step=2.170, val_loss=0.857, perplexity=2.360, train_loss_epoch=0.926, perplexity_epoch=2.530]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 5: 100% 29/29 [02:53<00:00,  5.98s/it, loss=0.911, v_num=1, train_loss_step=0.917, perplexity_step=2.500, val_loss=0.852, perplexity=2.350, train_loss_epoch=0.926, perplexity_epoch=2.530]\n","Epoch 5: 100% 29/29 [02:53<00:00,  5.98s/it, loss=0.911, v_num=1, train_loss_step=0.917, perplexity_step=2.500, val_loss=0.852, perplexity=2.350, train_loss_epoch=0.924, perplexity_epoch=2.530]Epoch 5, global step 137: val_loss reached 0.85185 (best 0.85185), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 6: 100% 29/29 [02:39<00:00,  5.50s/it, loss=0.932, v_num=1, train_loss_step=0.852, perplexity_step=2.350, val_loss=0.852, perplexity=2.350, train_loss_epoch=0.924, perplexity_epoch=2.530]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 6: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.928, v_num=1, train_loss_step=0.842, perplexity_step=2.320, val_loss=0.845, perplexity=2.330, train_loss_epoch=0.924, perplexity_epoch=2.530]\n","Epoch 6: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.928, v_num=1, train_loss_step=0.842, perplexity_step=2.320, val_loss=0.845, perplexity=2.330, train_loss_epoch=0.917, perplexity_epoch=2.510]Epoch 6, global step 160: val_loss reached 0.84506 (best 0.84506), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 7: 100% 29/29 [02:45<00:00,  5.70s/it, loss=0.897, v_num=1, train_loss_step=0.861, perplexity_step=2.370, val_loss=0.845, perplexity=2.330, train_loss_epoch=0.917, perplexity_epoch=2.510]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 7: 100% 29/29 [02:55<00:00,  6.04s/it, loss=0.891, v_num=1, train_loss_step=0.874, perplexity_step=2.400, val_loss=0.839, perplexity=2.320, train_loss_epoch=0.917, perplexity_epoch=2.510]\n","Epoch 7: 100% 29/29 [02:55<00:00,  6.04s/it, loss=0.891, v_num=1, train_loss_step=0.874, perplexity_step=2.400, val_loss=0.839, perplexity=2.320, train_loss_epoch=0.912, perplexity_epoch=2.500]Epoch 7, global step 183: val_loss reached 0.83917 (best 0.83917), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 8: 100% 29/29 [02:43<00:00,  5.63s/it, loss=0.888, v_num=1, train_loss_step=0.875, perplexity_step=2.400, val_loss=0.839, perplexity=2.320, train_loss_epoch=0.912, perplexity_epoch=2.500]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 8: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.887, v_num=1, train_loss_step=0.946, perplexity_step=2.580, val_loss=0.833, perplexity=2.310, train_loss_epoch=0.912, perplexity_epoch=2.500]\n","Epoch 8: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.887, v_num=1, train_loss_step=0.946, perplexity_step=2.580, val_loss=0.833, perplexity=2.310, train_loss_epoch=0.905, perplexity_epoch=2.480]Epoch 8, global step 206: val_loss reached 0.83318 (best 0.83318), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 9: 100% 29/29 [02:43<00:00,  5.64s/it, loss=0.899, v_num=1, train_loss_step=0.963, perplexity_step=2.620, val_loss=0.833, perplexity=2.310, train_loss_epoch=0.905, perplexity_epoch=2.480]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 9: 100% 29/29 [02:53<00:00,  5.98s/it, loss=0.914, v_num=1, train_loss_step=0.859, perplexity_step=2.360, val_loss=0.825, perplexity=2.290, train_loss_epoch=0.905, perplexity_epoch=2.480]\n","Epoch 9: 100% 29/29 [02:53<00:00,  5.98s/it, loss=0.914, v_num=1, train_loss_step=0.859, perplexity_step=2.360, val_loss=0.825, perplexity=2.290, train_loss_epoch=0.898, perplexity_epoch=2.460]Epoch 9, global step 229: val_loss reached 0.82530 (best 0.82530), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 10: 100% 29/29 [02:46<00:00,  5.75s/it, loss=0.895, v_num=1, train_loss_step=0.975, perplexity_step=2.650, val_loss=0.825, perplexity=2.290, train_loss_epoch=0.898, perplexity_epoch=2.460]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 10: 100% 29/29 [02:56<00:00,  6.09s/it, loss=0.894, v_num=1, train_loss_step=0.830, perplexity_step=2.290, val_loss=0.816, perplexity=2.270, train_loss_epoch=0.898, perplexity_epoch=2.460]\n","Epoch 10: 100% 29/29 [02:56<00:00,  6.10s/it, loss=0.894, v_num=1, train_loss_step=0.830, perplexity_step=2.290, val_loss=0.816, perplexity=2.270, train_loss_epoch=0.888, perplexity_epoch=2.440]Epoch 10, global step 252: val_loss reached 0.81557 (best 0.81557), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 11: 100% 29/29 [02:42<00:00,  5.61s/it, loss=0.896, v_num=1, train_loss_step=0.896, perplexity_step=2.450, val_loss=0.816, perplexity=2.270, train_loss_epoch=0.888, perplexity_epoch=2.440]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 11: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.904, v_num=1, train_loss_step=0.915, perplexity_step=2.500, val_loss=0.808, perplexity=2.250, train_loss_epoch=0.888, perplexity_epoch=2.440]\n","Epoch 11: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.904, v_num=1, train_loss_step=0.915, perplexity_step=2.500, val_loss=0.808, perplexity=2.250, train_loss_epoch=0.883, perplexity_epoch=2.420]Epoch 11, global step 275: val_loss reached 0.80751 (best 0.80751), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 12: 100% 29/29 [02:41<00:00,  5.56s/it, loss=0.822, v_num=1, train_loss_step=0.766, perplexity_step=2.150, val_loss=0.808, perplexity=2.250, train_loss_epoch=0.883, perplexity_epoch=2.420]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 12: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.831, v_num=1, train_loss_step=0.844, perplexity_step=2.330, val_loss=0.801, perplexity=2.230, train_loss_epoch=0.883, perplexity_epoch=2.420]\n","Epoch 12: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.831, v_num=1, train_loss_step=0.844, perplexity_step=2.330, val_loss=0.801, perplexity=2.230, train_loss_epoch=0.873, perplexity_epoch=2.400]Epoch 12, global step 298: val_loss reached 0.80091 (best 0.80091), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 13: 100% 29/29 [02:44<00:00,  5.68s/it, loss=0.863, v_num=1, train_loss_step=0.890, perplexity_step=2.430, val_loss=0.801, perplexity=2.230, train_loss_epoch=0.873, perplexity_epoch=2.400]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 13: 100% 29/29 [02:54<00:00,  6.02s/it, loss=0.849, v_num=1, train_loss_step=0.765, perplexity_step=2.150, val_loss=0.793, perplexity=2.210, train_loss_epoch=0.873, perplexity_epoch=2.400]\n","Epoch 13: 100% 29/29 [02:54<00:00,  6.03s/it, loss=0.849, v_num=1, train_loss_step=0.765, perplexity_step=2.150, val_loss=0.793, perplexity=2.210, train_loss_epoch=0.865, perplexity_epoch=2.380]Epoch 13, global step 321: val_loss reached 0.79286 (best 0.79286), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 14: 100% 29/29 [02:41<00:00,  5.59s/it, loss=0.851, v_num=1, train_loss_step=0.978, perplexity_step=2.660, val_loss=0.793, perplexity=2.210, train_loss_epoch=0.865, perplexity_epoch=2.380]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 14: 100% 29/29 [02:51<00:00,  5.90s/it, loss=0.859, v_num=1, train_loss_step=0.804, perplexity_step=2.240, val_loss=0.783, perplexity=2.190, train_loss_epoch=0.865, perplexity_epoch=2.380]\n","Epoch 14: 100% 29/29 [02:51<00:00,  5.90s/it, loss=0.859, v_num=1, train_loss_step=0.804, perplexity_step=2.240, val_loss=0.783, perplexity=2.190, train_loss_epoch=0.857, perplexity_epoch=2.360]Epoch 14, global step 344: val_loss reached 0.78298 (best 0.78298), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 15: 100% 29/29 [02:42<00:00,  5.61s/it, loss=0.859, v_num=1, train_loss_step=0.875, perplexity_step=2.400, val_loss=0.783, perplexity=2.190, train_loss_epoch=0.857, perplexity_epoch=2.360]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 15: 100% 29/29 [02:52<00:00,  5.94s/it, loss=0.846, v_num=1, train_loss_step=0.867, perplexity_step=2.380, val_loss=0.777, perplexity=2.180, train_loss_epoch=0.857, perplexity_epoch=2.360]\n","Epoch 15: 100% 29/29 [02:52<00:00,  5.94s/it, loss=0.846, v_num=1, train_loss_step=0.867, perplexity_step=2.380, val_loss=0.777, perplexity=2.180, train_loss_epoch=0.846, perplexity_epoch=2.340]Epoch 15, global step 367: val_loss reached 0.77677 (best 0.77677), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 16: 100% 29/29 [02:49<00:00,  5.83s/it, loss=0.824, v_num=1, train_loss_step=0.928, perplexity_step=2.530, val_loss=0.777, perplexity=2.180, train_loss_epoch=0.846, perplexity_epoch=2.340]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 16: 100% 29/29 [02:59<00:00,  6.18s/it, loss=0.836, v_num=1, train_loss_step=0.867, perplexity_step=2.380, val_loss=0.769, perplexity=2.160, train_loss_epoch=0.846, perplexity_epoch=2.340]\n","Epoch 16: 100% 29/29 [02:59<00:00,  6.18s/it, loss=0.836, v_num=1, train_loss_step=0.867, perplexity_step=2.380, val_loss=0.769, perplexity=2.160, train_loss_epoch=0.839, perplexity_epoch=2.320]Epoch 16, global step 390: val_loss reached 0.76920 (best 0.76920), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 17: 100% 29/29 [02:41<00:00,  5.58s/it, loss=0.799, v_num=1, train_loss_step=0.827, perplexity_step=2.290, val_loss=0.769, perplexity=2.160, train_loss_epoch=0.839, perplexity_epoch=2.320]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 17: 100% 29/29 [02:51<00:00,  5.90s/it, loss=0.809, v_num=1, train_loss_step=0.917, perplexity_step=2.500, val_loss=0.758, perplexity=2.140, train_loss_epoch=0.839, perplexity_epoch=2.320]\n","Epoch 17: 100% 29/29 [02:51<00:00,  5.90s/it, loss=0.809, v_num=1, train_loss_step=0.917, perplexity_step=2.500, val_loss=0.758, perplexity=2.140, train_loss_epoch=0.832, perplexity_epoch=2.300]Epoch 17, global step 413: val_loss reached 0.75767 (best 0.75767), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 18: 100% 29/29 [02:40<00:00,  5.54s/it, loss=0.778, v_num=1, train_loss_step=0.681, perplexity_step=1.980, val_loss=0.758, perplexity=2.140, train_loss_epoch=0.832, perplexity_epoch=2.300]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 18: 100% 29/29 [02:50<00:00,  5.86s/it, loss=0.763, v_num=1, train_loss_step=0.763, perplexity_step=2.140, val_loss=0.751, perplexity=2.120, train_loss_epoch=0.832, perplexity_epoch=2.300]\n","Epoch 18: 100% 29/29 [02:50<00:00,  5.86s/it, loss=0.763, v_num=1, train_loss_step=0.763, perplexity_step=2.140, val_loss=0.751, perplexity=2.120, train_loss_epoch=0.823, perplexity_epoch=2.280]Epoch 18, global step 436: val_loss reached 0.75114 (best 0.75114), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 19: 100% 29/29 [02:45<00:00,  5.71s/it, loss=0.776, v_num=1, train_loss_step=0.683, perplexity_step=1.980, val_loss=0.751, perplexity=2.120, train_loss_epoch=0.823, perplexity_epoch=2.280]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 19: 100% 29/29 [02:55<00:00,  6.06s/it, loss=0.787, v_num=1, train_loss_step=0.738, perplexity_step=2.090, val_loss=0.742, perplexity=2.110, train_loss_epoch=0.823, perplexity_epoch=2.280]\n","Epoch 19: 100% 29/29 [02:55<00:00,  6.06s/it, loss=0.787, v_num=1, train_loss_step=0.738, perplexity_step=2.090, val_loss=0.742, perplexity=2.110, train_loss_epoch=0.814, perplexity_epoch=2.260]Epoch 19, global step 459: val_loss reached 0.74244 (best 0.74244), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 20: 100% 29/29 [02:41<00:00,  5.56s/it, loss=0.795, v_num=1, train_loss_step=0.745, perplexity_step=2.110, val_loss=0.742, perplexity=2.110, train_loss_epoch=0.814, perplexity_epoch=2.260]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 20: 100% 29/29 [02:50<00:00,  5.87s/it, loss=0.79, v_num=1, train_loss_step=0.847, perplexity_step=2.330, val_loss=0.734, perplexity=2.090, train_loss_epoch=0.814, perplexity_epoch=2.260] \n","Epoch 20: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.79, v_num=1, train_loss_step=0.847, perplexity_step=2.330, val_loss=0.734, perplexity=2.090, train_loss_epoch=0.804, perplexity_epoch=2.240]Epoch 20, global step 482: val_loss reached 0.73388 (best 0.73388), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 21: 100% 29/29 [02:44<00:00,  5.66s/it, loss=0.768, v_num=1, train_loss_step=0.708, perplexity_step=2.030, val_loss=0.734, perplexity=2.090, train_loss_epoch=0.804, perplexity_epoch=2.240]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 21: 100% 29/29 [02:54<00:00,  6.00s/it, loss=0.786, v_num=1, train_loss_step=0.817, perplexity_step=2.260, val_loss=0.728, perplexity=2.080, train_loss_epoch=0.804, perplexity_epoch=2.240]\n","Epoch 21: 100% 29/29 [02:54<00:00,  6.00s/it, loss=0.786, v_num=1, train_loss_step=0.817, perplexity_step=2.260, val_loss=0.728, perplexity=2.080, train_loss_epoch=0.797, perplexity_epoch=2.220]Epoch 21, global step 505: val_loss reached 0.72839 (best 0.72839), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 22: 100% 29/29 [02:46<00:00,  5.75s/it, loss=0.775, v_num=1, train_loss_step=0.780, perplexity_step=2.180, val_loss=0.728, perplexity=2.080, train_loss_epoch=0.797, perplexity_epoch=2.220]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 22: 100% 29/29 [02:57<00:00,  6.11s/it, loss=0.77, v_num=1, train_loss_step=0.795, perplexity_step=2.210, val_loss=0.720, perplexity=2.060, train_loss_epoch=0.797, perplexity_epoch=2.220] \n","Epoch 22: 100% 29/29 [02:57<00:00,  6.11s/it, loss=0.77, v_num=1, train_loss_step=0.795, perplexity_step=2.210, val_loss=0.720, perplexity=2.060, train_loss_epoch=0.790, perplexity_epoch=2.210]Epoch 22, global step 528: val_loss reached 0.71958 (best 0.71958), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 23: 100% 29/29 [02:47<00:00,  5.76s/it, loss=0.746, v_num=1, train_loss_step=0.688, perplexity_step=1.990, val_loss=0.720, perplexity=2.060, train_loss_epoch=0.790, perplexity_epoch=2.210]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 23: 100% 29/29 [02:56<00:00,  6.08s/it, loss=0.76, v_num=1, train_loss_step=0.792, perplexity_step=2.210, val_loss=0.712, perplexity=2.040, train_loss_epoch=0.790, perplexity_epoch=2.210] \n","Epoch 23: 100% 29/29 [02:56<00:00,  6.08s/it, loss=0.76, v_num=1, train_loss_step=0.792, perplexity_step=2.210, val_loss=0.712, perplexity=2.040, train_loss_epoch=0.781, perplexity_epoch=2.190]Epoch 23, global step 551: val_loss reached 0.71222 (best 0.71222), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 24: 100% 29/29 [02:45<00:00,  5.71s/it, loss=0.758, v_num=1, train_loss_step=0.755, perplexity_step=2.130, val_loss=0.712, perplexity=2.040, train_loss_epoch=0.781, perplexity_epoch=2.190]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 24: 100% 29/29 [02:54<00:00,  6.03s/it, loss=0.751, v_num=1, train_loss_step=0.779, perplexity_step=2.180, val_loss=0.705, perplexity=2.030, train_loss_epoch=0.781, perplexity_epoch=2.190]\n","Epoch 24: 100% 29/29 [02:54<00:00,  6.03s/it, loss=0.751, v_num=1, train_loss_step=0.779, perplexity_step=2.180, val_loss=0.705, perplexity=2.030, train_loss_epoch=0.774, perplexity_epoch=2.170]Epoch 24, global step 574: val_loss reached 0.70539 (best 0.70539), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 25: 100% 29/29 [02:47<00:00,  5.78s/it, loss=0.725, v_num=1, train_loss_step=0.771, perplexity_step=2.160, val_loss=0.705, perplexity=2.030, train_loss_epoch=0.774, perplexity_epoch=2.170]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 25: 100% 29/29 [02:57<00:00,  6.12s/it, loss=0.724, v_num=1, train_loss_step=0.770, perplexity_step=2.160, val_loss=0.696, perplexity=2.010, train_loss_epoch=0.774, perplexity_epoch=2.170]\n","Epoch 25: 100% 29/29 [02:57<00:00,  6.13s/it, loss=0.724, v_num=1, train_loss_step=0.770, perplexity_step=2.160, val_loss=0.696, perplexity=2.010, train_loss_epoch=0.764, perplexity_epoch=2.150]Epoch 25, global step 597: val_loss reached 0.69633 (best 0.69633), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 26: 100% 29/29 [02:43<00:00,  5.65s/it, loss=0.745, v_num=1, train_loss_step=0.773, perplexity_step=2.170, val_loss=0.696, perplexity=2.010, train_loss_epoch=0.764, perplexity_epoch=2.150]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 26: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.751, v_num=1, train_loss_step=0.751, perplexity_step=2.120, val_loss=0.689, perplexity=2.000, train_loss_epoch=0.764, perplexity_epoch=2.150]\n","Epoch 26: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.751, v_num=1, train_loss_step=0.751, perplexity_step=2.120, val_loss=0.689, perplexity=2.000, train_loss_epoch=0.758, perplexity_epoch=2.140]Epoch 26, global step 620: val_loss reached 0.68903 (best 0.68903), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 27: 100% 29/29 [02:41<00:00,  5.56s/it, loss=0.721, v_num=1, train_loss_step=0.752, perplexity_step=2.120, val_loss=0.689, perplexity=2.000, train_loss_epoch=0.758, perplexity_epoch=2.140]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 27: 100% 29/29 [03:49<00:00,  7.93s/it, loss=0.723, v_num=1, train_loss_step=0.711, perplexity_step=2.040, val_loss=0.683, perplexity=1.980, train_loss_epoch=0.758, perplexity_epoch=2.140]\n","Epoch 27: 100% 29/29 [03:49<00:00,  7.93s/it, loss=0.723, v_num=1, train_loss_step=0.711, perplexity_step=2.040, val_loss=0.683, perplexity=1.980, train_loss_epoch=0.749, perplexity_epoch=2.120]Epoch 27, global step 643: val_loss reached 0.68279 (best 0.68279), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 28: 100% 29/29 [02:44<00:00,  5.68s/it, loss=0.708, v_num=1, train_loss_step=0.799, perplexity_step=2.220, val_loss=0.683, perplexity=1.980, train_loss_epoch=0.749, perplexity_epoch=2.120]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 28: 100% 29/29 [02:54<00:00,  6.02s/it, loss=0.719, v_num=1, train_loss_step=0.654, perplexity_step=1.920, val_loss=0.675, perplexity=1.970, train_loss_epoch=0.749, perplexity_epoch=2.120]\n","Epoch 28: 100% 29/29 [02:54<00:00,  6.02s/it, loss=0.719, v_num=1, train_loss_step=0.654, perplexity_step=1.920, val_loss=0.675, perplexity=1.970, train_loss_epoch=0.744, perplexity_epoch=2.110]Epoch 28, global step 666: val_loss reached 0.67534 (best 0.67534), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 29: 100% 29/29 [02:41<00:00,  5.55s/it, loss=0.704, v_num=1, train_loss_step=0.793, perplexity_step=2.210, val_loss=0.675, perplexity=1.970, train_loss_epoch=0.744, perplexity_epoch=2.110]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 29: 100% 29/29 [02:50<00:00,  5.87s/it, loss=0.707, v_num=1, train_loss_step=0.685, perplexity_step=1.980, val_loss=0.667, perplexity=1.950, train_loss_epoch=0.744, perplexity_epoch=2.110]\n","Epoch 29: 100% 29/29 [02:50<00:00,  5.87s/it, loss=0.707, v_num=1, train_loss_step=0.685, perplexity_step=1.980, val_loss=0.667, perplexity=1.950, train_loss_epoch=0.738, perplexity_epoch=2.100]Epoch 29, global step 689: val_loss reached 0.66747 (best 0.66747), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 30: 100% 29/29 [02:41<00:00,  5.58s/it, loss=0.728, v_num=1, train_loss_step=0.700, perplexity_step=2.010, val_loss=0.667, perplexity=1.950, train_loss_epoch=0.738, perplexity_epoch=2.100]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 30: 100% 29/29 [02:51<00:00,  5.90s/it, loss=0.73, v_num=1, train_loss_step=0.715, perplexity_step=2.040, val_loss=0.661, perplexity=1.940, train_loss_epoch=0.738, perplexity_epoch=2.100] \n","Epoch 30: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.73, v_num=1, train_loss_step=0.715, perplexity_step=2.040, val_loss=0.661, perplexity=1.940, train_loss_epoch=0.728, perplexity_epoch=2.080]Epoch 30, global step 712: val_loss reached 0.66149 (best 0.66149), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 31: 100% 29/29 [02:44<00:00,  5.66s/it, loss=0.721, v_num=1, train_loss_step=0.768, perplexity_step=2.160, val_loss=0.661, perplexity=1.940, train_loss_epoch=0.728, perplexity_epoch=2.080]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 31: 100% 29/29 [02:54<00:00,  6.00s/it, loss=0.737, v_num=1, train_loss_step=0.798, perplexity_step=2.220, val_loss=0.653, perplexity=1.930, train_loss_epoch=0.728, perplexity_epoch=2.080]\n","Epoch 31: 100% 29/29 [02:54<00:00,  6.00s/it, loss=0.737, v_num=1, train_loss_step=0.798, perplexity_step=2.220, val_loss=0.653, perplexity=1.930, train_loss_epoch=0.720, perplexity_epoch=2.060]Epoch 31, global step 735: val_loss reached 0.65345 (best 0.65345), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 32: 100% 29/29 [02:42<00:00,  5.61s/it, loss=0.685, v_num=1, train_loss_step=0.691, perplexity_step=2.000, val_loss=0.653, perplexity=1.930, train_loss_epoch=0.720, perplexity_epoch=2.060]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 32: 100% 29/29 [02:52<00:00,  5.93s/it, loss=0.695, v_num=1, train_loss_step=0.693, perplexity_step=2.000, val_loss=0.646, perplexity=1.910, train_loss_epoch=0.720, perplexity_epoch=2.060]\n","Epoch 32: 100% 29/29 [02:52<00:00,  5.94s/it, loss=0.695, v_num=1, train_loss_step=0.693, perplexity_step=2.000, val_loss=0.646, perplexity=1.910, train_loss_epoch=0.714, perplexity_epoch=2.050]Epoch 32, global step 758: val_loss reached 0.64644 (best 0.64644), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 33: 100% 29/29 [02:41<00:00,  5.58s/it, loss=0.699, v_num=1, train_loss_step=0.669, perplexity_step=1.950, val_loss=0.646, perplexity=1.910, train_loss_epoch=0.714, perplexity_epoch=2.050]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 33: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.711, v_num=1, train_loss_step=0.800, perplexity_step=2.220, val_loss=0.640, perplexity=1.900, train_loss_epoch=0.714, perplexity_epoch=2.050]\n","Epoch 33: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.711, v_num=1, train_loss_step=0.800, perplexity_step=2.220, val_loss=0.640, perplexity=1.900, train_loss_epoch=0.709, perplexity_epoch=2.030]Epoch 33, global step 781: val_loss reached 0.63972 (best 0.63972), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 34: 100% 29/29 [02:40<00:00,  5.52s/it, loss=0.689, v_num=1, train_loss_step=0.652, perplexity_step=1.920, val_loss=0.640, perplexity=1.900, train_loss_epoch=0.709, perplexity_epoch=2.030]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 34: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.699, v_num=1, train_loss_step=0.889, perplexity_step=2.430, val_loss=0.634, perplexity=1.890, train_loss_epoch=0.709, perplexity_epoch=2.030]\n","Epoch 34: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.699, v_num=1, train_loss_step=0.889, perplexity_step=2.430, val_loss=0.634, perplexity=1.890, train_loss_epoch=0.702, perplexity_epoch=2.020]Epoch 34, global step 804: val_loss reached 0.63402 (best 0.63402), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 35: 100% 29/29 [02:43<00:00,  5.63s/it, loss=0.701, v_num=1, train_loss_step=0.812, perplexity_step=2.250, val_loss=0.634, perplexity=1.890, train_loss_epoch=0.702, perplexity_epoch=2.020]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 35: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.702, v_num=1, train_loss_step=0.582, perplexity_step=1.790, val_loss=0.626, perplexity=1.870, train_loss_epoch=0.702, perplexity_epoch=2.020]\n","Epoch 35: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.702, v_num=1, train_loss_step=0.582, perplexity_step=1.790, val_loss=0.626, perplexity=1.870, train_loss_epoch=0.694, perplexity_epoch=2.010]Epoch 35, global step 827: val_loss reached 0.62643 (best 0.62643), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 36: 100% 29/29 [02:41<00:00,  5.58s/it, loss=0.659, v_num=1, train_loss_step=0.637, perplexity_step=1.890, val_loss=0.626, perplexity=1.870, train_loss_epoch=0.694, perplexity_epoch=2.010]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 36: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.669, v_num=1, train_loss_step=0.648, perplexity_step=1.910, val_loss=0.621, perplexity=1.860, train_loss_epoch=0.694, perplexity_epoch=2.010]\n","Epoch 36: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.669, v_num=1, train_loss_step=0.648, perplexity_step=1.910, val_loss=0.621, perplexity=1.860, train_loss_epoch=0.686, perplexity_epoch=1.990]Epoch 36, global step 850: val_loss reached 0.62071 (best 0.62071), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 37: 100% 29/29 [02:41<00:00,  5.57s/it, loss=0.654, v_num=1, train_loss_step=0.658, perplexity_step=1.930, val_loss=0.621, perplexity=1.860, train_loss_epoch=0.686, perplexity_epoch=1.990]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 37: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.652, v_num=1, train_loss_step=0.635, perplexity_step=1.890, val_loss=0.614, perplexity=1.850, train_loss_epoch=0.686, perplexity_epoch=1.990]\n","Epoch 37: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.652, v_num=1, train_loss_step=0.635, perplexity_step=1.890, val_loss=0.614, perplexity=1.850, train_loss_epoch=0.679, perplexity_epoch=1.980]Epoch 37, global step 873: val_loss reached 0.61406 (best 0.61406), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 38: 100% 29/29 [02:45<00:00,  5.71s/it, loss=0.653, v_num=1, train_loss_step=0.649, perplexity_step=1.910, val_loss=0.614, perplexity=1.850, train_loss_epoch=0.679, perplexity_epoch=1.980]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 38: 100% 29/29 [02:54<00:00,  6.03s/it, loss=0.657, v_num=1, train_loss_step=0.633, perplexity_step=1.880, val_loss=0.607, perplexity=1.840, train_loss_epoch=0.679, perplexity_epoch=1.980]\n","Epoch 38: 100% 29/29 [02:54<00:00,  6.03s/it, loss=0.657, v_num=1, train_loss_step=0.633, perplexity_step=1.880, val_loss=0.607, perplexity=1.840, train_loss_epoch=0.674, perplexity_epoch=1.970]Epoch 38, global step 896: val_loss reached 0.60724 (best 0.60724), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 39: 100% 29/29 [02:40<00:00,  5.55s/it, loss=0.645, v_num=1, train_loss_step=0.627, perplexity_step=1.870, val_loss=0.607, perplexity=1.840, train_loss_epoch=0.674, perplexity_epoch=1.970]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 39: 100% 29/29 [02:49<00:00,  5.86s/it, loss=0.643, v_num=1, train_loss_step=0.679, perplexity_step=1.970, val_loss=0.600, perplexity=1.830, train_loss_epoch=0.674, perplexity_epoch=1.970]\n","Epoch 39: 100% 29/29 [02:50<00:00,  5.86s/it, loss=0.643, v_num=1, train_loss_step=0.679, perplexity_step=1.970, val_loss=0.600, perplexity=1.830, train_loss_epoch=0.667, perplexity_epoch=1.950]Epoch 39, global step 919: val_loss reached 0.60013 (best 0.60013), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 40: 100% 29/29 [02:49<00:00,  5.85s/it, loss=0.621, v_num=1, train_loss_step=0.641, perplexity_step=1.900, val_loss=0.600, perplexity=1.830, train_loss_epoch=0.667, perplexity_epoch=1.950]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 40: 100% 29/29 [02:58<00:00,  6.17s/it, loss=0.622, v_num=1, train_loss_step=0.512, perplexity_step=1.670, val_loss=0.594, perplexity=1.810, train_loss_epoch=0.667, perplexity_epoch=1.950]\n","Epoch 40: 100% 29/29 [02:58<00:00,  6.17s/it, loss=0.622, v_num=1, train_loss_step=0.512, perplexity_step=1.670, val_loss=0.594, perplexity=1.810, train_loss_epoch=0.659, perplexity_epoch=1.940]Epoch 40, global step 942: val_loss reached 0.59416 (best 0.59416), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 41: 100% 29/29 [02:41<00:00,  5.56s/it, loss=0.671, v_num=1, train_loss_step=0.739, perplexity_step=2.090, val_loss=0.594, perplexity=1.810, train_loss_epoch=0.659, perplexity_epoch=1.940]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 41: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.661, v_num=1, train_loss_step=0.568, perplexity_step=1.770, val_loss=0.588, perplexity=1.800, train_loss_epoch=0.659, perplexity_epoch=1.940]\n","Epoch 41: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.661, v_num=1, train_loss_step=0.568, perplexity_step=1.770, val_loss=0.588, perplexity=1.800, train_loss_epoch=0.652, perplexity_epoch=1.920]Epoch 41, global step 965: val_loss reached 0.58820 (best 0.58820), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 42: 100% 29/29 [02:42<00:00,  5.59s/it, loss=0.643, v_num=1, train_loss_step=0.633, perplexity_step=1.880, val_loss=0.588, perplexity=1.800, train_loss_epoch=0.652, perplexity_epoch=1.920]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 42: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.631, v_num=1, train_loss_step=0.650, perplexity_step=1.920, val_loss=0.583, perplexity=1.790, train_loss_epoch=0.652, perplexity_epoch=1.920]\n","Epoch 42: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.631, v_num=1, train_loss_step=0.650, perplexity_step=1.920, val_loss=0.583, perplexity=1.790, train_loss_epoch=0.646, perplexity_epoch=1.910]Epoch 42, global step 988: val_loss reached 0.58252 (best 0.58252), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 43: 100% 29/29 [02:40<00:00,  5.52s/it, loss=0.635, v_num=1, train_loss_step=0.589, perplexity_step=1.800, val_loss=0.583, perplexity=1.790, train_loss_epoch=0.646, perplexity_epoch=1.910]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 43: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.64, v_num=1, train_loss_step=0.696, perplexity_step=2.000, val_loss=0.577, perplexity=1.780, train_loss_epoch=0.646, perplexity_epoch=1.910] \n","Epoch 43: 100% 29/29 [02:49<00:00,  5.85s/it, loss=0.64, v_num=1, train_loss_step=0.696, perplexity_step=2.000, val_loss=0.577, perplexity=1.780, train_loss_epoch=0.638, perplexity_epoch=1.900]Epoch 43, global step 1011: val_loss reached 0.57712 (best 0.57712), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 44: 100% 29/29 [02:47<00:00,  5.76s/it, loss=0.609, v_num=1, train_loss_step=0.681, perplexity_step=1.980, val_loss=0.577, perplexity=1.780, train_loss_epoch=0.638, perplexity_epoch=1.900]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 44: 100% 29/29 [02:57<00:00,  6.10s/it, loss=0.607, v_num=1, train_loss_step=0.610, perplexity_step=1.840, val_loss=0.571, perplexity=1.770, train_loss_epoch=0.638, perplexity_epoch=1.900]\n","Epoch 44: 100% 29/29 [02:57<00:00,  6.11s/it, loss=0.607, v_num=1, train_loss_step=0.610, perplexity_step=1.840, val_loss=0.571, perplexity=1.770, train_loss_epoch=0.632, perplexity_epoch=1.890]Epoch 44, global step 1034: val_loss reached 0.57109 (best 0.57109), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 45: 100% 29/29 [02:45<00:00,  5.71s/it, loss=0.623, v_num=1, train_loss_step=0.585, perplexity_step=1.800, val_loss=0.571, perplexity=1.770, train_loss_epoch=0.632, perplexity_epoch=1.890]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 45: 100% 29/29 [02:55<00:00,  6.04s/it, loss=0.613, v_num=1, train_loss_step=0.539, perplexity_step=1.710, val_loss=0.565, perplexity=1.760, train_loss_epoch=0.632, perplexity_epoch=1.890]\n","Epoch 45: 100% 29/29 [02:55<00:00,  6.04s/it, loss=0.613, v_num=1, train_loss_step=0.539, perplexity_step=1.710, val_loss=0.565, perplexity=1.760, train_loss_epoch=0.626, perplexity_epoch=1.870]Epoch 45, global step 1057: val_loss reached 0.56476 (best 0.56476), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 46: 100% 29/29 [02:42<00:00,  5.61s/it, loss=0.602, v_num=1, train_loss_step=0.558, perplexity_step=1.750, val_loss=0.565, perplexity=1.760, train_loss_epoch=0.626, perplexity_epoch=1.870]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 46: 100% 29/29 [02:52<00:00,  5.93s/it, loss=0.607, v_num=1, train_loss_step=0.730, perplexity_step=2.070, val_loss=0.559, perplexity=1.750, train_loss_epoch=0.626, perplexity_epoch=1.870]\n","Epoch 46: 100% 29/29 [02:52<00:00,  5.94s/it, loss=0.607, v_num=1, train_loss_step=0.730, perplexity_step=2.070, val_loss=0.559, perplexity=1.750, train_loss_epoch=0.620, perplexity_epoch=1.860]Epoch 46, global step 1080: val_loss reached 0.55908 (best 0.55908), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 47: 100% 29/29 [02:43<00:00,  5.65s/it, loss=0.607, v_num=1, train_loss_step=0.636, perplexity_step=1.890, val_loss=0.559, perplexity=1.750, train_loss_epoch=0.620, perplexity_epoch=1.860]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 47: 100% 29/29 [03:13<00:00,  6.67s/it, loss=0.607, v_num=1, train_loss_step=0.590, perplexity_step=1.800, val_loss=0.554, perplexity=1.740, train_loss_epoch=0.620, perplexity_epoch=1.860]\n","Epoch 47: 100% 29/29 [03:13<00:00,  6.67s/it, loss=0.607, v_num=1, train_loss_step=0.590, perplexity_step=1.800, val_loss=0.554, perplexity=1.740, train_loss_epoch=0.615, perplexity_epoch=1.850]Epoch 47, global step 1103: val_loss reached 0.55366 (best 0.55366), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 48: 100% 29/29 [02:41<00:00,  5.58s/it, loss=0.601, v_num=1, train_loss_step=0.590, perplexity_step=1.800, val_loss=0.554, perplexity=1.740, train_loss_epoch=0.615, perplexity_epoch=1.850]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 48: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.604, v_num=1, train_loss_step=0.600, perplexity_step=1.820, val_loss=0.548, perplexity=1.730, train_loss_epoch=0.615, perplexity_epoch=1.850]\n","Epoch 48: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.604, v_num=1, train_loss_step=0.600, perplexity_step=1.820, val_loss=0.548, perplexity=1.730, train_loss_epoch=0.607, perplexity_epoch=1.840]Epoch 48, global step 1126: val_loss reached 0.54768 (best 0.54768), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 49: 100% 29/29 [02:41<00:00,  5.58s/it, loss=0.601, v_num=1, train_loss_step=0.596, perplexity_step=1.810, val_loss=0.548, perplexity=1.730, train_loss_epoch=0.607, perplexity_epoch=1.840]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 49: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.594, v_num=1, train_loss_step=0.668, perplexity_step=1.950, val_loss=0.541, perplexity=1.720, train_loss_epoch=0.607, perplexity_epoch=1.840]\n","Epoch 49: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.594, v_num=1, train_loss_step=0.668, perplexity_step=1.950, val_loss=0.541, perplexity=1.720, train_loss_epoch=0.602, perplexity_epoch=1.830]Epoch 49, global step 1149: val_loss reached 0.54100 (best 0.54100), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 50: 100% 29/29 [02:43<00:00,  5.64s/it, loss=0.59, v_num=1, train_loss_step=0.602, perplexity_step=1.830, val_loss=0.541, perplexity=1.720, train_loss_epoch=0.602, perplexity_epoch=1.830]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 50: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.588, v_num=1, train_loss_step=0.484, perplexity_step=1.620, val_loss=0.536, perplexity=1.710, train_loss_epoch=0.602, perplexity_epoch=1.830]\n","Epoch 50: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.588, v_num=1, train_loss_step=0.484, perplexity_step=1.620, val_loss=0.536, perplexity=1.710, train_loss_epoch=0.595, perplexity_epoch=1.820]Epoch 50, global step 1172: val_loss reached 0.53584 (best 0.53584), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 51: 100% 29/29 [02:41<00:00,  5.58s/it, loss=0.582, v_num=1, train_loss_step=0.526, perplexity_step=1.690, val_loss=0.536, perplexity=1.710, train_loss_epoch=0.595, perplexity_epoch=1.820]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 51: 100% 29/29 [03:04<00:00,  6.36s/it, loss=0.582, v_num=1, train_loss_step=0.599, perplexity_step=1.820, val_loss=0.530, perplexity=1.700, train_loss_epoch=0.595, perplexity_epoch=1.820]\n","Epoch 51: 100% 29/29 [03:04<00:00,  6.36s/it, loss=0.582, v_num=1, train_loss_step=0.599, perplexity_step=1.820, val_loss=0.530, perplexity=1.700, train_loss_epoch=0.591, perplexity_epoch=1.810]Epoch 51, global step 1195: val_loss reached 0.53037 (best 0.53037), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 52: 100% 29/29 [02:41<00:00,  5.57s/it, loss=0.586, v_num=1, train_loss_step=0.581, perplexity_step=1.790, val_loss=0.530, perplexity=1.700, train_loss_epoch=0.591, perplexity_epoch=1.810]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 52: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.571, v_num=1, train_loss_step=0.598, perplexity_step=1.820, val_loss=0.524, perplexity=1.690, train_loss_epoch=0.591, perplexity_epoch=1.810]\n","Epoch 52: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.571, v_num=1, train_loss_step=0.598, perplexity_step=1.820, val_loss=0.524, perplexity=1.690, train_loss_epoch=0.586, perplexity_epoch=1.800]Epoch 52, global step 1218: val_loss reached 0.52422 (best 0.52422), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 53: 100% 29/29 [02:43<00:00,  5.65s/it, loss=0.596, v_num=1, train_loss_step=0.606, perplexity_step=1.830, val_loss=0.524, perplexity=1.690, train_loss_epoch=0.586, perplexity_epoch=1.800]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 53: 100% 29/29 [02:53<00:00,  5.98s/it, loss=0.578, v_num=1, train_loss_step=0.587, perplexity_step=1.800, val_loss=0.520, perplexity=1.680, train_loss_epoch=0.586, perplexity_epoch=1.800]\n","Epoch 53: 100% 29/29 [02:53<00:00,  5.98s/it, loss=0.578, v_num=1, train_loss_step=0.587, perplexity_step=1.800, val_loss=0.520, perplexity=1.680, train_loss_epoch=0.579, perplexity_epoch=1.790]Epoch 53, global step 1241: val_loss reached 0.52006 (best 0.52006), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 54: 100% 29/29 [02:43<00:00,  5.63s/it, loss=0.554, v_num=1, train_loss_step=0.569, perplexity_step=1.770, val_loss=0.520, perplexity=1.680, train_loss_epoch=0.579, perplexity_epoch=1.790]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 54: 100% 29/29 [02:52<00:00,  5.97s/it, loss=0.543, v_num=1, train_loss_step=0.618, perplexity_step=1.850, val_loss=0.513, perplexity=1.670, train_loss_epoch=0.579, perplexity_epoch=1.790]\n","Epoch 54: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.543, v_num=1, train_loss_step=0.618, perplexity_step=1.850, val_loss=0.513, perplexity=1.670, train_loss_epoch=0.573, perplexity_epoch=1.780]Epoch 54, global step 1264: val_loss reached 0.51318 (best 0.51318), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 55: 100% 29/29 [02:40<00:00,  5.55s/it, loss=0.556, v_num=1, train_loss_step=0.454, perplexity_step=1.570, val_loss=0.513, perplexity=1.670, train_loss_epoch=0.573, perplexity_epoch=1.780]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 55: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.551, v_num=1, train_loss_step=0.545, perplexity_step=1.720, val_loss=0.509, perplexity=1.670, train_loss_epoch=0.573, perplexity_epoch=1.780]\n","Epoch 55: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.551, v_num=1, train_loss_step=0.545, perplexity_step=1.720, val_loss=0.509, perplexity=1.670, train_loss_epoch=0.568, perplexity_epoch=1.770]Epoch 55, global step 1287: val_loss reached 0.50908 (best 0.50908), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 56: 100% 29/29 [02:41<00:00,  5.56s/it, loss=0.548, v_num=1, train_loss_step=0.549, perplexity_step=1.730, val_loss=0.509, perplexity=1.670, train_loss_epoch=0.568, perplexity_epoch=1.770]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 56: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.547, v_num=1, train_loss_step=0.558, perplexity_step=1.750, val_loss=0.501, perplexity=1.650, train_loss_epoch=0.568, perplexity_epoch=1.770]\n","Epoch 56: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.547, v_num=1, train_loss_step=0.558, perplexity_step=1.750, val_loss=0.501, perplexity=1.650, train_loss_epoch=0.562, perplexity_epoch=1.760]Epoch 56, global step 1310: val_loss reached 0.50112 (best 0.50112), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 57: 100% 29/29 [02:40<00:00,  5.53s/it, loss=0.561, v_num=1, train_loss_step=0.497, perplexity_step=1.640, val_loss=0.501, perplexity=1.650, train_loss_epoch=0.562, perplexity_epoch=1.760]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 57: 100% 29/29 [02:49<00:00,  5.85s/it, loss=0.561, v_num=1, train_loss_step=0.587, perplexity_step=1.800, val_loss=0.497, perplexity=1.650, train_loss_epoch=0.562, perplexity_epoch=1.760]\n","Epoch 57: 100% 29/29 [02:49<00:00,  5.85s/it, loss=0.561, v_num=1, train_loss_step=0.587, perplexity_step=1.800, val_loss=0.497, perplexity=1.650, train_loss_epoch=0.555, perplexity_epoch=1.750]Epoch 57, global step 1333: val_loss reached 0.49710 (best 0.49710), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 58: 100% 29/29 [02:43<00:00,  5.64s/it, loss=0.552, v_num=1, train_loss_step=0.585, perplexity_step=1.790, val_loss=0.497, perplexity=1.650, train_loss_epoch=0.555, perplexity_epoch=1.750]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 58: 100% 29/29 [02:52<00:00,  5.95s/it, loss=0.558, v_num=1, train_loss_step=0.606, perplexity_step=1.830, val_loss=0.492, perplexity=1.640, train_loss_epoch=0.555, perplexity_epoch=1.750]\n","Epoch 58: 100% 29/29 [02:52<00:00,  5.95s/it, loss=0.558, v_num=1, train_loss_step=0.606, perplexity_step=1.830, val_loss=0.492, perplexity=1.640, train_loss_epoch=0.552, perplexity_epoch=1.740]Epoch 58, global step 1356: val_loss reached 0.49189 (best 0.49189), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 59: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.543, v_num=1, train_loss_step=0.513, perplexity_step=1.670, val_loss=0.492, perplexity=1.640, train_loss_epoch=0.552, perplexity_epoch=1.740]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 59: 100% 29/29 [02:53<00:00,  5.99s/it, loss=0.541, v_num=1, train_loss_step=0.546, perplexity_step=1.730, val_loss=0.487, perplexity=1.630, train_loss_epoch=0.552, perplexity_epoch=1.740]\n","Epoch 59: 100% 29/29 [02:53<00:00,  5.99s/it, loss=0.541, v_num=1, train_loss_step=0.546, perplexity_step=1.730, val_loss=0.487, perplexity=1.630, train_loss_epoch=0.544, perplexity_epoch=1.730]Epoch 59, global step 1379: val_loss reached 0.48702 (best 0.48702), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 60: 100% 29/29 [02:42<00:00,  5.62s/it, loss=0.538, v_num=1, train_loss_step=0.501, perplexity_step=1.650, val_loss=0.487, perplexity=1.630, train_loss_epoch=0.544, perplexity_epoch=1.730]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 60: 100% 29/29 [02:52<00:00,  5.95s/it, loss=0.539, v_num=1, train_loss_step=0.509, perplexity_step=1.660, val_loss=0.484, perplexity=1.620, train_loss_epoch=0.544, perplexity_epoch=1.730]\n","Epoch 60: 100% 29/29 [02:52<00:00,  5.96s/it, loss=0.539, v_num=1, train_loss_step=0.509, perplexity_step=1.660, val_loss=0.484, perplexity=1.620, train_loss_epoch=0.540, perplexity_epoch=1.720]Epoch 60, global step 1402: val_loss reached 0.48351 (best 0.48351), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 61: 100% 29/29 [02:43<00:00,  5.65s/it, loss=0.514, v_num=1, train_loss_step=0.513, perplexity_step=1.670, val_loss=0.484, perplexity=1.620, train_loss_epoch=0.540, perplexity_epoch=1.720]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 61: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.52, v_num=1, train_loss_step=0.528, perplexity_step=1.690, val_loss=0.477, perplexity=1.610, train_loss_epoch=0.540, perplexity_epoch=1.720] \n","Epoch 61: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.52, v_num=1, train_loss_step=0.528, perplexity_step=1.690, val_loss=0.477, perplexity=1.610, train_loss_epoch=0.534, perplexity_epoch=1.710]Epoch 61, global step 1425: val_loss reached 0.47706 (best 0.47706), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 62: 100% 29/29 [02:45<00:00,  5.72s/it, loss=0.515, v_num=1, train_loss_step=0.441, perplexity_step=1.550, val_loss=0.477, perplexity=1.610, train_loss_epoch=0.534, perplexity_epoch=1.710]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 62: 100% 29/29 [02:55<00:00,  6.05s/it, loss=0.509, v_num=1, train_loss_step=0.494, perplexity_step=1.640, val_loss=0.474, perplexity=1.610, train_loss_epoch=0.534, perplexity_epoch=1.710]\n","Epoch 62: 100% 29/29 [02:55<00:00,  6.05s/it, loss=0.509, v_num=1, train_loss_step=0.494, perplexity_step=1.640, val_loss=0.474, perplexity=1.610, train_loss_epoch=0.527, perplexity_epoch=1.700]Epoch 62, global step 1448: val_loss reached 0.47416 (best 0.47416), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 63: 100% 29/29 [02:43<00:00,  5.65s/it, loss=0.516, v_num=1, train_loss_step=0.587, perplexity_step=1.800, val_loss=0.474, perplexity=1.610, train_loss_epoch=0.527, perplexity_epoch=1.700]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 63: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.514, v_num=1, train_loss_step=0.509, perplexity_step=1.660, val_loss=0.467, perplexity=1.600, train_loss_epoch=0.527, perplexity_epoch=1.700]\n","Epoch 63: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.514, v_num=1, train_loss_step=0.509, perplexity_step=1.660, val_loss=0.467, perplexity=1.600, train_loss_epoch=0.521, perplexity_epoch=1.690]Epoch 63, global step 1471: val_loss reached 0.46677 (best 0.46677), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 64: 100% 29/29 [02:43<00:00,  5.65s/it, loss=0.505, v_num=1, train_loss_step=0.512, perplexity_step=1.670, val_loss=0.467, perplexity=1.600, train_loss_epoch=0.521, perplexity_epoch=1.690]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 64: 100% 29/29 [02:53<00:00,  5.98s/it, loss=0.507, v_num=1, train_loss_step=0.541, perplexity_step=1.720, val_loss=0.463, perplexity=1.590, train_loss_epoch=0.521, perplexity_epoch=1.690]\n","Epoch 64: 100% 29/29 [02:53<00:00,  5.99s/it, loss=0.507, v_num=1, train_loss_step=0.541, perplexity_step=1.720, val_loss=0.463, perplexity=1.590, train_loss_epoch=0.519, perplexity_epoch=1.680]Epoch 64, global step 1494: val_loss reached 0.46325 (best 0.46325), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 65: 100% 29/29 [02:47<00:00,  5.77s/it, loss=0.49, v_num=1, train_loss_step=0.586, perplexity_step=1.800, val_loss=0.463, perplexity=1.590, train_loss_epoch=0.519, perplexity_epoch=1.680]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 65: 100% 29/29 [02:56<00:00,  6.09s/it, loss=0.495, v_num=1, train_loss_step=0.516, perplexity_step=1.680, val_loss=0.460, perplexity=1.590, train_loss_epoch=0.519, perplexity_epoch=1.680]\n","Epoch 65: 100% 29/29 [02:56<00:00,  6.10s/it, loss=0.495, v_num=1, train_loss_step=0.516, perplexity_step=1.680, val_loss=0.460, perplexity=1.590, train_loss_epoch=0.513, perplexity_epoch=1.670]Epoch 65, global step 1517: val_loss reached 0.45968 (best 0.45968), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 66: 100% 29/29 [02:40<00:00,  5.53s/it, loss=0.514, v_num=1, train_loss_step=0.514, perplexity_step=1.670, val_loss=0.460, perplexity=1.590, train_loss_epoch=0.513, perplexity_epoch=1.670]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 66: 100% 29/29 [02:49<00:00,  5.86s/it, loss=0.506, v_num=1, train_loss_step=0.501, perplexity_step=1.650, val_loss=0.454, perplexity=1.580, train_loss_epoch=0.513, perplexity_epoch=1.670]\n","Epoch 66: 100% 29/29 [02:49<00:00,  5.86s/it, loss=0.506, v_num=1, train_loss_step=0.501, perplexity_step=1.650, val_loss=0.454, perplexity=1.580, train_loss_epoch=0.506, perplexity_epoch=1.660]Epoch 66, global step 1540: val_loss reached 0.45448 (best 0.45448), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 67: 100% 29/29 [02:41<00:00,  5.58s/it, loss=0.499, v_num=1, train_loss_step=0.489, perplexity_step=1.630, val_loss=0.454, perplexity=1.580, train_loss_epoch=0.506, perplexity_epoch=1.660]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 67: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.505, v_num=1, train_loss_step=0.534, perplexity_step=1.710, val_loss=0.450, perplexity=1.570, train_loss_epoch=0.506, perplexity_epoch=1.660]\n","Epoch 67: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.505, v_num=1, train_loss_step=0.534, perplexity_step=1.710, val_loss=0.450, perplexity=1.570, train_loss_epoch=0.502, perplexity_epoch=1.660]Epoch 67, global step 1563: val_loss reached 0.45034 (best 0.45034), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 68: 100% 29/29 [02:41<00:00,  5.57s/it, loss=0.503, v_num=1, train_loss_step=0.614, perplexity_step=1.850, val_loss=0.450, perplexity=1.570, train_loss_epoch=0.502, perplexity_epoch=1.660]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 68: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.501, v_num=1, train_loss_step=0.451, perplexity_step=1.570, val_loss=0.443, perplexity=1.560, train_loss_epoch=0.502, perplexity_epoch=1.660]\n","Epoch 68: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.501, v_num=1, train_loss_step=0.451, perplexity_step=1.570, val_loss=0.443, perplexity=1.560, train_loss_epoch=0.497, perplexity_epoch=1.650]Epoch 68, global step 1586: val_loss reached 0.44344 (best 0.44344), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 69: 100% 29/29 [02:41<00:00,  5.57s/it, loss=0.473, v_num=1, train_loss_step=0.387, perplexity_step=1.470, val_loss=0.443, perplexity=1.560, train_loss_epoch=0.497, perplexity_epoch=1.650]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 69: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.472, v_num=1, train_loss_step=0.481, perplexity_step=1.620, val_loss=0.440, perplexity=1.550, train_loss_epoch=0.497, perplexity_epoch=1.650]\n","Epoch 69: 100% 29/29 [02:50<00:00,  5.90s/it, loss=0.472, v_num=1, train_loss_step=0.481, perplexity_step=1.620, val_loss=0.440, perplexity=1.550, train_loss_epoch=0.491, perplexity_epoch=1.640]Epoch 69, global step 1609: val_loss reached 0.44013 (best 0.44013), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 70: 100% 29/29 [02:40<00:00,  5.55s/it, loss=0.474, v_num=1, train_loss_step=0.514, perplexity_step=1.670, val_loss=0.440, perplexity=1.550, train_loss_epoch=0.491, perplexity_epoch=1.640]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 70: 100% 29/29 [02:50<00:00,  5.87s/it, loss=0.468, v_num=1, train_loss_step=0.458, perplexity_step=1.580, val_loss=0.436, perplexity=1.550, train_loss_epoch=0.491, perplexity_epoch=1.640]\n","Epoch 70: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.468, v_num=1, train_loss_step=0.458, perplexity_step=1.580, val_loss=0.436, perplexity=1.550, train_loss_epoch=0.490, perplexity_epoch=1.630]Epoch 70, global step 1632: val_loss reached 0.43585 (best 0.43585), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 71: 100% 29/29 [02:39<00:00,  5.49s/it, loss=0.471, v_num=1, train_loss_step=0.473, perplexity_step=1.600, val_loss=0.436, perplexity=1.550, train_loss_epoch=0.490, perplexity_epoch=1.630]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 71: 100% 29/29 [02:48<00:00,  5.81s/it, loss=0.476, v_num=1, train_loss_step=0.516, perplexity_step=1.680, val_loss=0.433, perplexity=1.540, train_loss_epoch=0.490, perplexity_epoch=1.630]\n","Epoch 71: 100% 29/29 [02:48<00:00,  5.81s/it, loss=0.476, v_num=1, train_loss_step=0.516, perplexity_step=1.680, val_loss=0.433, perplexity=1.540, train_loss_epoch=0.483, perplexity_epoch=1.620]Epoch 71, global step 1655: val_loss reached 0.43268 (best 0.43268), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 72: 100% 29/29 [02:39<00:00,  5.49s/it, loss=0.477, v_num=1, train_loss_step=0.471, perplexity_step=1.600, val_loss=0.433, perplexity=1.540, train_loss_epoch=0.483, perplexity_epoch=1.620]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 72: 100% 29/29 [02:48<00:00,  5.82s/it, loss=0.472, v_num=1, train_loss_step=0.458, perplexity_step=1.580, val_loss=0.428, perplexity=1.540, train_loss_epoch=0.483, perplexity_epoch=1.620]\n","Epoch 72: 100% 29/29 [02:48<00:00,  5.82s/it, loss=0.472, v_num=1, train_loss_step=0.458, perplexity_step=1.580, val_loss=0.428, perplexity=1.540, train_loss_epoch=0.477, perplexity_epoch=1.610]Epoch 72, global step 1678: val_loss reached 0.42796 (best 0.42796), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 73: 100% 29/29 [02:40<00:00,  5.52s/it, loss=0.456, v_num=1, train_loss_step=0.479, perplexity_step=1.620, val_loss=0.428, perplexity=1.540, train_loss_epoch=0.477, perplexity_epoch=1.610]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 73: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.459, v_num=1, train_loss_step=0.422, perplexity_step=1.520, val_loss=0.425, perplexity=1.530, train_loss_epoch=0.477, perplexity_epoch=1.610]\n","Epoch 73: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.459, v_num=1, train_loss_step=0.422, perplexity_step=1.520, val_loss=0.425, perplexity=1.530, train_loss_epoch=0.471, perplexity_epoch=1.600]Epoch 73, global step 1701: val_loss reached 0.42461 (best 0.42461), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 74: 100% 29/29 [02:33<00:00,  5.31s/it, loss=0.454, v_num=1, train_loss_step=0.478, perplexity_step=1.610, val_loss=0.425, perplexity=1.530, train_loss_epoch=0.471, perplexity_epoch=1.600]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 74: 100% 29/29 [03:39<00:00,  7.57s/it, loss=0.455, v_num=1, train_loss_step=0.394, perplexity_step=1.480, val_loss=0.418, perplexity=1.520, train_loss_epoch=0.471, perplexity_epoch=1.600]\n","Epoch 74: 100% 29/29 [03:39<00:00,  7.57s/it, loss=0.455, v_num=1, train_loss_step=0.394, perplexity_step=1.480, val_loss=0.418, perplexity=1.520, train_loss_epoch=0.469, perplexity_epoch=1.600]Epoch 74, global step 1724: val_loss reached 0.41840 (best 0.41840), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 75: 100% 29/29 [02:40<00:00,  5.53s/it, loss=0.427, v_num=1, train_loss_step=0.440, perplexity_step=1.550, val_loss=0.418, perplexity=1.520, train_loss_epoch=0.469, perplexity_epoch=1.600]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 75: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.425, v_num=1, train_loss_step=0.377, perplexity_step=1.460, val_loss=0.415, perplexity=1.520, train_loss_epoch=0.469, perplexity_epoch=1.600]\n","Epoch 75: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.425, v_num=1, train_loss_step=0.377, perplexity_step=1.460, val_loss=0.415, perplexity=1.520, train_loss_epoch=0.463, perplexity_epoch=1.590]Epoch 75, global step 1747: val_loss reached 0.41459 (best 0.41459), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 76: 100% 29/29 [02:40<00:00,  5.53s/it, loss=0.444, v_num=1, train_loss_step=0.525, perplexity_step=1.690, val_loss=0.415, perplexity=1.520, train_loss_epoch=0.463, perplexity_epoch=1.590]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 76: 100% 29/29 [02:49<00:00,  5.85s/it, loss=0.449, v_num=1, train_loss_step=0.389, perplexity_step=1.480, val_loss=0.410, perplexity=1.510, train_loss_epoch=0.463, perplexity_epoch=1.590]\n","Epoch 76: 100% 29/29 [02:49<00:00,  5.86s/it, loss=0.449, v_num=1, train_loss_step=0.389, perplexity_step=1.480, val_loss=0.410, perplexity=1.510, train_loss_epoch=0.459, perplexity_epoch=1.580]Epoch 76, global step 1770: val_loss reached 0.41042 (best 0.41042), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 77: 100% 29/29 [02:41<00:00,  5.56s/it, loss=0.424, v_num=1, train_loss_step=0.473, perplexity_step=1.600, val_loss=0.410, perplexity=1.510, train_loss_epoch=0.459, perplexity_epoch=1.580]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 77: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.426, v_num=1, train_loss_step=0.454, perplexity_step=1.570, val_loss=0.407, perplexity=1.500, train_loss_epoch=0.459, perplexity_epoch=1.580]\n","Epoch 77: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.426, v_num=1, train_loss_step=0.454, perplexity_step=1.570, val_loss=0.407, perplexity=1.500, train_loss_epoch=0.454, perplexity_epoch=1.580]Epoch 77, global step 1793: val_loss reached 0.40727 (best 0.40727), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 78: 100% 29/29 [02:41<00:00,  5.56s/it, loss=0.425, v_num=1, train_loss_step=0.420, perplexity_step=1.520, val_loss=0.407, perplexity=1.500, train_loss_epoch=0.454, perplexity_epoch=1.580]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 78: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.44, v_num=1, train_loss_step=0.522, perplexity_step=1.690, val_loss=0.402, perplexity=1.500, train_loss_epoch=0.454, perplexity_epoch=1.580] \n","Epoch 78: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.44, v_num=1, train_loss_step=0.522, perplexity_step=1.690, val_loss=0.402, perplexity=1.500, train_loss_epoch=0.449, perplexity_epoch=1.570]Epoch 78, global step 1816: val_loss reached 0.40179 (best 0.40179), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 79: 100% 29/29 [02:41<00:00,  5.57s/it, loss=0.407, v_num=1, train_loss_step=0.416, perplexity_step=1.520, val_loss=0.402, perplexity=1.500, train_loss_epoch=0.449, perplexity_epoch=1.570]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 79: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.407, v_num=1, train_loss_step=0.360, perplexity_step=1.430, val_loss=0.399, perplexity=1.490, train_loss_epoch=0.449, perplexity_epoch=1.570]\n","Epoch 79: 100% 29/29 [02:50<00:00,  5.89s/it, loss=0.407, v_num=1, train_loss_step=0.360, perplexity_step=1.430, val_loss=0.399, perplexity=1.490, train_loss_epoch=0.445, perplexity_epoch=1.560]Epoch 79, global step 1839: val_loss reached 0.39872 (best 0.39872), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 80: 100% 29/29 [02:41<00:00,  5.55s/it, loss=0.432, v_num=1, train_loss_step=0.500, perplexity_step=1.650, val_loss=0.399, perplexity=1.490, train_loss_epoch=0.445, perplexity_epoch=1.560]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 80: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.431, v_num=1, train_loss_step=0.425, perplexity_step=1.530, val_loss=0.394, perplexity=1.480, train_loss_epoch=0.445, perplexity_epoch=1.560]\n","Epoch 80: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.431, v_num=1, train_loss_step=0.425, perplexity_step=1.530, val_loss=0.394, perplexity=1.480, train_loss_epoch=0.442, perplexity_epoch=1.560]Epoch 80, global step 1862: val_loss reached 0.39407 (best 0.39407), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 81: 100% 29/29 [02:40<00:00,  5.53s/it, loss=0.409, v_num=1, train_loss_step=0.452, perplexity_step=1.570, val_loss=0.394, perplexity=1.480, train_loss_epoch=0.442, perplexity_epoch=1.560]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 81: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.405, v_num=1, train_loss_step=0.461, perplexity_step=1.590, val_loss=0.391, perplexity=1.480, train_loss_epoch=0.442, perplexity_epoch=1.560]\n","Epoch 81: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.405, v_num=1, train_loss_step=0.461, perplexity_step=1.590, val_loss=0.391, perplexity=1.480, train_loss_epoch=0.438, perplexity_epoch=1.550]Epoch 81, global step 1885: val_loss reached 0.39117 (best 0.39117), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 82: 100% 29/29 [02:40<00:00,  5.52s/it, loss=0.426, v_num=1, train_loss_step=0.445, perplexity_step=1.560, val_loss=0.391, perplexity=1.480, train_loss_epoch=0.438, perplexity_epoch=1.550]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 82: 100% 29/29 [02:49<00:00,  5.85s/it, loss=0.426, v_num=1, train_loss_step=0.345, perplexity_step=1.410, val_loss=0.387, perplexity=1.470, train_loss_epoch=0.438, perplexity_epoch=1.550]\n","Epoch 82: 100% 29/29 [02:49<00:00,  5.85s/it, loss=0.426, v_num=1, train_loss_step=0.345, perplexity_step=1.410, val_loss=0.387, perplexity=1.470, train_loss_epoch=0.433, perplexity_epoch=1.540]Epoch 82, global step 1908: val_loss reached 0.38736 (best 0.38736), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 83: 100% 29/29 [02:41<00:00,  5.57s/it, loss=0.412, v_num=1, train_loss_step=0.466, perplexity_step=1.590, val_loss=0.387, perplexity=1.470, train_loss_epoch=0.433, perplexity_epoch=1.540]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 83: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.411, v_num=1, train_loss_step=0.446, perplexity_step=1.560, val_loss=0.385, perplexity=1.470, train_loss_epoch=0.433, perplexity_epoch=1.540]\n","Epoch 83: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.411, v_num=1, train_loss_step=0.446, perplexity_step=1.560, val_loss=0.385, perplexity=1.470, train_loss_epoch=0.427, perplexity_epoch=1.530]Epoch 83, global step 1931: val_loss reached 0.38510 (best 0.38510), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 84: 100% 29/29 [02:42<00:00,  5.59s/it, loss=0.398, v_num=1, train_loss_step=0.426, perplexity_step=1.530, val_loss=0.385, perplexity=1.470, train_loss_epoch=0.427, perplexity_epoch=1.530]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 84: 100% 29/29 [02:51<00:00,  5.90s/it, loss=0.398, v_num=1, train_loss_step=0.377, perplexity_step=1.460, val_loss=0.379, perplexity=1.460, train_loss_epoch=0.427, perplexity_epoch=1.530]\n","Epoch 84: 100% 29/29 [02:51<00:00,  5.90s/it, loss=0.398, v_num=1, train_loss_step=0.377, perplexity_step=1.460, val_loss=0.379, perplexity=1.460, train_loss_epoch=0.424, perplexity_epoch=1.530]Epoch 84, global step 1954: val_loss reached 0.37933 (best 0.37933), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 85: 100% 29/29 [02:40<00:00,  5.53s/it, loss=0.399, v_num=1, train_loss_step=0.366, perplexity_step=1.440, val_loss=0.379, perplexity=1.460, train_loss_epoch=0.424, perplexity_epoch=1.530]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 85: 100% 29/29 [02:49<00:00,  5.85s/it, loss=0.39, v_num=1, train_loss_step=0.406, perplexity_step=1.500, val_loss=0.377, perplexity=1.460, train_loss_epoch=0.424, perplexity_epoch=1.530] \n","Epoch 85: 100% 29/29 [02:49<00:00,  5.86s/it, loss=0.39, v_num=1, train_loss_step=0.406, perplexity_step=1.500, val_loss=0.377, perplexity=1.460, train_loss_epoch=0.419, perplexity_epoch=1.520]Epoch 85, global step 1977: val_loss reached 0.37732 (best 0.37732), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 86: 100% 29/29 [02:39<00:00,  5.52s/it, loss=0.411, v_num=1, train_loss_step=0.411, perplexity_step=1.510, val_loss=0.377, perplexity=1.460, train_loss_epoch=0.419, perplexity_epoch=1.520]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 86: 100% 29/29 [02:49<00:00,  5.86s/it, loss=0.406, v_num=1, train_loss_step=0.317, perplexity_step=1.370, val_loss=0.373, perplexity=1.450, train_loss_epoch=0.419, perplexity_epoch=1.520]\n","Epoch 86: 100% 29/29 [02:49<00:00,  5.86s/it, loss=0.406, v_num=1, train_loss_step=0.317, perplexity_step=1.370, val_loss=0.373, perplexity=1.450, train_loss_epoch=0.418, perplexity_epoch=1.520]Epoch 86, global step 2000: val_loss reached 0.37319 (best 0.37319), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 87: 100% 29/29 [02:39<00:00,  5.49s/it, loss=0.417, v_num=1, train_loss_step=0.357, perplexity_step=1.430, val_loss=0.373, perplexity=1.450, train_loss_epoch=0.418, perplexity_epoch=1.520]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 87: 100% 29/29 [02:48<00:00,  5.82s/it, loss=0.412, v_num=1, train_loss_step=0.391, perplexity_step=1.480, val_loss=0.369, perplexity=1.450, train_loss_epoch=0.418, perplexity_epoch=1.520]\n","Epoch 87: 100% 29/29 [02:48<00:00,  5.82s/it, loss=0.412, v_num=1, train_loss_step=0.391, perplexity_step=1.480, val_loss=0.369, perplexity=1.450, train_loss_epoch=0.412, perplexity_epoch=1.510]Epoch 87, global step 2023: val_loss reached 0.36853 (best 0.36853), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 88: 100% 29/29 [02:37<00:00,  5.43s/it, loss=0.389, v_num=1, train_loss_step=0.327, perplexity_step=1.390, val_loss=0.369, perplexity=1.450, train_loss_epoch=0.412, perplexity_epoch=1.510]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 88: 100% 29/29 [02:47<00:00,  5.77s/it, loss=0.395, v_num=1, train_loss_step=0.448, perplexity_step=1.560, val_loss=0.366, perplexity=1.440, train_loss_epoch=0.412, perplexity_epoch=1.510]\n","Epoch 88: 100% 29/29 [02:47<00:00,  5.77s/it, loss=0.395, v_num=1, train_loss_step=0.448, perplexity_step=1.560, val_loss=0.366, perplexity=1.440, train_loss_epoch=0.408, perplexity_epoch=1.510]Epoch 88, global step 2046: val_loss reached 0.36576 (best 0.36576), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 89: 100% 29/29 [02:40<00:00,  5.54s/it, loss=0.385, v_num=1, train_loss_step=0.319, perplexity_step=1.380, val_loss=0.366, perplexity=1.440, train_loss_epoch=0.408, perplexity_epoch=1.510]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 89: 100% 29/29 [02:50<00:00,  5.87s/it, loss=0.386, v_num=1, train_loss_step=0.387, perplexity_step=1.470, val_loss=0.363, perplexity=1.440, train_loss_epoch=0.408, perplexity_epoch=1.510]\n","Epoch 89: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.386, v_num=1, train_loss_step=0.387, perplexity_step=1.470, val_loss=0.363, perplexity=1.440, train_loss_epoch=0.406, perplexity_epoch=1.500]Epoch 89, global step 2069: val_loss reached 0.36294 (best 0.36294), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 90: 100% 29/29 [02:40<00:00,  5.54s/it, loss=0.388, v_num=1, train_loss_step=0.349, perplexity_step=1.420, val_loss=0.363, perplexity=1.440, train_loss_epoch=0.406, perplexity_epoch=1.500]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 90: 100% 29/29 [02:50<00:00,  5.86s/it, loss=0.382, v_num=1, train_loss_step=0.409, perplexity_step=1.510, val_loss=0.359, perplexity=1.430, train_loss_epoch=0.406, perplexity_epoch=1.500]\n","Epoch 90: 100% 29/29 [02:50<00:00,  5.87s/it, loss=0.382, v_num=1, train_loss_step=0.409, perplexity_step=1.510, val_loss=0.359, perplexity=1.430, train_loss_epoch=0.401, perplexity_epoch=1.490]Epoch 90, global step 2092: val_loss reached 0.35894 (best 0.35894), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 91: 100% 29/29 [02:41<00:00,  5.56s/it, loss=0.379, v_num=1, train_loss_step=0.394, perplexity_step=1.480, val_loss=0.359, perplexity=1.430, train_loss_epoch=0.401, perplexity_epoch=1.490]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 91: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.369, v_num=1, train_loss_step=0.341, perplexity_step=1.410, val_loss=0.357, perplexity=1.430, train_loss_epoch=0.401, perplexity_epoch=1.490]\n","Epoch 91: 100% 29/29 [02:50<00:00,  5.88s/it, loss=0.369, v_num=1, train_loss_step=0.341, perplexity_step=1.410, val_loss=0.357, perplexity=1.430, train_loss_epoch=0.395, perplexity_epoch=1.490]Epoch 91, global step 2115: val_loss reached 0.35684 (best 0.35684), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 92: 100% 29/29 [02:42<00:00,  5.60s/it, loss=0.373, v_num=1, train_loss_step=0.393, perplexity_step=1.480, val_loss=0.357, perplexity=1.430, train_loss_epoch=0.395, perplexity_epoch=1.490]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 92: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.378, v_num=1, train_loss_step=0.460, perplexity_step=1.580, val_loss=0.353, perplexity=1.420, train_loss_epoch=0.395, perplexity_epoch=1.490]\n","Epoch 92: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.378, v_num=1, train_loss_step=0.460, perplexity_step=1.580, val_loss=0.353, perplexity=1.420, train_loss_epoch=0.392, perplexity_epoch=1.480]Epoch 92, global step 2138: val_loss reached 0.35313 (best 0.35313), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 93: 100% 29/29 [02:42<00:00,  5.59s/it, loss=0.389, v_num=1, train_loss_step=0.417, perplexity_step=1.520, val_loss=0.353, perplexity=1.420, train_loss_epoch=0.392, perplexity_epoch=1.480]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 93: 100% 29/29 [02:51<00:00,  5.92s/it, loss=0.376, v_num=1, train_loss_step=0.329, perplexity_step=1.390, val_loss=0.350, perplexity=1.420, train_loss_epoch=0.392, perplexity_epoch=1.480]\n","Epoch 93: 100% 29/29 [02:51<00:00,  5.93s/it, loss=0.376, v_num=1, train_loss_step=0.329, perplexity_step=1.390, val_loss=0.350, perplexity=1.420, train_loss_epoch=0.387, perplexity_epoch=1.480]Epoch 93, global step 2161: val_loss reached 0.34968 (best 0.34968), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 94: 100% 29/29 [02:43<00:00,  5.64s/it, loss=0.394, v_num=1, train_loss_step=0.447, perplexity_step=1.560, val_loss=0.350, perplexity=1.420, train_loss_epoch=0.387, perplexity_epoch=1.480]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 94: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.392, v_num=1, train_loss_step=0.489, perplexity_step=1.630, val_loss=0.346, perplexity=1.420, train_loss_epoch=0.387, perplexity_epoch=1.480]\n","Epoch 94: 100% 29/29 [02:53<00:00,  5.97s/it, loss=0.392, v_num=1, train_loss_step=0.489, perplexity_step=1.630, val_loss=0.346, perplexity=1.420, train_loss_epoch=0.386, perplexity_epoch=1.470]Epoch 94, global step 2184: val_loss reached 0.34645 (best 0.34645), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 95: 100% 29/29 [02:40<00:00,  5.52s/it, loss=0.378, v_num=1, train_loss_step=0.410, perplexity_step=1.510, val_loss=0.346, perplexity=1.420, train_loss_epoch=0.386, perplexity_epoch=1.470]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 95: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.375, v_num=1, train_loss_step=0.308, perplexity_step=1.360, val_loss=0.343, perplexity=1.410, train_loss_epoch=0.386, perplexity_epoch=1.470]\n","Epoch 95: 100% 29/29 [02:49<00:00,  5.84s/it, loss=0.375, v_num=1, train_loss_step=0.308, perplexity_step=1.360, val_loss=0.343, perplexity=1.410, train_loss_epoch=0.382, perplexity_epoch=1.470]Epoch 95, global step 2207: val_loss reached 0.34308 (best 0.34308), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 96: 100% 29/29 [02:38<00:00,  5.45s/it, loss=0.342, v_num=1, train_loss_step=0.356, perplexity_step=1.430, val_loss=0.343, perplexity=1.410, train_loss_epoch=0.382, perplexity_epoch=1.470]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 96: 100% 29/29 [02:47<00:00,  5.77s/it, loss=0.345, v_num=1, train_loss_step=0.328, perplexity_step=1.390, val_loss=0.340, perplexity=1.410, train_loss_epoch=0.382, perplexity_epoch=1.470]\n","Epoch 96: 100% 29/29 [02:47<00:00,  5.77s/it, loss=0.345, v_num=1, train_loss_step=0.328, perplexity_step=1.390, val_loss=0.340, perplexity=1.410, train_loss_epoch=0.376, perplexity_epoch=1.460]Epoch 96, global step 2230: val_loss reached 0.34039 (best 0.34039), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 97: 100% 29/29 [02:38<00:00,  5.46s/it, loss=0.376, v_num=1, train_loss_step=0.329, perplexity_step=1.390, val_loss=0.340, perplexity=1.410, train_loss_epoch=0.376, perplexity_epoch=1.460]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 97: 100% 29/29 [02:47<00:00,  5.79s/it, loss=0.366, v_num=1, train_loss_step=0.339, perplexity_step=1.400, val_loss=0.337, perplexity=1.400, train_loss_epoch=0.376, perplexity_epoch=1.460]\n","Epoch 97: 100% 29/29 [02:47<00:00,  5.79s/it, loss=0.366, v_num=1, train_loss_step=0.339, perplexity_step=1.400, val_loss=0.337, perplexity=1.400, train_loss_epoch=0.373, perplexity_epoch=1.450]Epoch 97, global step 2253: val_loss reached 0.33685 (best 0.33685), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 98: 100% 29/29 [02:40<00:00,  5.53s/it, loss=0.346, v_num=1, train_loss_step=0.297, perplexity_step=1.350, val_loss=0.337, perplexity=1.400, train_loss_epoch=0.373, perplexity_epoch=1.450]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 98: 100% 29/29 [02:50<00:00,  5.87s/it, loss=0.354, v_num=1, train_loss_step=0.436, perplexity_step=1.550, val_loss=0.334, perplexity=1.400, train_loss_epoch=0.373, perplexity_epoch=1.450]\n","Epoch 98: 100% 29/29 [02:50<00:00,  5.87s/it, loss=0.354, v_num=1, train_loss_step=0.436, perplexity_step=1.550, val_loss=0.334, perplexity=1.400, train_loss_epoch=0.368, perplexity_epoch=1.450]Epoch 98, global step 2276: val_loss reached 0.33364 (best 0.33364), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 99: 100% 29/29 [02:42<00:00,  5.59s/it, loss=0.36, v_num=1, train_loss_step=0.380, perplexity_step=1.460, val_loss=0.334, perplexity=1.400, train_loss_epoch=0.368, perplexity_epoch=1.450]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n","Epoch 99: 100% 29/29 [02:51<00:00,  5.90s/it, loss=0.363, v_num=1, train_loss_step=0.328, perplexity_step=1.390, val_loss=0.330, perplexity=1.390, train_loss_epoch=0.368, perplexity_epoch=1.450]\n","Epoch 99: 100% 29/29 [02:51<00:00,  5.91s/it, loss=0.363, v_num=1, train_loss_step=0.328, perplexity_step=1.390, val_loss=0.330, perplexity=1.390, train_loss_epoch=0.366, perplexity_epoch=1.440]Epoch 99, global step 2299: val_loss reached 0.33015 (best 0.33015), saving model to \"/content/logs/best-checkpoint.ckpt\" as top 1\n","Epoch 99: 100% 29/29 [03:14<00:00,  6.70s/it, loss=0.363, v_num=1, train_loss_step=0.328, perplexity_step=1.390, val_loss=0.330, perplexity=1.390, train_loss_epoch=0.366, perplexity_epoch=1.440]\n","Saving latest checkpoint...\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/tpu_spawn.py:204: UserWarning: cleaning up tpu spawn environment...\n","  rank_zero_warn(\"cleaning up tpu spawn environment...\")\n","user > 삼성화재가 구미에 공장을 증설했다.\n","생성 문장 </s> 지금은 구미있을 뿐이징~! ᄒᄒ 우리 회사두 대박 나겟다!!</s><pad><pad><pad><pad><pad><pad><pad><pad>\n","생성 문장 </s> 이번에 구미케 해주려고 재팬 만들었넹 ᄒᄒ!!! 그러니까~ 삼성이 한국에 공장을 더 많이 지울 수가 있엉 ᅮ</s>\n","생성 문장 </s> 웅웅! 구미에서 새로운 공법이 생겼넹 ᄒᄒ!!~ 완전 대박이징 ᄏᄏ</s><pad><pad><pad><pad><pad><pad>\n","생성 문장 </s> 한국도 구미에서 생산하는 자동차가 있엉 ᄒᄒ~! 성장했어!!</s><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","생성 문장 </s> 이번에 구미케 들렸넹!! 원래 구미에서 하고 있었징~ᄏᄏ~ 지금바로 그런거야ᅮ</s><pad><pad><pad><pad><pad>\n","Simsimi >  지금은 구미있을 뿐이징~! ᄒᄒ 우리 회사두 대박 나겟다!!\n","user > 맛있겠다\n","생성 문장 </s> 대박 맛있어 보이겟당!!! 완전 존맛탱~! 맛있겠당 ᄒᄒ</s><pad>\n","생성 문장 </s> 대박 맛있어 보인당!!! 나도 빵 진짜 좋아해!!!! ᄒᄒ~?</s><pad><pad>\n","생성 문장 </s> 대박 맛있어 보인당!!! 나도 맛 진짜진짜 존맛탱하고 싶엉 ᄒᄒ</s>\n","생성 문장 </s> 대박 맛있어 보인당!!! ᄒᄒ~! 엄청 맛있겟넹!!!!ᄒ</s><pad><pad>\n","생성 문장 </s> 진짜 맛있 맛보넹!!! ᄒᄒ!!!! 완전 대박이얗ᄒᄋᄉᄒ</s>\n","Simsimi >  대박 맛있어 보이겟당!!! 완전 존맛탱~! 맛있겠당 ᄒᄒ\n","user > 부러워\n","생성 문장 </s> 젤~ 대박대박 너무 부러워서 못살겠당 ᄒᄒ!!!!</s><pad><pad><pad><pad><pad><pad><pad><pad>\n","생성 문장 </s> 대박 가타!! 진짜 부러웡니다~!! ᄒᄒ!!!!!ㅜㅜ</s><pad><pad><pad><pad><pad><pad><pad><pad>\n","생성 문장 </s> 부럽다~! 대박이네 완전 부러웡!!! ᄒᄒ~~ 그래두 내겐 부러웠엉 ㅜㅜ</s>\n","생성 문장 </s> 좋아해ᄒᄒ~! ᄒ0!! 멋진 커플 같넹!!ᄒ ᅮ</s><pad><pad><pad><pad><pad><pad><pad><pad>\n","생성 문장 </s> 부럽다~! ᄒᄒ 매우 부러웡!!!!^^ ~!♡!!</s><pad><pad><pad><pad><pad><pad><pad><pad>\n","Simsimi >  젤~ 대박대박 너무 부러워서 못살겠당 ᄒᄒ!!!!\n","user > 나도 시켜줘\n","생성 문장 </s> 나두 나도 해줄게!! ᄒᄒ~! 내가 시켜서 하겠당 ᄋᄉᄒ</s>\n","생성 문장 </s> 나두 같이 시켜야 ᄒᄒ!!!! 시켜서 시켜줄게 ^0^ </s>\n","생성 문장 </s> 나두 나한테 맡겨봐!!! 나도 시키고 싶어ㅜㅜ ᅮ(!!)!!</s><pad><pad>\n","생성 문장 </s> 나두 내가 시켜줄게 ᄒᄒ!!!!(!!)?!!!! </s><pad><pad>\n","생성 문장 </s> 나두 시켜 ᄒᄒ~! 시켜주께!!! ^0^!!</s><pad><pad>\n","Simsimi >  나두 나도 해줄게!! ᄒᄒ~! 내가 시켜서 하겠당 ᄋᄉᄒ\n","user > 나도 같이 할래\n","생성 문장 </s> 나두 같이 나가자고! ᄒᄒ!!!?! 나 같은 애들도 가끔은 동반할랭??</s>\n","생성 문장 </s> 나두 같이 운동해!! 나도 응원하고 싶엉 ᄒᄒ!!!  ^0^</s><pad><pad><pad>\n","생성 문장 </s> 나두 같이 여행 가자고!!! 나도 응원할게!! ᄒᄒ~!!!!</s><pad><pad><pad><pad><pad>\n","생성 문장 </s> 나두 같이 골프 할랭?! 나도 맘씨가 좋을 거 같앙!!! ᄒᄒ</s><pad><pad><pad><pad>\n","생성 문장 </s> 나두 같이 가두 돼?!?!!! 너의 응원두~ ᄒᄒ</s><pad><pad><pad><pad><pad>\n","Simsimi >  나두 같이 나가자고! ᄒᄒ!!!?! 나 같은 애들도 가끔은 동반할랭??\n","user > quit\n"]}],"source":["#@title 실행\n","import os\n","from tensorflow.python.profiler import profiler_client\n","import gc\n","gc.collect()\n","print(os.environ[\"TPU_NAME\"])\n","os.environ[\"TOKENIZERS_PARALLELISM\"] =\"0\"\n","os.environ[\"TRIM_GRAPH_SIZE\"] = \"1000000\"\n","os.environ[\"MALLOC_MMAP_THRESHOLD_\"] = \"31961168\"\n","os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '1000000000'\n","os.environ[\"PR_SET_PDEATHSIG\"]=\"1\"\n","os.environ[\"PL_RECONCILE_PROCESS\"]=\"1\"\n","os.environ['XLA_USE_32BIT_LONG'] = '0'\n","os.environ['XLA_USE_BF16'] = '1'\n","os.environ['XLA_SYNC_WAIT'] = '1'\n","os.environ['PL_TORCH_DISTRIBUTED_BACKEND']=\"nlcc\" #nlcc gloo\n","# os.environ[\"XRT_TPU_CONFIG\"]=\"localservice;0;localhost:51011\"\n","tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n","print(profiler_client.monitor(tpu_profile_service_address, 100, 2))\n","assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n","# !mkdir logs/tb_logs/lightning_logs\n","!bash trainer.sh"]},{"cell_type":"markdown","metadata":{"id":"N5M6I0ySvfsO"},"source":["# Data load"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"background_save":true,"referenced_widgets":["cff61a91557041dcadc7d7b792dc622e"]},"id":"iW1It1TJU_Ce","outputId":"5f0c230f-2c83-40b8-8f27-ab37127f9487"},"outputs":[{"name":"stderr","output_type":"stream","text":["[kcbert] download kcbert-train.tar.gzaa: 100%|██████████| 2.10G/2.10G [00:30<00:00, 69.8MB/s]\n","[kcbert] download kcbert-train.tar.gzab: 100%|██████████| 2.10G/2.10G [01:35<00:00, 22.0MB/s]\n","[kcbert] download kcbert-train.tar.gzac: 671MB [00:07, 88.3MB/s]                           \n"]},{"name":"stdout","output_type":"stream","text":["Unzip tar. It needs a few minutes ... done\n","/bin/bash: @#: command not found\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cff61a91557041dcadc7d7b792dc622e","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["#@title KcBERT 댓글 데이터\n","#@markdown 바꾸는데 너무 오래걸림\n","from Korpora import Korpora\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","Korpora.fetch(\"kcbert\",\n","              root_dir=\"/content/\")\n","! @#\n","dummy = pd.DataFrame(data=None,columns=[\"pattern\",\"label\"])\n","with open(\"/content/kcbert/20190101_20200611_v2.txt\",\"r\") as f:\n","    for line in tqdm(f):\n","        dummy = dummy.append({\"pattern\":\"\",\"label\":line},ignore_index=True)\n","dummy.to_csv(\"kcbert.tsv\",index=False,sep=\"\\t\")\n","del dummy"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"DFXMHwY8sEo0"},"outputs":[],"source":["#@title 나무위키 데이터\n","import pandas as pd\n","import ijson\n","from multiprocessing import Pool\n","from namuwiki.extractor import extract_text\n","\n","capture_values = [\n","    (\"item.namespace\", \"string\"),\n","    (\"item.title\", \"string\"),\n","    (\"item.text\", \"string\")\n","]\n","\n","def parse_namuwiki_json(limit = -1, debug=False):\n","  i = 0\n","  doc = {}\n","  with open(\"/content/namuwiki_20210301.json\",\"r\") as f:\n","    for prefix, event, value in ijson.parse(f):\n","      if debug:\n","        print(prefix, event, value)\n","      if (prefix, event) in capture_values:\n","        doc[prefix[5:]] = value\n","      if (prefix, event, value) == (\"item\", \"end_map\", None):\n","        yield doc    \n","        doc = {}\n","        i += 1\n","        if limit > 0 and i >= limit:\n","          break\n","\n","temp = [[],[]]          \n","for doc in parse_namuwiki_json( debug=False):\n","    temp[0]+=[doc[\"title\"]]\n","    temp[1]+=[extract_text(doc['text'])]\n","\n","pd.DataFrame({\"pattern\":temp[0],\"label\":temp[1]}).to_csv(\"namuwiki.tsv\",index=False,sep=\"\\t\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"FOmTBiaXsCt6"},"outputs":[],"source":["#@title ko Wiki 데이터\n","from xml.etree import ElementTree\n","import pandas as pd\n","import os\n","import re\n","\n","filepath = \"/content/text/\"\n","file_list = list(map(lambda x: filepath + x, os.listdir(filepath)))\n","document_items=[[],[]]\n","for path in file_list:    \n","    for i in [file for file in os.listdir(path) if file.startswith('wiki')]:\n","        with open(f\"{path}/{i}\",'r') as f:\n","            root = ElementTree.fromstringlist(\n","                    \"<root>\"+\"\".join(f.readlines())+\"</root>\"\n","                )\n","            for document in root.getchildren():\n","                document_items[0] += [document.attrib[\"title\"]]\n","                document_items[1] += [document.text.replace(\"\\n\\n\",\"\\n\")[1:-1]]\n","pd.DataFrame({\"pattern\":document_items[0], \"label\":document_items[1]}).to_csv(\"kowiki.tsv\",index=False,sep=\"\\t\")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152282,"status":"ok","timestamp":1662013335564,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"W5Ov6O5TvhpJ","outputId":"aa59eb31-361b-46f9-854b-f8d6b5066e19"},"outputs":[{"name":"stdout","output_type":"stream","text":["전체 길이 : 5648396\n","Train.csv 파일 크기 : 1.9284 GB\n","Test.csv 파일 크기 : 0.4803 GB\n","Dev.csv 파일 크기 : 0.0245 GB\n","Dev_s.csv 파일 크기 : 0.0024 GB\n"]}],"source":["#@title 데이터 통합\n","import os\n","import pandas as pd\n","import json\n","\n","DEFAULT_PATH = \"/content/drive/MyDrive/Colab Notebooks/data/chatbot\"\n","filepath = DEFAULT_PATH+\"/PET data/\"\n","file_list = os.listdir(filepath)\n","try:\n","    df = pd.concat([pd.read_csv(\"kowiki.tsv\",sep=\"\\t\").dropna(),\n","                pd.read_csv(\"namuwiki.tsv\",sep=\"\\t\").dropna()],\n","               ignore_index=True)\n","except:\n","    df = pd.DataFrame()\n","\n","for i in [file for file in file_list if file.endswith('.csv')]:\n","    try:\n","        data = pd.read_csv(filepath + i)\n","    except:\n","        continue\n","    df = pd.concat([df,data])\n","data = df.dropna().reset_index(drop = True)               \n","\n","from sklearn.model_selection import train_test_split\n","print(f\"전체 길이 : {len(data)}\")\n","train, test = train_test_split(data, test_size=0.2)\n","_,dev =train_test_split(data, test_size=0.01)\n","_,dev_small =train_test_split(dev, test_size=0.1)\n","train.to_csv(\"Train.csv\",index=None)\n","print('Train.csv 파일 크기 : %.4f GB'%(os.path.getsize(\"Train.csv\")/(1024.0 * 1024.0 * 1000.0)))\n","test.to_csv(\"Test.csv\",index=None)\n","print('Test.csv 파일 크기 : %.4f GB'%(os.path.getsize(\"Test.csv\")/(1024.0 * 1024.0 * 1000.0)))\n","dev.to_csv(\"Dev.csv\",index=None)\n","print('Dev.csv 파일 크기 : %.4f GB'%(os.path.getsize(\"Dev.csv\")/(1024.0 * 1024.0 * 1000.0)))\n","dev_small.to_csv(\"Dev_s.csv\",index=None)\n","print('Dev_s.csv 파일 크기 : %.4f GB'%(os.path.getsize(\"Dev_s.csv\")/(1024.0 * 1024.0 * 1000.0)))"]},{"cell_type":"markdown","metadata":{"id":"x6pV_73CrXUS"},"source":["# Pretraining Test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1661832161927,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"6NsmHViL7WYC","outputId":"4de2f255-a2aa-40da-f422-53ad51bb03fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting config.json\n"]}],"source":["#@markdown writefile t5 config.json\n","%%writefile config.json\n","{\n","  \"_name_or_path\": \"Gunulhona/tb_t5_base\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 0,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"transformers_version\": \"4.4.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 64128\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1662012164006,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"wiWasIyv73rj","outputId":"21496f36-a77d-412b-9edd-2a656eefc783"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing config.json\n"]}],"source":["#@markdown writefile bart config.json\n","%%writefile config.json\n","{ \n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu_new\",\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 12,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 9,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 12,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 2,\n","  \"forced_eos_token_id\": 2,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_position_embeddings\": 1026,\n","  \"model_type\": \"bart\",\n","  \"pad_token_id\": 3,\n","  \"num_hidden_layers\": 6,\n","  \"scale_embedding\": false,\n","  \"transformers_version\": \"4.14.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 30000\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1662012164008,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"yuAXLwuI1Mfp","outputId":"68d70b14-ef2e-4b41-d15b-2263d11fb9aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing bart_custom.py\n"]}],"source":["#@title Custom Bart 파일 저장\n","%%writefile bart_custom.py\n","\n","import copy\n","import math\n","import random\n","import warnings\n","from typing import Optional, Tuple\n","\n","import torch\n","import torch.utils.checkpoint\n","from torch import nn\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n","\n","from transformers.activations import ACT2FN\n","from transformers.file_utils import (\n","    add_code_sample_docstrings,\n","    add_end_docstrings,\n","    add_start_docstrings,\n","    add_start_docstrings_to_model_forward,\n","    replace_return_docstrings,\n",")\n","from transformers.modeling_outputs import (\n","    BaseModelOutput,\n","    BaseModelOutputWithPastAndCrossAttentions,\n","    CausalLMOutputWithCrossAttentions,\n","    Seq2SeqLMOutput,\n","    MaskedLMOutput,\n","    Seq2SeqModelOutput,\n","    Seq2SeqQuestionAnsweringModelOutput,\n","    Seq2SeqSequenceClassifierOutput,\n",")\n","from transformers.models.bart.modeling_bart import *\n","from transformers.modeling_utils import PreTrainedModel\n","from transformers.utils import logging\n","from transformers.models.bart.configuration_bart import BartConfig\n","\n","_CHECKPOINT_FOR_DOC = \"facebook/bart-large\"\n","_CONFIG_FOR_DOC = \"BartConfig\"\n","_TOKENIZER_FOR_DOC = \"BartTokenizer\"\n","\n","@add_start_docstrings(\n","    \"The BART Model with a language modeling head. Can be used for summarization.\", BART_START_DOCSTRING\n",")\n","class BartForMaskedLM(BartPretrainedModel):\n","    base_model_prefix = \"model\"\n","    _keys_to_ignore_on_load_missing = [r\"final_logits_bias\", r\"lm_head\\.weight\"]\n","\n","    def __init__(self, config: BartConfig):\n","        super().__init__(config)\n","        self.model = BartModel(config)\n","        self.register_buffer(\"final_logits_bias\", torch.zeros((1, self.model.shared.num_embeddings)))\n","        self.lm_head = nn.Linear(config.d_model, self.model.shared.num_embeddings, bias=False)\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def get_encoder(self):\n","        return self.model.get_encoder()\n","\n","    def get_decoder(self):\n","        return self.model.get_decoder()\n","\n","    def resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n","        new_embeddings = super().resize_token_embeddings(new_num_tokens)\n","        self._resize_final_logits_bias(new_num_tokens)\n","        return new_embeddings\n","\n","    def _resize_final_logits_bias(self, new_num_tokens: int) -> None:\n","        old_num_tokens = self.final_logits_bias.shape[-1]\n","        if new_num_tokens <= old_num_tokens:\n","            new_bias = self.final_logits_bias[:, :new_num_tokens]\n","        else:\n","            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n","            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n","        self.register_buffer(\"final_logits_bias\", new_bias)\n","\n","    def get_output_embeddings(self):\n","        return self.lm_head\n","\n","    def set_output_embeddings(self, new_embeddings):\n","        self.lm_head = new_embeddings\n","\n","    @add_start_docstrings_to_model_forward(BART_INPUTS_DOCSTRING)\n","    @replace_return_docstrings(output_type=Seq2SeqLMOutput, config_class=_CONFIG_FOR_DOC)\n","    @add_end_docstrings(BART_GENERATION_EXAMPLE)\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        decoder_input_ids=None,\n","        decoder_attention_mask=None,\n","        head_mask=None,\n","        decoder_head_mask=None,\n","        cross_attn_head_mask=None,\n","        encoder_outputs=None,\n","        past_key_values=None,\n","        inputs_embeds=None,\n","        decoder_inputs_embeds=None,\n","        labels=None,\n","        use_cache=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n","            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n","            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n","            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n","        Returns:\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        if labels is not None:\n","            if decoder_input_ids is None and decoder_inputs_embeds is None:\n","                decoder_input_ids = shift_tokens_right(\n","                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n","                )\n","\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            encoder_outputs=encoder_outputs,\n","            decoder_attention_mask=decoder_attention_mask,\n","            head_mask=head_mask,\n","            decoder_head_mask=decoder_head_mask,\n","            cross_attn_head_mask=cross_attn_head_mask,\n","            past_key_values=past_key_values,\n","            inputs_embeds=inputs_embeds,\n","            decoder_inputs_embeds=decoder_inputs_embeds,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n","\n","        masked_lm_loss = None\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (lm_logits,) + outputs[1:]\n","            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n","\n","        return Seq2SeqLMOutput(\n","            loss=masked_lm_loss,\n","            logits=lm_logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            cross_attentions=outputs.cross_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n","\n","    def prepare_inputs_for_generation(\n","        self,\n","        decoder_input_ids,\n","        past=None,\n","        attention_mask=None,\n","        head_mask=None,\n","        decoder_head_mask=None,\n","        cross_attn_head_mask=None,\n","        use_cache=None,\n","        encoder_outputs=None,\n","        **kwargs\n","    ):\n","        # cut decoder_input_ids if past is used\n","        if past is not None:\n","            decoder_input_ids = decoder_input_ids[:, -1:]\n","\n","        return {\n","            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n","            \"encoder_outputs\": encoder_outputs,\n","            \"past_key_values\": past,\n","            \"decoder_input_ids\": decoder_input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"head_mask\": head_mask,\n","            \"decoder_head_mask\": decoder_head_mask,\n","            \"cross_attn_head_mask\": cross_attn_head_mask,\n","            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n","        }\n","\n","    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n","        return shift_tokens_right(labels, self.config.pad_token_id, self.config.decoder_start_token_id)\n","\n","    @staticmethod\n","    def _reorder_cache(past, beam_idx):\n","        reordered_past = ()\n","        for layer_past in past:\n","            # cached cross_attention states don't have to be reordered -> they are always the same\n","            reordered_past += (\n","                tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n","            )\n","        return reordered_past"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1662014588000,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"5AyUCVYEPCxH","outputId":"3a15f377-9248-4632-9909-650d5e2c47ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting kobart_mlm.py\n"]}],"source":["#@title kobart_mlm (causal mlm) 파일 저장\n","%%writefile kobart_mlm.py\n","import argparse\n","import logging\n","import os\n","import warnings\n","\n","import numpy as np\n","import pandas as pd\n","import pytorch_lightning as pl\n","import torch\n","\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import (BartForConditionalGeneration,\n","                          BartForCausalLM,\n","                          BartModel, BartConfig,\n","                          BartForSequenceClassification,\n","                          T5Model, T5Config, T5Tokenizer,\n","                          T5ForConditionalGeneration,\n","                          PreTrainedTokenizerFast)\n","from transformers.optimization import (AdamW, get_cosine_schedule_with_warmup,\n","                                       get_cosine_with_hard_restarts_schedule_with_warmup)\n","\n","from pytorch_lightning import loggers as pl_loggers\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.trainer.supporters import CombinedLoader\n","\n","import wandb\n","from copy import deepcopy\n","from scipy.stats import poisson\n","\n","\n","warnings.filterwarnings(action=\"ignore\")\n","\n","\n","parser = argparse.ArgumentParser(description='KoBART Chit-Chat')\n","\n","parser.add_argument('--checkpoint_path',\n","                    type=str,\n","                    help='checkpoint path')\n","\n","parser.add_argument('--chat',\n","                    action='store_true',\n","                    default=False,\n","                    help='response generation on given user input')\n","\n","LOGGER = logging.getLogger()\n","LOGGER.setLevel(logging.INFO)\n","\n","\n","class ArgsBase():\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):\n","        parser = argparse.ArgumentParser(parents=[parent_parser], add_help=False)\n","        parser.add_argument('--train_file',\n","                            type=str,\n","                            default='/dev_t.csv',\n","                            help='train file')\n","\n","        parser.add_argument('--val_file',\n","                            type=str,\n","                            default='/dev_v.csv',\n","                            help='val file')\n","\n","        parser.add_argument('--test_file',\n","                            type=str,\n","                            default='/dev_v.csv',\n","                            help='test file')\n","\n","        parser.add_argument('--tokenizer_path',\n","                            type=str,\n","                            default='tokenizer',\n","                            help='tokenizer')\n","        \n","        parser.add_argument('--batch_size',\n","                            type=int,\n","                            default=4,\n","                            help='')\n","        parser.add_argument('--max_seq_len',\n","                            type=int,\n","                            default=1024,\n","                            help='max seq len')\n","        return parser\n","\n","\n","class Pet_Dataset(Dataset):\n","    def __init__(self,\n","                 file_root_path=None,\n","                 tokenizer_path=None,\n","                 max_seq_len=512):\n","        self.filepath = file_root_path\n","        self.data = pd.read_csv(self.filepath).dropna()\n","        self.max_seq_len = max_seq_len\n","        # self.tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n","        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n","        self.masking_start, self.masking_end = self.tokenizer.encode(\"[]\")[:-1]\n","\n","    def __len__(self):\n","        return self.data.__len__()\n","\n","    def _encode(self, text):\n","        tokens = [self.tokenizer.eos_token] + self.tokenizer.tokenize(text) + [self.tokenizer.eos_token]\n","        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n","        attention_mask = [1]*len(input_ids)\n","        if len(input_ids) < self.max_seq_len:\n","            while len(input_ids)<self.max_seq_len:\n","                input_ids+=[self.tokenizer.pad_token_id]\n","                attention_mask+=[0]\n","        else:\n","            input_ids = input_ids[:self.max_seq_len-1]+[self.tokenizer.eos_token_id]\n","            attention_mask = attention_mask[:self.max_seq_len]\n","        return input_ids, attention_mask\n","\n","    def _labeling(self,label):\n","        tokens = self.tokenizer.tokenize(label)+[self.tokenizer.eos_token]\n","        label_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n","        if len(label_ids) < self.max_seq_len:\n","            while len(label_ids)<self.max_seq_len:\n","                label_ids+=[-100]\n","        else:\n","            label_ids = label_ids[:self.max_seq_len-1] + [self.tokenizer.eos_token_id]\n","        return label_ids\n","\n","    def _masking(self, tokens, mask=None):\n","        mask = self.tokenizer.encode(mask)[0] if mask else self.tokenizer.mask_token_id\n","        masked = tokens\n","        mask_idx=[]\n","        while self.masking_start in masked and self.masking_end in masked:\n","            start_idx = masked.index(self.masking_start)\n","            end_idx = masked.index(self.masking_end)+1\n","            if start_idx < end_idx:\n","                mask_idx +=[[start_idx,end_idx]]\n","                masked[start_idx:end_idx] = [mask]*len(masked[start_idx:end_idx])\n","            else: break\n","        return masked, mask_idx\n","\n","    def _label_masking(self, tokens, idx):\n","        masked = np.array(tokens)\n","        index,position =[],[]\n","        for i in idx:\n","            index+=range(i[0],i[1])\n","        for n,x in enumerate(tokens):\n","            position += [n not in index]\n","        masked[position] = [-100]\n","        return masked.tolist()\n","\n","class Masked_Dataset(Pet_Dataset):\n","    def _random_masking(self,input, mask=None, ratio=0.15):\n","        mask = self.tokenizer.encode(mask)[0] if mask else self.tokenizer.mask_token_id\n","        input = np.array(input)\n","        rand = np.random.rand(input.size)\n","        mask_arr = (rand < ratio) * (input != self.tokenizer.eos_token_id) * (input != self.tokenizer.eos_token_id)\n","        input[mask_arr.nonzero()] = mask\n","        return input.tolist()\n","\n","    def __getitem__(self,index):\n","        record = self.data.iloc[index]\n","        pattern, label = record[\"pattern\"], record[\"label\"]\n","        encoder_input_ids, encoder_attention_mask = self._encode(pattern+label)\n","        decoder_input_ids, decoder_attention_mask = self._encode(pattern+label)        \n","        labels = self._labeling(pattern+label)\n","        mask = f\"<extra_id_{np.random.randint(0,100)}>\"\n","        encoder_input_ids,mask_idx = self._masking(encoder_input_ids,mask=mask)\n","        encoder_input_ids = self._random_masking(encoder_input_ids,mask=mask)\n","        return {\"input_ids\":np.array(encoder_input_ids, dtype=np.int_),\n","                \"attention_mask\":np.array(encoder_attention_mask,dtype=np.float32),\n","                \"decoder_input_ids\":np.array(decoder_input_ids, dtype=np.int_),\n","                \"decoder_attention_mask\":np.array(decoder_attention_mask,dtype=np.float32),\n","                \"labels\":np.array(labels,dtype=np.int_)}\n","\n","class Permutation_Dataset(Pet_Dataset):\n","    def _random_rotation(self, input):\n","        input = np.array(input)\n","        start_idx = np.where(input==self.tokenizer.eos_token_id)[0][0]\n","        end_idx = np.where(input==self.tokenizer.eos_token_id)[0][0]\n","        np.random.shuffle(input[start_idx:end_idx])\n","        return input.tolist()\n","\n","    def __getitem__(self,index):\n","        record = self.data.iloc[index]\n","        pattern, label = record[\"pattern\"], record[\"label\"]\n","        encoder_input_ids, encoder_attention_mask = self._encode(pattern+label)\n","        decoder_input_ids, decoder_attention_mask = self._encode(pattern+label)        \n","        labels = self._labeling(pattern+label)\n","        encoder_input_ids = self._random_rotation(encoder_input_ids)\n","\n","        return {\"input_ids\":np.array(encoder_input_ids, dtype=np.int_),\n","                \"attention_mask\":np.array(encoder_attention_mask,dtype=np.float32),\n","                \"decoder_input_ids\":np.array(decoder_input_ids, dtype=np.int_),\n","                \"decoder_attention_mask\":np.array(decoder_attention_mask,dtype=np.float32),\n","                \"labels\":np.array(labels,dtype=np.int_)}\n","\n","class Deletion_Dataset(Pet_Dataset):\n","    def _random_deletion(self,input, ratio=0.15):\n","        input = np.array(input)\n","        eos_idx = np.where(input==self.tokenizer.eos_token_id)[0][0]\n","        rand = np.random.rand(input[:eos_idx].size)\n","        rand = np.append(rand,[1.]*input[eos_idx:].size)\n","        del_arr = (rand < ratio) * (input != self.tokenizer.eos_token_id) * (input != self.tokenizer.eos_token_id)\n","        input = np.delete(input, del_arr.nonzero())\n","        return np.int_(np.append(input,[self.tokenizer.pad_token_id]*del_arr.nonzero()[0].size)).tolist()\n","\n","    def __getitem__(self,index):\n","        record = self.data.iloc[index]\n","        pattern, label = record[\"pattern\"], record[\"label\"]\n","        encoder_input_ids, encoder_attention_mask = self._encode(pattern+label)\n","        decoder_input_ids, decoder_attention_mask = self._encode(pattern+label)        \n","        labels = self._labeling(pattern+label)\n","        encoder_input_ids = self._random_deletion(encoder_input_ids)\n","\n","        return {\"input_ids\":np.array(encoder_input_ids, dtype=np.int_),\n","                \"attention_mask\":np.array(encoder_attention_mask,dtype=np.float32),\n","                \"decoder_input_ids\":np.array(decoder_input_ids, dtype=np.int_),\n","                \"decoder_attention_mask\":np.array(decoder_attention_mask,dtype=np.float32),\n","                \"labels\":np.array(labels,dtype=np.int_)}\n","\n","class Infilling_Dataset(Pet_Dataset):\n","    def _random_infilling(self,input, mask=None, ratio=0.15, l=3):\n","        mask = self.tokenizer.encode(mask)[0] if mask else self.tokenizer.mask_token_id\n","        input = np.array(input)\n","        eos_idx = np.where(input[1:]==self.tokenizer.eos_token_id)[0][0]\n","        text_range = input[1:eos_idx]\n","        poi = poisson(l).pmf(text_range) > ratio\n","        infill = np.where(poi, np.array([mask]+[-100]*(poi.size-1)), text_range)\n","        infill = np.append(input[0], np.delete(infill,np.where(infill == -100)))\n","        infill = np.append(infill, [self.tokenizer.pad_token_id]*(np.count_nonzero(poi)-1))\n","        infill = np.append(infill, input[eos_idx:])\n","        if poi.max() == poi.min():\n","            if not len(infill) > len(input):\n","                infill = np.insert(infill, np.random.choice(len(text_range)), \n","                                   mask)[:len(input)]                    \n","            else:\n","                _size = int(len(text_range)*ratio)\n","                infill = np.insert(infill, np.random.choice(len(text_range),\n","                                                            size=_size), mask)[:len(input)-1]\n","                infill = np.append(infill, [self.tokenizer.eos_token_id])\n","        if infill.size == (self.max_seq_len-1):\n","            infill = np.append(infill, input[-1])\n","        return np.int_(infill).tolist()\n","\n","    def __getitem__(self,index):\n","        record = self.data.iloc[index]\n","        pattern, label = record[\"pattern\"], record[\"label\"]\n","        encoder_input_ids, encoder_attention_mask = self._encode(pattern+label)\n","        decoder_input_ids, decoder_attention_mask = self._encode(pattern+label)\n","        labels = self._labeling(pattern+label)\n","        mask = f\"<extra_id_{np.random.randint(0,100)}>\"        \n","        encoder_input_ids = self._random_infilling(encoder_input_ids, mask=mask)\n","\n","        return {\"input_ids\":np.array(encoder_input_ids, dtype=np.int_),\n","                \"attention_mask\":np.array(encoder_attention_mask,dtype=np.float32),\n","                \"decoder_input_ids\":np.array(decoder_input_ids, dtype=np.int_),\n","                \"decoder_attention_mask\":np.array(decoder_attention_mask,dtype=np.float32),\n","                \"labels\":np.array(labels,dtype=np.int_)}\n","\n","class ChatDataModule(pl.LightningDataModule):\n","    def __init__(self, \n","                 train_file,\n","                 val_file,\n","                 test_file, \n","                 tokenizer_path,\n","                 max_seq_len=1024,\n","                 batch_size=4,\n","                 num_workers=None):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.max_seq_len = max_seq_len\n","        self.train_file_path = train_file\n","        self.val_file_path = val_file\n","        self.test_file_path = test_file\n","        self.tokenizer_path = tokenizer_path\n","        self.num_workers = num_workers\n","\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):\n","        parser = argparse.ArgumentParser(\n","            parents=[parent_parser], add_help=False)\n","        parser.add_argument('--num_workers',\n","                            type=int,\n","                            default=8,\n","                            help='num of worker for dataloader')\n","        return parser\n","    # OPTIONAL, called for every GPU/machine (assigning state is OK)\n","\n","    def _load_multiple(self, file_path, shuffle):\n","        return {\n","            \"Deletion Data\":DataLoader(Deletion_Dataset(file_path, self.tokenizer_path, self.max_seq_len),\n","                          batch_size=self.batch_size,\n","                          num_workers=self.num_workers, shuffle=shuffle),\n","            \"Permutation Data\":DataLoader(Permutation_Dataset(file_path, self.tokenizer_path, self.max_seq_len),\n","                          batch_size=self.batch_size,\n","                          num_workers=self.num_workers, shuffle=shuffle),\n","            \"Masked Data\":DataLoader(Masked_Dataset(file_path, self.tokenizer_path, self.max_seq_len),\n","                          batch_size=self.batch_size,\n","                          num_workers=self.num_workers, shuffle=shuffle),\n","            \"Infilling Data\":DataLoader(Infilling_Dataset(file_path, self.tokenizer_path, self.max_seq_len),\n","                          batch_size=self.batch_size,\n","                          num_workers=self.num_workers, shuffle=shuffle)\n","        }\n","\n","    def setup(self, stage):\n","        # split dataset\n","        # self.train = Deletion_Dataset(self.train_file_path, self.tokenizer_path, self.max_seq_len)\n","\n","        # self.val = Deletion_Dataset(self.val_file_path, self.tokenizer_path, self.max_seq_len)\n","\n","        # self.test = Deletion_Dataset(self.test_file_path, self.tokenizer_path, self.max_seq_len)\n","\n","        self.train = self._load_multiple(file_path=self.train_file_path, shuffle=True)\n","\n","        self.val = self._load_multiple(file_path=self.val_file_path, shuffle=True)\n","\n","        self.test = self._load_multiple(file_path=self.test_file_path, shuffle=True)\n","\n","    # def train_dataloader(self):\n","    #     return DataLoader(self.train,\n","    #                        batch_size=self.batch_size,\n","    #                        num_workers=self.num_workers, shuffle=True)\n","\n","    # def val_dataloader(self):\n","    #     return DataLoader(self.test,\n","    #                      batch_size=self.batch_size,\n","    #                      num_workers=self.num_workers, shuffle=False)\n","\n","    # def test_dataloader(self):\n","    #     return DataLoader(self.test,\n","    #                       batch_size=self.batch_size,\n","    #                       num_workers=self.num_workers, shuffle=False)\n","        \n","    def train_dataloader(self):\n","        return CombinedLoader(self.train, mode=\"max_size_cycle\")\n","\n","    def val_dataloader(self):\n","        return CombinedLoader(self.val, mode=\"max_size_cycle\")\n","\n","    def test_dataloader(self):\n","        return CombinedLoader(self.test, mode=\"max_size_cycle\")\n","\n","class Base(pl.LightningModule):\n","    def __init__(self, hparams, **kwargs) -> None:\n","        super(Base, self).__init__()\n","        self.save_hyperparameters(hparams)\n","\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):\n","        # add model specific args\n","        parser = argparse.ArgumentParser(\n","            parents=[parent_parser], add_help=False)\n","\n","        parser.add_argument('--batch-size',\n","                            type=int,\n","                            default=4,\n","                            help='batch size for training (default: 4)')\n","\n","        parser.add_argument('--lr',\n","                            type=float,\n","                            default=5e-8,\n","                            help='The initial learning rate')\n","\n","        parser.add_argument('--warmup_ratio',\n","                            type=float,\n","                            default=0.1,\n","                            help='warmup ratio')\n","\n","        parser.add_argument('--model_path',\n","                            type=str,\n","                            default=None,\n","                            help='kobart model path')\n","        return parser\n","\n","    def configure_optimizers(self):\n","        # Prepare optimizer\n","        param_optimizer = list(self.model.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {'params': [p for n, p in param_optimizer if not any(\n","                nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","            {'params': [p for n, p in param_optimizer if any(\n","                nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters,\n","                          lr=self.hparams.lr, correct_bias=False)\n","        # warm up lr\n","        num_workers = (self.hparams.gpus if self.hparams.gpus is not None else 1) * (self.hparams.num_nodes if self.hparams.num_nodes is not None else 1)\n","        data_len = len(self.trainer._data_connector._train_dataloader_source.dataloader().dataset)\n","        logging.info(f'number of workers {num_workers}, data length {data_len}')\n","        num_train_steps = int(data_len / (self.hparams.batch_size * num_workers) * self.hparams.max_epochs)\n","        logging.info(f'num_train_steps : {num_train_steps}')\n","        num_warmup_steps = int(num_train_steps * self.hparams.warmup_ratio)\n","        logging.info(f'num_warmup_steps : {num_warmup_steps}')\n","        scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps, \n","            num_training_steps=num_train_steps)\n","        lr_scheduler = {'scheduler': scheduler, \n","                        'monitor': 'loss', 'interval': 'step',\n","                        'frequency': 1}\n","        return [optimizer], [lr_scheduler]\n","\n","class KoBARTConditionalGeneration(Base):\n","    def __init__(self, hparams, **kwargs):\n","        super(KoBARTConditionalGeneration, self).__init__(hparams, **kwargs)\n","        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(self.hparams.tokenizer_path)\n","        self.model = BartForConditionalGeneration.from_pretrained(self.hparams.model_path) if self.hparams.model_path\\\n","                     else BartForConditionalGeneration(BartConfig.from_json_file(\"config.json\"))\n","        self.model.config.eos_token_id=1\n","        self.model.config.bos_token_id=0\n","        # self.model = BartForConditionalGeneration(BartConfig.from_json_file(\"config.json\"))\n","        # self.tokenizer = T5Tokenizer.from_pretrained(self.hparams.tokenizer_path)\n","        # self.model = T5ForConditionalGeneration.from_pretrained(self.hparams.model_path) if self.hparams.model_path\\\n","        #              else T5ForConditionalGeneration(T5Config.from_json_file(\"config.json\"))\n","        # self.model = T5ForConditionalGeneration(T5Config.from_json_file(\"config.json\"))\n","        # self._resize_token_embeddings()\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","        # self.model.share_memory().train()\n","    \n","    @staticmethod\n","    def save_hf_repo(tokenizer, model):\n","        MODEL_SAVE_REPO = 'Gunulhona/tb_pretrained'\n","        HUGGINGFACE_AUTO_TOKEN = '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' \n","        tokenizer.push_to_hub(MODEL_SAVE_REPO, \n","        \t\t\t\t\t  use_temp_dir=True, \n","        \t\t\t\t\t  use_auth_token=HUGGINGFACE_AUTO_TOKEN)\n","        model.cpu().push_to_hub(MODEL_SAVE_REPO, \n","\t\t\t\t                use_temp_dir=True, \n","\t\t\t\t                use_auth_token=HUGGINGFACE_AUTO_TOKEN)\n","\n","    def _resize_token_embeddings(self):\n","        tokens = {\"additional_special_tokens\":[\"<P01>\",\"<P02>\",\"<P03>\",\"<P04>\",\"<P05>\",\"<P06>\",\"<P07>\",\"<P08>\",\"<P09>\"]}\n","        self.tokenizer.add_special_tokens(tokens)\n","        self.model.resize_token_embeddings(len(self.tokenizer))\n","\n","    def forward(self, inputs):\n","        outs = self.model(input_ids=inputs['input_ids'],\n","                         attention_mask=inputs['attention_mask'],\n","                         decoder_input_ids=inputs['decoder_input_ids'],\n","                         decoder_attention_mask=inputs['decoder_attention_mask'],\n","                         labels=inputs['labels'],\n","                         return_dict=True)\n","        return outs\n","\n","    def training_step(self, batch, batch_idx):\n","        # outs = self(batch)\n","        # loss = outs.loss\n","        loss_list = torch.tensor([]).to(self.model.device)\n","        for loader in batch:\n","            outputs = self(batch[loader])\n","            loss_list = torch.cat([loss_list, outputs.loss.view(-1)])\n","        loss = loss_list.sum()\n","        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n","        # self.model.model.decoder.eval()\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        # outs = self(batch)\n","        # loss = outs.loss\n","        loss_list = torch.tensor([]).to(self.model.device)\n","        for loader in batch:\n","            outputs = self(batch[loader])\n","            loss_list = torch.cat([loss_list, outputs.loss.view(-1)])\n","        loss = loss_list.sum()\n","        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n","\n","    # def training_epoch_end(self, training_step_outputs):\n","        # all_preds = torch.stack(training_step_outputs)\n","        # self.save_hf_repo(self.tokenizer, self.model)\n","\n","    def chat(self, text):\n","        input_ids =  [self.tokenizer.eos_token_id] + self.tokenizer.encode(text) + [self.tokenizer.eos_token_id]\n","        res_ids = self.model.generate(torch.tensor([input_ids]),\n","                                      max_length=self.hparams.max_seq_len,\n","                                      # num_beams=1,\n","                                      # max_new_tokens=3,\n","                                      # top_p=0.80,\n","                                      top_k=200,\n","                                      temperature=0.88,\n","                                      do_sample=True,\n","                                      length_penalty = 1.0,\n","                                      repetition_penalty=1.0,\n","                                      no_repeat_ngram_size=2,)\n","        a = self.tokenizer.batch_decode(res_ids.tolist())\n","        for i, x in enumerate(a):\n","            print(f\"생성된 문장 {i+1} : \",x)\n","        return a[0].replace('<s>', '').replace('</s>', '').replace('<usr>','').replace('<sys>','')\n","\n","#main만 고쳐서 실행\n","if __name__ == '__main__':\n","    parser = Base.add_model_specific_args(parser)\n","    parser = ArgsBase.add_model_specific_args(parser)\n","    parser = ChatDataModule.add_model_specific_args(parser)\n","    parser = pl.Trainer(callbacks=[EarlyStopping(monitor=\"val_loss\")]).add_argparse_args(parser)\n","    args = parser.parse_args()\n","    logging.info(args)\n","\n","    model = KoBARTConditionalGeneration(args)\n","\n","    dm = ChatDataModule(args.train_file,\n","                        args.val_file,\n","                        args.test_file,\n","                        args.tokenizer_path,\n","                        max_seq_len=args.max_seq_len,\n","                        num_workers=args.num_workers)\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss',\n","                                                       dirpath=args.default_root_dir,\n","                                                       filename=\"best-checkpoint\",\n","                                                    #    vereose=True,\n","                                                       save_last=True,\n","                                                       mode='min',\n","                                                       save_top_k=-1,)\n","\n","    # logger = pl_loggers.TensorBoardLogger(os.path.join(args.default_root_dir, 'tb_logs'))\n","    logger = pl_loggers.WandbLogger(name=\"test_pretraining\", project=\"pytorchlightning-test\", log_model=\"all\",)\n","    if not args.chat and args.tpu_cores > 1:\n","        wandb.require(\"service\")\n","        wandb.setup()\n","    lr_logger = pl.callbacks.LearningRateMonitor()\n","    trainer = pl.Trainer.from_argparse_args(args, logger=logger,\n","                                            callbacks=[checkpoint_callback, lr_logger],)\n","    trainer.fit(model, dm, )\n","\n","    if args.chat:\n","        model.model.eval()\n","        while 1:\n","            q = input('prompt > ').strip()\n","            if q == 'quit':\n","                break\n","            elif q == 'save':\n","                save_path = \"/content/drive/MyDrive/Colab Notebooks/data/chatbot/EMO_Model/\"\n","                torch.save(model.model.state_dict(),save_path)\n","                print(f'kobart-chat model.pth has saved at {save_path}')\n","            result=model.chat(q)\n","            print(\"Result > {}\".format(result))\n","    else:\n","        model.save_hf_repo(tokenizer=model.tokenizer, model=model.model)"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1662014385670,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"x3GQoWMK4dcW","outputId":"df5033ed-f143-418a-ed0e-9bfdff62bd6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting training\n"]}],"source":["#@title trainer\n","#  --strategy $STRATEGY\\\n","# KETI-AIR/ke-t5-large-ko\n","%%writefile training\n","EXECUTEFILE=\"/content/kobart_mlm.py\" #@param [\"\\\"/content/kobart_mlm.py\\\"\"] {type:\"raw\", allow-input: true}\n","BATCHSIZE=4 #@param {type:\"integer\"}\n","LEARNINGRATE=5e-5 #@param\n","EPOCHS=1 #@param {type:\"integer\"}\n","TRAINFILE=\"/content/Dev_s.csv\" #@param\n","TESTFILE=\"/content/Dev_s.csv\" #@param\n","VALFILE=\"/content/Dev_s.csv\" #@param\n","MODELPATH=\"Gunulhona/tb_pretrained\" #@param\n","TOKENIZERPATH=\"Gunulhona/tb_pretrained\" #@param\n","MAXSEQUENCELEN=128 #@param {type:\"integer\"}\n","STRATEGY=\"tpu_spawn\" #@param {type:\"string\"}\n","python $EXECUTEFILE\\\n","  --gradient_clip_val 1.0\\\n","  --precision 16\\\n","  --max_epochs $EPOCHS\\\n","  --lr $LEARNINGRATE\\\n","  --batch_size $BATCHSIZE\\\n","  --default_root_dir logs\\\n","  --train_file $TRAINFILE\\\n","  --test_file $TESTFILE\\\n","  --val_file $TESTFILE\\\n","  --model_path $MODELPATH\\\n","  --tokenizer_path $TOKENIZERPATH\\\n","  --max_seq_len $MAXSEQUENCELEN\\\n","  --tpu_cores 8\\\n","  --num_workers 2\\\n","  --weights_save_path /content/logs/weight.pth\\\n","  --sync_batchnorm True\\\n","  --profiler simple\\\n","  --num_sanity_val_steps=5"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"nHJLv1WPcrU_"},"outputs":[],"source":["#@title restart runtime\n","import os\n","def restart_runtime():\n","  os.kill(os.getpid(), 9)\n","restart_runtime()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":422,"status":"ok","timestamp":1662012164416,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"1_TtMnr1Hemp"},"outputs":[],"source":["!mkdir logs\n","!touch logs/best-checkpoint.ckpt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhJouogb9Ge1"},"outputs":[],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGlwDdFQj9xn"},"outputs":[],"source":["!pip install -U pytorch-lightning"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47479,"status":"ok","timestamp":1662014788342,"user":{"displayName":"정권환","userId":"03859214150473665717"},"user_tz":-540},"id":"BjC1OKhURE7_","outputId":"4af6504b-d72d-4abd-d464-e3185d7c21d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["  Timestamp: 06:46:06\n","  TPU type: TPU v2\n","  Utilization of TPU Matrix Units (higher is better): 0.000%\n","\n","\n","WARNING:root:TPU has started up successfully with version pytorch-1.9\n","GPU available: False, used: False\n","TPU available: True, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","INFO:root:Namespace(accelerator=None, accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=4, benchmark=None, chat=False, check_val_every_n_epoch=1, checkpoint_path=None, default_root_dir='logs', detect_anomaly=False, deterministic=None, devices=None, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, fast_dev_run=False, gpus=None, gradient_clip_algorithm=None, gradient_clip_val=1.0, ipus=None, limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, logger=True, lr=5e-05, max_epochs=1, max_seq_len=128, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, model_path='Gunulhona/tb_pretrained', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=5, num_workers=2, overfit_batches=0.0, plugins=None, precision=16, profiler='simple', reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, strategy=None, sync_batchnorm=True, test_file='/content/Dev_s.csv', tokenizer_path='Gunulhona/tb_pretrained', tpu_cores=8, track_grad_norm=-1, train_file='/content/Dev_s.csv', val_check_interval=None, val_file='/content/Dev_s.csv', warmup_ratio=0.1, weights_save_path='/content/logs/weight.pth')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkevintb\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220901_064624-2medtg6b\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtest_pretraining\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kevintb/pytorchlightning-test\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/kevintb/pytorchlightning-test/runs/2medtg6b\u001b[0m\n","GPU available: False, used: False\n","TPU available: True, using: 8 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","Exception in device=TPU:7: not enough values to unpack (expected 2, got 1)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n","    fn(gindex, *args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 157, in wrapped\n","    fn(rank, *_args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n","    results = function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n","    results = self._run(model, ckpt_path=self.ckpt_path)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1105, in _run\n","    self._call_setup_hook()  # allow user to setup lightning_module in accelerator environment\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1447, in _call_setup_hook\n","    self._call_lightning_datamodule_hook(\"setup\", stage=fn)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1569, in _call_lightning_datamodule_hook\n","    return fn(*args, **kwargs)\n","  File \"/content/kobart_mlm.py\", line 307, in setup\n","    self.train = self._load_multiple(file_path=self.train_file_path, shuffle=True)\n","  File \"/content/kobart_mlm.py\", line 285, in _load_multiple\n","    \"Deletion Data\":DataLoader(Deletion_Dataset(file_path, self.tokenizer_path, self.max_seq_len),\n","  File \"/content/kobart_mlm.py\", line 94, in __init__\n","    self.masking_start, self.masking_end = self.tokenizer.encode(\"[]\")[:-1]\n","ValueError: not enough values to unpack (expected 2, got 1)\n","Exception in device=TPU:0: not enough values to unpack (expected 2, got 1)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n","    fn(gindex, *args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 157, in wrapped\n","    fn(rank, *_args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n","    results = function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n","    results = self._run(model, ckpt_path=self.ckpt_path)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1105, in _run\n","    self._call_setup_hook()  # allow user to setup lightning_module in accelerator environment\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1447, in _call_setup_hook\n","    self._call_lightning_datamodule_hook(\"setup\", stage=fn)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1569, in _call_lightning_datamodule_hook\n","    return fn(*args, **kwargs)\n","  File \"/content/kobart_mlm.py\", line 307, in setup\n","    self.train = self._load_multiple(file_path=self.train_file_path, shuffle=True)\n","  File \"/content/kobart_mlm.py\", line 285, in _load_multiple\n","    \"Deletion Data\":DataLoader(Deletion_Dataset(file_path, self.tokenizer_path, self.max_seq_len),\n","  File \"/content/kobart_mlm.py\", line 94, in __init__\n","    self.masking_start, self.masking_end = self.tokenizer.encode(\"[]\")[:-1]\n","ValueError: not enough values to unpack (expected 2, got 1)\n","Exception in device=TPU:5: not enough values to unpack (expected 2, got 1)\n","Exception in device=TPU:4: not enough values to unpack (expected 2, got 1)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n","    fn(gindex, *args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 157, in wrapped\n","    fn(rank, *_args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n","    results = function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n","    results = self._run(model, ckpt_path=self.ckpt_path)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1105, in _run\n","    self._call_setup_hook()  # allow user to setup lightning_module in accelerator environment\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1447, in _call_setup_hook\n","    self._call_lightning_datamodule_hook(\"setup\", stage=fn)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1569, in _call_lightning_datamodule_hook\n","    return fn(*args, **kwargs)\n","  File \"/content/kobart_mlm.py\", line 307, in setup\n","    self.train = self._load_multiple(file_path=self.train_file_path, shuffle=True)\n","  File \"/content/kobart_mlm.py\", line 285, in _load_multiple\n","    \"Deletion Data\":DataLoader(Deletion_Dataset(file_path, self.tokenizer_path, self.max_seq_len),\n","  File \"/content/kobart_mlm.py\", line 94, in __init__\n","    self.masking_start, self.masking_end = self.tokenizer.encode(\"[]\")[:-1]\n","ValueError: not enough values to unpack (expected 2, got 1)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n","    fn(gindex, *args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 157, in wrapped\n","    fn(rank, *_args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n","    results = function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n","    results = self._run(model, ckpt_path=self.ckpt_path)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1105, in _run\n","    self._call_setup_hook()  # allow user to setup lightning_module in accelerator environment\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1447, in _call_setup_hook\n","    self._call_lightning_datamodule_hook(\"setup\", stage=fn)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1569, in _call_lightning_datamodule_hook\n","    return fn(*args, **kwargs)\n","  File \"/content/kobart_mlm.py\", line 307, in setup\n","    self.train = self._load_multiple(file_path=self.train_file_path, shuffle=True)\n","  File \"/content/kobart_mlm.py\", line 285, in _load_multiple\n","    \"Deletion Data\":DataLoader(Deletion_Dataset(file_path, self.tokenizer_path, self.max_seq_len),\n","  File \"/content/kobart_mlm.py\", line 94, in __init__\n","    self.masking_start, self.masking_end = self.tokenizer.encode(\"[]\")[:-1]\n","ValueError: not enough values to unpack (expected 2, got 1)\n","Traceback (most recent call last):\n","  File \"/content/kobart_mlm.py\", line 517, in <module>\n","    trainer.fit(model, dm, )\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 697, in fit\n","    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 648, in _call_and_handle_interrupt\n","    return self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 87, in launch\n","    start_method=self._start_method,\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 168, in _save_spawn\n","    return xmp.spawn(wrapped, args=args, nprocs=nprocs, join=join, daemon=daemon, start_method=start_method)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 394, in spawn\n","    start_method=start_method)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 188, in start_processes\n","    while not context.join():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 144, in join\n","    exit_code=exitcode\n","torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with exit code 17\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mtest_pretraining\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kevintb/pytorchlightning-test/runs/2medtg6b\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220901_064624-2medtg6b/logs\u001b[0m\n"]}],"source":["#@title Training with TPU\n","import os\n","from tensorflow.python.profiler import profiler_client\n","import gc\n","gc.collect()\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] =\"0\"\n","os.environ[\"TRIM_GRAPH_SIZE\"] = \"1000000\"\n","os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '1000000000'\n","os.environ[\"PR_SET_PDEATHSIG\"]=\"1\"\n","os.environ[\"PL_RECONCILE_PROCESS\"]=\"1\"\n","os.environ['XLA_USE_32BIT_LONG'] = '0'\n","os.environ['XLA_USE_BF16'] = '1'\n","os.environ['WANDB_CONSOLE'] = 'off'\n","tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n","print(profiler_client.monitor(tpu_profile_service_address, 100, 2))\n","assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n","\n","!sh training"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"29-CShctCMWP"},"outputs":[],"source":["#@title generate test\n","import os\n","from tensorflow.python.profiler import profiler_client\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] =\"0\"\n","os.environ[\"TRIM_GRAPH_SIZE\"] = \"1000000\"\n","os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '1000000000'\n","os.environ[\"PR_SET_PDEATHSIG\"]=\"1\"\n","os.environ[\"PL_RECONCILE_PROCESS\"]=\"1\"\n","os.environ['XLA_USE_32BIT_LONG'] = '0'\n","os.environ['XLA_USE_BF16'] = '1'\n","tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n","print(profiler_client.monitor(tpu_profile_service_address, 100, 2))\n","assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n","\n","!python \"/content/kobart_mlm.py\"\\\n","  --gradient_clip_val 1.0\\\n","  --max_epochs 1\\\n","  --lr 5e-7\\\n","  --batch_size 512\\\n","  --default_root_dir logs\\\n","  --train_file Dev.csv\\\n","  --val_file Dev.csv\\\n","  --test_file Dev.csv\\\n","  --model_path \"gogamza/kobart-base-v1\"\\\n","  --tokenizer_path \"Gunulhona/tbbarttokenizer\"\\\n","  --progress_bar_refresh_rate 50\\\n","  --max_seq_len 768\\\n","  --num_sanity_val_steps 0\\\n","  --chat \\\n","  --resume_from_checkpoint \"/content/logs/last.ckpt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3_Vjipd2YnK"},"outputs":[],"source":[" !rm -rdf logs"]},{"cell_type":"markdown","metadata":{"id":"rhOX8jeBi8AI"},"source":["## 접기"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"kjBjJmYGYxWB"},"outputs":[],"source":["#@title Datasets\n","import argparse\n","import logging\n","import os\n","import warnings\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import (BartForConditionalGeneration,\n","                          PreTrainedTokenizerFast)\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","\n","class Pet_Dataset(Dataset):\n","    def __init__(self, file_root_path=None, max_seq_len=512):\n","        self.filepath = file_root_path\n","        self.data = pd.read_csv(self.filepath).dropna()\n","        self.max_seq_len = max_seq_len\n","        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(\"Gunulhona/tbbarttokenizer\")\n","        self.masking_start=self.tokenizer.encode(\"[]\")[0]\n","        self.masking_end=self.tokenizer.encode(\"[]\")[-1]\n","\n","    def __len__(self):\n","        return self.data.__len__()\n","\n","    def _encode(self, text):\n","        tokens = [self.tokenizer.bos_token]+self.tokenizer.tokenize(text)+[self.tokenizer.eos_token]\n","        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n","        attention_mask = [1]*len(input_ids)\n","        if len(input_ids) < self.max_seq_len:\n","            while len(input_ids)<self.max_seq_len:\n","                input_ids+=[self.tokenizer.pad_token_id]\n","                attention_mask+=[0]\n","        else:\n","            input_ids = input_ids[:self.max_seq_len-1]+[self.tokenizer.eos_token_id]\n","            attention_mask = attention_mask[:self.max_seq_len]\n","        return input_ids, attention_mask\n","\n","    def _labeling(self,label):\n","        tokens = [self.tokenizer.bos_token]+self.tokenizer.tokenize(label)+[self.tokenizer.eos_token]\n","        label_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n","        if len(label_ids) < self.max_seq_len:\n","            while len(label_ids)<self.max_seq_len:\n","                label_ids+=[-100]\n","        else:\n","            label_ids = label_ids[:self.max_seq_len-1] + [self.tokenizer.eos_token_id]\n","        return label_ids\n","\n","    def _masking(self, tokens):\n","        masked = tokens\n","        mask_idx=[]\n","        while self.masking_start in masked and self.masking_end in masked:\n","            mask_idx +=[[masked.index(self.masking_start),masked.index(self.masking_end)+1]]\n","            masked[masked.index(self.masking_start):masked.index(self.masking_end)+1] = \\\n","              [self.tokenizer.mask_token_id]*len(masked[masked.index(self.masking_start):masked.index(self.masking_end)+1])\n","        return masked, mask_idx\n","\n","    def _label_masking(self, tokens, idx):\n","        masked = np.array(tokens)\n","        index,position =[],[]\n","        for i in idx:\n","            index+=range(i[0],i[1])\n","        for n,x in enumerate(tokens):\n","            position += [n not in index]\n","        masked[position] = self.tokenizer.mask_token_id\n","        return masked.tolist()\n","\n","    def __getitem__(self,index):\n","        record = self.data.iloc[index]\n","        pattern, label = record[\"pattern\"], record[\"label\"]\n","        label = pattern+label\n","        encoder_input_ids, encoder_attention_mask = self._encode(pattern)\n","        decoder_input_ids, decoder_attention_mask = self._encode(label)\n","        encoder_input_ids,mask_idx = self._masking(encoder_input_ids)\n","        label = self._labeling(label)\n","        pin = encoder_input_ids.index(self.tokenizer.eos_token_id)-2\n","        label_position = decoder_input_ids[pin:]\n","        decoder_input_ids = self._label_masking(decoder_input_ids,mask_idx)\n","        decoder_input_ids = decoder_input_ids[:pin+1] +label_position\n","\n","        return {\"input_ids\":np.array(encoder_input_ids, dtype=np.int_),\n","                \"attention_mask\":np.array(encoder_attention_mask,dtype=np.float32),\n","                \"decoder_input_ids\":np.array(decoder_input_ids, dtype=np.int_),\n","                \"decoder_attention_mask\":np.array(decoder_attention_mask,dtype=np.float32),\n","                \"labels\":np.array(label,dtype=np.int_)}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OY7LetqxmovH"},"outputs":[],"source":["pet_df =  Pet_Dataset( \"/content/drive/MyDrive/Colab Notebooks/data/chatbot/PET data/pretrain/Dev.csv\",128)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uw3SGhOXxRag"},"outputs":[],"source":["2 in [range(2,4),range(2,5)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pq704T4gmq4w"},"outputs":[],"source":["for x in pet_df:\n","    print(x)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJ8qqNFLdxyq"},"outputs":[],"source":["%%shell\n","git clone https://github.com/thunlp/OpenPrompt.git\n","cd OpenPrompt\n","pip install -r requirements.txt\n","python setup.py install"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"25GZlchneWuR"},"outputs":[],"source":["from transformers import BartForSequenceClassification, AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained('Gunulhona/tbbarttokenizer')\n","model = BartForSequenceClassification.from_pretrained('gogamza/kobart-base-v1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTj1dGkKYFXN"},"outputs":[],"source":["# P-tuning \n","!git clone https://github.com/ppijbb/P-tuning-v2.git\n","!pip install -r /content/P-tuning-v2/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0boJWIjYWgH"},"outputs":[],"source":["import os\n","from tensorflow.python.profiler import profiler_client\n","import gc\n","gc.collect()\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] =\"0\"\n","os.environ[\"TRIM_GRAPH_SIZE\"] = \"1000000\"\n","os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '1000000000'\n","os.environ[\"PR_SET_PDEATHSIG\"]=\"1\"\n","os.environ[\"PL_RECONCILE_PROCESS\"]=\"1\"\n","os.environ['XLA_USE_32BIT_LONG'] = '0'\n","os.environ['XLA_USE_BF16'] = '1'\n","tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n","print(profiler_client.monitor(tpu_profile_service_address, 100, 2))\n","assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n","\n","%cd /content/P-tuning-v2\n","!bash run_script/run_rte_roberta.sh\n","%cd /content/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQCU2f-duVv0"},"outputs":[],"source":["# PET\n","!git clone -b feature/genpet https://github.com/ppijbb/pet.git\n","!pip install -r /content/pet/requirements.txt\n","!pip uninstall -y datasets\n","!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqsn1zWmxeIK"},"outputs":[],"source":["from datasets import list_datasets, load_dataset\n","\n","esnli_dataset = load_dataset(\"multi_nli\",\"plain_text\",split=\"train\")\n","labels = esnli_dataset.features['label'].names\n","esnli_dataset = esnli_dataset.map(lambda x :{\n","    \"hypothesis\":x['hypothesis'],\n","    \"label\":labels[x['label']],\n","    \"premise\":x[\"premise\"]\n","})\n","esnli_dataset.to_csv(\"/content/train.tsv\",sep=\"\\t\")\n","esnli_dataset = load_dataset(\"multi_nli\",\"plain_text\",split=\"validation_matched\")\n","esnli_dataset = esnli_dataset.map(lambda x :{\n","    \"hypothesis\":x['hypothesis'],\n","    \"label\":labels[x['label']],\n","    \"premise\":x[\"premise\"]\n","})\n","esnli_dataset.to_csv(\"/content/dev_matched.tsv\",sep=\"\\t\")\n","esnli_dataset = load_dataset(\"multi_nli\",\"plain_text\",split=\"validation_mismatched\")\n","esnli_dataset = esnli_dataset.map(lambda x :{\n","    \"hypothesis\":x['hypothesis'],\n","    \"label\":labels[x['label']],\n","    \"premise\":x[\"premise\"]\n","})\n","esnli_dataset.to_csv(\"/content/dev_mismatched.tsv\",sep=\"\\t\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VcIW1KeCJ6Sr"},"outputs":[],"source":["from datasets import list_datasets, load_dataset\n","\n","esnli_dataset = load_dataset(\"aeslc\",\"plain_text\",split=\"train\")\n","# labels = esnli_dataset.features['label'].names\n","# esnli_dataset = esnli_dataset.map(lambda x :{\n","#     \"hypothesis\":x['hypothesis'],\n","#     \"label\":labels[x['label']],\n","#     \"premise\":x[\"premise\"]\n","# })\n","esnli_dataset.to_csv(\"/content/train.tsv\",sep=\"\\t\")\n","esnli_dataset = load_dataset(\"aeslc\",\"plain_text\",split=\"test\")\n","# esnli_dataset = esnli_dataset.map(lambda x :{\n","#     \"hypothesis\":x['hypothesis'],\n","#     \"label\":labels[x['label']],\n","#     \"premise\":x[\"premise\"]\n","# })\n","esnli_dataset.to_csv(\"/content/test.tsv\",sep=\"\\t\")\n","esnli_dataset = load_dataset(\"aeslc\",\"plain_text\",split=\"validation\")\n","# esnli_dataset = esnli_dataset.map(lambda x :{\n","#     \"hypothesis\":x['hypothesis'],\n","#     \"label\":labels[x['label']],\n","#     \"premise\":x[\"premise\"]\n","# })\n","esnli_dataset.to_csv(\"/content/validation.tsv\",sep=\"\\t\")"]},{"cell_type":"markdown","metadata":{"id":"c_bfeThJ0O5E"},"source":["GENPET => pet/ipet train => classifier => pet ensemble => train single\n","\n","modeling 391 -> \n","\n","```python\n","\tif not all_train_data and not config.use_logits:\n","\t\tlogger.warning('Training method was called without training examples')\n","```"]},{"cell_type":"markdown","metadata":{"id":"Lk5hSj6A7rvd"},"source":["few shot generation 예시\n","```shell\n","python3 cli.py \\\n","\t--method pet \\\n","\t--wrapper_type generative \\\n","\t--pattern_ids 2 3 4 5 \\\n","\t--data_dir . \\\n","\t--model_type pegasus \\\n","\t--model_name_or_path google/pegasus-large \\\n","\t--task_name ${TASK} \\\n","\t--output_dir ${OUTPUT_DIR} \\\n","\t--train_examples ${NUM_EXAMPLES} \\\n","\t--test_examples 10000 \\\n","\t--unlabeled_examples 1000 \\\n","\t--do_eval \\\n","\t--learning_rate 1e-4 \\\n","\t--eval_set test \\\n","\t--pet_per_gpu_eval_batch_size 32 \\\n","\t--pet_per_gpu_train_batch_size 2 \\\n","\t--pet_gradient_accumulation_steps 4 \\\n","\t--output_max_seq_length ${OUTPUT_MAX_SEQ_LENGTH} \\\n","\t--pet_max_steps 250 \\\n","\t--pet_max_seq_length 512 \\\n","\t--sc_per_gpu_train_batch_size 2 \\\n","\t--sc_gradient_accumulation_steps 4 \\\n","\t--sc_per_gpu_eval_batch_size 32 \\\n","\t--sc_max_steps 250 \\\n","\t--sc_max_seq_length 512 \\\n","\t--optimizer adafactor \\\n","\t--epsilon 0.1 \\\n","\t--do_train \\\n","\t--pet_repetitions 1 \\\n","\t--train_data_seed ${TRAIN_DATA_SEED} \\\n","\t--multi_pattern_training \\\n","\t--untrained_model_scoring \\\n","\t--cutoff_percentage 0.2\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sP4x5hKdu9OG"},"outputs":[],"source":["# pegasus\n","# google/peagsus-large\n","%%shell\n","rm -rdf outs\n","\n","PATTERN_IDS=\"0 1 2 3\"\n","DATA_DIR=\"/content/\"\n","MODEL_TYPE=\"pegasus\"\n","MODEL_NAME_OR_PATH=\"google/pegasus-aeslc\"\n","OUTPUT_DIR=\"/content/outs/\"\n","TASK=\"aeslc\"\n","WRAPPER_TYPE=\"generative\"\n","\n","cd /content/pet\n","\n","python3 cli.py \\\n","--wrapper_type $WRAPPER_TYPE \\\n","--method pet \\\n","--pattern_ids $PATTERN_IDS \\\n","--data_dir $DATA_DIR \\\n","--model_type $MODEL_TYPE \\\n","--model_name_or_path $MODEL_NAME_OR_PATH \\\n","--task_name $TASK \\\n","--output_dir $OUTPUT_DIR \\\n","--optimizer adam \\\n","--do_train \\\n","--do_eval \\\n","--train_example 2 \\\n","--pet_per_gpu_train_batch_size 4 \\\n","\n","cd /content/"]},{"cell_type":"markdown","metadata":{"id":"VGonasSrwhZr"},"source":["wrapper.py 533 에서 \n","```python\n","            print(\"in train input_ids: \",self.tokenizer.decode(batch['input_ids'][0]))\n","            print(\"in train labels: \",batch['labels'][0])\n","            print(\"in train token_type_ids: \", batch['token_type_ids'][0])\n","            print(\"in train mlm_labels: \",batch['mlm_labels'][0])\n","            print(\"in train logits: \", batch['logits'][0])\n","            print(\"In train idx: \", batch['idx'][0])\n","```"]},{"cell_type":"markdown","metadata":{"id":"cpWMzdN42Clh"},"source":["## 접기"]},{"cell_type":"markdown","metadata":{"id":"kySsdzp_16na"},"source":["```python\n","\n","logger = logging.get_logger(__name__)\n","\n","_CHECKPOINT_FOR_DOC = \"facebook/bart-large\"\n","_CONFIG_FOR_DOC = \"BartConfig\"\n","_TOKENIZER_FOR_DOC = \"BartTokenizer\"\n","\n","\n","BART_PRETRAINED_MODEL_ARCHIVE_LIST = [\n","    \"facebook/bart-large\",\n","    # See all BART models at https://huggingface.co/models?filter=bart\n","]\n","\n","\n","def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n","    \"\"\"\n","    Shift input ids one token to the right.\n","    \"\"\"\n","    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n","    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n","    shifted_input_ids[:, 0] = decoder_start_token_id\n","\n","    if pad_token_id is None:\n","        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n","    # replace possible -100 values in labels by `pad_token_id`\n","    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n","\n","    return shifted_input_ids\n","\n","\n","def _make_causal_mask(input_ids_shape: torch.Size, dtype: torch.dtype, past_key_values_length: int = 0):\n","    \"\"\"\n","    Make causal mask used for bi-directional self-attention.\n","    \"\"\"\n","    bsz, tgt_len = input_ids_shape\n","    mask = torch.full((tgt_len, tgt_len), float(\"-inf\"))\n","    mask_cond = torch.arange(mask.size(-1))\n","    mask.masked_fill_(mask_cond < (mask_cond + 1).view(mask.size(-1), 1), 0)\n","    mask = mask.to(dtype)\n","\n","    if past_key_values_length > 0:\n","        mask = torch.cat([torch.zeros(tgt_len, past_key_values_length, dtype=dtype), mask], dim=-1)\n","    return mask[None, None, :, :].expand(bsz, 1, tgt_len, tgt_len + past_key_values_length)\n","\n","\n","def _expand_mask(mask: torch.Tensor, dtype: torch.dtype, tgt_len: Optional[int] = None):\n","    \"\"\"\n","    Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.\n","    \"\"\"\n","    bsz, src_len = mask.size()\n","    tgt_len = tgt_len if tgt_len is not None else src_len\n","\n","    expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)\n","\n","    inverted_mask = 1.0 - expanded_mask\n","\n","    return inverted_mask.masked_fill(inverted_mask.bool(), torch.finfo(dtype).min)\n","\n","\n","class BartLearnedPositionalEmbedding(nn.Embedding):\n","    \"\"\"\n","    This module learns positional embeddings up to a fixed maximum size.\n","    \"\"\"\n","\n","    def __init__(self, num_embeddings: int, embedding_dim: int):\n","        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n","        # and adjust num_embeddings appropriately. Other models don't have this hack\n","        self.offset = 2\n","        super().__init__(num_embeddings + self.offset, embedding_dim)\n","\n","    def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0):\n","        \"\"\"`input_ids_shape` is expected to be [bsz x seqlen].\"\"\"\n","        bsz, seq_len = input_ids_shape[:2]\n","        positions = torch.arange(\n","            past_key_values_length, past_key_values_length + seq_len, dtype=torch.long, device=self.weight.device\n","        )\n","        return super().forward(positions + self.offset)\n","\n","\n","class BartAttention(nn.Module):\n","    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n","\n","    def __init__(\n","        self,\n","        embed_dim: int,\n","        num_heads: int,\n","        dropout: float = 0.0,\n","        is_decoder: bool = False,\n","        bias: bool = True,\n","    ):\n","        super().__init__()\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.dropout = dropout\n","        self.head_dim = embed_dim // num_heads\n","\n","        if (self.head_dim * num_heads) != self.embed_dim:\n","            raise ValueError(\n","                f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim}\"\n","                f\" and `num_heads`: {num_heads}).\"\n","            )\n","        self.scaling = self.head_dim ** -0.5\n","        self.is_decoder = is_decoder\n","\n","        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","\n","    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):\n","        return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()\n","\n","    def forward(\n","        self,\n","        hidden_states: torch.Tensor,\n","        key_value_states: Optional[torch.Tensor] = None,\n","        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        layer_head_mask: Optional[torch.Tensor] = None,\n","        output_attentions: bool = False,\n","    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n","        \"\"\"Input shape: Batch x Time x Channel\"\"\"\n","\n","        # if key_value_states are provided this layer is used as a cross-attention layer\n","        # for the decoder\n","        is_cross_attention = key_value_states is not None\n","\n","        bsz, tgt_len, _ = hidden_states.size()\n","\n","        # get query proj\n","        query_states = self.q_proj(hidden_states) * self.scaling\n","        # get key, value proj\n","        if is_cross_attention and past_key_value is not None:\n","            # reuse k,v, cross_attentions\n","            key_states = past_key_value[0]\n","            value_states = past_key_value[1]\n","        elif is_cross_attention:\n","            # cross_attentions\n","            key_states = self._shape(self.k_proj(key_value_states), -1, bsz)\n","            value_states = self._shape(self.v_proj(key_value_states), -1, bsz)\n","        elif past_key_value is not None:\n","            # reuse k, v, self_attention\n","            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n","            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n","            key_states = torch.cat([past_key_value[0], key_states], dim=2)\n","            value_states = torch.cat([past_key_value[1], value_states], dim=2)\n","        else:\n","            # self_attention\n","            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n","            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n","\n","        if self.is_decoder:\n","            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n","            # Further calls to cross_attention layer can then reuse all cross-attention\n","            # key/value_states (first \"if\" case)\n","            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n","            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n","            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n","            # if encoder bi-directional self-attention `past_key_value` is always `None`\n","            past_key_value = (key_states, value_states)\n","\n","        proj_shape = (bsz * self.num_heads, -1, self.head_dim)\n","        query_states = self._shape(query_states, tgt_len, bsz).view(*proj_shape)\n","        key_states = key_states.view(*proj_shape)\n","        value_states = value_states.view(*proj_shape)\n","\n","        src_len = key_states.size(1)\n","        attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n","\n","        if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n","            raise ValueError(\n","                f\"Attention weights should be of size {(bsz * self.num_heads, tgt_len, src_len)}, but is {attn_weights.size()}\"\n","            )\n","\n","        if attention_mask is not None:\n","            if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n","                raise ValueError(\n","                    f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {attention_mask.size()}\"\n","                )\n","            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask\n","            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n","\n","        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n","\n","        if layer_head_mask is not None:\n","            if layer_head_mask.size() != (self.num_heads,):\n","                raise ValueError(\n","                    f\"Head mask for a single layer should be of size {(self.num_heads,)}, but is {layer_head_mask.size()}\"\n","                )\n","            attn_weights = layer_head_mask.view(1, -1, 1, 1) * attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n","            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n","\n","        if output_attentions:\n","            # this operation is a bit awkward, but it's required to\n","            # make sure that attn_weights keeps its gradient.\n","            # In order to do so, attn_weights have to be reshaped\n","            # twice and have to be reused in the following\n","            attn_weights_reshaped = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n","            attn_weights = attn_weights_reshaped.view(bsz * self.num_heads, tgt_len, src_len)\n","        else:\n","            attn_weights_reshaped = None\n","\n","        attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n","\n","        attn_output = torch.bmm(attn_probs, value_states)\n","\n","        if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n","            raise ValueError(\n","                f\"`attn_output` should be of size {(bsz, self.num_heads, tgt_len, self.head_dim)}, but is {attn_output.size()}\"\n","            )\n","\n","        attn_output = attn_output.view(bsz, self.num_heads, tgt_len, self.head_dim)\n","        attn_output = attn_output.transpose(1, 2)\n","\n","        # Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\n","        # partitioned aross GPUs when using tensor-parallelism.\n","        attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)\n","\n","        attn_output = self.out_proj(attn_output)\n","\n","        return attn_output, attn_weights_reshaped, past_key_value\n","\n","# GPT Neo attention\n","class GPTNeoSelfAttention(nn.Module):\n","    def __init__(self, config, attention_type):\n","        super().__init__()\n","\n","        max_positions = config.max_position_embeddings\n","        bias = torch.tril(torch.ones((max_positions, max_positions), dtype=torch.uint8)).view(\n","            1, 1, max_positions, max_positions\n","        )\n","\n","        # local causal self attention is a sliding window where each token can only attend to the previous\n","        # window_size tokens. This is implemented by updating the causal mask such that for each token\n","        # all other tokens are masked except the previous window_size tokens.\n","        if attention_type == \"local\":\n","            bias = torch.bitwise_xor(bias, torch.tril(bias, -config.window_size))\n","\n","        self.register_buffer(\"bias\", bias)\n","        self.register_buffer(\"masked_bias\", torch.tensor(-1e9))\n","\n","        self.attn_dropout = nn.Dropout(config.attention_dropout)\n","        self.resid_dropout = nn.Dropout(config.resid_dropout)\n","\n","        self.embed_dim = config.hidden_size\n","        self.num_heads = config.num_heads\n","        self.head_dim = self.embed_dim // self.num_heads\n","        if self.head_dim * self.num_heads != self.embed_dim:\n","            raise ValueError(\n","                f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim} and `num_heads`: {self.num_heads}).\"\n","            )\n","\n","        self.k_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n","        self.v_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n","        self.q_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n","        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n","\n","    def _split_heads(self, tensor, num_heads, attn_head_size):\n","        \"\"\"\n","        Splits hidden_size dim into attn_head_size and num_heads\n","        \"\"\"\n","        new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n","        tensor = tensor.view(new_shape)\n","        return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n","\n","    def _merge_heads(self, tensor, num_heads, attn_head_size):\n","        \"\"\"\n","        Merges attn_head_size dim and num_attn_heads dim into hidden_size\n","        \"\"\"\n","        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n","        new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n","        return tensor.view(new_shape)\n","\n","    def _attn(self, query, key, value, attention_mask=None, head_mask=None):\n","        # Keep the attention weights computation in fp32 to avoid overflow issues\n","        query = query.to(torch.float32)\n","        key = key.to(torch.float32)\n","\n","        attn_weights = torch.matmul(query, key.transpose(-1, -2))\n","\n","        query_length, key_length = query.size(-2), key.size(-2)\n","        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].bool()\n","        attn_weights = torch.where(causal_mask, attn_weights, self.masked_bias.to(attn_weights.dtype))\n","\n","        if attention_mask is not None:\n","            # Apply the attention mask\n","            attn_weights = attn_weights + attention_mask\n","\n","        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n","        attn_weights = attn_weights.to(value.dtype)\n","        attn_weights = self.attn_dropout(attn_weights)\n","\n","        # Mask heads if we want to\n","        if head_mask is not None:\n","            attn_weights = attn_weights * head_mask\n","\n","        attn_output = torch.matmul(attn_weights, value)\n","\n","        return attn_output, attn_weights\n","\n","    def forward(\n","        self,\n","        hidden_states,\n","        attention_mask=None,\n","        layer_past=None,\n","        head_mask=None,\n","        use_cache=False,\n","        output_attentions=False,\n","    ):\n","\n","        query = self.q_proj(hidden_states)\n","        key = self.k_proj(hidden_states)\n","        value = self.v_proj(hidden_states)\n","\n","        query = self._split_heads(query, self.num_heads, self.head_dim)\n","        key = self._split_heads(key, self.num_heads, self.head_dim)\n","        value = self._split_heads(value, self.num_heads, self.head_dim)\n","\n","        if layer_past is not None:\n","            past_key = layer_past[0]\n","            past_value = layer_past[1]\n","            key = torch.cat((past_key, key), dim=-2)\n","            value = torch.cat((past_value, value), dim=-2)\n","\n","        if use_cache is True:\n","            present = (key, value)\n","        else:\n","            present = None\n","\n","        attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\n","\n","        attn_output = self._merge_heads(attn_output, self.num_heads, self.head_dim)\n","        attn_output = self.out_proj(attn_output)\n","        attn_output = self.resid_dropout(attn_output)\n","\n","        outputs = (attn_output, present)\n","        if output_attentions:\n","            outputs += (attn_weights,)\n","\n","        return outputs  # a, present, (attentions)\n","\n","\n","class GPTNeoAttention(nn.Module):\n","    def __init__(self, config, layer_id=0):\n","        super().__init__()\n","        self.layer_id = layer_id\n","        self.attention_layers = config.attention_layers\n","        self.attention_type = self.attention_layers[layer_id]\n","\n","        if self.attention_type in [\"global\", \"local\"]:\n","            self.attention = GPTNeoSelfAttention(config, self.attention_type)\n","        else:\n","            raise NotImplementedError(\n","                \"Only attn layer types 'global' and 'local' exist, but got `config.attention_layers`: \"\n","                f\"{config.attention_layers}. Select attn layer types from ['global', 'local'] only.\"\n","            )\n","\n","    def forward(\n","        self,\n","        hidden_states,\n","        layer_past=None,\n","        attention_mask=None,\n","        head_mask=None,\n","        use_cache=False,\n","        output_attentions=False,\n","    ):\n","        return self.attention(\n","            hidden_states,\n","            attention_mask=attention_mask,\n","            layer_past=layer_past,\n","            head_mask=head_mask,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","        )\n","\n","\n","class BartEncoderLayer(nn.Module):\n","    def __init__(self, config: BartConfig):\n","        super().__init__()\n","        self.embed_dim = config.d_model\n","        self.self_attn = BartAttention(\n","            embed_dim=self.embed_dim,\n","            num_heads=config.encoder_attention_heads,\n","            dropout=config.attention_dropout,\n","        )\n","        self.self_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n","        self.dropout = config.dropout\n","        self.activation_fn = ACT2FN[config.activation_function]\n","        self.activation_dropout = config.activation_dropout\n","        self.fc1 = nn.Linear(self.embed_dim, config.encoder_ffn_dim)\n","        self.fc2 = nn.Linear(config.encoder_ffn_dim, self.embed_dim)\n","        self.final_layer_norm = nn.LayerNorm(self.embed_dim)\n","\n","    def forward(\n","        self,\n","        hidden_states: torch.Tensor,\n","        attention_mask: torch.Tensor,\n","        layer_head_mask: torch.Tensor,\n","        output_attentions: bool = False,\n","    ):\n","        \"\"\"\n","        Args:\n","            hidden_states (`torch.FloatTensor`): input to the layer of shape *(seq_len, batch, embed_dim)*\n","            attention_mask (`torch.FloatTensor`): attention mask of size\n","                *(batch, 1, tgt_len, src_len)* where padding elements are indicated by very large negative values.\n","            layer_head_mask (`torch.FloatTensor`): mask for attention heads in a given layer of size\n","                *(encoder_attention_heads,)*.\n","            output_attentions (`bool`, *optional*):\n","                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n","                returned tensors for more detail.\n","        \"\"\"\n","        residual = hidden_states\n","        hidden_states, attn_weights, _ = self.self_attn(\n","            hidden_states=hidden_states,\n","            attention_mask=attention_mask,\n","            layer_head_mask=layer_head_mask,\n","            output_attentions=output_attentions,\n","        )\n","        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n","        hidden_states = residual + hidden_states\n","        hidden_states = self.self_attn_layer_norm(hidden_states)\n","\n","        residual = hidden_states\n","        hidden_states = self.activation_fn(self.fc1(hidden_states))\n","        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n","        hidden_states = self.fc2(hidden_states)\n","        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n","        hidden_states = residual + hidden_states\n","        hidden_states = self.final_layer_norm(hidden_states)\n","\n","        if hidden_states.dtype == torch.float16 and (\n","            torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()\n","        ):\n","            clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n","            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n","\n","        outputs = (hidden_states,)\n","\n","        if output_attentions:\n","            outputs += (attn_weights,)\n","\n","        return outputs\n","\n","\n","class BartDecoderLayer(nn.Module):\n","    def __init__(self, config: BartConfig):\n","        super().__init__()\n","        self.embed_dim = config.d_model\n","\n","        self.self_attn = BartAttention(\n","            embed_dim=self.embed_dim,\n","            num_heads=config.decoder_attention_heads,\n","            dropout=config.attention_dropout,\n","            is_decoder=True,\n","        )\n","        self.dropout = config.dropout\n","        self.activation_fn = ACT2FN[config.activation_function]\n","        self.activation_dropout = config.activation_dropout\n","\n","        self.self_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n","        self.encoder_attn = BartAttention(\n","            self.embed_dim,\n","            config.decoder_attention_heads,\n","            dropout=config.attention_dropout,\n","            is_decoder=True,\n","        )\n","        self.encoder_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n","        self.fc1 = nn.Linear(self.embed_dim, config.decoder_ffn_dim)\n","        self.fc2 = nn.Linear(config.decoder_ffn_dim, self.embed_dim)\n","        self.final_layer_norm = nn.LayerNorm(self.embed_dim)\n","        self.lmhead = BartClassificationHead(self.embed_dim,config)\n","\n","    def forward(\n","        self,\n","        hidden_states: torch.Tensor,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        encoder_hidden_states: Optional[torch.Tensor] = None,\n","        encoder_attention_mask: Optional[torch.Tensor] = None,\n","        layer_head_mask: Optional[torch.Tensor] = None,\n","        cross_attn_layer_head_mask: Optional[torch.Tensor] = None,\n","        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n","        output_attentions: Optional[bool] = False,\n","        use_cache: Optional[bool] = True,\n","    ):\n","        \"\"\"\n","        Args:\n","            hidden_states (`torch.FloatTensor`): input to the layer of shape *(batch, seq_len, embed_dim)*\n","            attention_mask (`torch.FloatTensor`): attention mask of size\n","                *(batch, 1, tgt_len, src_len)* where padding elements are indicated by very large negative values.\n","            encoder_hidden_states (`torch.FloatTensor`):\n","                cross attention input to the layer of shape *(batch, seq_len, embed_dim)*\n","            encoder_attention_mask (`torch.FloatTensor`): encoder attention mask of size\n","                *(batch, 1, tgt_len, src_len)* where padding elements are indicated by very large negative values.\n","            layer_head_mask (`torch.FloatTensor`): mask for attention heads in a given layer of size\n","                *(encoder_attention_heads,)*.\n","            cross_attn_layer_head_mask (`torch.FloatTensor`): mask for cross-attention heads in a given layer of\n","                size *(decoder_attention_heads,)*.\n","            past_key_value (`Tuple(torch.FloatTensor)`): cached past key and value projection states\n","            output_attentions (`bool`, *optional*):\n","                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n","                returned tensors for more detail.\n","        \"\"\"\n","        residual = hidden_states\n","\n","        # Self Attention\n","        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n","        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n","        # add present self-attn cache to positions 1,2 of present_key_value tuple\n","        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n","            hidden_states=hidden_states,\n","            past_key_value=self_attn_past_key_value,\n","            attention_mask=attention_mask,\n","            layer_head_mask=layer_head_mask,\n","            output_attentions=output_attentions,\n","        )\n","        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n","        hidden_states = residual + hidden_states\n","        hidden_states = self.self_attn_layer_norm(hidden_states)\n","\n","        # Cross-Attention Block\n","        cross_attn_present_key_value = None\n","        cross_attn_weights = None\n","        if encoder_hidden_states is not None:\n","            residual = hidden_states\n","\n","            # cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\n","            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n","            hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n","                hidden_states=hidden_states,\n","                key_value_states=encoder_hidden_states,\n","                attention_mask=encoder_attention_mask,\n","                layer_head_mask=cross_attn_layer_head_mask,\n","                past_key_value=cross_attn_past_key_value,\n","                output_attentions=output_attentions,\n","            )\n","            hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n","            hidden_states = residual + hidden_states\n","            hidden_states = self.encoder_attn_layer_norm(hidden_states)\n","\n","            # add cross-attn to positions 3,4 of present_key_value tuple\n","            present_key_value = present_key_value + cross_attn_present_key_value\n","\n","        # Fully Connected\n","        residual = hidden_states\n","        hidden_states = self.lmhead(self.fc1(hidden_states))#self.activation_fn(self.fc1(hidden_states))\n","        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n","        hidden_states = self.fc2(hidden_states)\n","        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n","        hidden_states = residual + hidden_states\n","        hidden_states = self.final_layer_norm(hidden_states)\n","\n","        outputs = (hidden_states,)\n","\n","        if output_attentions:\n","            outputs += (self_attn_weights, cross_attn_weights)\n","\n","        if use_cache:\n","            outputs += (present_key_value,)\n","\n","        return outputs\n","\n","\n","class BartClassificationHead(nn.Module):\n","    \"\"\"Head for sentence-level classification tasks.\"\"\"\n","\n","    def __init__(\n","        self,\n","        input_dim: int,\n","        inner_dim: int,\n","        num_classes: int,\n","        pooler_dropout: float,\n","        config\n","    ):\n","        super().__init__()\n","        self.dense = nn.Linear(input_dim, inner_dim)\n","        self.act = ACT2FN[config.activaiton_function]\n","        self.dropout = nn.Dropout(p=pooler_dropout)\n","        self.out_proj = nn.Linear(inner_dim, num_classes)\n","\n","    def forward(self, hidden_states: torch.Tensor):\n","        hidden_states = self.dropout(hidden_states)\n","        hidden_states = self.dense(hidden_states)\n","        hidden_states = self.act(hidden_states) # torch.tanh(hidden_states)\n","        hidden_states = self.out_proj(hidden_states)\n","        hidden_states = self.dropout(hidden_states)\n","        \n","        return hidden_states\n","\n","\n","class BartPretrainedModel(PreTrainedModel):\n","    config_class = BartConfig\n","    base_model_prefix = \"model\"\n","    supports_gradient_checkpointing = True\n","    _keys_to_ignore_on_load_unexpected = [r\"encoder\\.version\", r\"decoder\\.version\"]\n","\n","    def _init_weights(self, module):\n","        std = self.config.init_std\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=std)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=std)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","\n","    def _set_gradient_checkpointing(self, module, value=False):\n","        if isinstance(module, (BartDecoder, BartEncoder)):\n","            module.gradient_checkpointing = value\n","\n","    @property\n","    def dummy_inputs(self):\n","        pad_token = self.config.pad_token_id\n","        input_ids = torch.tensor([[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device)\n","        dummy_inputs = {\n","            \"attention_mask\": input_ids.ne(pad_token),\n","            \"input_ids\": input_ids,\n","        }\n","        return dummy_inputs\n","\n","\n","class PretrainedBartModel(BartPretrainedModel):\n","    def __init_subclass__(self):\n","        warnings.warn(\n","            \"The class `PretrainedBartModel` has been depreciated, please use `BartPretrainedModel` instead.\",\n","            FutureWarning,\n","        )\n","\n","\n","BART_START_DOCSTRING = r\"\"\"\n","    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n","    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n","    etc.)\n","    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n","    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n","    and behavior.\n","    Parameters:\n","        config ([`BartConfig`]):\n","            Model configuration class with all the parameters of the model. Initializing with a config file does not\n","            load the weights associated with the model, only the configuration. Check out the\n","            [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n","\"\"\"\n","\n","BART_GENERATION_EXAMPLE = r\"\"\"\n","    Summarization example:\n","    ```python\n","    >>> from transformers import BartTokenizer, BartForConditionalGeneration\n","    >>> model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n","    >>> tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n","    >>> ARTICLE_TO_SUMMARIZE = \"My friends are cool but they eat too many carbs.\"\n","    >>> inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors=\"pt\")\n","    >>> # Generate Summary\n","    >>> summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=5)\n","    >>> print(tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False))\n","    ```\n","    Mask filling example:\n","    ```python\n","    >>> from transformers import BartTokenizer, BartForConditionalGeneration\n","    >>> tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n","    >>> TXT = \"My friends are <mask> but they eat too many carbs.\"\n","    >>> model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n","    >>> input_ids = tokenizer([TXT], return_tensors=\"pt\")[\"input_ids\"]\n","    >>> logits = model(input_ids).logits\n","    >>> masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n","    >>> probs = logits[0, masked_index].softmax(dim=0)\n","    >>> values, predictions = probs.topk(5)\n","    >>> tokenizer.decode(predictions).split()\n","    ```\n","\"\"\"\n","\n","BART_INPUTS_DOCSTRING = r\"\"\"\n","    Args:\n","        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n","            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide\n","            it.\n","            Indices can be obtained using [`BartTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n","            [`PreTrainedTokenizer.__call__`] for details.\n","            [What are input IDs?](../glossary#input-ids)\n","        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n","            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n","            - 1 for tokens that are **not masked**,\n","            - 0 for tokens that are **masked**.\n","            [What are attention masks?](../glossary#attention-mask)\n","        decoder_input_ids (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`, *optional*):\n","            Indices of decoder input sequence tokens in the vocabulary.\n","            Indices can be obtained using [`BartTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n","            [`PreTrainedTokenizer.__call__`] for details.\n","            [What are decoder input IDs?](../glossary#decoder-input-ids)\n","            Bart uses the `eos_token_id` as the starting token for `decoder_input_ids` generation. If `past_key_values`\n","            is used, optionally only the last `decoder_input_ids` have to be input (see `past_key_values`).\n","            For translation and summarization training, `decoder_input_ids` should be provided. If no\n","            `decoder_input_ids` is provided, the model will create this tensor by shifting the `input_ids` to the right\n","            for denoising pre-training following the paper.\n","        decoder_attention_mask (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`, *optional*):\n","            Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`. Causal mask will also\n","            be used by default.\n","            If you want to change padding behavior, you should read [`modeling_bart._prepare_decoder_inputs`] and\n","            modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more information\n","            on the default strategy.\n","        head_mask (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`, *optional*):\n","            Mask to nullify selected heads of the attention modules in the encoder. Mask values selected in `[0, 1]`:\n","            - 1 indicates the head is **not masked**,\n","            - 0 indicates the head is **masked**.\n","        decoder_head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n","            Mask to nullify selected heads of the attention modules in the decoder. Mask values selected in `[0, 1]`:\n","            - 1 indicates the head is **not masked**,\n","            - 0 indicates the head is **masked**.\n","        cross_attn_head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n","            Mask to nullify selected heads of the cross-attention modules in the decoder. Mask values selected in `[0,\n","            1]`:\n","            - 1 indicates the head is **not masked**,\n","            - 0 indicates the head is **masked**.\n","        encoder_outputs (`tuple(tuple(torch.FloatTensor)`, *optional*):\n","            Tuple consists of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)\n","            `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) is a sequence of\n","            hidden-states at the output of the last layer of the encoder. Used in the cross-attention of the decoder.\n","        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n","            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n","            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n","            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n","            Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n","            blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n","            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n","            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n","            ``decoder_input_ids``` of shape `(batch_size, sequence_length)`. inputs_embeds (`torch.FloatTensor` of\n","            shape `(batch_size, sequence_length, hidden_size)`, *optional*): Optionally, instead of passing `input_ids`\n","            you can choose to directly pass an embedded representation. This is useful if you want more control over\n","            how to convert `input_ids` indices into associated vectors than the model's internal embedding lookup\n","            matrix.\n","        decoder_inputs_embeds (`torch.FloatTensor` of shape `(batch_size, target_sequence_length, hidden_size)`, *optional*):\n","            Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded\n","            representation. If `past_key_values` is used, optionally only the last `decoder_inputs_embeds` have to be\n","            input (see `past_key_values`). This is useful if you want more control over how to convert\n","            `decoder_input_ids` indices into associated vectors than the model's internal embedding lookup matrix.\n","            If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds` takes the value\n","            of `inputs_embeds`.\n","        use_cache (`bool`, *optional*):\n","            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n","            `past_key_values`).\n","        output_attentions (`bool`, *optional*):\n","            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n","            tensors for more detail.\n","        output_hidden_states (`bool`, *optional*):\n","            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n","            more detail.\n","        return_dict (`bool`, *optional*):\n","            Whether or not to return a [`~file_utils.ModelOutput`] instead of a plain tuple.\n","\"\"\"\n","\n","\n","class BartEncoder(BartPretrainedModel):\n","    \"\"\"\n","    Transformer encoder consisting of *config.encoder_layers* self attention layers. Each layer is a\n","    [`BartEncoderLayer`].\n","    Args:\n","        config: BartConfig\n","        embed_tokens (nn.Embedding): output embedding\n","    \"\"\"\n","\n","    def __init__(self, config: BartConfig, embed_tokens: Optional[nn.Embedding] = None):\n","        super().__init__(config)\n","\n","        self.dropout = config.dropout\n","        self.layerdrop = config.encoder_layerdrop\n","\n","        embed_dim = config.d_model\n","        self.padding_idx = config.pad_token_id\n","        self.max_source_positions = config.max_position_embeddings\n","        self.embed_scale = math.sqrt(embed_dim) if config.scale_embedding else 1.0\n","\n","        if embed_tokens is not None:\n","            self.embed_tokens = embed_tokens\n","        else:\n","            self.embed_tokens = nn.Embedding(config.vocab_size, embed_dim, self.padding_idx)\n","\n","        self.embed_positions = BartLearnedPositionalEmbedding(\n","            config.max_position_embeddings,\n","            embed_dim,\n","        )\n","        self.layers = nn.ModuleList([BartEncoderLayer(config) for _ in range(config.encoder_layers)])\n","        self.layernorm_embedding = nn.LayerNorm(embed_dim)\n","\n","        self.gradient_checkpointing = False\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def get_input_embeddings(self):\n","        return self.embed_tokens\n","\n","    def set_input_embeddings(self, value):\n","        self.embed_tokens = value\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        Args:\n","            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n","                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n","                provide it.\n","                Indices can be obtained using [`BartTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n","                [`PreTrainedTokenizer.__call__`] for details.\n","                [What are input IDs?](../glossary#input-ids)\n","            attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n","                Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n","                - 1 for tokens that are **not masked**,\n","                - 0 for tokens that are **masked**.\n","                [What are attention masks?](../glossary#attention-mask)\n","            head_mask (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`, *optional*):\n","                Mask to nullify selected heads of the attention modules. Mask values selected in `[0, 1]`:\n","                - 1 indicates the head is **not masked**,\n","                - 0 indicates the head is **masked**.\n","            inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n","                Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.\n","                This is useful if you want more control over how to convert `input_ids` indices into associated vectors\n","                than the model's internal embedding lookup matrix.\n","            output_attentions (`bool`, *optional*):\n","                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n","                returned tensors for more detail.\n","            output_hidden_states (`bool`, *optional*):\n","                Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors\n","                for more detail.\n","            return_dict (`bool`, *optional*):\n","                Whether or not to return a [`~file_utils.ModelOutput`] instead of a plain tuple.\n","        \"\"\"\n","        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n","        output_hidden_states = (\n","            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n","        )\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        # retrieve input_ids and inputs_embeds\n","        if input_ids is not None and inputs_embeds is not None:\n","            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n","        elif input_ids is not None:\n","            input_shape = input_ids.size()\n","            input_ids = input_ids.view(-1, input_shape[-1])\n","        elif inputs_embeds is not None:\n","            input_shape = inputs_embeds.size()[:-1]\n","        else:\n","            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n","\n","        if inputs_embeds is None:\n","            inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n","\n","        embed_pos = self.embed_positions(input_shape)\n","\n","        hidden_states = inputs_embeds + embed_pos\n","        hidden_states = self.layernorm_embedding(hidden_states)\n","        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n","\n","        # expand attention_mask\n","        if attention_mask is not None:\n","            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n","            attention_mask = _expand_mask(attention_mask, inputs_embeds.dtype)\n","\n","        encoder_states = () if output_hidden_states else None\n","        all_attentions = () if output_attentions else None\n","\n","        # check if head_mask has a correct number of layers specified if desired\n","        if head_mask is not None:\n","            if head_mask.size()[0] != (len(self.layers)):\n","                raise ValueError(\n","                    f\"The head_mask should be specified for {len(self.layers)} layers, but it is for {head_mask.size()[0]}.\"\n","                )\n","\n","        for idx, encoder_layer in enumerate(self.layers):\n","            if output_hidden_states:\n","                encoder_states = encoder_states + (hidden_states,)\n","            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n","            dropout_probability = random.uniform(0, 1)\n","            if self.training and (dropout_probability < self.layerdrop):  # skip the layer\n","                layer_outputs = (None, None)\n","            else:\n","                if self.gradient_checkpointing and self.training:\n","\n","                    def create_custom_forward(module):\n","                        def custom_forward(*inputs):\n","                            return module(*inputs, output_attentions)\n","\n","                        return custom_forward\n","\n","                    layer_outputs = torch.utils.checkpoint.checkpoint(\n","                        create_custom_forward(encoder_layer),\n","                        hidden_states,\n","                        attention_mask,\n","                        (head_mask[idx] if head_mask is not None else None),\n","                    )\n","                else:\n","                    layer_outputs = encoder_layer(\n","                        hidden_states,\n","                        attention_mask,\n","                        layer_head_mask=(head_mask[idx] if head_mask is not None else None),\n","                        output_attentions=output_attentions,\n","                    )\n","\n","                hidden_states = layer_outputs[0]\n","\n","            if output_attentions:\n","                all_attentions = all_attentions + (layer_outputs[1],)\n","\n","        if output_hidden_states:\n","            encoder_states = encoder_states + (hidden_states,)\n","\n","        if not return_dict:\n","            return tuple(v for v in [hidden_states, encoder_states, all_attentions] if v is not None)\n","        return BaseModelOutput(\n","            last_hidden_state=hidden_states, hidden_states=encoder_states, attentions=all_attentions\n","        )\n","\n","\n","class BartDecoder(BartPretrainedModel):\n","    \"\"\"\n","    Transformer decoder consisting of *config.decoder_layers* layers. Each layer is a [`BartDecoderLayer`]\n","    Args:\n","        config: BartConfig\n","        embed_tokens (nn.Embedding): output embedding\n","    \"\"\"\n","\n","    def __init__(self, config: BartConfig, embed_tokens: Optional[nn.Embedding] = None):\n","        super().__init__(config)\n","        self.dropout = config.dropout\n","        self.layerdrop = config.decoder_layerdrop\n","        self.padding_idx = config.pad_token_id\n","        self.max_target_positions = config.max_position_embeddings\n","        self.embed_scale = math.sqrt(config.d_model) if config.scale_embedding else 1.0\n","\n","        if embed_tokens is not None:\n","            self.embed_tokens = embed_tokens\n","        else:\n","            self.embed_tokens = nn.Embedding(config.vocab_size, config.d_model, self.padding_idx)\n","\n","        self.embed_positions = BartLearnedPositionalEmbedding(\n","            config.max_position_embeddings,\n","            config.d_model,\n","        )\n","        self.layers = nn.ModuleList([BartDecoderLayer(config) for _ in range(config.decoder_layers)])\n","        self.layernorm_embedding = nn.LayerNorm(config.d_model)\n","        self.gradient_checkpointing = False\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def get_input_embeddings(self):\n","        return self.embed_tokens\n","\n","    def set_input_embeddings(self, value):\n","        self.embed_tokens = value\n","\n","    def _prepare_decoder_attention_mask(self, attention_mask, input_shape, inputs_embeds, past_key_values_length):\n","        # create causal mask\n","        # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n","        combined_attention_mask = None\n","        if input_shape[-1] > 1:\n","            combined_attention_mask = _make_causal_mask(\n","                input_shape, inputs_embeds.dtype, past_key_values_length=past_key_values_length\n","            ).to(self.device)\n","\n","        if attention_mask is not None:\n","            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n","            expanded_attn_mask = _expand_mask(attention_mask, inputs_embeds.dtype, tgt_len=input_shape[-1])\n","            combined_attention_mask = (\n","                expanded_attn_mask if combined_attention_mask is None else expanded_attn_mask + combined_attention_mask\n","            )\n","\n","        return combined_attention_mask\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        encoder_hidden_states=None,\n","        encoder_attention_mask=None,\n","        head_mask=None,\n","        cross_attn_head_mask=None,\n","        past_key_values=None,\n","        inputs_embeds=None,\n","        use_cache=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        Args:\n","            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n","                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n","                provide it.\n","                Indices can be obtained using [`BartTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n","                [`PreTrainedTokenizer.__call__`] for details.\n","                [What are input IDs?](../glossary#input-ids)\n","            attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n","                Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n","                - 1 for tokens that are **not masked**,\n","                - 0 for tokens that are **masked**.\n","                [What are attention masks?](../glossary#attention-mask)\n","            encoder_hidden_states (`torch.FloatTensor` of shape `(batch_size, encoder_sequence_length, hidden_size)`, *optional*):\n","                Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention\n","                of the decoder.\n","            encoder_attention_mask (`torch.LongTensor` of shape `(batch_size, encoder_sequence_length)`, *optional*):\n","                Mask to avoid performing cross-attention on padding tokens indices of encoder input_ids. Mask values\n","                selected in `[0, 1]`:\n","                - 1 for tokens that are **not masked**,\n","                - 0 for tokens that are **masked**.\n","                [What are attention masks?](../glossary#attention-mask)\n","            head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n","                Mask to nullify selected heads of the attention modules. Mask values selected in `[0, 1]`:\n","                - 1 indicates the head is **not masked**,\n","                - 0 indicates the head is **masked**.\n","            cross_attn_head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n","                Mask to nullify selected heads of the cross-attention modules in the decoder to avoid performing\n","                cross-attention on hidden heads. Mask values selected in `[0, 1]`:\n","                - 1 indicates the head is **not masked**,\n","                - 0 indicates the head is **masked**.\n","            past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n","                Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of\n","                shape `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of\n","                shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n","                Contains pre-computed hidden-states (key and values in the self-attention blocks and in the\n","                cross-attention blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n","                If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those\n","                that don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of\n","                all ``decoder_input_ids``` of shape `(batch_size, sequence_length)`. inputs_embeds (`torch.FloatTensor`\n","                of shape `(batch_size, sequence_length, hidden_size)`, *optional*): Optionally, instead of passing\n","                `input_ids` you can choose to directly pass an embedded representation. This is useful if you want more\n","                control over how to convert `input_ids` indices into associated vectors than the model's internal\n","                embedding lookup matrix.\n","            output_attentions (`bool`, *optional*):\n","                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n","                returned tensors for more detail.\n","            output_hidden_states (`bool`, *optional*):\n","                Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors\n","                for more detail.\n","            return_dict (`bool`, *optional*):\n","                Whether or not to return a [`~file_utils.ModelOutput`] instead of a plain tuple.\n","        \"\"\"\n","        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n","        output_hidden_states = (\n","            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n","        )\n","        use_cache = use_cache if use_cache is not None else self.config.use_cache\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        # retrieve input_ids and inputs_embeds\n","        if input_ids is not None and inputs_embeds is not None:\n","            raise ValueError(\"You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\")\n","        elif input_ids is not None:\n","            input_shape = input_ids.size()\n","            input_ids = input_ids.view(-1, input_shape[-1])\n","        elif inputs_embeds is not None:\n","            input_shape = inputs_embeds.size()[:-1]\n","        else:\n","            raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n","\n","        # past_key_values_length\n","        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n","\n","        if inputs_embeds is None:\n","            inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n","\n","        attention_mask = self._prepare_decoder_attention_mask(\n","            attention_mask, input_shape, inputs_embeds, past_key_values_length\n","        )\n","\n","        # expand encoder attention mask\n","        if encoder_hidden_states is not None and encoder_attention_mask is not None:\n","            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n","            encoder_attention_mask = _expand_mask(encoder_attention_mask, inputs_embeds.dtype, tgt_len=input_shape[-1])\n","\n","        # embed positions\n","        positions = self.embed_positions(input_shape, past_key_values_length)\n","\n","        hidden_states = inputs_embeds + positions\n","        hidden_states = self.layernorm_embedding(hidden_states)\n","\n","        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n","\n","        # decoder layers\n","        all_hidden_states = () if output_hidden_states else None\n","        all_self_attns = () if output_attentions else None\n","        all_cross_attentions = () if (output_attentions and encoder_hidden_states is not None) else None\n","        next_decoder_cache = () if use_cache else None\n","\n","        # check if head_mask/cross_attn_head_mask has a correct number of layers specified if desired\n","        for attn_mask, mask_name in zip([head_mask, cross_attn_head_mask], [\"head_mask\", \"cross_attn_head_mask\"]):\n","            if attn_mask is not None:\n","                if attn_mask.size()[0] != (len(self.layers)):\n","                    raise ValueError(\n","                        \"The `{mask_name}` should be specified for {len(self.layers)} layers, but it is for {head_mask.size()[0]}.\"\n","                    )\n","\n","        for idx, decoder_layer in enumerate(self.layers):\n","            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n","            if output_hidden_states:\n","                all_hidden_states += (hidden_states,)\n","            dropout_probability = random.uniform(0, 1)\n","            if self.training and (dropout_probability < self.layerdrop):\n","                continue\n","\n","            past_key_value = past_key_values[idx] if past_key_values is not None else None\n","\n","            if self.gradient_checkpointing and self.training:\n","\n","                if use_cache:\n","                    logger.warning(\n","                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n","                    )\n","                    use_cache = False\n","\n","                def create_custom_forward(module):\n","                    def custom_forward(*inputs):\n","                        # None for past_key_value\n","                        return module(*inputs, output_attentions, use_cache)\n","\n","                    return custom_forward\n","\n","                layer_outputs = torch.utils.checkpoint.checkpoint(\n","                    create_custom_forward(decoder_layer),\n","                    hidden_states,\n","                    attention_mask,\n","                    encoder_hidden_states,\n","                    encoder_attention_mask,\n","                    head_mask[idx] if head_mask is not None else None,\n","                    cross_attn_head_mask[idx] if cross_attn_head_mask is not None else None,\n","                    None,\n","                )\n","            else:\n","\n","                layer_outputs = decoder_layer(\n","                    hidden_states,\n","                    attention_mask=attention_mask,\n","                    encoder_hidden_states=encoder_hidden_states,\n","                    encoder_attention_mask=encoder_attention_mask,\n","                    layer_head_mask=(head_mask[idx] if head_mask is not None else None),\n","                    cross_attn_layer_head_mask=(\n","                        cross_attn_head_mask[idx] if cross_attn_head_mask is not None else None\n","                    ),\n","                    past_key_value=past_key_value,\n","                    output_attentions=output_attentions,\n","                    use_cache=use_cache,\n","                )\n","            hidden_states = layer_outputs[0]\n","\n","            if use_cache:\n","                next_decoder_cache += (layer_outputs[3 if output_attentions else 1],)\n","\n","            if output_attentions:\n","                all_self_attns += (layer_outputs[1],)\n","\n","                if encoder_hidden_states is not None:\n","                    all_cross_attentions += (layer_outputs[2],)\n","\n","        # add hidden states from the last decoder layer\n","        if output_hidden_states:\n","            all_hidden_states += (hidden_states,)\n","\n","        next_cache = next_decoder_cache if use_cache else None\n","        if not return_dict:\n","            return tuple(\n","                v\n","                for v in [hidden_states, next_cache, all_hidden_states, all_self_attns, all_cross_attentions]\n","                if v is not None\n","            )\n","        return BaseModelOutputWithPastAndCrossAttentions(\n","            last_hidden_state=hidden_states,\n","            past_key_values=next_cache,\n","            hidden_states=all_hidden_states,\n","            attentions=all_self_attns,\n","            cross_attentions=all_cross_attentions,\n","        )\n","\n","\n","@add_start_docstrings(\n","    \"The bare BART Model outputting raw hidden-states without any specific head on top.\",\n","    BART_START_DOCSTRING,\n",")\n","class BartModel(BartPretrainedModel):\n","    def __init__(self, config: BartConfig):\n","        super().__init__(config)\n","\n","        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n","        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n","\n","        self.encoder = BartEncoder(config, self.shared)\n","        self.decoder = BartDecoder(config, self.shared)\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def get_input_embeddings(self):\n","        return self.shared\n","\n","    def set_input_embeddings(self, value):\n","        self.shared = value\n","        self.encoder.embed_tokens = self.shared\n","        self.decoder.embed_tokens = self.shared\n","\n","    def get_encoder(self):\n","        return self.encoder\n","\n","    def get_decoder(self):\n","        return self.decoder\n","\n","    @add_start_docstrings_to_model_forward(BART_INPUTS_DOCSTRING)\n","    @add_code_sample_docstrings(\n","        processor_class=_TOKENIZER_FOR_DOC,\n","        checkpoint=_CHECKPOINT_FOR_DOC,\n","        output_type=Seq2SeqModelOutput,\n","        config_class=_CONFIG_FOR_DOC,\n","    )\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        decoder_input_ids=None,\n","        decoder_attention_mask=None,\n","        head_mask=None,\n","        decoder_head_mask=None,\n","        cross_attn_head_mask=None,\n","        encoder_outputs=None,\n","        past_key_values=None,\n","        inputs_embeds=None,\n","        decoder_inputs_embeds=None,\n","        use_cache=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","\n","        # different to other models, Bart automatically creates decoder_input_ids from\n","        # input_ids if no decoder_input_ids are provided\n","        if decoder_input_ids is None and decoder_inputs_embeds is None:\n","            if input_ids is None:\n","                raise ValueError(\n","                    \"If no `decoder_input_ids` or `decoder_inputs_embeds` are \"\n","                    \"passed, `input_ids` cannot be `None`. Please pass either \"\n","                    \"`input_ids` or `decoder_input_ids` or `decoder_inputs_embeds`.\"\n","                )\n","\n","            decoder_input_ids = shift_tokens_right(\n","                input_ids, self.config.pad_token_id, self.config.decoder_start_token_id\n","            )\n","\n","        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n","        output_hidden_states = (\n","            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n","        )\n","        use_cache = use_cache if use_cache is not None else self.config.use_cache\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        if encoder_outputs is None:\n","            encoder_outputs = self.encoder(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                head_mask=head_mask,\n","                inputs_embeds=inputs_embeds,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict,\n","            )\n","        # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\n","        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n","            encoder_outputs = BaseModelOutput(\n","                last_hidden_state=encoder_outputs[0],\n","                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n","                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n","            )\n","\n","        # decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\n","        decoder_outputs = self.decoder(\n","            input_ids=decoder_input_ids,\n","            attention_mask=decoder_attention_mask,\n","            encoder_hidden_states=encoder_outputs[0],\n","            encoder_attention_mask=attention_mask,\n","            head_mask=decoder_head_mask,\n","            cross_attn_head_mask=cross_attn_head_mask,\n","            past_key_values=past_key_values,\n","            inputs_embeds=decoder_inputs_embeds,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        if not return_dict:\n","            return decoder_outputs + encoder_outputs\n","\n","        return Seq2SeqModelOutput(\n","            last_hidden_state=decoder_outputs.last_hidden_state,\n","            past_key_values=decoder_outputs.past_key_values,\n","            decoder_hidden_states=decoder_outputs.hidden_states,\n","            decoder_attentions=decoder_outputs.attentions,\n","            cross_attentions=decoder_outputs.cross_attentions,\n","            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n","            encoder_hidden_states=encoder_outputs.hidden_states,\n","            encoder_attentions=encoder_outputs.attentions,\n","        )\n","```"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyObCEirTQsIKSzHWKwf1G9m","collapsed_sections":["XfahULH_8nv3","4u5or6kb4qE6","N5M6I0ySvfsO","x6pV_73CrXUS","rhOX8jeBi8AI","cpWMzdN42Clh"],"mount_file_id":"1GZSIOUwiPq-S9xXy6PEiWIdDGNnlxqQl","provenance":[]},"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.8"},"vscode":{"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"}}},"nbformat":4,"nbformat_minor":0}
