{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppijbb/NLP_study/blob/main/bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxdwEB0QeIKn",
        "outputId": "f0cd06e8-3684-4089-8a4d-9b3b21144d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=9c6bcbad4de1ed3338fbfd356bcc91ad4264dd8e9d90021a30e5610667e732e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rKyRIgJeN7g",
        "outputId": "74cc3357-9282-404f-9c43-7384bdf89ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = \"/content/drive/My Drive/Colab_Notebooks/data/transformer-evolution\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "arGquipReTbf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from random import random, randrange, randint, shuffle, choice\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joUUnASVei4w",
        "outputId": "8697cff0-b06f-4987-8be0-59d75a6d8ceb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3MZvoqNeeklv"
      },
      "outputs": [],
      "source": [
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDkXl0Uwembg",
        "outputId": "1786dad3-1191-4845-ba5b-5df48a139d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ]
        }
      ],
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_seg_type\": 2,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "92B4iT58eotH"
      },
      "outputs": [],
      "source": [
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2]) \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2]) \n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "# attention pad mask\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "# attention decoder mask\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) \n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "# scale dot product attention \n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "# multi head attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "# feed forward\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MFtL12bBersH"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        return ffn_outputs, attn_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U5QhGQPGetwX"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        self.pos_emb = nn.Embedding(self.config.n_enc_seq + 1, self.config.d_hidn)\n",
        "        self.seg_emb = nn.Embedding(self.config.n_seg_type, self.config.d_hidn)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)  + self.seg_emb(segments)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        return outputs, attn_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sEQfRpBdevG3"
      },
      "outputs": [],
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "\n",
        "        self.linear = nn.Linear(config.d_hidn, config.d_hidn)\n",
        "        self.activation = torch.tanh\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        outputs, self_attn_probs = self.encoder(inputs, segments)\n",
        "        outputs_cls = outputs[:, 0].contiguous()\n",
        "        outputs_cls = self.linear(outputs_cls)\n",
        "        outputs_cls = self.activation(outputs_cls)\n",
        "        return outputs, outputs_cls, self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GZ3oxfcsexVX"
      },
      "outputs": [],
      "source": [
        "class BERTPretrain(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BERT(self.config)\n",
        "        self.projection_cls = nn.Linear(self.config.d_hidn, 2, bias=False)\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_enc_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.bert.encoder.enc_emb.weight\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\n",
        "        logits_cls = self.projection_cls(outputs_cls)\n",
        "        logits_lm = self.projection_lm(outputs)\n",
        "        return logits_cls, logits_lm, attn_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a-kWlRceeyjf"
      },
      "outputs": [],
      "source": [
        "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
        "    cand_idx = []\n",
        "    for (i, token) in enumerate(tokens):\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
        "            continue\n",
        "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "            cand_idx[-1].append(i)\n",
        "        else:\n",
        "            cand_idx.append([i])\n",
        "    shuffle(cand_idx)\n",
        "\n",
        "    mask_lms = []\n",
        "    for index_set in cand_idx:\n",
        "        if len(mask_lms) >= mask_cnt:\n",
        "            break\n",
        "        if len(mask_lms) + len(index_set) > mask_cnt:\n",
        "            continue\n",
        "        for index in index_set:\n",
        "            masked_token = None\n",
        "            if random() < 0.8: \n",
        "                masked_token = \"[MASK]\"\n",
        "            else:\n",
        "                if random() < 0.5: \n",
        "                    masked_token = tokens[index]\n",
        "                else:\n",
        "                    masked_token = choice(vocab_list)\n",
        "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
        "            tokens[index] = masked_token\n",
        "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
        "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
        "    mask_label = [p[\"label\"] for p in mask_lms]\n",
        "\n",
        "    return tokens, mask_idx, mask_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KqQKO9BWe1Qm"
      },
      "outputs": [],
      "source": [
        "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_seq:\n",
        "            break\n",
        "\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            del tokens_a[0]\n",
        "        else:\n",
        "            tokens_b.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K5l4gSP4e3Co"
      },
      "outputs": [],
      "source": [
        "def create_pretrain_instances(docs, doc_idx, doc, n_seq, mask_prob, vocab_list):\n",
        "    max_seq = n_seq - 3\n",
        "    tgt_seq = max_seq\n",
        "    \n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i])\n",
        "        current_length += len(doc[i])\n",
        "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
        "            if 0 < len(current_chunk):\n",
        "                a_end = 1\n",
        "                if 1 < len(current_chunk):\n",
        "                    a_end = randrange(1, len(current_chunk))\n",
        "                tokens_a = []\n",
        "                for j in range(a_end):\n",
        "                    tokens_a.extend(current_chunk[j])\n",
        "                \n",
        "                tokens_b = []\n",
        "                if len(current_chunk) == 1 or random() < 0.5:\n",
        "                    is_next = 0\n",
        "                    tokens_b_len = tgt_seq - len(tokens_a)\n",
        "                    random_doc_idx = doc_idx\n",
        "                    while doc_idx == random_doc_idx:\n",
        "                        random_doc_idx = randrange(0, len(docs))\n",
        "                    random_doc = docs[random_doc_idx]\n",
        "\n",
        "                    random_start = randrange(0, len(random_doc))\n",
        "                    for j in range(random_start, len(random_doc)):\n",
        "                        tokens_b.extend(random_doc[j])\n",
        "                else:\n",
        "                    is_next = 1\n",
        "                    for j in range(a_end, len(current_chunk)):\n",
        "                        tokens_b.extend(current_chunk[j])\n",
        "\n",
        "                trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "                assert 0 < len(tokens_a)\n",
        "                assert 0 < len(tokens_b)\n",
        "\n",
        "                tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "                segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "                tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
        "\n",
        "                instance = {\n",
        "                    \"tokens\": tokens,\n",
        "                    \"segment\": segment,\n",
        "                    \"is_next\": is_next,\n",
        "                    \"mask_idx\": mask_idx,\n",
        "                    \"mask_label\": mask_label\n",
        "                }\n",
        "                instances.append(instance)\n",
        "\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5gRfipxye49I"
      },
      "outputs": [],
      "source": [
        "def make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob):\n",
        "    vocab_list = []\n",
        "    for id in range(vocab.get_piece_size()):\n",
        "        if not vocab.is_unknown(id):\n",
        "            vocab_list.append(vocab.id_to_piece(id))\n",
        "\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "    \n",
        "    docs = []\n",
        "    with open(in_file, \"r\") as f:\n",
        "        doc = []\n",
        "        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if 0 < len(doc):\n",
        "                        docs.append(doc)\n",
        "                        doc = []\n",
        "                        if 100000 < len(docs): break\n",
        "                else:\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "                pbar.update(1)\n",
        "        if doc:\n",
        "            docs.append(doc)\n",
        "\n",
        "    for index in range(count):\n",
        "        output = out_file.format(index)\n",
        "        if os.path.isfile(output): continue\n",
        "\n",
        "        with open(output, \"w\") as out_f:\n",
        "            with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n",
        "                for i, doc in enumerate(docs):\n",
        "                    instances = create_pretrain_instances(docs, i, doc, n_seq, mask_prob, vocab_list)\n",
        "                    for instance in instances:\n",
        "                        out_f.write(json.dumps(instance))\n",
        "                        out_f.write(\"\\n\")\n",
        "                    pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "f6963d22a26c4eac80465e7b1f025974",
            "a1f01ee6d8c045e18444f0032410e6c4",
            "c9a24bb9fe2047119d3f9a4fb10f654e",
            "4c8a042fb54340d4882330ce6dde4b2e",
            "308d62a128ad4594b97cda16d569ff00",
            "0446d728714244f8a9780fe6885a0b1e",
            "7b8fb91d4d944814a8665338b66231e8",
            "527eda2565204d0dae4ca69819149041"
          ]
        },
        "id": "iNeS6tSXe7BI",
        "outputId": "0f91b60d-30dc-4216-e53b-aaaef8f324c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6963d22a26c4eac80465e7b1f025974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Loading', max=3724301.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "in_file = f\"{data_dir}/kowiki.txt\"\n",
        "out_file = f\"{data_dir}/kowiki_bert\" + \"_{}.json\"\n",
        "count = 1\n",
        "n_seq = 256\n",
        "mask_prob = 0.15\n",
        "make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PuNdMwJ-e8mn"
      },
      "outputs": [],
      "source": [
        "class PretrainDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels_cls = []\n",
        "        self.labels_lm = []\n",
        "        self.sentences = []\n",
        "        self.segments = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                instance = json.loads(line)\n",
        "                self.labels_cls.append(instance[\"is_next\"])\n",
        "                sentences = [vocab.piece_to_id(p) for p in instance[\"tokens\"]]\n",
        "                self.sentences.append(sentences)\n",
        "                self.segments.append(instance[\"segment\"])\n",
        "                mask_idx = np.array(instance[\"mask_idx\"], dtype=np.int)\n",
        "                mask_label = np.array([vocab.piece_to_id(p) for p in instance[\"mask_label\"]], dtype=np.int)\n",
        "                label_lm = np.full(len(sentences), dtype=np.int, fill_value=-1)\n",
        "                label_lm[mask_idx] = mask_label\n",
        "                self.labels_lm.append(label_lm)\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels_cls) == len(self.labels_lm)\n",
        "        assert len(self.labels_cls) == len(self.sentences)\n",
        "        assert len(self.labels_cls) == len(self.segments)\n",
        "        return len(self.labels_cls)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels_cls[item]),\n",
        "                torch.tensor(self.labels_lm[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor(self.segments[item]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TaqUG5HZGUgd"
      },
      "outputs": [],
      "source": [
        "def pretrin_collate_fn(inputs):\n",
        "    labels_cls, labels_lm, inputs, segments = list(zip(*inputs))\n",
        "\n",
        "    labels_lm = torch.nn.utils.rnn.pad_sequence(labels_lm, batch_first=True, padding_value=-1)\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels_cls, dim=0),\n",
        "        labels_lm,\n",
        "        inputs,\n",
        "        segments\n",
        "    ]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXfTguFiGXBa",
        "outputId": "8247f088-481f-49ab-f6a8-70d69eab8adb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Colab_Notebooks/data/transformer-evolution/kowiki_bert_0.json: 100%|██████████| 239857/239857 [01:29<00:00, 2677.88 lines/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_bert_0.json\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p4uy-jSYGY-y"
      },
      "outputs": [],
      "source": [
        "def train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels_cls, labels_lm, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, segments)\n",
        "            logits_cls, logits_lm = outputs[0], outputs[1]\n",
        "\n",
        "            loss_cls = criterion_cls(logits_cls, labels_cls)\n",
        "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
        "            loss = loss_cls + loss_lm\n",
        "\n",
        "            loss_val = loss_lm.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfD0Dl_nGaxS",
        "outputId": "caede1ea-34a3-4139-b6f1-0d7b42ce9251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cpu')}\n"
          ]
        }
      ],
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "C0LUvoWBGcTC",
        "outputId": "cfc7ff11-9e43-43b6-87cb-5ce60069c927"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2e99f0c9c76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_pretrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_pretrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-299b8bbf3686>\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    136\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "model = BERTPretrain(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_bert_pretrain.pth\"\n",
        "best_epoch, best_loss = 0, 0\n",
        "if os.path.isfile(save_pretrain):\n",
        "    best_epoch, best_loss = model.bert.load(save_pretrain)\n",
        "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
        "    best_epoch += 1\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
        "criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "offset = best_epoch\n",
        "for step in range(n_epoch):\n",
        "    epoch = step + offset\n",
        "    if 0 < step:\n",
        "        del train_loader\n",
        "        dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_bert_{epoch % count}.json\")\n",
        "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)\n",
        "\n",
        "    loss = train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader)\n",
        "    losses.append(loss)\n",
        "    model.bert.save(epoch, loss, save_pretrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "-LDOYbzaGewy",
        "outputId": "c6e2875d-a50b-46e6-d8a3-e4a0ac0153c8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ecc18e71bd64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m }\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        }
      ],
      "source": [
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6b7yugZGgoa",
        "outputId": "841c9c9b-c139-471d-df15-adec170fca05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Gg4l79ChGnkK"
      },
      "outputs": [],
      "source": [
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_BoGAjgGpii",
        "outputId": "f81e159c-34e3-4bd1-895d-882097a1f911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ]
        }
      ],
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_seg_type\": 2,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Revx6PdrGq97"
      },
      "outputs": [],
      "source": [
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2]) \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2]) \n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "# attention pad mask\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)\n",
        "    return pad_attn_mask\n",
        "\n",
        "# attention decoder mask\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1)\n",
        "    return subsequent_mask\n",
        "\n",
        "# scale dot product attention\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        return context, attn_prob\n",
        "\n",
        "# multi head attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        return output, attn_prob\n",
        "\n",
        "# feed forward\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bKokdo7nGuSp"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        return ffn_outputs, attn_prob\n",
        "\n",
        "# encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        self.pos_emb = nn.Embedding(self.config.n_enc_seq + 1, self.config.d_hidn)\n",
        "        self.seg_emb = nn.Embedding(self.config.n_seg_type, self.config.d_hidn)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)  + self.seg_emb(segments)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        return outputs, attn_probs\n",
        "\n",
        "# bert\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.encoder = Encoder(self.config)\n",
        "        self.linear = nn.Linear(config.d_hidn, config.d_hidn)\n",
        "        self.activation = torch.tanh\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        outputs, self_attn_probs = self.encoder(inputs, segments)\n",
        "        outputs_cls = outputs[:, 0].contiguous()\n",
        "        outputs_cls = self.linear(outputs_cls)\n",
        "        outputs_cls = self.activation(outputs_cls)\n",
        "        return outputs, outputs_cls, self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "w6QwfYsuGxmy"
      },
      "outputs": [],
      "source": [
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BERT(self.config)\n",
        "        self.projection_cls = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\n",
        "        logits_cls = self.projection_cls(outputs_cls)\n",
        "        return logits_cls, attn_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ppiT3sxRG0dq"
      },
      "outputs": [],
      "source": [
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "        self.segments = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=\"Loading Dataset\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"])\n",
        "                sentence = [vocab.piece_to_id(\"[CLS]\")] + [vocab.piece_to_id(p) for p in data[\"doc\"]] + [vocab.piece_to_id(\"[SEP]\")]\n",
        "                self.sentences.append(sentence)\n",
        "                self.segments.append([0] * len(sentence))\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        assert len(self.labels) == len(self.segments)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor(self.segments[item]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3RfhFr5yG21T"
      },
      "outputs": [],
      "source": [
        "def movie_collate_fn(inputs):\n",
        "    labels, inputs, segments = list(zip(*inputs))\n",
        "\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels, dim=0),\n",
        "        inputs,\n",
        "        segments,\n",
        "    ]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQGnztkcG4xq",
        "outputId": "85282694-6f47-4095-c480-db06733ef8e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading Dataset: 100%|██████████| 149995/149995 [00:08<00:00, 17363.54 lines/s]\n",
            "Loading Dataset: 100%|██████████| 49997/49997 [00:01<00:00, 25603.65 lines/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "AGc5uSaxG6IT"
      },
      "outputs": [],
      "source": [
        "def eval_epoch(config, model, data_loader):\n",
        "    matchs = []\n",
        "    model.eval()\n",
        "\n",
        "    n_word_total = 0\n",
        "    n_correct_total = 0\n",
        "    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, value in enumerate(data_loader):\n",
        "            labels, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            outputs = model(inputs, segments)\n",
        "            logits_cls = outputs[0]\n",
        "            _, indices = logits_cls.max(1)\n",
        "\n",
        "            match = torch.eq(indices, labels).detach()\n",
        "            matchs.extend(match.cpu())\n",
        "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
        "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DI2wKpu2G7wK"
      },
      "outputs": [],
      "source": [
        "def train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, segments)\n",
        "            logits_cls = outputs[0]\n",
        "\n",
        "            loss_cls = criterion_cls(logits_cls, labels)\n",
        "            loss = loss_cls\n",
        "\n",
        "            loss_val = loss_cls.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gph21wxG9dy",
        "outputId": "64ce1d2f-4177-4dee-e4ba-d7ceb6ec5cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cpu'), 'n_output': 2}\n"
          ]
        }
      ],
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config.n_output = 2\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pFzu6NJ6G-7K"
      },
      "outputs": [],
      "source": [
        "def train(model):\n",
        "    model.to(config.device)\n",
        "\n",
        "    criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_epoch, best_loss, best_score = 0, 0, 0\n",
        "    losses, scores = [], []\n",
        "    for epoch in range(n_epoch):\n",
        "        loss = train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader)\n",
        "        score = eval_epoch(config, model, test_loader)\n",
        "\n",
        "        losses.append(loss)\n",
        "        scores.append(score)\n",
        "\n",
        "        if best_score < score:\n",
        "            best_epoch, best_loss, best_score = epoch, loss, score\n",
        "    print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")\n",
        "    return losses, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnaXu79KHAYi",
        "outputId": "d76edd1f-a72c-438c-b018-20a38b3912eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train(0): 100%|██████████| 1172/1172 [3:08:22<00:00,  9.64s/it, Loss: 0.512 (0.522)]\n",
            "Valid: 100%|██████████| 391/391 [21:07<00:00,  3.24s/it, Acc: 0.766]\n",
            "Train(1): 100%|██████████| 1172/1172 [3:07:50<00:00,  9.62s/it, Loss: 0.375 (0.435)]\n",
            "Valid: 100%|██████████| 391/391 [21:07<00:00,  3.24s/it, Acc: 0.801]\n",
            "Train(2):   9%|▉         | 107/1172 [17:17<2:48:09,  9.47s/it, Loss: 0.414 (0.403)]"
          ]
        }
      ],
      "source": [
        "model = MovieClassification(config)\n",
        "\n",
        "losses_00, scores_00 = train(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKO2eE8PHDMy"
      },
      "outputs": [],
      "source": [
        "model = MovieClassification(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_bert_pretrain.pth\"\n",
        "model.bert.load(save_pretrain)\n",
        "\n",
        "losses_20, scores_20 = train(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1F4TojRHE4a"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"loss_00\": losses_00,\n",
        "    \"socre_00\": scores_00,\n",
        "    \"loss_20\": losses_20,\n",
        "    \"socre_20\": scores_20,\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(scores_00, label=\"score_00\")\n",
        "plt.plot(scores_20, label=\"score_20\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWU54wdnugI4sk4L8AUA7E",
      "include_colab_link": true,
      "mount_file_id": "18tXF_kEtaS2qyv2L7_TOeznef2pbv2jw",
      "name": "bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0446d728714244f8a9780fe6885a0b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308d62a128ad4594b97cda16d569ff00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "4c8a042fb54340d4882330ce6dde4b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_527eda2565204d0dae4ca69819149041",
            "placeholder": "​",
            "style": "IPY_MODEL_7b8fb91d4d944814a8665338b66231e8",
            "value": " 1039716/3724301 [02:15&lt;05:50, 7664.57it/s]"
          }
        },
        "527eda2565204d0dae4ca69819149041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b8fb91d4d944814a8665338b66231e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1f01ee6d8c045e18444f0032410e6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a24bb9fe2047119d3f9a4fb10f654e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "Loading:  28%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0446d728714244f8a9780fe6885a0b1e",
            "max": 3724301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_308d62a128ad4594b97cda16d569ff00",
            "value": 1039716
          }
        },
        "f6963d22a26c4eac80465e7b1f025974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9a24bb9fe2047119d3f9a4fb10f654e",
              "IPY_MODEL_4c8a042fb54340d4882330ce6dde4b2e"
            ],
            "layout": "IPY_MODEL_a1f01ee6d8c045e18444f0032410e6c4"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
